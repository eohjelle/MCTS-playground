{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to the root of the project\n",
    "import os \n",
    "os.chdir('..')\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "from applications.tic_tac_toe.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'loss',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        # Optimizer parameters\n",
    "        'learning_rate': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 0.00001,\n",
    "            'max': 0.1\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 0.00001,\n",
    "            'max': 0.1\n",
    "        },\n",
    "\n",
    "        # Model parameters\n",
    "        'attention_layers': {\n",
    "            'values': [1, 2, 3, 4]\n",
    "        },\n",
    "        'transformer_size': {\n",
    "            'values': ['tiny', 'small', 'medium', 'large', 'xlarge']\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.0, 0.1, 0.01, 0.001, 0.0001]\n",
    "        },\n",
    "        'norm_first': {\n",
    "            'values': [True, False]\n",
    "        },\n",
    "        'activation': {\n",
    "            'values': ['relu', 'gelu']\n",
    "        },\n",
    "\n",
    "        # Trainer parameters\n",
    "        'replay_buffer_max_size': {\n",
    "            'value': 10000\n",
    "        },\n",
    "        'value_softness': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.0,\n",
    "            'max': 1.0\n",
    "        },\n",
    "        'mask_illegal_moves': {\n",
    "            'values': [True, False]\n",
    "        },\n",
    "        'mask_value': {\n",
    "            'values': [-20.0, -15.0, -10.0, -5.0]\n",
    "        },\n",
    "\n",
    "        # Training parameters\n",
    "        'num_iterations': {\n",
    "            'value': 100\n",
    "        },\n",
    "        'games_per_iteration': {\n",
    "            'value': 10\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [128, 256, 512, 1024]\n",
    "        },\n",
    "        'steps_per_iteration': {\n",
    "            'value': 100\n",
    "        },\n",
    "        'num_simulations': {\n",
    "            'values': [100]\n",
    "        },\n",
    "        'checkpoint_frequency': {\n",
    "            'value': 20\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Transformer size mapping\n",
    "transformer_size_mapping = {\n",
    "    'tiny': { 'embed_dim': 4, 'num_heads': 1, 'feedforward_dim': 16 },\n",
    "    'small': { 'embed_dim': 8, 'num_heads': 2, 'feedforward_dim': 32 },\n",
    "    'medium': { 'embed_dim': 16, 'num_heads': 4, 'feedforward_dim': 64 },\n",
    "    'large': { 'embed_dim': 32, 'num_heads': 8, 'feedforward_dim': 128 },\n",
    "    'xlarge': { 'embed_dim': 64, 'num_heads': 16, 'feedforward_dim': 256 }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some default parameters\n",
    "\n",
    "from core.implementations.AlphaZero import AlphaZeroConfig\n",
    "\n",
    "# AlphaZero parameters\n",
    "alphazero_config = AlphaZeroConfig(\n",
    "    exploration_constant=1.0,\n",
    "    dirichlet_alpha=0.3,\n",
    "    dirichlet_epsilon=0.25,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "# AlphaZero evaluation parameters\n",
    "alphazero_eval_config = AlphaZeroConfig(\n",
    "    exploration_constant=1.0,\n",
    "    dirichlet_alpha=0.0,\n",
    "    dirichlet_epsilon=0.0,\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from applications.tic_tac_toe.transformer_model import TicTacToeTransformerInterface\n",
    "\n",
    "def sweep_agent():\n",
    "    with wandb.init(project='AlphaZero-TicTacToe') as run:\n",
    "        config = {\n",
    "            'model_type': 'transformer',\n",
    "            'model_params': {\n",
    "                'attention_layers': run.config.attention_layers,\n",
    "                **transformer_size_mapping[run.config.transformer_size]\n",
    "            },\n",
    "            'device': 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu',\n",
    "            'tree_search_params': alphazero_config,\n",
    "            'tree_search_eval_params': alphazero_eval_config,\n",
    "            'trainer_params': {\n",
    "                'replay_buffer_max_size': run.config.replay_buffer_max_size,\n",
    "                'value_softness': run.config.value_softness,\n",
    "                'mask_illegal_moves': run.config.mask_illegal_moves,\n",
    "                'mask_value': run.config.mask_value\n",
    "            },\n",
    "            'optimizer_params': {\n",
    "                'lr': run.config.learning_rate,\n",
    "                'betas': (0.9, 0.999),\n",
    "                'eps': 1e-8,\n",
    "                'weight_decay': run.config.weight_decay,\n",
    "                'amsgrad': False\n",
    "            },\n",
    "            'training_params': {\n",
    "                'num_iterations': run.config.num_iterations,\n",
    "                'games_per_iteration': run.config.games_per_iteration,\n",
    "                'batch_size': run.config.batch_size,\n",
    "                'steps_per_iteration': run.config.steps_per_iteration,\n",
    "                'num_simulations': run.config.num_simulations,\n",
    "                'checkpoint_frequency': run.config.checkpoint_frequency\n",
    "            }\n",
    "        }\n",
    "\n",
    "        model = TicTacToeTransformerInterface(\n",
    "            device=config['device'],\n",
    "            **config['model_params']\n",
    "        )\n",
    "\n",
    "        # Use training script\n",
    "        train(\n",
    "            config=config,\n",
    "            model=model,\n",
    "            use_wandb=True,\n",
    "            wandb_watch_params={\n",
    "                'watch': True,\n",
    "                'log': 'all',\n",
    "                'log_freq': 100,\n",
    "                'log_graph': True\n",
    "            },\n",
    "            wandb_run=run\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: z91b8lti\n",
      "Sweep URL: https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1tvknncm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007647649282292424\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.27162888872040936\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.005288860670490674\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meohjelle\u001b[0m (\u001b[33meigenway\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250228_222840-1tvknncm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1tvknncm' target=\"_blank\">dainty-sweep-1</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1tvknncm' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1tvknncm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 2.6434\n",
      "Average policy_loss: 1.8133\n",
      "Average value_loss: 0.8301\n",
      "Replay buffer size: 98\n",
      "Time taken: 6.7s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.8988\n",
      "Average policy_loss: 1.1526\n",
      "Average value_loss: 0.7461\n",
      "Replay buffer size: 188\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.4862\n",
      "Average policy_loss: 0.8457\n",
      "Average value_loss: 0.6405\n",
      "Replay buffer size: 282\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.4541\n",
      "Average policy_loss: 0.9220\n",
      "Average value_loss: 0.5321\n",
      "Replay buffer size: 376\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.3576\n",
      "Average policy_loss: 0.8601\n",
      "Average value_loss: 0.4975\n",
      "Replay buffer size: 468\n",
      "Time taken: 40.0s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.3005\n",
      "Average policy_loss: 0.8356\n",
      "Average value_loss: 0.4649\n",
      "Replay buffer size: 563\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.2257\n",
      "Average policy_loss: 0.8208\n",
      "Average value_loss: 0.4049\n",
      "Replay buffer size: 663\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.1924\n",
      "Average policy_loss: 0.8311\n",
      "Average value_loss: 0.3613\n",
      "Replay buffer size: 755\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.1650\n",
      "Average policy_loss: 0.8179\n",
      "Average value_loss: 0.3471\n",
      "Replay buffer size: 843\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.1409\n",
      "Average policy_loss: 0.8264\n",
      "Average value_loss: 0.3145\n",
      "Replay buffer size: 937\n",
      "Time taken: 38.8s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.1360\n",
      "Average policy_loss: 0.8282\n",
      "Average value_loss: 0.3078\n",
      "Replay buffer size: 1027\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.1234\n",
      "Average policy_loss: 0.8311\n",
      "Average value_loss: 0.2924\n",
      "Replay buffer size: 1112\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.1468\n",
      "Average policy_loss: 0.8386\n",
      "Average value_loss: 0.3082\n",
      "Replay buffer size: 1198\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.1266\n",
      "Average policy_loss: 0.8394\n",
      "Average value_loss: 0.2872\n",
      "Replay buffer size: 1278\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.1172\n",
      "Average policy_loss: 0.8393\n",
      "Average value_loss: 0.2779\n",
      "Replay buffer size: 1366\n",
      "Time taken: 39.2s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.1020\n",
      "Average policy_loss: 0.8441\n",
      "Average value_loss: 0.2579\n",
      "Replay buffer size: 1448\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.1210\n",
      "Average policy_loss: 0.8500\n",
      "Average value_loss: 0.2710\n",
      "Replay buffer size: 1530\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.1197\n",
      "Average policy_loss: 0.8485\n",
      "Average value_loss: 0.2711\n",
      "Replay buffer size: 1614\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.1353\n",
      "Average policy_loss: 0.8659\n",
      "Average value_loss: 0.2695\n",
      "Replay buffer size: 1699\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.1331\n",
      "Average policy_loss: 0.8681\n",
      "Average value_loss: 0.2650\n",
      "Replay buffer size: 1781\n",
      "Time taken: 44.2s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.1238\n",
      "Average policy_loss: 0.8632\n",
      "Average value_loss: 0.2606\n",
      "Replay buffer size: 1869\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.1287\n",
      "Average policy_loss: 0.8665\n",
      "Average value_loss: 0.2622\n",
      "Replay buffer size: 1952\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.1372\n",
      "Average policy_loss: 0.8765\n",
      "Average value_loss: 0.2607\n",
      "Replay buffer size: 2034\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.1440\n",
      "Average policy_loss: 0.8814\n",
      "Average value_loss: 0.2627\n",
      "Replay buffer size: 2116\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.1435\n",
      "Average policy_loss: 0.8766\n",
      "Average value_loss: 0.2670\n",
      "Replay buffer size: 2191\n",
      "Time taken: 41.5s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.1478\n",
      "Average policy_loss: 0.8829\n",
      "Average value_loss: 0.2649\n",
      "Replay buffer size: 2279\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.1578\n",
      "Average policy_loss: 0.8896\n",
      "Average value_loss: 0.2682\n",
      "Replay buffer size: 2359\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.1618\n",
      "Average policy_loss: 0.8899\n",
      "Average value_loss: 0.2718\n",
      "Replay buffer size: 2434\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.1618\n",
      "Average policy_loss: 0.8979\n",
      "Average value_loss: 0.2639\n",
      "Replay buffer size: 2508\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.1605\n",
      "Average policy_loss: 0.8923\n",
      "Average value_loss: 0.2682\n",
      "Replay buffer size: 2579\n",
      "Time taken: 42.4s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.1644\n",
      "Average policy_loss: 0.8925\n",
      "Average value_loss: 0.2719\n",
      "Replay buffer size: 2666\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.1757\n",
      "Average policy_loss: 0.8985\n",
      "Average value_loss: 0.2772\n",
      "Replay buffer size: 2749\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.1675\n",
      "Average policy_loss: 0.8986\n",
      "Average value_loss: 0.2689\n",
      "Replay buffer size: 2827\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.1599\n",
      "Average policy_loss: 0.8923\n",
      "Average value_loss: 0.2676\n",
      "Replay buffer size: 2910\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.1566\n",
      "Average policy_loss: 0.8922\n",
      "Average value_loss: 0.2644\n",
      "Replay buffer size: 2998\n",
      "Time taken: 44.8s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.1606\n",
      "Average policy_loss: 0.8992\n",
      "Average value_loss: 0.2614\n",
      "Replay buffer size: 3082\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.1592\n",
      "Average policy_loss: 0.8953\n",
      "Average value_loss: 0.2639\n",
      "Replay buffer size: 3165\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.1515\n",
      "Average policy_loss: 0.8931\n",
      "Average value_loss: 0.2584\n",
      "Replay buffer size: 3245\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.1477\n",
      "Average policy_loss: 0.8965\n",
      "Average value_loss: 0.2511\n",
      "Replay buffer size: 3331\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.1539\n",
      "Average policy_loss: 0.8965\n",
      "Average value_loss: 0.2574\n",
      "Replay buffer size: 3406\n",
      "Time taken: 43.1s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.1524\n",
      "Average policy_loss: 0.8963\n",
      "Average value_loss: 0.2561\n",
      "Replay buffer size: 3477\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.1454\n",
      "Average policy_loss: 0.8950\n",
      "Average value_loss: 0.2504\n",
      "Replay buffer size: 3563\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.1643\n",
      "Average policy_loss: 0.9073\n",
      "Average value_loss: 0.2570\n",
      "Replay buffer size: 3639\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.1527\n",
      "Average policy_loss: 0.8979\n",
      "Average value_loss: 0.2548\n",
      "Replay buffer size: 3719\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.1553\n",
      "Average policy_loss: 0.8977\n",
      "Average value_loss: 0.2576\n",
      "Replay buffer size: 3795\n",
      "Time taken: 45.5s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.1526\n",
      "Average policy_loss: 0.9000\n",
      "Average value_loss: 0.2526\n",
      "Replay buffer size: 3874\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.1587\n",
      "Average policy_loss: 0.9024\n",
      "Average value_loss: 0.2564\n",
      "Replay buffer size: 3960\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.1611\n",
      "Average policy_loss: 0.9039\n",
      "Average value_loss: 0.2572\n",
      "Replay buffer size: 4044\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.1635\n",
      "Average policy_loss: 0.9061\n",
      "Average value_loss: 0.2574\n",
      "Replay buffer size: 4128\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.1562\n",
      "Average policy_loss: 0.9008\n",
      "Average value_loss: 0.2555\n",
      "Replay buffer size: 4215\n",
      "Time taken: 48.5s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.1510\n",
      "Average policy_loss: 0.8999\n",
      "Average value_loss: 0.2510\n",
      "Replay buffer size: 4295\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.1576\n",
      "Average policy_loss: 0.9038\n",
      "Average value_loss: 0.2538\n",
      "Replay buffer size: 4378\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.1544\n",
      "Average policy_loss: 0.9022\n",
      "Average value_loss: 0.2521\n",
      "Replay buffer size: 4462\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.1536\n",
      "Average policy_loss: 0.9003\n",
      "Average value_loss: 0.2533\n",
      "Replay buffer size: 4536\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.1475\n",
      "Average policy_loss: 0.8937\n",
      "Average value_loss: 0.2537\n",
      "Replay buffer size: 4615\n",
      "Time taken: 41.1s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.1608\n",
      "Average policy_loss: 0.9057\n",
      "Average value_loss: 0.2551\n",
      "Replay buffer size: 4687\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.1571\n",
      "Average policy_loss: 0.9055\n",
      "Average value_loss: 0.2516\n",
      "Replay buffer size: 4779\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.1484\n",
      "Average policy_loss: 0.8980\n",
      "Average value_loss: 0.2503\n",
      "Replay buffer size: 4864\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.1485\n",
      "Average policy_loss: 0.8994\n",
      "Average value_loss: 0.2491\n",
      "Replay buffer size: 4946\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.1579\n",
      "Average policy_loss: 0.9041\n",
      "Average value_loss: 0.2538\n",
      "Replay buffer size: 5032\n",
      "Time taken: 48.1s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.1539\n",
      "Average policy_loss: 0.9049\n",
      "Average value_loss: 0.2490\n",
      "Replay buffer size: 5115\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.1566\n",
      "Average policy_loss: 0.9085\n",
      "Average value_loss: 0.2481\n",
      "Replay buffer size: 5189\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.1482\n",
      "Average policy_loss: 0.9010\n",
      "Average value_loss: 0.2471\n",
      "Replay buffer size: 5271\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.1587\n",
      "Average policy_loss: 0.9031\n",
      "Average value_loss: 0.2556\n",
      "Replay buffer size: 5363\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.1548\n",
      "Average policy_loss: 0.9038\n",
      "Average value_loss: 0.2510\n",
      "Replay buffer size: 5454\n",
      "Time taken: 47.4s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.1708\n",
      "Average policy_loss: 0.9106\n",
      "Average value_loss: 0.2602\n",
      "Replay buffer size: 5538\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.1695\n",
      "Average policy_loss: 0.9104\n",
      "Average value_loss: 0.2591\n",
      "Replay buffer size: 5625\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.1736\n",
      "Average policy_loss: 0.9144\n",
      "Average value_loss: 0.2592\n",
      "Replay buffer size: 5713\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.1619\n",
      "Average policy_loss: 0.9049\n",
      "Average value_loss: 0.2570\n",
      "Replay buffer size: 5806\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.1734\n",
      "Average policy_loss: 0.9128\n",
      "Average value_loss: 0.2606\n",
      "Replay buffer size: 5891\n",
      "Time taken: 47.6s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.1613\n",
      "Average policy_loss: 0.9030\n",
      "Average value_loss: 0.2583\n",
      "Replay buffer size: 5979\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.1759\n",
      "Average policy_loss: 0.9140\n",
      "Average value_loss: 0.2619\n",
      "Replay buffer size: 6051\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.1645\n",
      "Average policy_loss: 0.9043\n",
      "Average value_loss: 0.2602\n",
      "Replay buffer size: 6141\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.1788\n",
      "Average policy_loss: 0.9134\n",
      "Average value_loss: 0.2653\n",
      "Replay buffer size: 6229\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.1778\n",
      "Average policy_loss: 0.9155\n",
      "Average value_loss: 0.2623\n",
      "Replay buffer size: 6316\n",
      "Time taken: 48.5s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.1848\n",
      "Average policy_loss: 0.9208\n",
      "Average value_loss: 0.2640\n",
      "Replay buffer size: 6403\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.1829\n",
      "Average policy_loss: 0.9183\n",
      "Average value_loss: 0.2646\n",
      "Replay buffer size: 6492\n",
      "Time taken: 19.4s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.1857\n",
      "Average policy_loss: 0.9231\n",
      "Average value_loss: 0.2627\n",
      "Replay buffer size: 6584\n",
      "Time taken: 19.4s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.1807\n",
      "Average policy_loss: 0.9226\n",
      "Average value_loss: 0.2581\n",
      "Replay buffer size: 6676\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.1717\n",
      "Average policy_loss: 0.9142\n",
      "Average value_loss: 0.2575\n",
      "Replay buffer size: 6768\n",
      "Time taken: 48.6s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.1744\n",
      "Average policy_loss: 0.9196\n",
      "Average value_loss: 0.2548\n",
      "Replay buffer size: 6866\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.1856\n",
      "Average policy_loss: 0.9239\n",
      "Average value_loss: 0.2617\n",
      "Replay buffer size: 6948\n",
      "Time taken: 19.2s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.1882\n",
      "Average policy_loss: 0.9244\n",
      "Average value_loss: 0.2638\n",
      "Replay buffer size: 7032\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.1864\n",
      "Average policy_loss: 0.9229\n",
      "Average value_loss: 0.2635\n",
      "Replay buffer size: 7118\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.1882\n",
      "Average policy_loss: 0.9240\n",
      "Average value_loss: 0.2642\n",
      "Replay buffer size: 7204\n",
      "Time taken: 52.6s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.1883\n",
      "Average policy_loss: 0.9256\n",
      "Average value_loss: 0.2627\n",
      "Replay buffer size: 7289\n",
      "Time taken: 19.1s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.1837\n",
      "Average policy_loss: 0.9220\n",
      "Average value_loss: 0.2617\n",
      "Replay buffer size: 7370\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.1817\n",
      "Average policy_loss: 0.9229\n",
      "Average value_loss: 0.2588\n",
      "Replay buffer size: 7459\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.1845\n",
      "Average policy_loss: 0.9224\n",
      "Average value_loss: 0.2621\n",
      "Replay buffer size: 7554\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.1869\n",
      "Average policy_loss: 0.9271\n",
      "Average value_loss: 0.2598\n",
      "Replay buffer size: 7640\n",
      "Time taken: 51.3s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.1926\n",
      "Average policy_loss: 0.9273\n",
      "Average value_loss: 0.2654\n",
      "Replay buffer size: 7722\n",
      "Time taken: 19.1s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.1822\n",
      "Average policy_loss: 0.9243\n",
      "Average value_loss: 0.2579\n",
      "Replay buffer size: 7810\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.1898\n",
      "Average policy_loss: 0.9291\n",
      "Average value_loss: 0.2607\n",
      "Replay buffer size: 7899\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.1847\n",
      "Average policy_loss: 0.9239\n",
      "Average value_loss: 0.2609\n",
      "Replay buffer size: 7993\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.1823\n",
      "Average policy_loss: 0.9236\n",
      "Average value_loss: 0.2587\n",
      "Replay buffer size: 8077\n",
      "Time taken: 52.7s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.1864\n",
      "Average policy_loss: 0.9211\n",
      "Average value_loss: 0.2653\n",
      "Replay buffer size: 8162\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.1812\n",
      "Average policy_loss: 0.9186\n",
      "Average value_loss: 0.2625\n",
      "Replay buffer size: 8257\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.1855\n",
      "Average policy_loss: 0.9245\n",
      "Average value_loss: 0.2610\n",
      "Replay buffer size: 8348\n",
      "Time taken: 20.8s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.1793\n",
      "Average policy_loss: 0.9193\n",
      "Average value_loss: 0.2600\n",
      "Replay buffer size: 8431\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.1890\n",
      "Average policy_loss: 0.9255\n",
      "Average value_loss: 0.2634\n",
      "Replay buffer size: 8519\n",
      "Time taken: 50.3s\n",
      "\n",
      "Training complete! Total time: 0.6h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>iteration_time</td><td>▁▁▂▆▂▆▂▂▂▂▂▂▂▇▂▂▇▂▂▃▇▂▃▃▂▂▃█▃▃▃█▃▃▃▃▃▃▃▃</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▆▇▆█▅▄▄▄▂▃▂▁▄▃▅▃▂▃▄▂▄▅▄▂▄▆▄▅▆▆▅▅█▄▄▅▄▅▄▄</td></tr><tr><td>policy_loss</td><td>█▃▂▁▁▁▁▂▂▂▂▂▃▃▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>value_loss</td><td>█▅▃▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.3</td></tr><tr><td>buffer_size</td><td>8519</td></tr><tr><td>iteration_time</td><td>50.30384</td></tr><tr><td>loss</td><td>1.18897</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>88</td></tr><tr><td>policy_loss</td><td>0.92552</td></tr><tr><td>total_time_hours</td><td>0.59856</td></tr><tr><td>value_loss</td><td>0.26345</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dainty-sweep-1</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1tvknncm' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1tvknncm</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 22 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250228_222840-1tvknncm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h47yk2qs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.015988642514553713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.3581637718293932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.00015937504990452334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250228_230443-h47yk2qs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/h47yk2qs' target=\"_blank\">dark-sweep-2</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/h47yk2qs' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/h47yk2qs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 3.0407\n",
      "Average policy_loss: 2.5109\n",
      "Average value_loss: 0.5299\n",
      "Replay buffer size: 77\n",
      "Time taken: 5.6s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.4659\n",
      "Average policy_loss: 0.9214\n",
      "Average value_loss: 0.5445\n",
      "Replay buffer size: 148\n",
      "Time taken: 5.9s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.3646\n",
      "Average policy_loss: 0.8745\n",
      "Average value_loss: 0.4901\n",
      "Replay buffer size: 225\n",
      "Time taken: 5.3s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.2981\n",
      "Average policy_loss: 0.9000\n",
      "Average value_loss: 0.3981\n",
      "Replay buffer size: 300\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.3020\n",
      "Average policy_loss: 0.9096\n",
      "Average value_loss: 0.3925\n",
      "Replay buffer size: 380\n",
      "Time taken: 24.2s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.1920\n",
      "Average policy_loss: 0.8501\n",
      "Average value_loss: 0.3419\n",
      "Replay buffer size: 460\n",
      "Time taken: 6.7s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.1656\n",
      "Average policy_loss: 0.8328\n",
      "Average value_loss: 0.3329\n",
      "Replay buffer size: 538\n",
      "Time taken: 6.0s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.1299\n",
      "Average policy_loss: 0.7866\n",
      "Average value_loss: 0.3433\n",
      "Replay buffer size: 628\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.1340\n",
      "Average policy_loss: 0.7611\n",
      "Average value_loss: 0.3729\n",
      "Replay buffer size: 713\n",
      "Time taken: 6.6s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.2060\n",
      "Average policy_loss: 0.7771\n",
      "Average value_loss: 0.4289\n",
      "Replay buffer size: 799\n",
      "Time taken: 26.6s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.1707\n",
      "Average policy_loss: 0.7375\n",
      "Average value_loss: 0.4332\n",
      "Replay buffer size: 889\n",
      "Time taken: 7.6s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.1533\n",
      "Average policy_loss: 0.7262\n",
      "Average value_loss: 0.4271\n",
      "Replay buffer size: 970\n",
      "Time taken: 7.7s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.0975\n",
      "Average policy_loss: 0.7278\n",
      "Average value_loss: 0.3696\n",
      "Replay buffer size: 1052\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.0505\n",
      "Average policy_loss: 0.7063\n",
      "Average value_loss: 0.3442\n",
      "Replay buffer size: 1148\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.0884\n",
      "Average policy_loss: 0.7686\n",
      "Average value_loss: 0.3198\n",
      "Replay buffer size: 1239\n",
      "Time taken: 37.7s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.0819\n",
      "Average policy_loss: 0.7767\n",
      "Average value_loss: 0.3052\n",
      "Replay buffer size: 1329\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.0708\n",
      "Average policy_loss: 0.7775\n",
      "Average value_loss: 0.2933\n",
      "Replay buffer size: 1411\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.0863\n",
      "Average policy_loss: 0.8021\n",
      "Average value_loss: 0.2842\n",
      "Replay buffer size: 1499\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.0562\n",
      "Average policy_loss: 0.7812\n",
      "Average value_loss: 0.2751\n",
      "Replay buffer size: 1595\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.0550\n",
      "Average policy_loss: 0.7820\n",
      "Average value_loss: 0.2730\n",
      "Replay buffer size: 1681\n",
      "Time taken: 40.5s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.0488\n",
      "Average policy_loss: 0.7791\n",
      "Average value_loss: 0.2697\n",
      "Replay buffer size: 1779\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.0321\n",
      "Average policy_loss: 0.7660\n",
      "Average value_loss: 0.2661\n",
      "Replay buffer size: 1867\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.0276\n",
      "Average policy_loss: 0.7696\n",
      "Average value_loss: 0.2579\n",
      "Replay buffer size: 1958\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.0083\n",
      "Average policy_loss: 0.7551\n",
      "Average value_loss: 0.2532\n",
      "Replay buffer size: 2058\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.0120\n",
      "Average policy_loss: 0.7626\n",
      "Average value_loss: 0.2494\n",
      "Replay buffer size: 2156\n",
      "Time taken: 41.1s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.0000\n",
      "Average policy_loss: 0.7559\n",
      "Average value_loss: 0.2441\n",
      "Replay buffer size: 2248\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.0085\n",
      "Average policy_loss: 0.7700\n",
      "Average value_loss: 0.2385\n",
      "Replay buffer size: 2345\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.0136\n",
      "Average policy_loss: 0.7757\n",
      "Average value_loss: 0.2379\n",
      "Replay buffer size: 2439\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.9723\n",
      "Average policy_loss: 0.7411\n",
      "Average value_loss: 0.2312\n",
      "Replay buffer size: 2536\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.9922\n",
      "Average policy_loss: 0.7607\n",
      "Average value_loss: 0.2315\n",
      "Replay buffer size: 2629\n",
      "Time taken: 42.4s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.9658\n",
      "Average policy_loss: 0.7456\n",
      "Average value_loss: 0.2202\n",
      "Replay buffer size: 2729\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.9487\n",
      "Average policy_loss: 0.7302\n",
      "Average value_loss: 0.2185\n",
      "Replay buffer size: 2823\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.9821\n",
      "Average policy_loss: 0.7570\n",
      "Average value_loss: 0.2251\n",
      "Replay buffer size: 2899\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.9739\n",
      "Average policy_loss: 0.7459\n",
      "Average value_loss: 0.2279\n",
      "Replay buffer size: 2995\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 100.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.9675\n",
      "Average policy_loss: 0.7442\n",
      "Average value_loss: 0.2233\n",
      "Replay buffer size: 3092\n",
      "Time taken: 41.5s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.9342\n",
      "Average policy_loss: 0.7204\n",
      "Average value_loss: 0.2138\n",
      "Replay buffer size: 3192\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.9436\n",
      "Average policy_loss: 0.7274\n",
      "Average value_loss: 0.2162\n",
      "Replay buffer size: 3287\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.9233\n",
      "Average policy_loss: 0.7089\n",
      "Average value_loss: 0.2144\n",
      "Replay buffer size: 3382\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.9443\n",
      "Average policy_loss: 0.7317\n",
      "Average value_loss: 0.2126\n",
      "Replay buffer size: 3476\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.9337\n",
      "Average policy_loss: 0.7272\n",
      "Average value_loss: 0.2065\n",
      "Replay buffer size: 3570\n",
      "Time taken: 41.5s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.9295\n",
      "Average policy_loss: 0.7268\n",
      "Average value_loss: 0.2027\n",
      "Replay buffer size: 3667\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.9162\n",
      "Average policy_loss: 0.7160\n",
      "Average value_loss: 0.2002\n",
      "Replay buffer size: 3762\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.9284\n",
      "Average policy_loss: 0.7242\n",
      "Average value_loss: 0.2042\n",
      "Replay buffer size: 3855\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.9250\n",
      "Average policy_loss: 0.7232\n",
      "Average value_loss: 0.2018\n",
      "Replay buffer size: 3943\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 100.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.9296\n",
      "Average policy_loss: 0.7266\n",
      "Average value_loss: 0.2030\n",
      "Replay buffer size: 4043\n",
      "Time taken: 44.4s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.8994\n",
      "Average policy_loss: 0.7118\n",
      "Average value_loss: 0.1876\n",
      "Replay buffer size: 4136\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.9189\n",
      "Average policy_loss: 0.7208\n",
      "Average value_loss: 0.1982\n",
      "Replay buffer size: 4230\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.8924\n",
      "Average policy_loss: 0.7062\n",
      "Average value_loss: 0.1862\n",
      "Replay buffer size: 4323\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.8976\n",
      "Average policy_loss: 0.7078\n",
      "Average value_loss: 0.1898\n",
      "Replay buffer size: 4423\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.8783\n",
      "Average policy_loss: 0.6969\n",
      "Average value_loss: 0.1814\n",
      "Replay buffer size: 4523\n",
      "Time taken: 43.2s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.8808\n",
      "Average policy_loss: 0.7033\n",
      "Average value_loss: 0.1775\n",
      "Replay buffer size: 4614\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.8883\n",
      "Average policy_loss: 0.7051\n",
      "Average value_loss: 0.1831\n",
      "Replay buffer size: 4703\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.8732\n",
      "Average policy_loss: 0.6984\n",
      "Average value_loss: 0.1747\n",
      "Replay buffer size: 4803\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.8895\n",
      "Average policy_loss: 0.7118\n",
      "Average value_loss: 0.1777\n",
      "Replay buffer size: 4894\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.8645\n",
      "Average policy_loss: 0.6906\n",
      "Average value_loss: 0.1739\n",
      "Replay buffer size: 4981\n",
      "Time taken: 44.0s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.8696\n",
      "Average policy_loss: 0.6939\n",
      "Average value_loss: 0.1757\n",
      "Replay buffer size: 5081\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.8738\n",
      "Average policy_loss: 0.6957\n",
      "Average value_loss: 0.1781\n",
      "Replay buffer size: 5174\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.8761\n",
      "Average policy_loss: 0.6966\n",
      "Average value_loss: 0.1795\n",
      "Replay buffer size: 5268\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.8641\n",
      "Average policy_loss: 0.6932\n",
      "Average value_loss: 0.1709\n",
      "Replay buffer size: 5361\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.8641\n",
      "Average policy_loss: 0.6936\n",
      "Average value_loss: 0.1705\n",
      "Replay buffer size: 5457\n",
      "Time taken: 43.1s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.8782\n",
      "Average policy_loss: 0.7077\n",
      "Average value_loss: 0.1705\n",
      "Replay buffer size: 5550\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.8500\n",
      "Average policy_loss: 0.6827\n",
      "Average value_loss: 0.1673\n",
      "Replay buffer size: 5640\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.8621\n",
      "Average policy_loss: 0.6903\n",
      "Average value_loss: 0.1718\n",
      "Replay buffer size: 5732\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.8496\n",
      "Average policy_loss: 0.6840\n",
      "Average value_loss: 0.1656\n",
      "Replay buffer size: 5827\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.8475\n",
      "Average policy_loss: 0.6766\n",
      "Average value_loss: 0.1709\n",
      "Replay buffer size: 5919\n",
      "Time taken: 44.0s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.8519\n",
      "Average policy_loss: 0.6861\n",
      "Average value_loss: 0.1658\n",
      "Replay buffer size: 6018\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.8486\n",
      "Average policy_loss: 0.6789\n",
      "Average value_loss: 0.1697\n",
      "Replay buffer size: 6115\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.8394\n",
      "Average policy_loss: 0.6742\n",
      "Average value_loss: 0.1652\n",
      "Replay buffer size: 6205\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.8511\n",
      "Average policy_loss: 0.6892\n",
      "Average value_loss: 0.1619\n",
      "Replay buffer size: 6293\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.8578\n",
      "Average policy_loss: 0.6905\n",
      "Average value_loss: 0.1673\n",
      "Replay buffer size: 6386\n",
      "Time taken: 43.1s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.8464\n",
      "Average policy_loss: 0.6799\n",
      "Average value_loss: 0.1664\n",
      "Replay buffer size: 6477\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.8374\n",
      "Average policy_loss: 0.6720\n",
      "Average value_loss: 0.1654\n",
      "Replay buffer size: 6574\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.8331\n",
      "Average policy_loss: 0.6689\n",
      "Average value_loss: 0.1641\n",
      "Replay buffer size: 6667\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.8363\n",
      "Average policy_loss: 0.6701\n",
      "Average value_loss: 0.1662\n",
      "Replay buffer size: 6761\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.8368\n",
      "Average policy_loss: 0.6725\n",
      "Average value_loss: 0.1642\n",
      "Replay buffer size: 6859\n",
      "Time taken: 42.4s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.8429\n",
      "Average policy_loss: 0.6744\n",
      "Average value_loss: 0.1685\n",
      "Replay buffer size: 6954\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.8406\n",
      "Average policy_loss: 0.6705\n",
      "Average value_loss: 0.1701\n",
      "Replay buffer size: 7043\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.8485\n",
      "Average policy_loss: 0.6839\n",
      "Average value_loss: 0.1646\n",
      "Replay buffer size: 7137\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.8389\n",
      "Average policy_loss: 0.6721\n",
      "Average value_loss: 0.1669\n",
      "Replay buffer size: 7230\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.8243\n",
      "Average policy_loss: 0.6634\n",
      "Average value_loss: 0.1610\n",
      "Replay buffer size: 7326\n",
      "Time taken: 42.8s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.8331\n",
      "Average policy_loss: 0.6680\n",
      "Average value_loss: 0.1651\n",
      "Replay buffer size: 7422\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.8195\n",
      "Average policy_loss: 0.6650\n",
      "Average value_loss: 0.1545\n",
      "Replay buffer size: 7521\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.8317\n",
      "Average policy_loss: 0.6717\n",
      "Average value_loss: 0.1600\n",
      "Replay buffer size: 7619\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.8387\n",
      "Average policy_loss: 0.6787\n",
      "Average value_loss: 0.1600\n",
      "Replay buffer size: 7717\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.8411\n",
      "Average policy_loss: 0.6782\n",
      "Average value_loss: 0.1629\n",
      "Replay buffer size: 7810\n",
      "Time taken: 43.7s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.8308\n",
      "Average policy_loss: 0.6743\n",
      "Average value_loss: 0.1566\n",
      "Replay buffer size: 7903\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.8230\n",
      "Average policy_loss: 0.6678\n",
      "Average value_loss: 0.1552\n",
      "Replay buffer size: 7991\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.8112\n",
      "Average policy_loss: 0.6552\n",
      "Average value_loss: 0.1560\n",
      "Replay buffer size: 8085\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.8166\n",
      "Average policy_loss: 0.6590\n",
      "Average value_loss: 0.1575\n",
      "Replay buffer size: 8177\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.8281\n",
      "Average policy_loss: 0.6705\n",
      "Average value_loss: 0.1576\n",
      "Replay buffer size: 8265\n",
      "Time taken: 46.4s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.8333\n",
      "Average policy_loss: 0.6736\n",
      "Average value_loss: 0.1596\n",
      "Replay buffer size: 8353\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.8304\n",
      "Average policy_loss: 0.6684\n",
      "Average value_loss: 0.1621\n",
      "Replay buffer size: 8449\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.8151\n",
      "Average policy_loss: 0.6600\n",
      "Average value_loss: 0.1552\n",
      "Replay buffer size: 8541\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.8148\n",
      "Average policy_loss: 0.6586\n",
      "Average value_loss: 0.1563\n",
      "Replay buffer size: 8629\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.8326\n",
      "Average policy_loss: 0.6766\n",
      "Average value_loss: 0.1561\n",
      "Replay buffer size: 8727\n",
      "Time taken: 47.1s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.8186\n",
      "Average policy_loss: 0.6653\n",
      "Average value_loss: 0.1533\n",
      "Replay buffer size: 8821\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.8224\n",
      "Average policy_loss: 0.6688\n",
      "Average value_loss: 0.1537\n",
      "Replay buffer size: 8911\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.8117\n",
      "Average policy_loss: 0.6627\n",
      "Average value_loss: 0.1490\n",
      "Replay buffer size: 9001\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.8296\n",
      "Average policy_loss: 0.6692\n",
      "Average value_loss: 0.1604\n",
      "Replay buffer size: 9097\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.8322\n",
      "Average policy_loss: 0.6736\n",
      "Average value_loss: 0.1586\n",
      "Replay buffer size: 9189\n",
      "Time taken: 44.4s\n",
      "\n",
      "Training complete! Total time: 0.5h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇██</td></tr><tr><td>iteration_time</td><td>▁▁▁▁▁▁▁▁▆▂▂▂▇▂▂▂▇▂▂▇▂▂▂▂▂▂▂▂▂▇▃▂▂▂▇▂▂███</td></tr><tr><td>loss</td><td>█▇▅▅▆▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▂▁▅▄▃▇▅▃▇▅▆▁▇▇▆▇▇▆▆▆██▅█▆▆▇▆█▇▅▇▆▇▇▇▆▅▅▅</td></tr><tr><td>policy_loss</td><td>█▄▄▅▅▅▅▄▅▄▃▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▂▁▁</td></tr><tr><td>value_loss</td><td>█▅▇▇▅▄▃▃▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.05</td></tr><tr><td>buffer_size</td><td>9189</td></tr><tr><td>iteration_time</td><td>44.42413</td></tr><tr><td>loss</td><td>0.83218</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>92</td></tr><tr><td>policy_loss</td><td>0.67355</td></tr><tr><td>total_time_hours</td><td>0.49617</td></tr><tr><td>value_loss</td><td>0.15863</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dark-sweep-2</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/h47yk2qs' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/h47yk2qs</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250228_230443-h47yk2qs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gmj6nbnq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000696525560025685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: medium\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.3835268511490555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001228261684577894\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250228_233439-gmj6nbnq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/gmj6nbnq' target=\"_blank\">effortless-sweep-3</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/gmj6nbnq' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/gmj6nbnq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 4.0069\n",
      "Average policy_loss: 3.0167\n",
      "Average value_loss: 0.9902\n",
      "Replay buffer size: 74\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 2.5127\n",
      "Average policy_loss: 1.8395\n",
      "Average value_loss: 0.6732\n",
      "Replay buffer size: 167\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 2.0815\n",
      "Average policy_loss: 1.5837\n",
      "Average value_loss: 0.4978\n",
      "Replay buffer size: 253\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.8694\n",
      "Average policy_loss: 1.4378\n",
      "Average value_loss: 0.4316\n",
      "Replay buffer size: 337\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.7789\n",
      "Average policy_loss: 1.3805\n",
      "Average value_loss: 0.3984\n",
      "Replay buffer size: 423\n",
      "Time taken: 58.4s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.6790\n",
      "Average policy_loss: 1.3072\n",
      "Average value_loss: 0.3718\n",
      "Replay buffer size: 505\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.6546\n",
      "Average policy_loss: 1.3091\n",
      "Average value_loss: 0.3455\n",
      "Replay buffer size: 596\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.5887\n",
      "Average policy_loss: 1.2560\n",
      "Average value_loss: 0.3326\n",
      "Replay buffer size: 688\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.5820\n",
      "Average policy_loss: 1.2543\n",
      "Average value_loss: 0.3277\n",
      "Replay buffer size: 770\n",
      "Time taken: 20.8s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.5405\n",
      "Average policy_loss: 1.2227\n",
      "Average value_loss: 0.3177\n",
      "Replay buffer size: 860\n",
      "Time taken: 63.6s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.4963\n",
      "Average policy_loss: 1.1985\n",
      "Average value_loss: 0.2978\n",
      "Replay buffer size: 958\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.4629\n",
      "Average policy_loss: 1.1715\n",
      "Average value_loss: 0.2915\n",
      "Replay buffer size: 1043\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.4320\n",
      "Average policy_loss: 1.1515\n",
      "Average value_loss: 0.2805\n",
      "Replay buffer size: 1123\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.3978\n",
      "Average policy_loss: 1.1275\n",
      "Average value_loss: 0.2704\n",
      "Replay buffer size: 1219\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.3916\n",
      "Average policy_loss: 1.1246\n",
      "Average value_loss: 0.2671\n",
      "Replay buffer size: 1316\n",
      "Time taken: 64.7s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.3714\n",
      "Average policy_loss: 1.1094\n",
      "Average value_loss: 0.2620\n",
      "Replay buffer size: 1403\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.3478\n",
      "Average policy_loss: 1.0932\n",
      "Average value_loss: 0.2546\n",
      "Replay buffer size: 1496\n",
      "Time taken: 19.2s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.3316\n",
      "Average policy_loss: 1.0837\n",
      "Average value_loss: 0.2479\n",
      "Replay buffer size: 1587\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.3182\n",
      "Average policy_loss: 1.0760\n",
      "Average value_loss: 0.2422\n",
      "Replay buffer size: 1683\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.2960\n",
      "Average policy_loss: 1.0637\n",
      "Average value_loss: 0.2322\n",
      "Replay buffer size: 1781\n",
      "Time taken: 70.7s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.2916\n",
      "Average policy_loss: 1.0587\n",
      "Average value_loss: 0.2328\n",
      "Replay buffer size: 1862\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.2784\n",
      "Average policy_loss: 1.0451\n",
      "Average value_loss: 0.2333\n",
      "Replay buffer size: 1953\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.2731\n",
      "Average policy_loss: 1.0465\n",
      "Average value_loss: 0.2266\n",
      "Replay buffer size: 2048\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.2592\n",
      "Average policy_loss: 1.0332\n",
      "Average value_loss: 0.2260\n",
      "Replay buffer size: 2122\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.2573\n",
      "Average policy_loss: 1.0362\n",
      "Average value_loss: 0.2212\n",
      "Replay buffer size: 2212\n",
      "Time taken: 70.8s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.2447\n",
      "Average policy_loss: 1.0262\n",
      "Average value_loss: 0.2185\n",
      "Replay buffer size: 2300\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.2435\n",
      "Average policy_loss: 1.0266\n",
      "Average value_loss: 0.2169\n",
      "Replay buffer size: 2393\n",
      "Time taken: 22.1s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.2431\n",
      "Average policy_loss: 1.0260\n",
      "Average value_loss: 0.2171\n",
      "Replay buffer size: 2475\n",
      "Time taken: 24.3s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.2364\n",
      "Average policy_loss: 1.0192\n",
      "Average value_loss: 0.2172\n",
      "Replay buffer size: 2564\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.2255\n",
      "Average policy_loss: 1.0156\n",
      "Average value_loss: 0.2099\n",
      "Replay buffer size: 2660\n",
      "Time taken: 69.8s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.2269\n",
      "Average policy_loss: 1.0141\n",
      "Average value_loss: 0.2128\n",
      "Replay buffer size: 2747\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.2187\n",
      "Average policy_loss: 1.0094\n",
      "Average value_loss: 0.2093\n",
      "Replay buffer size: 2833\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.2165\n",
      "Average policy_loss: 1.0090\n",
      "Average value_loss: 0.2075\n",
      "Replay buffer size: 2923\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.2118\n",
      "Average policy_loss: 1.0063\n",
      "Average value_loss: 0.2055\n",
      "Replay buffer size: 3008\n",
      "Time taken: 23.0s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.2140\n",
      "Average policy_loss: 1.0078\n",
      "Average value_loss: 0.2062\n",
      "Replay buffer size: 3093\n",
      "Time taken: 73.5s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.2106\n",
      "Average policy_loss: 1.0100\n",
      "Average value_loss: 0.2006\n",
      "Replay buffer size: 3183\n",
      "Time taken: 23.3s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.2114\n",
      "Average policy_loss: 1.0051\n",
      "Average value_loss: 0.2063\n",
      "Replay buffer size: 3265\n",
      "Time taken: 24.3s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.2038\n",
      "Average policy_loss: 1.0004\n",
      "Average value_loss: 0.2034\n",
      "Replay buffer size: 3357\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.1957\n",
      "Average policy_loss: 0.9958\n",
      "Average value_loss: 0.1998\n",
      "Replay buffer size: 3444\n",
      "Time taken: 23.6s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.1892\n",
      "Average policy_loss: 0.9895\n",
      "Average value_loss: 0.1997\n",
      "Replay buffer size: 3534\n",
      "Time taken: 74.7s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.1895\n",
      "Average policy_loss: 0.9907\n",
      "Average value_loss: 0.1988\n",
      "Replay buffer size: 3627\n",
      "Time taken: 23.0s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.1852\n",
      "Average policy_loss: 0.9888\n",
      "Average value_loss: 0.1963\n",
      "Replay buffer size: 3707\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.1783\n",
      "Average policy_loss: 0.9855\n",
      "Average value_loss: 0.1927\n",
      "Replay buffer size: 3797\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.1803\n",
      "Average policy_loss: 0.9861\n",
      "Average value_loss: 0.1941\n",
      "Replay buffer size: 3886\n",
      "Time taken: 23.9s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.1762\n",
      "Average policy_loss: 0.9828\n",
      "Average value_loss: 0.1935\n",
      "Replay buffer size: 3968\n",
      "Time taken: 74.7s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.1806\n",
      "Average policy_loss: 0.9861\n",
      "Average value_loss: 0.1944\n",
      "Replay buffer size: 4049\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.1809\n",
      "Average policy_loss: 0.9848\n",
      "Average value_loss: 0.1960\n",
      "Replay buffer size: 4126\n",
      "Time taken: 23.6s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.1802\n",
      "Average policy_loss: 0.9827\n",
      "Average value_loss: 0.1975\n",
      "Replay buffer size: 4210\n",
      "Time taken: 23.7s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.1795\n",
      "Average policy_loss: 0.9804\n",
      "Average value_loss: 0.1991\n",
      "Replay buffer size: 4298\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.1715\n",
      "Average policy_loss: 0.9780\n",
      "Average value_loss: 0.1934\n",
      "Replay buffer size: 4394\n",
      "Time taken: 75.5s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.1736\n",
      "Average policy_loss: 0.9783\n",
      "Average value_loss: 0.1954\n",
      "Replay buffer size: 4487\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.1603\n",
      "Average policy_loss: 0.9714\n",
      "Average value_loss: 0.1889\n",
      "Replay buffer size: 4577\n",
      "Time taken: 23.1s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.1522\n",
      "Average policy_loss: 0.9649\n",
      "Average value_loss: 0.1873\n",
      "Replay buffer size: 4677\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.1500\n",
      "Average policy_loss: 0.9613\n",
      "Average value_loss: 0.1887\n",
      "Replay buffer size: 4768\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.1541\n",
      "Average policy_loss: 0.9663\n",
      "Average value_loss: 0.1878\n",
      "Replay buffer size: 4866\n",
      "Time taken: 73.6s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.1414\n",
      "Average policy_loss: 0.9548\n",
      "Average value_loss: 0.1866\n",
      "Replay buffer size: 4958\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.1396\n",
      "Average policy_loss: 0.9515\n",
      "Average value_loss: 0.1881\n",
      "Replay buffer size: 5041\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.1516\n",
      "Average policy_loss: 0.9626\n",
      "Average value_loss: 0.1890\n",
      "Replay buffer size: 5122\n",
      "Time taken: 23.1s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.1434\n",
      "Average policy_loss: 0.9525\n",
      "Average value_loss: 0.1910\n",
      "Replay buffer size: 5214\n",
      "Time taken: 24.8s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.1400\n",
      "Average policy_loss: 0.9541\n",
      "Average value_loss: 0.1859\n",
      "Replay buffer size: 5312\n",
      "Time taken: 77.8s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.1428\n",
      "Average policy_loss: 0.9583\n",
      "Average value_loss: 0.1845\n",
      "Replay buffer size: 5411\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.1330\n",
      "Average policy_loss: 0.9489\n",
      "Average value_loss: 0.1841\n",
      "Replay buffer size: 5495\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.1352\n",
      "Average policy_loss: 0.9522\n",
      "Average value_loss: 0.1830\n",
      "Replay buffer size: 5583\n",
      "Time taken: 23.9s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.1375\n",
      "Average policy_loss: 0.9518\n",
      "Average value_loss: 0.1857\n",
      "Replay buffer size: 5670\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.1282\n",
      "Average policy_loss: 0.9477\n",
      "Average value_loss: 0.1805\n",
      "Replay buffer size: 5770\n",
      "Time taken: 72.4s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.1193\n",
      "Average policy_loss: 0.9400\n",
      "Average value_loss: 0.1793\n",
      "Replay buffer size: 5857\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.1269\n",
      "Average policy_loss: 0.9445\n",
      "Average value_loss: 0.1823\n",
      "Replay buffer size: 5949\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.1287\n",
      "Average policy_loss: 0.9497\n",
      "Average value_loss: 0.1790\n",
      "Replay buffer size: 6037\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.1181\n",
      "Average policy_loss: 0.9401\n",
      "Average value_loss: 0.1780\n",
      "Replay buffer size: 6123\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.1262\n",
      "Average policy_loss: 0.9475\n",
      "Average value_loss: 0.1788\n",
      "Replay buffer size: 6213\n",
      "Time taken: 72.7s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.1206\n",
      "Average policy_loss: 0.9421\n",
      "Average value_loss: 0.1785\n",
      "Replay buffer size: 6301\n",
      "Time taken: 23.9s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.1240\n",
      "Average policy_loss: 0.9432\n",
      "Average value_loss: 0.1808\n",
      "Replay buffer size: 6388\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.1234\n",
      "Average policy_loss: 0.9461\n",
      "Average value_loss: 0.1773\n",
      "Replay buffer size: 6480\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.1197\n",
      "Average policy_loss: 0.9403\n",
      "Average value_loss: 0.1794\n",
      "Replay buffer size: 6563\n",
      "Time taken: 24.0s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.1154\n",
      "Average policy_loss: 0.9378\n",
      "Average value_loss: 0.1776\n",
      "Replay buffer size: 6655\n",
      "Time taken: 73.6s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.1123\n",
      "Average policy_loss: 0.9353\n",
      "Average value_loss: 0.1770\n",
      "Replay buffer size: 6750\n",
      "Time taken: 22.4s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.1168\n",
      "Average policy_loss: 0.9374\n",
      "Average value_loss: 0.1794\n",
      "Replay buffer size: 6830\n",
      "Time taken: 24.5s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.1033\n",
      "Average policy_loss: 0.9254\n",
      "Average value_loss: 0.1779\n",
      "Replay buffer size: 6914\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.1192\n",
      "Average policy_loss: 0.9370\n",
      "Average value_loss: 0.1822\n",
      "Replay buffer size: 7003\n",
      "Time taken: 23.9s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.1174\n",
      "Average policy_loss: 0.9352\n",
      "Average value_loss: 0.1821\n",
      "Replay buffer size: 7082\n",
      "Time taken: 74.3s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.1097\n",
      "Average policy_loss: 0.9316\n",
      "Average value_loss: 0.1782\n",
      "Replay buffer size: 7167\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.1112\n",
      "Average policy_loss: 0.9302\n",
      "Average value_loss: 0.1809\n",
      "Replay buffer size: 7252\n",
      "Time taken: 24.9s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.1103\n",
      "Average policy_loss: 0.9281\n",
      "Average value_loss: 0.1822\n",
      "Replay buffer size: 7342\n",
      "Time taken: 23.8s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.1156\n",
      "Average policy_loss: 0.9346\n",
      "Average value_loss: 0.1811\n",
      "Replay buffer size: 7438\n",
      "Time taken: 25.4s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.1144\n",
      "Average policy_loss: 0.9335\n",
      "Average value_loss: 0.1809\n",
      "Replay buffer size: 7526\n",
      "Time taken: 75.7s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.1093\n",
      "Average policy_loss: 0.9285\n",
      "Average value_loss: 0.1808\n",
      "Replay buffer size: 7616\n",
      "Time taken: 23.7s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.1139\n",
      "Average policy_loss: 0.9341\n",
      "Average value_loss: 0.1798\n",
      "Replay buffer size: 7704\n",
      "Time taken: 24.6s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.1050\n",
      "Average policy_loss: 0.9294\n",
      "Average value_loss: 0.1756\n",
      "Replay buffer size: 7797\n",
      "Time taken: 23.9s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.1080\n",
      "Average policy_loss: 0.9291\n",
      "Average value_loss: 0.1789\n",
      "Replay buffer size: 7888\n",
      "Time taken: 25.5s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.1014\n",
      "Average policy_loss: 0.9251\n",
      "Average value_loss: 0.1763\n",
      "Replay buffer size: 7987\n",
      "Time taken: 76.8s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.1055\n",
      "Average policy_loss: 0.9276\n",
      "Average value_loss: 0.1779\n",
      "Replay buffer size: 8072\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.1088\n",
      "Average policy_loss: 0.9303\n",
      "Average value_loss: 0.1785\n",
      "Replay buffer size: 8165\n",
      "Time taken: 23.8s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.1022\n",
      "Average policy_loss: 0.9236\n",
      "Average value_loss: 0.1786\n",
      "Replay buffer size: 8260\n",
      "Time taken: 24.5s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.1061\n",
      "Average policy_loss: 0.9279\n",
      "Average value_loss: 0.1782\n",
      "Replay buffer size: 8355\n",
      "Time taken: 23.3s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.1002\n",
      "Average policy_loss: 0.9253\n",
      "Average value_loss: 0.1749\n",
      "Replay buffer size: 8441\n",
      "Time taken: 77.0s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.0996\n",
      "Average policy_loss: 0.9237\n",
      "Average value_loss: 0.1759\n",
      "Replay buffer size: 8532\n",
      "Time taken: 23.2s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.1001\n",
      "Average policy_loss: 0.9229\n",
      "Average value_loss: 0.1772\n",
      "Replay buffer size: 8621\n",
      "Time taken: 24.4s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.1021\n",
      "Average policy_loss: 0.9250\n",
      "Average value_loss: 0.1771\n",
      "Replay buffer size: 8705\n",
      "Time taken: 23.2s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.1024\n",
      "Average policy_loss: 0.9228\n",
      "Average value_loss: 0.1796\n",
      "Replay buffer size: 8798\n",
      "Time taken: 24.0s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.0963\n",
      "Average policy_loss: 0.9186\n",
      "Average value_loss: 0.1776\n",
      "Replay buffer size: 8890\n",
      "Time taken: 76.8s\n",
      "\n",
      "Training complete! Total time: 0.9h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇██</td></tr><tr><td>iteration_time</td><td>▁▁▁▆▁▁▁▁▇▁▇▂▇▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▇▂▂▁█▁█▁▂▁██</td></tr><tr><td>loss</td><td>█▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▃▅▆▂▃▅▂▅▅▇▃▅▂▆▄▆▂▃▄▆█▆▂▂▃▄▆▃▅▄▆▁▅▁▃▄▅█▆▆</td></tr><tr><td>policy_loss</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>██▇▆▆▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.15</td></tr><tr><td>buffer_size</td><td>8890</td></tr><tr><td>iteration_time</td><td>76.78697</td></tr><tr><td>loss</td><td>1.09626</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>92</td></tr><tr><td>policy_loss</td><td>0.91862</td></tr><tr><td>total_time_hours</td><td>0.89752</td></tr><tr><td>value_loss</td><td>0.17764</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effortless-sweep-3</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/gmj6nbnq' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/gmj6nbnq</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250228_233439-gmj6nbnq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zno139it with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02312932352647822\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.12951020836647031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005114952601260686\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_002848-zno139it</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/zno139it' target=\"_blank\">fresh-sweep-4</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/zno139it' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/zno139it</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.4415\n",
      "Average policy_loss: 1.2819\n",
      "Average value_loss: 0.1596\n",
      "Replay buffer size: 80\n",
      "Time taken: 6.6s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 0.4980\n",
      "Average policy_loss: 0.4389\n",
      "Average value_loss: 0.0590\n",
      "Replay buffer size: 160\n",
      "Time taken: 7.1s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 0.3726\n",
      "Average policy_loss: 0.3358\n",
      "Average value_loss: 0.0368\n",
      "Replay buffer size: 238\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.4152\n",
      "Average policy_loss: 0.3569\n",
      "Average value_loss: 0.0583\n",
      "Replay buffer size: 322\n",
      "Time taken: 8.8s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.4165\n",
      "Average policy_loss: 0.3731\n",
      "Average value_loss: 0.0434\n",
      "Replay buffer size: 394\n",
      "Time taken: 30.1s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.3836\n",
      "Average policy_loss: 0.3518\n",
      "Average value_loss: 0.0318\n",
      "Replay buffer size: 468\n",
      "Time taken: 7.2s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.6039\n",
      "Average policy_loss: 0.4168\n",
      "Average value_loss: 0.1870\n",
      "Replay buffer size: 566\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.6226\n",
      "Average policy_loss: 0.3800\n",
      "Average value_loss: 0.2426\n",
      "Replay buffer size: 656\n",
      "Time taken: 7.4s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.5370\n",
      "Average policy_loss: 0.3681\n",
      "Average value_loss: 0.1689\n",
      "Replay buffer size: 754\n",
      "Time taken: 6.4s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.4950\n",
      "Average policy_loss: 0.3457\n",
      "Average value_loss: 0.1493\n",
      "Replay buffer size: 850\n",
      "Time taken: 30.5s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.5166\n",
      "Average policy_loss: 0.3665\n",
      "Average value_loss: 0.1501\n",
      "Replay buffer size: 938\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.5915\n",
      "Average policy_loss: 0.4086\n",
      "Average value_loss: 0.1829\n",
      "Replay buffer size: 1022\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.5689\n",
      "Average policy_loss: 0.3880\n",
      "Average value_loss: 0.1809\n",
      "Replay buffer size: 1118\n",
      "Time taken: 8.5s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.5981\n",
      "Average policy_loss: 0.4028\n",
      "Average value_loss: 0.1953\n",
      "Replay buffer size: 1194\n",
      "Time taken: 9.4s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.6193\n",
      "Average policy_loss: 0.4153\n",
      "Average value_loss: 0.2040\n",
      "Replay buffer size: 1271\n",
      "Time taken: 35.5s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.6448\n",
      "Average policy_loss: 0.4374\n",
      "Average value_loss: 0.2074\n",
      "Replay buffer size: 1357\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.6656\n",
      "Average policy_loss: 0.4614\n",
      "Average value_loss: 0.2043\n",
      "Replay buffer size: 1430\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 65 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.6802\n",
      "Average policy_loss: 0.4661\n",
      "Average value_loss: 0.2141\n",
      "Replay buffer size: 1495\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.6808\n",
      "Average policy_loss: 0.4746\n",
      "Average value_loss: 0.2063\n",
      "Replay buffer size: 1567\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.7014\n",
      "Average policy_loss: 0.4967\n",
      "Average value_loss: 0.2048\n",
      "Replay buffer size: 1641\n",
      "Time taken: 36.8s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.6887\n",
      "Average policy_loss: 0.4935\n",
      "Average value_loss: 0.1952\n",
      "Replay buffer size: 1717\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.7013\n",
      "Average policy_loss: 0.5037\n",
      "Average value_loss: 0.1976\n",
      "Replay buffer size: 1791\n",
      "Time taken: 9.7s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.7050\n",
      "Average policy_loss: 0.5091\n",
      "Average value_loss: 0.1958\n",
      "Replay buffer size: 1857\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.6933\n",
      "Average policy_loss: 0.5090\n",
      "Average value_loss: 0.1844\n",
      "Replay buffer size: 1927\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.7086\n",
      "Average policy_loss: 0.5155\n",
      "Average value_loss: 0.1931\n",
      "Replay buffer size: 1996\n",
      "Time taken: 37.6s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.7073\n",
      "Average policy_loss: 0.5180\n",
      "Average value_loss: 0.1892\n",
      "Replay buffer size: 2068\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.6984\n",
      "Average policy_loss: 0.5183\n",
      "Average value_loss: 0.1802\n",
      "Replay buffer size: 2142\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.6957\n",
      "Average policy_loss: 0.5172\n",
      "Average value_loss: 0.1785\n",
      "Replay buffer size: 2216\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.7085\n",
      "Average policy_loss: 0.5260\n",
      "Average value_loss: 0.1825\n",
      "Replay buffer size: 2288\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.7189\n",
      "Average policy_loss: 0.5368\n",
      "Average value_loss: 0.1821\n",
      "Replay buffer size: 2358\n",
      "Time taken: 37.4s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.7430\n",
      "Average policy_loss: 0.5482\n",
      "Average value_loss: 0.1948\n",
      "Replay buffer size: 2445\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.7553\n",
      "Average policy_loss: 0.5643\n",
      "Average value_loss: 0.1910\n",
      "Replay buffer size: 2539\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.7639\n",
      "Average policy_loss: 0.5697\n",
      "Average value_loss: 0.1942\n",
      "Replay buffer size: 2627\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.7723\n",
      "Average policy_loss: 0.5775\n",
      "Average value_loss: 0.1949\n",
      "Replay buffer size: 2725\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.7599\n",
      "Average policy_loss: 0.5765\n",
      "Average value_loss: 0.1834\n",
      "Replay buffer size: 2819\n",
      "Time taken: 42.1s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.7664\n",
      "Average policy_loss: 0.5786\n",
      "Average value_loss: 0.1878\n",
      "Replay buffer size: 2907\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.7827\n",
      "Average policy_loss: 0.5899\n",
      "Average value_loss: 0.1928\n",
      "Replay buffer size: 2997\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.7877\n",
      "Average policy_loss: 0.5965\n",
      "Average value_loss: 0.1912\n",
      "Replay buffer size: 3086\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.7873\n",
      "Average policy_loss: 0.6025\n",
      "Average value_loss: 0.1848\n",
      "Replay buffer size: 3178\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.7937\n",
      "Average policy_loss: 0.6077\n",
      "Average value_loss: 0.1861\n",
      "Replay buffer size: 3255\n",
      "Time taken: 42.8s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.7922\n",
      "Average policy_loss: 0.6053\n",
      "Average value_loss: 0.1869\n",
      "Replay buffer size: 3341\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.7944\n",
      "Average policy_loss: 0.6119\n",
      "Average value_loss: 0.1825\n",
      "Replay buffer size: 3429\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.8066\n",
      "Average policy_loss: 0.6205\n",
      "Average value_loss: 0.1861\n",
      "Replay buffer size: 3520\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.8200\n",
      "Average policy_loss: 0.6274\n",
      "Average value_loss: 0.1927\n",
      "Replay buffer size: 3605\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.8181\n",
      "Average policy_loss: 0.6271\n",
      "Average value_loss: 0.1910\n",
      "Replay buffer size: 3689\n",
      "Time taken: 43.1s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.8170\n",
      "Average policy_loss: 0.6340\n",
      "Average value_loss: 0.1830\n",
      "Replay buffer size: 3769\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.8168\n",
      "Average policy_loss: 0.6283\n",
      "Average value_loss: 0.1884\n",
      "Replay buffer size: 3847\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.8293\n",
      "Average policy_loss: 0.6457\n",
      "Average value_loss: 0.1835\n",
      "Replay buffer size: 3929\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.8292\n",
      "Average policy_loss: 0.6457\n",
      "Average value_loss: 0.1836\n",
      "Replay buffer size: 4011\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.8374\n",
      "Average policy_loss: 0.6541\n",
      "Average value_loss: 0.1833\n",
      "Replay buffer size: 4085\n",
      "Time taken: 38.7s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.8315\n",
      "Average policy_loss: 0.6547\n",
      "Average value_loss: 0.1768\n",
      "Replay buffer size: 4165\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.8338\n",
      "Average policy_loss: 0.6547\n",
      "Average value_loss: 0.1790\n",
      "Replay buffer size: 4247\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.8442\n",
      "Average policy_loss: 0.6582\n",
      "Average value_loss: 0.1860\n",
      "Replay buffer size: 4324\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.8492\n",
      "Average policy_loss: 0.6645\n",
      "Average value_loss: 0.1848\n",
      "Replay buffer size: 4404\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.8378\n",
      "Average policy_loss: 0.6608\n",
      "Average value_loss: 0.1770\n",
      "Replay buffer size: 4482\n",
      "Time taken: 41.8s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.8454\n",
      "Average policy_loss: 0.6633\n",
      "Average value_loss: 0.1821\n",
      "Replay buffer size: 4562\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.8381\n",
      "Average policy_loss: 0.6633\n",
      "Average value_loss: 0.1748\n",
      "Replay buffer size: 4636\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.8508\n",
      "Average policy_loss: 0.6744\n",
      "Average value_loss: 0.1764\n",
      "Replay buffer size: 4718\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.8570\n",
      "Average policy_loss: 0.6778\n",
      "Average value_loss: 0.1792\n",
      "Replay buffer size: 4796\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.8552\n",
      "Average policy_loss: 0.6773\n",
      "Average value_loss: 0.1779\n",
      "Replay buffer size: 4870\n",
      "Time taken: 41.5s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.8564\n",
      "Average policy_loss: 0.6787\n",
      "Average value_loss: 0.1777\n",
      "Replay buffer size: 4948\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.8630\n",
      "Average policy_loss: 0.6806\n",
      "Average value_loss: 0.1824\n",
      "Replay buffer size: 5023\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.8550\n",
      "Average policy_loss: 0.6792\n",
      "Average value_loss: 0.1757\n",
      "Replay buffer size: 5105\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.8583\n",
      "Average policy_loss: 0.6826\n",
      "Average value_loss: 0.1756\n",
      "Replay buffer size: 5179\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.8649\n",
      "Average policy_loss: 0.6895\n",
      "Average value_loss: 0.1754\n",
      "Replay buffer size: 5261\n",
      "Time taken: 40.9s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.8640\n",
      "Average policy_loss: 0.6930\n",
      "Average value_loss: 0.1710\n",
      "Replay buffer size: 5341\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.8651\n",
      "Average policy_loss: 0.6941\n",
      "Average value_loss: 0.1710\n",
      "Replay buffer size: 5414\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.8741\n",
      "Average policy_loss: 0.6945\n",
      "Average value_loss: 0.1796\n",
      "Replay buffer size: 5495\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.8722\n",
      "Average policy_loss: 0.6961\n",
      "Average value_loss: 0.1761\n",
      "Replay buffer size: 5575\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.8841\n",
      "Average policy_loss: 0.7044\n",
      "Average value_loss: 0.1796\n",
      "Replay buffer size: 5657\n",
      "Time taken: 46.2s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.8838\n",
      "Average policy_loss: 0.7028\n",
      "Average value_loss: 0.1810\n",
      "Replay buffer size: 5734\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.8800\n",
      "Average policy_loss: 0.7084\n",
      "Average value_loss: 0.1716\n",
      "Replay buffer size: 5814\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.8875\n",
      "Average policy_loss: 0.7103\n",
      "Average value_loss: 0.1773\n",
      "Replay buffer size: 5888\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.8852\n",
      "Average policy_loss: 0.7094\n",
      "Average value_loss: 0.1758\n",
      "Replay buffer size: 5964\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.8857\n",
      "Average policy_loss: 0.7091\n",
      "Average value_loss: 0.1765\n",
      "Replay buffer size: 6046\n",
      "Time taken: 46.1s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.9361\n",
      "Average policy_loss: 0.7276\n",
      "Average value_loss: 0.2085\n",
      "Replay buffer size: 6126\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.0857\n",
      "Average policy_loss: 0.8043\n",
      "Average value_loss: 0.2814\n",
      "Replay buffer size: 6201\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.9267\n",
      "Average policy_loss: 0.7270\n",
      "Average value_loss: 0.1997\n",
      "Replay buffer size: 6273\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.9930\n",
      "Average policy_loss: 0.7477\n",
      "Average value_loss: 0.2454\n",
      "Replay buffer size: 6355\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.9181\n",
      "Average policy_loss: 0.7265\n",
      "Average value_loss: 0.1916\n",
      "Replay buffer size: 6432\n",
      "Time taken: 43.2s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.8966\n",
      "Average policy_loss: 0.7188\n",
      "Average value_loss: 0.1778\n",
      "Replay buffer size: 6505\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.8922\n",
      "Average policy_loss: 0.7153\n",
      "Average value_loss: 0.1769\n",
      "Replay buffer size: 6597\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.9097\n",
      "Average policy_loss: 0.7237\n",
      "Average value_loss: 0.1860\n",
      "Replay buffer size: 6681\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.9466\n",
      "Average policy_loss: 0.7369\n",
      "Average value_loss: 0.2097\n",
      "Replay buffer size: 6776\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.9190\n",
      "Average policy_loss: 0.7261\n",
      "Average value_loss: 0.1929\n",
      "Replay buffer size: 6855\n",
      "Time taken: 47.9s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.9279\n",
      "Average policy_loss: 0.7344\n",
      "Average value_loss: 0.1935\n",
      "Replay buffer size: 6936\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.9240\n",
      "Average policy_loss: 0.7354\n",
      "Average value_loss: 0.1885\n",
      "Replay buffer size: 7024\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.9317\n",
      "Average policy_loss: 0.7368\n",
      "Average value_loss: 0.1949\n",
      "Replay buffer size: 7114\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.9332\n",
      "Average policy_loss: 0.7401\n",
      "Average value_loss: 0.1930\n",
      "Replay buffer size: 7195\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.9432\n",
      "Average policy_loss: 0.7527\n",
      "Average value_loss: 0.1905\n",
      "Replay buffer size: 7277\n",
      "Time taken: 52.3s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.9458\n",
      "Average policy_loss: 0.7446\n",
      "Average value_loss: 0.2012\n",
      "Replay buffer size: 7363\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.9486\n",
      "Average policy_loss: 0.7512\n",
      "Average value_loss: 0.1974\n",
      "Replay buffer size: 7444\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.9675\n",
      "Average policy_loss: 0.7612\n",
      "Average value_loss: 0.2063\n",
      "Replay buffer size: 7518\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.9582\n",
      "Average policy_loss: 0.7587\n",
      "Average value_loss: 0.1994\n",
      "Replay buffer size: 7593\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.9562\n",
      "Average policy_loss: 0.7535\n",
      "Average value_loss: 0.2027\n",
      "Replay buffer size: 7675\n",
      "Time taken: 53.8s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.9747\n",
      "Average policy_loss: 0.7649\n",
      "Average value_loss: 0.2098\n",
      "Replay buffer size: 7755\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.0768\n",
      "Average policy_loss: 0.7929\n",
      "Average value_loss: 0.2839\n",
      "Replay buffer size: 7830\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.9909\n",
      "Average policy_loss: 0.7738\n",
      "Average value_loss: 0.2172\n",
      "Replay buffer size: 7910\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.9686\n",
      "Average policy_loss: 0.7642\n",
      "Average value_loss: 0.2044\n",
      "Replay buffer size: 7988\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.9607\n",
      "Average policy_loss: 0.7570\n",
      "Average value_loss: 0.2037\n",
      "Replay buffer size: 8061\n",
      "Time taken: 53.3s\n",
      "\n",
      "Training complete! Total time: 0.5h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>iteration_time</td><td>▁▁▁▁▅▁▆▂▂▁▂▂▂▂▂▇▂▂▂▂▂▂▂▂▂▂▇▂▂█▂█▇▂█▂▃▂▃▃</td></tr><tr><td>loss</td><td>▂▁▁▄▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇█▇▇▇▇███</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▄▅▂██▅▁▂▃▃▂▃▃▂▂▇▆▇▄▆▄▄▄▃▄▃▅▃▄▅▂▅▅▇▄▅▃▃▄▃</td></tr><tr><td>policy_loss</td><td>█▁▁▁▂▂▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>value_loss</td><td>▂▁▅▇▅▆▆▅▅▅▆▅▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▇▅▅▅▆▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.25</td></tr><tr><td>buffer_size</td><td>8061</td></tr><tr><td>iteration_time</td><td>53.33186</td></tr><tr><td>loss</td><td>0.96067</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>73</td></tr><tr><td>policy_loss</td><td>0.75696</td></tr><tr><td>total_time_hours</td><td>0.49783</td></tr><tr><td>value_loss</td><td>0.20372</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-sweep-4</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/zno139it' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/zno139it</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 24 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_002848-zno139it/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: axgf7yh4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0030123667783113514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: medium\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.6408811770146178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.00022273427496412733\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_005849-axgf7yh4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/axgf7yh4' target=\"_blank\">celestial-sweep-5</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/axgf7yh4' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/axgf7yh4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 2.1487\n",
      "Average policy_loss: 1.5257\n",
      "Average value_loss: 0.6230\n",
      "Replay buffer size: 89\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.6744\n",
      "Average policy_loss: 1.1825\n",
      "Average value_loss: 0.4919\n",
      "Replay buffer size: 168\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.4395\n",
      "Average policy_loss: 1.1220\n",
      "Average value_loss: 0.3175\n",
      "Replay buffer size: 259\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.3731\n",
      "Average policy_loss: 1.1266\n",
      "Average value_loss: 0.2465\n",
      "Replay buffer size: 347\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.3822\n",
      "Average policy_loss: 1.1151\n",
      "Average value_loss: 0.2672\n",
      "Replay buffer size: 427\n",
      "Time taken: 56.4s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.3438\n",
      "Average policy_loss: 1.1057\n",
      "Average value_loss: 0.2381\n",
      "Replay buffer size: 515\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.3257\n",
      "Average policy_loss: 1.0948\n",
      "Average value_loss: 0.2310\n",
      "Replay buffer size: 600\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.3246\n",
      "Average policy_loss: 1.1004\n",
      "Average value_loss: 0.2242\n",
      "Replay buffer size: 677\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.3297\n",
      "Average policy_loss: 1.1116\n",
      "Average value_loss: 0.2181\n",
      "Replay buffer size: 749\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.3458\n",
      "Average policy_loss: 1.1262\n",
      "Average value_loss: 0.2196\n",
      "Replay buffer size: 824\n",
      "Time taken: 52.8s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.3162\n",
      "Average policy_loss: 1.1102\n",
      "Average value_loss: 0.2061\n",
      "Replay buffer size: 904\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.3155\n",
      "Average policy_loss: 1.1146\n",
      "Average value_loss: 0.2008\n",
      "Replay buffer size: 974\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.2909\n",
      "Average policy_loss: 1.0945\n",
      "Average value_loss: 0.1964\n",
      "Replay buffer size: 1053\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.2754\n",
      "Average policy_loss: 1.0875\n",
      "Average value_loss: 0.1880\n",
      "Replay buffer size: 1131\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.2656\n",
      "Average policy_loss: 1.0785\n",
      "Average value_loss: 0.1871\n",
      "Replay buffer size: 1207\n",
      "Time taken: 46.8s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.2675\n",
      "Average policy_loss: 1.0741\n",
      "Average value_loss: 0.1935\n",
      "Replay buffer size: 1287\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.2553\n",
      "Average policy_loss: 1.0736\n",
      "Average value_loss: 0.1817\n",
      "Replay buffer size: 1363\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.2476\n",
      "Average policy_loss: 1.0590\n",
      "Average value_loss: 0.1885\n",
      "Replay buffer size: 1440\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.2347\n",
      "Average policy_loss: 1.0535\n",
      "Average value_loss: 0.1813\n",
      "Replay buffer size: 1514\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.2225\n",
      "Average policy_loss: 1.0475\n",
      "Average value_loss: 0.1750\n",
      "Replay buffer size: 1588\n",
      "Time taken: 42.1s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.2283\n",
      "Average policy_loss: 1.0502\n",
      "Average value_loss: 0.1781\n",
      "Replay buffer size: 1662\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.2238\n",
      "Average policy_loss: 1.0476\n",
      "Average value_loss: 0.1762\n",
      "Replay buffer size: 1740\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.2177\n",
      "Average policy_loss: 1.0445\n",
      "Average value_loss: 0.1732\n",
      "Replay buffer size: 1818\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.2111\n",
      "Average policy_loss: 1.0421\n",
      "Average value_loss: 0.1690\n",
      "Replay buffer size: 1894\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.2037\n",
      "Average policy_loss: 1.0386\n",
      "Average value_loss: 0.1651\n",
      "Replay buffer size: 1972\n",
      "Time taken: 42.9s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.1839\n",
      "Average policy_loss: 1.0165\n",
      "Average value_loss: 0.1674\n",
      "Replay buffer size: 2046\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.1752\n",
      "Average policy_loss: 1.0139\n",
      "Average value_loss: 0.1613\n",
      "Replay buffer size: 2122\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.1777\n",
      "Average policy_loss: 1.0199\n",
      "Average value_loss: 0.1578\n",
      "Replay buffer size: 2194\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.1636\n",
      "Average policy_loss: 1.0086\n",
      "Average value_loss: 0.1550\n",
      "Replay buffer size: 2270\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.1604\n",
      "Average policy_loss: 1.0040\n",
      "Average value_loss: 0.1565\n",
      "Replay buffer size: 2345\n",
      "Time taken: 40.7s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.1557\n",
      "Average policy_loss: 0.9935\n",
      "Average value_loss: 0.1622\n",
      "Replay buffer size: 2419\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.1538\n",
      "Average policy_loss: 0.9953\n",
      "Average value_loss: 0.1586\n",
      "Replay buffer size: 2493\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.1442\n",
      "Average policy_loss: 0.9864\n",
      "Average value_loss: 0.1577\n",
      "Replay buffer size: 2562\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.1408\n",
      "Average policy_loss: 0.9819\n",
      "Average value_loss: 0.1589\n",
      "Replay buffer size: 2637\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.1451\n",
      "Average policy_loss: 0.9824\n",
      "Average value_loss: 0.1628\n",
      "Replay buffer size: 2706\n",
      "Time taken: 44.1s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.1354\n",
      "Average policy_loss: 0.9750\n",
      "Average value_loss: 0.1604\n",
      "Replay buffer size: 2782\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.1386\n",
      "Average policy_loss: 0.9793\n",
      "Average value_loss: 0.1593\n",
      "Replay buffer size: 2864\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.1439\n",
      "Average policy_loss: 0.9780\n",
      "Average value_loss: 0.1659\n",
      "Replay buffer size: 2944\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.1354\n",
      "Average policy_loss: 0.9712\n",
      "Average value_loss: 0.1642\n",
      "Replay buffer size: 3027\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.1407\n",
      "Average policy_loss: 0.9707\n",
      "Average value_loss: 0.1700\n",
      "Replay buffer size: 3101\n",
      "Time taken: 44.5s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.1338\n",
      "Average policy_loss: 0.9618\n",
      "Average value_loss: 0.1720\n",
      "Replay buffer size: 3187\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.1419\n",
      "Average policy_loss: 0.9683\n",
      "Average value_loss: 0.1736\n",
      "Replay buffer size: 3268\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.1398\n",
      "Average policy_loss: 0.9631\n",
      "Average value_loss: 0.1767\n",
      "Replay buffer size: 3359\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.1319\n",
      "Average policy_loss: 0.9522\n",
      "Average value_loss: 0.1797\n",
      "Replay buffer size: 3448\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.1407\n",
      "Average policy_loss: 0.9615\n",
      "Average value_loss: 0.1792\n",
      "Replay buffer size: 3523\n",
      "Time taken: 48.3s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.1401\n",
      "Average policy_loss: 0.9621\n",
      "Average value_loss: 0.1780\n",
      "Replay buffer size: 3609\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.1413\n",
      "Average policy_loss: 0.9638\n",
      "Average value_loss: 0.1775\n",
      "Replay buffer size: 3697\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.1366\n",
      "Average policy_loss: 0.9596\n",
      "Average value_loss: 0.1770\n",
      "Replay buffer size: 3782\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.1405\n",
      "Average policy_loss: 0.9621\n",
      "Average value_loss: 0.1784\n",
      "Replay buffer size: 3864\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.1346\n",
      "Average policy_loss: 0.9612\n",
      "Average value_loss: 0.1734\n",
      "Replay buffer size: 3942\n",
      "Time taken: 47.9s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.1252\n",
      "Average policy_loss: 0.9528\n",
      "Average value_loss: 0.1725\n",
      "Replay buffer size: 4022\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.1394\n",
      "Average policy_loss: 0.9626\n",
      "Average value_loss: 0.1768\n",
      "Replay buffer size: 4106\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.1458\n",
      "Average policy_loss: 0.9738\n",
      "Average value_loss: 0.1721\n",
      "Replay buffer size: 4188\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.1437\n",
      "Average policy_loss: 0.9656\n",
      "Average value_loss: 0.1781\n",
      "Replay buffer size: 4274\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.1461\n",
      "Average policy_loss: 0.9646\n",
      "Average value_loss: 0.1815\n",
      "Replay buffer size: 4353\n",
      "Time taken: 49.2s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.1489\n",
      "Average policy_loss: 0.9670\n",
      "Average value_loss: 0.1819\n",
      "Replay buffer size: 4442\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.1569\n",
      "Average policy_loss: 0.9675\n",
      "Average value_loss: 0.1893\n",
      "Replay buffer size: 4520\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.1460\n",
      "Average policy_loss: 0.9597\n",
      "Average value_loss: 0.1862\n",
      "Replay buffer size: 4600\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.1483\n",
      "Average policy_loss: 0.9621\n",
      "Average value_loss: 0.1862\n",
      "Replay buffer size: 4689\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.1524\n",
      "Average policy_loss: 0.9645\n",
      "Average value_loss: 0.1879\n",
      "Replay buffer size: 4775\n",
      "Time taken: 50.2s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.1473\n",
      "Average policy_loss: 0.9629\n",
      "Average value_loss: 0.1844\n",
      "Replay buffer size: 4858\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.1587\n",
      "Average policy_loss: 0.9650\n",
      "Average value_loss: 0.1937\n",
      "Replay buffer size: 4939\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.1608\n",
      "Average policy_loss: 0.9622\n",
      "Average value_loss: 0.1986\n",
      "Replay buffer size: 5029\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.1585\n",
      "Average policy_loss: 0.9626\n",
      "Average value_loss: 0.1959\n",
      "Replay buffer size: 5112\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.1737\n",
      "Average policy_loss: 0.9762\n",
      "Average value_loss: 0.1975\n",
      "Replay buffer size: 5196\n",
      "Time taken: 51.3s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.1609\n",
      "Average policy_loss: 0.9687\n",
      "Average value_loss: 0.1922\n",
      "Replay buffer size: 5285\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.1632\n",
      "Average policy_loss: 0.9704\n",
      "Average value_loss: 0.1928\n",
      "Replay buffer size: 5372\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.1580\n",
      "Average policy_loss: 0.9635\n",
      "Average value_loss: 0.1944\n",
      "Replay buffer size: 5464\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.1563\n",
      "Average policy_loss: 0.9588\n",
      "Average value_loss: 0.1976\n",
      "Replay buffer size: 5552\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.1614\n",
      "Average policy_loss: 0.9639\n",
      "Average value_loss: 0.1975\n",
      "Replay buffer size: 5639\n",
      "Time taken: 52.0s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.1732\n",
      "Average policy_loss: 0.9662\n",
      "Average value_loss: 0.2070\n",
      "Replay buffer size: 5726\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.1742\n",
      "Average policy_loss: 0.9726\n",
      "Average value_loss: 0.2017\n",
      "Replay buffer size: 5814\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.1666\n",
      "Average policy_loss: 0.9650\n",
      "Average value_loss: 0.2017\n",
      "Replay buffer size: 5904\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.1681\n",
      "Average policy_loss: 0.9669\n",
      "Average value_loss: 0.2012\n",
      "Replay buffer size: 5992\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.1620\n",
      "Average policy_loss: 0.9661\n",
      "Average value_loss: 0.1959\n",
      "Replay buffer size: 6075\n",
      "Time taken: 53.9s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.1604\n",
      "Average policy_loss: 0.9615\n",
      "Average value_loss: 0.1989\n",
      "Replay buffer size: 6161\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.1623\n",
      "Average policy_loss: 0.9633\n",
      "Average value_loss: 0.1990\n",
      "Replay buffer size: 6251\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.1578\n",
      "Average policy_loss: 0.9584\n",
      "Average value_loss: 0.1994\n",
      "Replay buffer size: 6341\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.1594\n",
      "Average policy_loss: 0.9572\n",
      "Average value_loss: 0.2022\n",
      "Replay buffer size: 6425\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.1592\n",
      "Average policy_loss: 0.9627\n",
      "Average value_loss: 0.1966\n",
      "Replay buffer size: 6518\n",
      "Time taken: 54.7s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.1643\n",
      "Average policy_loss: 0.9646\n",
      "Average value_loss: 0.1997\n",
      "Replay buffer size: 6600\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.1674\n",
      "Average policy_loss: 0.9651\n",
      "Average value_loss: 0.2023\n",
      "Replay buffer size: 6693\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.1623\n",
      "Average policy_loss: 0.9645\n",
      "Average value_loss: 0.1978\n",
      "Replay buffer size: 6785\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.1737\n",
      "Average policy_loss: 0.9701\n",
      "Average value_loss: 0.2035\n",
      "Replay buffer size: 6874\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.1546\n",
      "Average policy_loss: 0.9560\n",
      "Average value_loss: 0.1986\n",
      "Replay buffer size: 6963\n",
      "Time taken: 53.7s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.1654\n",
      "Average policy_loss: 0.9622\n",
      "Average value_loss: 0.2032\n",
      "Replay buffer size: 7059\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.1589\n",
      "Average policy_loss: 0.9584\n",
      "Average value_loss: 0.2005\n",
      "Replay buffer size: 7152\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.1702\n",
      "Average policy_loss: 0.9685\n",
      "Average value_loss: 0.2017\n",
      "Replay buffer size: 7241\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.1674\n",
      "Average policy_loss: 0.9650\n",
      "Average value_loss: 0.2025\n",
      "Replay buffer size: 7322\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.1608\n",
      "Average policy_loss: 0.9590\n",
      "Average value_loss: 0.2018\n",
      "Replay buffer size: 7418\n",
      "Time taken: 47.7s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.1612\n",
      "Average policy_loss: 0.9631\n",
      "Average value_loss: 0.1981\n",
      "Replay buffer size: 7502\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.1659\n",
      "Average policy_loss: 0.9643\n",
      "Average value_loss: 0.2016\n",
      "Replay buffer size: 7598\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.1600\n",
      "Average policy_loss: 0.9604\n",
      "Average value_loss: 0.1995\n",
      "Replay buffer size: 7676\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.1553\n",
      "Average policy_loss: 0.9547\n",
      "Average value_loss: 0.2006\n",
      "Replay buffer size: 7763\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.1577\n",
      "Average policy_loss: 0.9607\n",
      "Average value_loss: 0.1970\n",
      "Replay buffer size: 7857\n",
      "Time taken: 53.1s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.1653\n",
      "Average policy_loss: 0.9639\n",
      "Average value_loss: 0.2014\n",
      "Replay buffer size: 7946\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.1624\n",
      "Average policy_loss: 0.9619\n",
      "Average value_loss: 0.2005\n",
      "Replay buffer size: 8033\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.1706\n",
      "Average policy_loss: 0.9689\n",
      "Average value_loss: 0.2017\n",
      "Replay buffer size: 8114\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.1647\n",
      "Average policy_loss: 0.9646\n",
      "Average value_loss: 0.2001\n",
      "Replay buffer size: 8197\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.1722\n",
      "Average policy_loss: 0.9712\n",
      "Average value_loss: 0.2010\n",
      "Replay buffer size: 8279\n",
      "Time taken: 55.4s\n",
      "\n",
      "Training complete! Total time: 0.6h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>iteration_time</td><td>▂▂█▂▇▁▁▆▁▁▁▁▁▁▁▂▂▂▂▂▂▇▂▇▂▂▂▂▂█▂▂█▂▂█▇▂▂█</td></tr><tr><td>loss</td><td>█▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▇▆▄▅▂▄▁▃▃▃▃▃▃▂▃▂▂▃▁▄▇▃▅▄▄▆▅▆▆▅▄▇▆█▄█▃▆▆▄</td></tr><tr><td>policy_loss</td><td>█▇█▇▆▆▆▅▅▅▅▄▄▄▃▂▂▂▂▂▂▁▁▁▁▁▁▂▂▁▂▁▁▁▂▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.25</td></tr><tr><td>buffer_size</td><td>8279</td></tr><tr><td>iteration_time</td><td>55.43388</td></tr><tr><td>loss</td><td>1.17218</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>82</td></tr><tr><td>policy_loss</td><td>0.97116</td></tr><tr><td>total_time_hours</td><td>0.61343</td></tr><tr><td>value_loss</td><td>0.20102</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-sweep-5</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/axgf7yh4' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/axgf7yh4</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 22 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_005849-axgf7yh4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kh2a625t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.6908936633823125e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.664563195460991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 4.528343525113816e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_013545-kh2a625t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kh2a625t' target=\"_blank\">lunar-sweep-6</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kh2a625t' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kh2a625t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 4.4561\n",
      "Average policy_loss: 3.3945\n",
      "Average value_loss: 1.0615\n",
      "Replay buffer size: 93\n",
      "Time taken: 4.8s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 2.8106\n",
      "Average policy_loss: 1.7705\n",
      "Average value_loss: 1.0401\n",
      "Replay buffer size: 191\n",
      "Time taken: 6.0s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 2.6104\n",
      "Average policy_loss: 1.5903\n",
      "Average value_loss: 1.0201\n",
      "Replay buffer size: 291\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 2.3972\n",
      "Average policy_loss: 1.3655\n",
      "Average value_loss: 1.0317\n",
      "Replay buffer size: 387\n",
      "Time taken: 5.0s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 2.3027\n",
      "Average policy_loss: 1.2862\n",
      "Average value_loss: 1.0165\n",
      "Replay buffer size: 484\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 2.1325\n",
      "Average policy_loss: 1.1136\n",
      "Average value_loss: 1.0189\n",
      "Replay buffer size: 580\n",
      "Time taken: 5.8s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 2.0389\n",
      "Average policy_loss: 1.0235\n",
      "Average value_loss: 1.0154\n",
      "Replay buffer size: 680\n",
      "Time taken: 4.9s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 2.0774\n",
      "Average policy_loss: 1.0629\n",
      "Average value_loss: 1.0145\n",
      "Replay buffer size: 780\n",
      "Time taken: 5.7s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 2.0840\n",
      "Average policy_loss: 1.0607\n",
      "Average value_loss: 1.0233\n",
      "Replay buffer size: 875\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.9477\n",
      "Average policy_loss: 0.9330\n",
      "Average value_loss: 1.0147\n",
      "Replay buffer size: 975\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.9941\n",
      "Average policy_loss: 0.9803\n",
      "Average value_loss: 1.0138\n",
      "Replay buffer size: 1075\n",
      "Time taken: 6.2s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.9849\n",
      "Average policy_loss: 0.9706\n",
      "Average value_loss: 1.0142\n",
      "Replay buffer size: 1173\n",
      "Time taken: 5.7s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 2.0091\n",
      "Average policy_loss: 0.9896\n",
      "Average value_loss: 1.0195\n",
      "Replay buffer size: 1271\n",
      "Time taken: 7.7s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.9496\n",
      "Average policy_loss: 0.9335\n",
      "Average value_loss: 1.0160\n",
      "Replay buffer size: 1371\n",
      "Time taken: 6.1s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.9632\n",
      "Average policy_loss: 0.9768\n",
      "Average value_loss: 0.9864\n",
      "Replay buffer size: 1468\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.9538\n",
      "Average policy_loss: 0.9893\n",
      "Average value_loss: 0.9645\n",
      "Replay buffer size: 1564\n",
      "Time taken: 7.6s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.9521\n",
      "Average policy_loss: 1.0048\n",
      "Average value_loss: 0.9474\n",
      "Replay buffer size: 1657\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.9627\n",
      "Average policy_loss: 1.0497\n",
      "Average value_loss: 0.9130\n",
      "Replay buffer size: 1755\n",
      "Time taken: 7.3s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.9611\n",
      "Average policy_loss: 1.0786\n",
      "Average value_loss: 0.8825\n",
      "Replay buffer size: 1852\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 15.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.9440\n",
      "Average policy_loss: 1.0669\n",
      "Average value_loss: 0.8770\n",
      "Replay buffer size: 1943\n",
      "Time taken: 27.3s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.9527\n",
      "Average policy_loss: 1.0858\n",
      "Average value_loss: 0.8669\n",
      "Replay buffer size: 2036\n",
      "Time taken: 7.9s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.9704\n",
      "Average policy_loss: 1.1038\n",
      "Average value_loss: 0.8665\n",
      "Replay buffer size: 2131\n",
      "Time taken: 7.3s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.9349\n",
      "Average policy_loss: 1.0787\n",
      "Average value_loss: 0.8562\n",
      "Replay buffer size: 2229\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.9289\n",
      "Average policy_loss: 1.0691\n",
      "Average value_loss: 0.8598\n",
      "Replay buffer size: 2326\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.8499\n",
      "Average policy_loss: 1.0070\n",
      "Average value_loss: 0.8429\n",
      "Replay buffer size: 2426\n",
      "Time taken: 26.9s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.8382\n",
      "Average policy_loss: 1.0178\n",
      "Average value_loss: 0.8204\n",
      "Replay buffer size: 2522\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.8102\n",
      "Average policy_loss: 1.0103\n",
      "Average value_loss: 0.7999\n",
      "Replay buffer size: 2622\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.8295\n",
      "Average policy_loss: 1.0406\n",
      "Average value_loss: 0.7889\n",
      "Replay buffer size: 2717\n",
      "Time taken: 7.9s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.8474\n",
      "Average policy_loss: 1.0545\n",
      "Average value_loss: 0.7929\n",
      "Replay buffer size: 2814\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.8289\n",
      "Average policy_loss: 1.0386\n",
      "Average value_loss: 0.7903\n",
      "Replay buffer size: 2911\n",
      "Time taken: 27.7s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.7820\n",
      "Average policy_loss: 0.9988\n",
      "Average value_loss: 0.7832\n",
      "Replay buffer size: 3006\n",
      "Time taken: 8.1s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.7948\n",
      "Average policy_loss: 1.0113\n",
      "Average value_loss: 0.7835\n",
      "Replay buffer size: 3099\n",
      "Time taken: 8.1s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.7980\n",
      "Average policy_loss: 1.0190\n",
      "Average value_loss: 0.7791\n",
      "Replay buffer size: 3199\n",
      "Time taken: 7.1s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.7774\n",
      "Average policy_loss: 1.0116\n",
      "Average value_loss: 0.7658\n",
      "Replay buffer size: 3299\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 45.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.7737\n",
      "Average policy_loss: 1.0070\n",
      "Average value_loss: 0.7668\n",
      "Replay buffer size: 3390\n",
      "Time taken: 27.3s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.7427\n",
      "Average policy_loss: 0.9852\n",
      "Average value_loss: 0.7575\n",
      "Replay buffer size: 3490\n",
      "Time taken: 7.3s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.7413\n",
      "Average policy_loss: 0.9921\n",
      "Average value_loss: 0.7492\n",
      "Replay buffer size: 3590\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.7205\n",
      "Average policy_loss: 0.9784\n",
      "Average value_loss: 0.7421\n",
      "Replay buffer size: 3688\n",
      "Time taken: 7.3s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.6825\n",
      "Average policy_loss: 0.9527\n",
      "Average value_loss: 0.7298\n",
      "Replay buffer size: 3784\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.6980\n",
      "Average policy_loss: 0.9577\n",
      "Average value_loss: 0.7403\n",
      "Replay buffer size: 3877\n",
      "Time taken: 28.2s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.6947\n",
      "Average policy_loss: 0.9661\n",
      "Average value_loss: 0.7287\n",
      "Replay buffer size: 3973\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.6894\n",
      "Average policy_loss: 0.9703\n",
      "Average value_loss: 0.7191\n",
      "Replay buffer size: 4073\n",
      "Time taken: 7.2s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.6888\n",
      "Average policy_loss: 0.9676\n",
      "Average value_loss: 0.7211\n",
      "Replay buffer size: 4167\n",
      "Time taken: 7.2s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.6489\n",
      "Average policy_loss: 0.9445\n",
      "Average value_loss: 0.7043\n",
      "Replay buffer size: 4265\n",
      "Time taken: 7.9s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.6478\n",
      "Average policy_loss: 0.9484\n",
      "Average value_loss: 0.6994\n",
      "Replay buffer size: 4361\n",
      "Time taken: 26.1s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.6325\n",
      "Average policy_loss: 0.9427\n",
      "Average value_loss: 0.6898\n",
      "Replay buffer size: 4458\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.6505\n",
      "Average policy_loss: 0.9563\n",
      "Average value_loss: 0.6942\n",
      "Replay buffer size: 4558\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.6276\n",
      "Average policy_loss: 0.9514\n",
      "Average value_loss: 0.6762\n",
      "Replay buffer size: 4648\n",
      "Time taken: 7.9s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.6182\n",
      "Average policy_loss: 0.9587\n",
      "Average value_loss: 0.6596\n",
      "Replay buffer size: 4743\n",
      "Time taken: 7.6s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 55.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.5777\n",
      "Average policy_loss: 0.9475\n",
      "Average value_loss: 0.6302\n",
      "Replay buffer size: 4832\n",
      "Time taken: 27.0s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.5673\n",
      "Average policy_loss: 0.9462\n",
      "Average value_loss: 0.6211\n",
      "Replay buffer size: 4928\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.5415\n",
      "Average policy_loss: 0.9366\n",
      "Average value_loss: 0.6049\n",
      "Replay buffer size: 5020\n",
      "Time taken: 7.4s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.5288\n",
      "Average policy_loss: 0.9433\n",
      "Average value_loss: 0.5855\n",
      "Replay buffer size: 5110\n",
      "Time taken: 7.8s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.5115\n",
      "Average policy_loss: 0.9300\n",
      "Average value_loss: 0.5815\n",
      "Replay buffer size: 5206\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 55.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.5164\n",
      "Average policy_loss: 0.9450\n",
      "Average value_loss: 0.5714\n",
      "Replay buffer size: 5300\n",
      "Time taken: 28.3s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.4902\n",
      "Average policy_loss: 0.9229\n",
      "Average value_loss: 0.5673\n",
      "Replay buffer size: 5394\n",
      "Time taken: 6.4s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.4993\n",
      "Average policy_loss: 0.9380\n",
      "Average value_loss: 0.5613\n",
      "Replay buffer size: 5482\n",
      "Time taken: 7.6s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.4859\n",
      "Average policy_loss: 0.9274\n",
      "Average value_loss: 0.5584\n",
      "Replay buffer size: 5578\n",
      "Time taken: 7.3s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.4613\n",
      "Average policy_loss: 0.9169\n",
      "Average value_loss: 0.5444\n",
      "Replay buffer size: 5676\n",
      "Time taken: 7.1s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 50.00%, Draw rate = 40.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.4538\n",
      "Average policy_loss: 0.9082\n",
      "Average value_loss: 0.5456\n",
      "Replay buffer size: 5773\n",
      "Time taken: 28.4s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.4790\n",
      "Average policy_loss: 0.9404\n",
      "Average value_loss: 0.5386\n",
      "Replay buffer size: 5869\n",
      "Time taken: 7.4s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.4652\n",
      "Average policy_loss: 0.9334\n",
      "Average value_loss: 0.5318\n",
      "Replay buffer size: 5968\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.4433\n",
      "Average policy_loss: 0.9076\n",
      "Average value_loss: 0.5358\n",
      "Replay buffer size: 6068\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.4666\n",
      "Average policy_loss: 0.9482\n",
      "Average value_loss: 0.5185\n",
      "Replay buffer size: 6165\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.4330\n",
      "Average policy_loss: 0.9158\n",
      "Average value_loss: 0.5172\n",
      "Replay buffer size: 6254\n",
      "Time taken: 27.6s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.4023\n",
      "Average policy_loss: 0.8848\n",
      "Average value_loss: 0.5175\n",
      "Replay buffer size: 6348\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.4125\n",
      "Average policy_loss: 0.9017\n",
      "Average value_loss: 0.5109\n",
      "Replay buffer size: 6446\n",
      "Time taken: 6.3s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.4058\n",
      "Average policy_loss: 0.8975\n",
      "Average value_loss: 0.5083\n",
      "Replay buffer size: 6542\n",
      "Time taken: 7.1s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.3914\n",
      "Average policy_loss: 0.8968\n",
      "Average value_loss: 0.4946\n",
      "Replay buffer size: 6638\n",
      "Time taken: 8.8s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.3988\n",
      "Average policy_loss: 0.8974\n",
      "Average value_loss: 0.5015\n",
      "Replay buffer size: 6730\n",
      "Time taken: 27.0s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.4073\n",
      "Average policy_loss: 0.9143\n",
      "Average value_loss: 0.4930\n",
      "Replay buffer size: 6826\n",
      "Time taken: 7.3s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.4001\n",
      "Average policy_loss: 0.9013\n",
      "Average value_loss: 0.4987\n",
      "Replay buffer size: 6926\n",
      "Time taken: 7.8s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.3694\n",
      "Average policy_loss: 0.8824\n",
      "Average value_loss: 0.4870\n",
      "Replay buffer size: 7024\n",
      "Time taken: 6.7s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.3591\n",
      "Average policy_loss: 0.8778\n",
      "Average value_loss: 0.4813\n",
      "Replay buffer size: 7106\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.3816\n",
      "Average policy_loss: 0.8936\n",
      "Average value_loss: 0.4880\n",
      "Replay buffer size: 7202\n",
      "Time taken: 27.2s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.3655\n",
      "Average policy_loss: 0.8875\n",
      "Average value_loss: 0.4780\n",
      "Replay buffer size: 7292\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.3702\n",
      "Average policy_loss: 0.8939\n",
      "Average value_loss: 0.4763\n",
      "Replay buffer size: 7392\n",
      "Time taken: 7.7s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.3507\n",
      "Average policy_loss: 0.8742\n",
      "Average value_loss: 0.4765\n",
      "Replay buffer size: 7489\n",
      "Time taken: 7.8s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.3367\n",
      "Average policy_loss: 0.8637\n",
      "Average value_loss: 0.4730\n",
      "Replay buffer size: 7580\n",
      "Time taken: 7.7s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.3479\n",
      "Average policy_loss: 0.8789\n",
      "Average value_loss: 0.4690\n",
      "Replay buffer size: 7674\n",
      "Time taken: 28.4s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.3268\n",
      "Average policy_loss: 0.8669\n",
      "Average value_loss: 0.4599\n",
      "Replay buffer size: 7764\n",
      "Time taken: 7.9s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.3377\n",
      "Average policy_loss: 0.8701\n",
      "Average value_loss: 0.4676\n",
      "Replay buffer size: 7851\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.3157\n",
      "Average policy_loss: 0.8540\n",
      "Average value_loss: 0.4617\n",
      "Replay buffer size: 7948\n",
      "Time taken: 7.6s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.3116\n",
      "Average policy_loss: 0.8575\n",
      "Average value_loss: 0.4541\n",
      "Replay buffer size: 8046\n",
      "Time taken: 7.8s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.3107\n",
      "Average policy_loss: 0.8607\n",
      "Average value_loss: 0.4500\n",
      "Replay buffer size: 8134\n",
      "Time taken: 26.8s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.3085\n",
      "Average policy_loss: 0.8596\n",
      "Average value_loss: 0.4489\n",
      "Replay buffer size: 8223\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.3164\n",
      "Average policy_loss: 0.8732\n",
      "Average value_loss: 0.4432\n",
      "Replay buffer size: 8307\n",
      "Time taken: 6.7s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.3044\n",
      "Average policy_loss: 0.8667\n",
      "Average value_loss: 0.4377\n",
      "Replay buffer size: 8403\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.3009\n",
      "Average policy_loss: 0.8661\n",
      "Average value_loss: 0.4348\n",
      "Replay buffer size: 8503\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.3009\n",
      "Average policy_loss: 0.8643\n",
      "Average value_loss: 0.4366\n",
      "Replay buffer size: 8592\n",
      "Time taken: 27.7s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.2560\n",
      "Average policy_loss: 0.8336\n",
      "Average value_loss: 0.4223\n",
      "Replay buffer size: 8690\n",
      "Time taken: 7.2s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.2618\n",
      "Average policy_loss: 0.8394\n",
      "Average value_loss: 0.4225\n",
      "Replay buffer size: 8784\n",
      "Time taken: 8.1s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.2542\n",
      "Average policy_loss: 0.8346\n",
      "Average value_loss: 0.4196\n",
      "Replay buffer size: 8880\n",
      "Time taken: 6.9s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.2865\n",
      "Average policy_loss: 0.8571\n",
      "Average value_loss: 0.4294\n",
      "Replay buffer size: 8971\n",
      "Time taken: 7.6s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.2715\n",
      "Average policy_loss: 0.8476\n",
      "Average value_loss: 0.4240\n",
      "Replay buffer size: 9061\n",
      "Time taken: 29.1s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.2587\n",
      "Average policy_loss: 0.8438\n",
      "Average value_loss: 0.4149\n",
      "Replay buffer size: 9151\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.2541\n",
      "Average policy_loss: 0.8390\n",
      "Average value_loss: 0.4150\n",
      "Replay buffer size: 9246\n",
      "Time taken: 6.3s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.2236\n",
      "Average policy_loss: 0.8156\n",
      "Average value_loss: 0.4080\n",
      "Replay buffer size: 9336\n",
      "Time taken: 6.2s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.2467\n",
      "Average policy_loss: 0.8405\n",
      "Average value_loss: 0.4062\n",
      "Replay buffer size: 9429\n",
      "Time taken: 8.3s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 50.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.2306\n",
      "Average policy_loss: 0.8287\n",
      "Average value_loss: 0.4020\n",
      "Replay buffer size: 9525\n",
      "Time taken: 24.8s\n",
      "\n",
      "Training complete! Total time: 0.3h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>iteration_time</td><td>▁▁▅▁▁▅▁▂▁▆▂▂▂█▂▂█▂▂▇▂▂▂█▂█▁▂▂▂▂█▂▂▂█▂█▂▁</td></tr><tr><td>loss</td><td>█▆▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▅█▆█▇▇▆▇▇▅▇█▇▅███▇▇▄▆▅▆▅▅▇▇▇▆▄▂▇▇▃▁▃▇▅▄▄</td></tr><tr><td>policy_loss</td><td>█▄▂▂▁▁▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█████▇▆▆▆▆▅▅▅▅▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>0.85</td></tr><tr><td>buffer_size</td><td>9525</td></tr><tr><td>iteration_time</td><td>24.78189</td></tr><tr><td>loss</td><td>1.23062</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>96</td></tr><tr><td>policy_loss</td><td>0.82865</td></tr><tr><td>total_time_hours</td><td>0.30604</td></tr><tr><td>value_loss</td><td>0.40197</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lunar-sweep-6</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kh2a625t' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kh2a625t</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 22 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_013545-kh2a625t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 27j6qc22 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00022019063459171505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.8407042315628009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.002038351667423441\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_015423-27j6qc22</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/27j6qc22' target=\"_blank\">fast-sweep-7</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/27j6qc22' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/27j6qc22</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.3786\n",
      "Average policy_loss: 0.7106\n",
      "Average value_loss: 0.6680\n",
      "Replay buffer size: 69\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 2.0586\n",
      "Average policy_loss: 1.0200\n",
      "Average value_loss: 1.0386\n",
      "Replay buffer size: 143\n",
      "Time taken: 5.3s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.7712\n",
      "Average policy_loss: 0.8054\n",
      "Average value_loss: 0.9658\n",
      "Replay buffer size: 219\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.1766\n",
      "Average policy_loss: 0.7661\n",
      "Average value_loss: 0.4104\n",
      "Replay buffer size: 294\n",
      "Time taken: 4.3s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.0805\n",
      "Average policy_loss: 0.7422\n",
      "Average value_loss: 0.3383\n",
      "Replay buffer size: 360\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.9782\n",
      "Average policy_loss: 0.6727\n",
      "Average value_loss: 0.3055\n",
      "Replay buffer size: 428\n",
      "Time taken: 5.6s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 67 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.9396\n",
      "Average policy_loss: 0.6582\n",
      "Average value_loss: 0.2814\n",
      "Replay buffer size: 495\n",
      "Time taken: 5.3s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.8891\n",
      "Average policy_loss: 0.6327\n",
      "Average value_loss: 0.2563\n",
      "Replay buffer size: 567\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.8643\n",
      "Average policy_loss: 0.6187\n",
      "Average value_loss: 0.2456\n",
      "Replay buffer size: 638\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.8088\n",
      "Average policy_loss: 0.5835\n",
      "Average value_loss: 0.2253\n",
      "Replay buffer size: 706\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.7783\n",
      "Average policy_loss: 0.5651\n",
      "Average value_loss: 0.2132\n",
      "Replay buffer size: 778\n",
      "Time taken: 5.4s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.7584\n",
      "Average policy_loss: 0.5617\n",
      "Average value_loss: 0.1968\n",
      "Replay buffer size: 840\n",
      "Time taken: 4.7s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.7233\n",
      "Average policy_loss: 0.5415\n",
      "Average value_loss: 0.1818\n",
      "Replay buffer size: 902\n",
      "Time taken: 4.9s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.6896\n",
      "Average policy_loss: 0.5251\n",
      "Average value_loss: 0.1645\n",
      "Replay buffer size: 964\n",
      "Time taken: 4.2s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.6702\n",
      "Average policy_loss: 0.5165\n",
      "Average value_loss: 0.1538\n",
      "Replay buffer size: 1030\n",
      "Time taken: 18.5s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 65 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.6526\n",
      "Average policy_loss: 0.5056\n",
      "Average value_loss: 0.1470\n",
      "Replay buffer size: 1095\n",
      "Time taken: 4.4s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.6409\n",
      "Average policy_loss: 0.5022\n",
      "Average value_loss: 0.1387\n",
      "Replay buffer size: 1157\n",
      "Time taken: 4.7s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.6265\n",
      "Average policy_loss: 0.4960\n",
      "Average value_loss: 0.1305\n",
      "Replay buffer size: 1221\n",
      "Time taken: 4.5s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 65 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.6110\n",
      "Average policy_loss: 0.4872\n",
      "Average value_loss: 0.1238\n",
      "Replay buffer size: 1286\n",
      "Time taken: 4.7s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.6118\n",
      "Average policy_loss: 0.4869\n",
      "Average value_loss: 0.1250\n",
      "Replay buffer size: 1348\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.5881\n",
      "Average policy_loss: 0.4759\n",
      "Average value_loss: 0.1122\n",
      "Replay buffer size: 1410\n",
      "Time taken: 4.6s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 60 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.5704\n",
      "Average policy_loss: 0.4625\n",
      "Average value_loss: 0.1080\n",
      "Replay buffer size: 1470\n",
      "Time taken: 4.2s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.6002\n",
      "Average policy_loss: 0.4782\n",
      "Average value_loss: 0.1219\n",
      "Replay buffer size: 1538\n",
      "Time taken: 4.8s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.5697\n",
      "Average policy_loss: 0.4635\n",
      "Average value_loss: 0.1062\n",
      "Replay buffer size: 1602\n",
      "Time taken: 4.6s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.5664\n",
      "Average policy_loss: 0.4603\n",
      "Average value_loss: 0.1061\n",
      "Replay buffer size: 1666\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 60 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.5553\n",
      "Average policy_loss: 0.4517\n",
      "Average value_loss: 0.1036\n",
      "Replay buffer size: 1726\n",
      "Time taken: 4.7s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.5601\n",
      "Average policy_loss: 0.4530\n",
      "Average value_loss: 0.1071\n",
      "Replay buffer size: 1792\n",
      "Time taken: 4.4s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 60 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.5341\n",
      "Average policy_loss: 0.4368\n",
      "Average value_loss: 0.0973\n",
      "Replay buffer size: 1852\n",
      "Time taken: 4.2s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.5379\n",
      "Average policy_loss: 0.4424\n",
      "Average value_loss: 0.0955\n",
      "Replay buffer size: 1924\n",
      "Time taken: 4.8s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.5288\n",
      "Average policy_loss: 0.4403\n",
      "Average value_loss: 0.0885\n",
      "Replay buffer size: 1990\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 67 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.5279\n",
      "Average policy_loss: 0.4401\n",
      "Average value_loss: 0.0878\n",
      "Replay buffer size: 2057\n",
      "Time taken: 4.9s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.5208\n",
      "Average policy_loss: 0.4354\n",
      "Average value_loss: 0.0854\n",
      "Replay buffer size: 2119\n",
      "Time taken: 4.5s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.5143\n",
      "Average policy_loss: 0.4306\n",
      "Average value_loss: 0.0838\n",
      "Replay buffer size: 2181\n",
      "Time taken: 4.4s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.5119\n",
      "Average policy_loss: 0.4308\n",
      "Average value_loss: 0.0811\n",
      "Replay buffer size: 2249\n",
      "Time taken: 4.8s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.4968\n",
      "Average policy_loss: 0.4178\n",
      "Average value_loss: 0.0789\n",
      "Replay buffer size: 2311\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.4950\n",
      "Average policy_loss: 0.4191\n",
      "Average value_loss: 0.0759\n",
      "Replay buffer size: 2375\n",
      "Time taken: 4.5s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.4929\n",
      "Average policy_loss: 0.4207\n",
      "Average value_loss: 0.0721\n",
      "Replay buffer size: 2439\n",
      "Time taken: 4.6s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.4873\n",
      "Average policy_loss: 0.4141\n",
      "Average value_loss: 0.0731\n",
      "Replay buffer size: 2501\n",
      "Time taken: 4.4s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.4930\n",
      "Average policy_loss: 0.4196\n",
      "Average value_loss: 0.0733\n",
      "Replay buffer size: 2563\n",
      "Time taken: 4.7s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.4927\n",
      "Average policy_loss: 0.4246\n",
      "Average value_loss: 0.0681\n",
      "Replay buffer size: 2631\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.4826\n",
      "Average policy_loss: 0.4136\n",
      "Average value_loss: 0.0690\n",
      "Replay buffer size: 2695\n",
      "Time taken: 4.4s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 65 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.4811\n",
      "Average policy_loss: 0.4136\n",
      "Average value_loss: 0.0675\n",
      "Replay buffer size: 2760\n",
      "Time taken: 5.0s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.4805\n",
      "Average policy_loss: 0.4152\n",
      "Average value_loss: 0.0654\n",
      "Replay buffer size: 2822\n",
      "Time taken: 4.3s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 67 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.4820\n",
      "Average policy_loss: 0.4146\n",
      "Average value_loss: 0.0674\n",
      "Replay buffer size: 2889\n",
      "Time taken: 5.0s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.4792\n",
      "Average policy_loss: 0.4134\n",
      "Average value_loss: 0.0658\n",
      "Replay buffer size: 2951\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 60 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.4743\n",
      "Average policy_loss: 0.4122\n",
      "Average value_loss: 0.0621\n",
      "Replay buffer size: 3011\n",
      "Time taken: 4.7s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.4710\n",
      "Average policy_loss: 0.4098\n",
      "Average value_loss: 0.0611\n",
      "Replay buffer size: 3077\n",
      "Time taken: 4.4s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.4662\n",
      "Average policy_loss: 0.4107\n",
      "Average value_loss: 0.0554\n",
      "Replay buffer size: 3147\n",
      "Time taken: 4.7s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.4641\n",
      "Average policy_loss: 0.4099\n",
      "Average value_loss: 0.0542\n",
      "Replay buffer size: 3209\n",
      "Time taken: 4.7s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.4624\n",
      "Average policy_loss: 0.4055\n",
      "Average value_loss: 0.0570\n",
      "Replay buffer size: 3271\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.4563\n",
      "Average policy_loss: 0.4035\n",
      "Average value_loss: 0.0528\n",
      "Replay buffer size: 3335\n",
      "Time taken: 4.5s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.4608\n",
      "Average policy_loss: 0.4065\n",
      "Average value_loss: 0.0542\n",
      "Replay buffer size: 3403\n",
      "Time taken: 4.7s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.4556\n",
      "Average policy_loss: 0.4012\n",
      "Average value_loss: 0.0544\n",
      "Replay buffer size: 3467\n",
      "Time taken: 4.4s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.4574\n",
      "Average policy_loss: 0.4009\n",
      "Average value_loss: 0.0565\n",
      "Replay buffer size: 3531\n",
      "Time taken: 4.2s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.4529\n",
      "Average policy_loss: 0.4020\n",
      "Average value_loss: 0.0509\n",
      "Replay buffer size: 3595\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.4564\n",
      "Average policy_loss: 0.4058\n",
      "Average value_loss: 0.0506\n",
      "Replay buffer size: 3657\n",
      "Time taken: 3.9s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.4456\n",
      "Average policy_loss: 0.3961\n",
      "Average value_loss: 0.0495\n",
      "Replay buffer size: 3725\n",
      "Time taken: 4.4s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 60 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.4480\n",
      "Average policy_loss: 0.3998\n",
      "Average value_loss: 0.0482\n",
      "Replay buffer size: 3785\n",
      "Time taken: 4.5s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.4447\n",
      "Average policy_loss: 0.3971\n",
      "Average value_loss: 0.0477\n",
      "Replay buffer size: 3857\n",
      "Time taken: 5.0s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.4484\n",
      "Average policy_loss: 0.3984\n",
      "Average value_loss: 0.0499\n",
      "Replay buffer size: 3919\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.4434\n",
      "Average policy_loss: 0.3944\n",
      "Average value_loss: 0.0489\n",
      "Replay buffer size: 3985\n",
      "Time taken: 4.3s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 60 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.4466\n",
      "Average policy_loss: 0.3974\n",
      "Average value_loss: 0.0492\n",
      "Replay buffer size: 4045\n",
      "Time taken: 4.3s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.4374\n",
      "Average policy_loss: 0.3913\n",
      "Average value_loss: 0.0462\n",
      "Replay buffer size: 4113\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.4451\n",
      "Average policy_loss: 0.3974\n",
      "Average value_loss: 0.0478\n",
      "Replay buffer size: 4183\n",
      "Time taken: 4.9s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.4431\n",
      "Average policy_loss: 0.3975\n",
      "Average value_loss: 0.0455\n",
      "Replay buffer size: 4253\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.4414\n",
      "Average policy_loss: 0.3973\n",
      "Average value_loss: 0.0442\n",
      "Replay buffer size: 4315\n",
      "Time taken: 4.4s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.4443\n",
      "Average policy_loss: 0.3980\n",
      "Average value_loss: 0.0463\n",
      "Replay buffer size: 4385\n",
      "Time taken: 5.0s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.4383\n",
      "Average policy_loss: 0.3949\n",
      "Average value_loss: 0.0434\n",
      "Replay buffer size: 4453\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.4393\n",
      "Average policy_loss: 0.3973\n",
      "Average value_loss: 0.0419\n",
      "Replay buffer size: 4521\n",
      "Time taken: 5.7s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.4347\n",
      "Average policy_loss: 0.3906\n",
      "Average value_loss: 0.0441\n",
      "Replay buffer size: 4585\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.4402\n",
      "Average policy_loss: 0.3946\n",
      "Average value_loss: 0.0455\n",
      "Replay buffer size: 4649\n",
      "Time taken: 4.5s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 67 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.4438\n",
      "Average policy_loss: 0.3982\n",
      "Average value_loss: 0.0456\n",
      "Replay buffer size: 4716\n",
      "Time taken: 4.8s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.4385\n",
      "Average policy_loss: 0.3935\n",
      "Average value_loss: 0.0450\n",
      "Replay buffer size: 4782\n",
      "Time taken: 4.3s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.4426\n",
      "Average policy_loss: 0.3984\n",
      "Average value_loss: 0.0442\n",
      "Replay buffer size: 4852\n",
      "Time taken: 4.6s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.4372\n",
      "Average policy_loss: 0.3939\n",
      "Average value_loss: 0.0433\n",
      "Replay buffer size: 4918\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.4403\n",
      "Average policy_loss: 0.3960\n",
      "Average value_loss: 0.0444\n",
      "Replay buffer size: 4990\n",
      "Time taken: 4.8s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.4396\n",
      "Average policy_loss: 0.3975\n",
      "Average value_loss: 0.0420\n",
      "Replay buffer size: 5066\n",
      "Time taken: 4.6s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.4370\n",
      "Average policy_loss: 0.3936\n",
      "Average value_loss: 0.0434\n",
      "Replay buffer size: 5128\n",
      "Time taken: 4.6s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.4413\n",
      "Average policy_loss: 0.3974\n",
      "Average value_loss: 0.0439\n",
      "Replay buffer size: 5190\n",
      "Time taken: 4.2s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 60 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.4315\n",
      "Average policy_loss: 0.3912\n",
      "Average value_loss: 0.0403\n",
      "Replay buffer size: 5250\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.4351\n",
      "Average policy_loss: 0.3936\n",
      "Average value_loss: 0.0415\n",
      "Replay buffer size: 5316\n",
      "Time taken: 5.4s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.4328\n",
      "Average policy_loss: 0.3896\n",
      "Average value_loss: 0.0431\n",
      "Replay buffer size: 5382\n",
      "Time taken: 4.6s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.4400\n",
      "Average policy_loss: 0.3965\n",
      "Average value_loss: 0.0435\n",
      "Replay buffer size: 5444\n",
      "Time taken: 4.3s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.4334\n",
      "Average policy_loss: 0.3906\n",
      "Average value_loss: 0.0429\n",
      "Replay buffer size: 5508\n",
      "Time taken: 4.1s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.4299\n",
      "Average policy_loss: 0.3903\n",
      "Average value_loss: 0.0395\n",
      "Replay buffer size: 5572\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.4285\n",
      "Average policy_loss: 0.3907\n",
      "Average value_loss: 0.0377\n",
      "Replay buffer size: 5642\n",
      "Time taken: 5.0s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.4358\n",
      "Average policy_loss: 0.3957\n",
      "Average value_loss: 0.0401\n",
      "Replay buffer size: 5706\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.4340\n",
      "Average policy_loss: 0.3899\n",
      "Average value_loss: 0.0441\n",
      "Replay buffer size: 5770\n",
      "Time taken: 4.3s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.4442\n",
      "Average policy_loss: 0.3956\n",
      "Average value_loss: 0.0486\n",
      "Replay buffer size: 5840\n",
      "Time taken: 5.2s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.4449\n",
      "Average policy_loss: 0.4019\n",
      "Average value_loss: 0.0430\n",
      "Replay buffer size: 5908\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.4365\n",
      "Average policy_loss: 0.3938\n",
      "Average value_loss: 0.0427\n",
      "Replay buffer size: 5976\n",
      "Time taken: 4.9s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.4315\n",
      "Average policy_loss: 0.3886\n",
      "Average value_loss: 0.0429\n",
      "Replay buffer size: 6042\n",
      "Time taken: 4.4s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.4420\n",
      "Average policy_loss: 0.3985\n",
      "Average value_loss: 0.0435\n",
      "Replay buffer size: 6112\n",
      "Time taken: 5.4s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.4390\n",
      "Average policy_loss: 0.3971\n",
      "Average value_loss: 0.0419\n",
      "Replay buffer size: 6176\n",
      "Time taken: 4.6s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.4421\n",
      "Average policy_loss: 0.3990\n",
      "Average value_loss: 0.0430\n",
      "Replay buffer size: 6240\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.4406\n",
      "Average policy_loss: 0.3971\n",
      "Average value_loss: 0.0435\n",
      "Replay buffer size: 6308\n",
      "Time taken: 4.7s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.4381\n",
      "Average policy_loss: 0.3973\n",
      "Average value_loss: 0.0408\n",
      "Replay buffer size: 6370\n",
      "Time taken: 4.5s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 60 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.4315\n",
      "Average policy_loss: 0.3912\n",
      "Average value_loss: 0.0403\n",
      "Replay buffer size: 6430\n",
      "Time taken: 4.3s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.4293\n",
      "Average policy_loss: 0.3864\n",
      "Average value_loss: 0.0429\n",
      "Replay buffer size: 6494\n",
      "Time taken: 4.6s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.4324\n",
      "Average policy_loss: 0.3916\n",
      "Average value_loss: 0.0408\n",
      "Replay buffer size: 6558\n",
      "Time taken: 18.0s\n",
      "\n",
      "Training complete! Total time: 0.2h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>iteration_time</td><td>▂▂▂▁▂▂▁▁▁▁▁▇▁▁▁▇▁▁▁▁▁▂▂▇▁▁▁▂▇▁▂▇▁█▁▁▁▂█▁</td></tr><tr><td>loss</td><td>█▇▄▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>██▄▄▆▃▂▃▃▃▄▂▂▃▃▅▄▄▂▃▃▃▅▁▆▃▄▄▆▄▂▂▄▃▆▅▅▃▅▁</td></tr><tr><td>policy_loss</td><td>█▆▅▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.15</td></tr><tr><td>buffer_size</td><td>6558</td></tr><tr><td>iteration_time</td><td>18.03187</td></tr><tr><td>loss</td><td>0.43243</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>64</td></tr><tr><td>policy_loss</td><td>0.39159</td></tr><tr><td>total_time_hours</td><td>0.20416</td></tr><tr><td>value_loss</td><td>0.04084</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-sweep-7</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/27j6qc22' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/27j6qc22</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 16 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_015423-27j6qc22/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jpt57a2u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.026750570538997133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: small\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.8864439875622776\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.02283766580110489\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_020646-jpt57a2u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/jpt57a2u' target=\"_blank\">stoic-sweep-8</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/jpt57a2u' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/jpt57a2u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 0.8244\n",
      "Average policy_loss: 0.6561\n",
      "Average value_loss: 0.1684\n",
      "Replay buffer size: 80\n",
      "Time taken: 5.8s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 0.4510\n",
      "Average policy_loss: 0.4410\n",
      "Average value_loss: 0.0099\n",
      "Replay buffer size: 158\n",
      "Time taken: 8.3s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 0.6549\n",
      "Average policy_loss: 0.5899\n",
      "Average value_loss: 0.0651\n",
      "Replay buffer size: 249\n",
      "Time taken: 18.5s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.7230\n",
      "Average policy_loss: 0.6243\n",
      "Average value_loss: 0.0986\n",
      "Replay buffer size: 330\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.7489\n",
      "Average policy_loss: 0.6328\n",
      "Average value_loss: 0.1161\n",
      "Replay buffer size: 423\n",
      "Time taken: 48.4s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.8079\n",
      "Average policy_loss: 0.6726\n",
      "Average value_loss: 0.1354\n",
      "Replay buffer size: 508\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.8092\n",
      "Average policy_loss: 0.6650\n",
      "Average value_loss: 0.1442\n",
      "Replay buffer size: 602\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.7873\n",
      "Average policy_loss: 0.6497\n",
      "Average value_loss: 0.1376\n",
      "Replay buffer size: 698\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.8146\n",
      "Average policy_loss: 0.6777\n",
      "Average value_loss: 0.1370\n",
      "Replay buffer size: 778\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.8816\n",
      "Average policy_loss: 0.7074\n",
      "Average value_loss: 0.1742\n",
      "Replay buffer size: 869\n",
      "Time taken: 46.5s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.8197\n",
      "Average policy_loss: 0.6950\n",
      "Average value_loss: 0.1246\n",
      "Replay buffer size: 955\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.8346\n",
      "Average policy_loss: 0.7153\n",
      "Average value_loss: 0.1193\n",
      "Replay buffer size: 1019\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.8304\n",
      "Average policy_loss: 0.7193\n",
      "Average value_loss: 0.1111\n",
      "Replay buffer size: 1087\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.0171\n",
      "Average policy_loss: 0.7753\n",
      "Average value_loss: 0.2418\n",
      "Replay buffer size: 1168\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.8841\n",
      "Average policy_loss: 0.7594\n",
      "Average value_loss: 0.1247\n",
      "Replay buffer size: 1244\n",
      "Time taken: 44.7s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.9027\n",
      "Average policy_loss: 0.7782\n",
      "Average value_loss: 0.1246\n",
      "Replay buffer size: 1331\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.9044\n",
      "Average policy_loss: 0.7820\n",
      "Average value_loss: 0.1224\n",
      "Replay buffer size: 1423\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.9398\n",
      "Average policy_loss: 0.8071\n",
      "Average value_loss: 0.1327\n",
      "Replay buffer size: 1502\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.9725\n",
      "Average policy_loss: 0.8233\n",
      "Average value_loss: 0.1492\n",
      "Replay buffer size: 1584\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.9444\n",
      "Average policy_loss: 0.8173\n",
      "Average value_loss: 0.1271\n",
      "Replay buffer size: 1675\n",
      "Time taken: 63.1s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.9849\n",
      "Average policy_loss: 0.8306\n",
      "Average value_loss: 0.1543\n",
      "Replay buffer size: 1770\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.9555\n",
      "Average policy_loss: 0.8267\n",
      "Average value_loss: 0.1288\n",
      "Replay buffer size: 1844\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.9503\n",
      "Average policy_loss: 0.8259\n",
      "Average value_loss: 0.1245\n",
      "Replay buffer size: 1942\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.9734\n",
      "Average policy_loss: 0.8394\n",
      "Average value_loss: 0.1341\n",
      "Replay buffer size: 2024\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.9925\n",
      "Average policy_loss: 0.8532\n",
      "Average value_loss: 0.1393\n",
      "Replay buffer size: 2108\n",
      "Time taken: 67.3s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.9908\n",
      "Average policy_loss: 0.8475\n",
      "Average value_loss: 0.1433\n",
      "Replay buffer size: 2198\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.0019\n",
      "Average policy_loss: 0.8575\n",
      "Average value_loss: 0.1444\n",
      "Replay buffer size: 2279\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.9872\n",
      "Average policy_loss: 0.8515\n",
      "Average value_loss: 0.1356\n",
      "Replay buffer size: 2364\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.0121\n",
      "Average policy_loss: 0.8609\n",
      "Average value_loss: 0.1512\n",
      "Replay buffer size: 2463\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.9930\n",
      "Average policy_loss: 0.8552\n",
      "Average value_loss: 0.1378\n",
      "Replay buffer size: 2558\n",
      "Time taken: 59.5s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.9900\n",
      "Average policy_loss: 0.8552\n",
      "Average value_loss: 0.1348\n",
      "Replay buffer size: 2652\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.9923\n",
      "Average policy_loss: 0.8596\n",
      "Average value_loss: 0.1327\n",
      "Replay buffer size: 2742\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.0152\n",
      "Average policy_loss: 0.8703\n",
      "Average value_loss: 0.1449\n",
      "Replay buffer size: 2825\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.0042\n",
      "Average policy_loss: 0.8675\n",
      "Average value_loss: 0.1368\n",
      "Replay buffer size: 2906\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.0042\n",
      "Average policy_loss: 0.8666\n",
      "Average value_loss: 0.1375\n",
      "Replay buffer size: 2994\n",
      "Time taken: 67.8s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.0096\n",
      "Average policy_loss: 0.8757\n",
      "Average value_loss: 0.1338\n",
      "Replay buffer size: 3083\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.0018\n",
      "Average policy_loss: 0.8683\n",
      "Average value_loss: 0.1335\n",
      "Replay buffer size: 3174\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.0009\n",
      "Average policy_loss: 0.8681\n",
      "Average value_loss: 0.1327\n",
      "Replay buffer size: 3264\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.0113\n",
      "Average policy_loss: 0.8752\n",
      "Average value_loss: 0.1362\n",
      "Replay buffer size: 3355\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.0016\n",
      "Average policy_loss: 0.8666\n",
      "Average value_loss: 0.1349\n",
      "Replay buffer size: 3451\n",
      "Time taken: 64.7s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.9954\n",
      "Average policy_loss: 0.8623\n",
      "Average value_loss: 0.1330\n",
      "Replay buffer size: 3545\n",
      "Time taken: 19.2s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.9971\n",
      "Average policy_loss: 0.8668\n",
      "Average value_loss: 0.1303\n",
      "Replay buffer size: 3627\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.9843\n",
      "Average policy_loss: 0.8572\n",
      "Average value_loss: 0.1271\n",
      "Replay buffer size: 3725\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.9956\n",
      "Average policy_loss: 0.8628\n",
      "Average value_loss: 0.1328\n",
      "Replay buffer size: 3816\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.9924\n",
      "Average policy_loss: 0.8665\n",
      "Average value_loss: 0.1259\n",
      "Replay buffer size: 3906\n",
      "Time taken: 66.2s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.9975\n",
      "Average policy_loss: 0.8665\n",
      "Average value_loss: 0.1310\n",
      "Replay buffer size: 4002\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.9736\n",
      "Average policy_loss: 0.8538\n",
      "Average value_loss: 0.1198\n",
      "Replay buffer size: 4093\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.9924\n",
      "Average policy_loss: 0.8652\n",
      "Average value_loss: 0.1272\n",
      "Replay buffer size: 4184\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.9801\n",
      "Average policy_loss: 0.8577\n",
      "Average value_loss: 0.1224\n",
      "Replay buffer size: 4278\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.9865\n",
      "Average policy_loss: 0.8602\n",
      "Average value_loss: 0.1264\n",
      "Replay buffer size: 4355\n",
      "Time taken: 68.1s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.9829\n",
      "Average policy_loss: 0.8593\n",
      "Average value_loss: 0.1236\n",
      "Replay buffer size: 4449\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.0034\n",
      "Average policy_loss: 0.8656\n",
      "Average value_loss: 0.1378\n",
      "Replay buffer size: 4546\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.9906\n",
      "Average policy_loss: 0.8568\n",
      "Average value_loss: 0.1338\n",
      "Replay buffer size: 4645\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.9699\n",
      "Average policy_loss: 0.8527\n",
      "Average value_loss: 0.1172\n",
      "Replay buffer size: 4738\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.9926\n",
      "Average policy_loss: 0.8599\n",
      "Average value_loss: 0.1327\n",
      "Replay buffer size: 4821\n",
      "Time taken: 69.6s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.9694\n",
      "Average policy_loss: 0.8522\n",
      "Average value_loss: 0.1172\n",
      "Replay buffer size: 4911\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.9729\n",
      "Average policy_loss: 0.8545\n",
      "Average value_loss: 0.1184\n",
      "Replay buffer size: 4997\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.9688\n",
      "Average policy_loss: 0.8510\n",
      "Average value_loss: 0.1177\n",
      "Replay buffer size: 5085\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.9850\n",
      "Average policy_loss: 0.8560\n",
      "Average value_loss: 0.1289\n",
      "Replay buffer size: 5178\n",
      "Time taken: 23.8s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.9705\n",
      "Average policy_loss: 0.8511\n",
      "Average value_loss: 0.1194\n",
      "Replay buffer size: 5270\n",
      "Time taken: 68.6s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.9702\n",
      "Average policy_loss: 0.8531\n",
      "Average value_loss: 0.1171\n",
      "Replay buffer size: 5367\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.9618\n",
      "Average policy_loss: 0.8460\n",
      "Average value_loss: 0.1158\n",
      "Replay buffer size: 5461\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.9717\n",
      "Average policy_loss: 0.8519\n",
      "Average value_loss: 0.1198\n",
      "Replay buffer size: 5550\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.9678\n",
      "Average policy_loss: 0.8507\n",
      "Average value_loss: 0.1171\n",
      "Replay buffer size: 5634\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.9694\n",
      "Average policy_loss: 0.8531\n",
      "Average value_loss: 0.1163\n",
      "Replay buffer size: 5727\n",
      "Time taken: 70.0s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.9789\n",
      "Average policy_loss: 0.8581\n",
      "Average value_loss: 0.1208\n",
      "Replay buffer size: 5813\n",
      "Time taken: 23.2s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.9918\n",
      "Average policy_loss: 0.8645\n",
      "Average value_loss: 0.1273\n",
      "Replay buffer size: 5903\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.9771\n",
      "Average policy_loss: 0.8578\n",
      "Average value_loss: 0.1193\n",
      "Replay buffer size: 5989\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.9725\n",
      "Average policy_loss: 0.8535\n",
      "Average value_loss: 0.1189\n",
      "Replay buffer size: 6077\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.9681\n",
      "Average policy_loss: 0.8504\n",
      "Average value_loss: 0.1177\n",
      "Replay buffer size: 6176\n",
      "Time taken: 66.6s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.9691\n",
      "Average policy_loss: 0.8519\n",
      "Average value_loss: 0.1172\n",
      "Replay buffer size: 6267\n",
      "Time taken: 23.1s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.9696\n",
      "Average policy_loss: 0.8522\n",
      "Average value_loss: 0.1174\n",
      "Replay buffer size: 6359\n",
      "Time taken: 24.8s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.9711\n",
      "Average policy_loss: 0.8545\n",
      "Average value_loss: 0.1166\n",
      "Replay buffer size: 6440\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.9700\n",
      "Average policy_loss: 0.8528\n",
      "Average value_loss: 0.1172\n",
      "Replay buffer size: 6528\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.0197\n",
      "Average policy_loss: 0.8737\n",
      "Average value_loss: 0.1460\n",
      "Replay buffer size: 6614\n",
      "Time taken: 70.0s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.9765\n",
      "Average policy_loss: 0.8607\n",
      "Average value_loss: 0.1158\n",
      "Replay buffer size: 6701\n",
      "Time taken: 23.6s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.9875\n",
      "Average policy_loss: 0.8623\n",
      "Average value_loss: 0.1253\n",
      "Replay buffer size: 6786\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.9808\n",
      "Average policy_loss: 0.8599\n",
      "Average value_loss: 0.1209\n",
      "Replay buffer size: 6865\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.9755\n",
      "Average policy_loss: 0.8601\n",
      "Average value_loss: 0.1153\n",
      "Replay buffer size: 6954\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.0012\n",
      "Average policy_loss: 0.8643\n",
      "Average value_loss: 0.1369\n",
      "Replay buffer size: 7041\n",
      "Time taken: 66.9s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.9768\n",
      "Average policy_loss: 0.8601\n",
      "Average value_loss: 0.1166\n",
      "Replay buffer size: 7129\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.9853\n",
      "Average policy_loss: 0.8657\n",
      "Average value_loss: 0.1196\n",
      "Replay buffer size: 7209\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.9788\n",
      "Average policy_loss: 0.8627\n",
      "Average value_loss: 0.1161\n",
      "Replay buffer size: 7302\n",
      "Time taken: 24.1s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.9840\n",
      "Average policy_loss: 0.8628\n",
      "Average value_loss: 0.1212\n",
      "Replay buffer size: 7389\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.9694\n",
      "Average policy_loss: 0.8538\n",
      "Average value_loss: 0.1157\n",
      "Replay buffer size: 7480\n",
      "Time taken: 71.9s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.9748\n",
      "Average policy_loss: 0.8564\n",
      "Average value_loss: 0.1185\n",
      "Replay buffer size: 7567\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.9753\n",
      "Average policy_loss: 0.8600\n",
      "Average value_loss: 0.1153\n",
      "Replay buffer size: 7656\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.9663\n",
      "Average policy_loss: 0.8524\n",
      "Average value_loss: 0.1140\n",
      "Replay buffer size: 7752\n",
      "Time taken: 24.0s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.9767\n",
      "Average policy_loss: 0.8633\n",
      "Average value_loss: 0.1135\n",
      "Replay buffer size: 7846\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.9744\n",
      "Average policy_loss: 0.8609\n",
      "Average value_loss: 0.1136\n",
      "Replay buffer size: 7930\n",
      "Time taken: 67.2s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.9768\n",
      "Average policy_loss: 0.8602\n",
      "Average value_loss: 0.1166\n",
      "Replay buffer size: 8022\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.9826\n",
      "Average policy_loss: 0.8624\n",
      "Average value_loss: 0.1202\n",
      "Replay buffer size: 8111\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.9747\n",
      "Average policy_loss: 0.8588\n",
      "Average value_loss: 0.1159\n",
      "Replay buffer size: 8209\n",
      "Time taken: 19.2s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.9716\n",
      "Average policy_loss: 0.8576\n",
      "Average value_loss: 0.1140\n",
      "Replay buffer size: 8298\n",
      "Time taken: 24.5s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.9775\n",
      "Average policy_loss: 0.8644\n",
      "Average value_loss: 0.1131\n",
      "Replay buffer size: 8385\n",
      "Time taken: 71.4s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.9701\n",
      "Average policy_loss: 0.8563\n",
      "Average value_loss: 0.1138\n",
      "Replay buffer size: 8478\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.9718\n",
      "Average policy_loss: 0.8570\n",
      "Average value_loss: 0.1148\n",
      "Replay buffer size: 8564\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.9814\n",
      "Average policy_loss: 0.8564\n",
      "Average value_loss: 0.1249\n",
      "Replay buffer size: 8662\n",
      "Time taken: 22.1s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.9648\n",
      "Average policy_loss: 0.8572\n",
      "Average value_loss: 0.1075\n",
      "Replay buffer size: 8758\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.9680\n",
      "Average policy_loss: 0.8556\n",
      "Average value_loss: 0.1124\n",
      "Replay buffer size: 8851\n",
      "Time taken: 68.5s\n",
      "\n",
      "Training complete! Total time: 0.8h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>iteration_time</td><td>▅▁▁▅▁▅▂▂▂▂▂▂▇▂▂▂▂▂▇▂▂█▂▂▂▂▂▂▂▂▂▇█▂▂▂▃█▂▂</td></tr><tr><td>loss</td><td>▂▁▄▄▆▆▆▇█▇██████▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▂▁▆▆▄▇▂▆▆▆▅▂▄▇▅█▅▆▁▇▆▅▆▇▆▆▂▄▄▂▆▄▆▅█▄▆▄█▆</td></tr><tr><td>policy_loss</td><td>▄▁▃▄▅▆▆▆▇▇██████████████████████████████</td></tr><tr><td>value_loss</td><td>▁▅█▇▇▆█▆▇██▇▇▇▇▇▆▆▆▇▅▆▆▅▆▆▅▅▅▆▆▅▆▅▅▅▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.15</td></tr><tr><td>buffer_size</td><td>8851</td></tr><tr><td>iteration_time</td><td>68.52719</td></tr><tr><td>loss</td><td>0.96798</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>93</td></tr><tr><td>policy_loss</td><td>0.8556</td></tr><tr><td>total_time_hours</td><td>0.79989</td></tr><tr><td>value_loss</td><td>0.11238</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stoic-sweep-8</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/jpt57a2u' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/jpt57a2u</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_020646-jpt57a2u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7aae0iuu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0040883839026580986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.3471896281740898\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.007121786630147011\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_025454-7aae0iuu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/7aae0iuu' target=\"_blank\">summer-sweep-9</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/7aae0iuu' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/7aae0iuu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 2.1128\n",
      "Average policy_loss: 1.7193\n",
      "Average value_loss: 0.3935\n",
      "Replay buffer size: 85\n",
      "Time taken: 7.4s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.1234\n",
      "Average policy_loss: 0.7409\n",
      "Average value_loss: 0.3824\n",
      "Replay buffer size: 175\n",
      "Time taken: 9.8s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.0090\n",
      "Average policy_loss: 0.6561\n",
      "Average value_loss: 0.3529\n",
      "Replay buffer size: 261\n",
      "Time taken: 8.8s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.9114\n",
      "Average policy_loss: 0.6532\n",
      "Average value_loss: 0.2582\n",
      "Replay buffer size: 357\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.8657\n",
      "Average policy_loss: 0.6447\n",
      "Average value_loss: 0.2210\n",
      "Replay buffer size: 453\n",
      "Time taken: 42.6s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.8004\n",
      "Average policy_loss: 0.6365\n",
      "Average value_loss: 0.1638\n",
      "Replay buffer size: 541\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.7802\n",
      "Average policy_loss: 0.6154\n",
      "Average value_loss: 0.1647\n",
      "Replay buffer size: 637\n",
      "Time taken: 9.5s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.7439\n",
      "Average policy_loss: 0.5971\n",
      "Average value_loss: 0.1468\n",
      "Replay buffer size: 725\n",
      "Time taken: 9.7s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.7649\n",
      "Average policy_loss: 0.5919\n",
      "Average value_loss: 0.1730\n",
      "Replay buffer size: 819\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.7653\n",
      "Average policy_loss: 0.5876\n",
      "Average value_loss: 0.1776\n",
      "Replay buffer size: 909\n",
      "Time taken: 40.9s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.7484\n",
      "Average policy_loss: 0.5823\n",
      "Average value_loss: 0.1661\n",
      "Replay buffer size: 1006\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.7323\n",
      "Average policy_loss: 0.5661\n",
      "Average value_loss: 0.1662\n",
      "Replay buffer size: 1095\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.6956\n",
      "Average policy_loss: 0.5461\n",
      "Average value_loss: 0.1496\n",
      "Replay buffer size: 1191\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.6954\n",
      "Average policy_loss: 0.5498\n",
      "Average value_loss: 0.1456\n",
      "Replay buffer size: 1283\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.7095\n",
      "Average policy_loss: 0.5494\n",
      "Average value_loss: 0.1602\n",
      "Replay buffer size: 1383\n",
      "Time taken: 39.2s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.6591\n",
      "Average policy_loss: 0.5239\n",
      "Average value_loss: 0.1352\n",
      "Replay buffer size: 1471\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.6833\n",
      "Average policy_loss: 0.5479\n",
      "Average value_loss: 0.1354\n",
      "Replay buffer size: 1563\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.6436\n",
      "Average policy_loss: 0.5251\n",
      "Average value_loss: 0.1186\n",
      "Replay buffer size: 1663\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.6508\n",
      "Average policy_loss: 0.5292\n",
      "Average value_loss: 0.1216\n",
      "Replay buffer size: 1751\n",
      "Time taken: 8.1s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.6841\n",
      "Average policy_loss: 0.5575\n",
      "Average value_loss: 0.1266\n",
      "Replay buffer size: 1843\n",
      "Time taken: 36.0s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.6759\n",
      "Average policy_loss: 0.5496\n",
      "Average value_loss: 0.1263\n",
      "Replay buffer size: 1939\n",
      "Time taken: 8.1s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.6700\n",
      "Average policy_loss: 0.5472\n",
      "Average value_loss: 0.1228\n",
      "Replay buffer size: 2031\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.6544\n",
      "Average policy_loss: 0.5485\n",
      "Average value_loss: 0.1058\n",
      "Replay buffer size: 2131\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.6424\n",
      "Average policy_loss: 0.5456\n",
      "Average value_loss: 0.0968\n",
      "Replay buffer size: 2227\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.6445\n",
      "Average policy_loss: 0.5330\n",
      "Average value_loss: 0.1115\n",
      "Replay buffer size: 2321\n",
      "Time taken: 44.0s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.6513\n",
      "Average policy_loss: 0.5505\n",
      "Average value_loss: 0.1008\n",
      "Replay buffer size: 2409\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.6433\n",
      "Average policy_loss: 0.5447\n",
      "Average value_loss: 0.0986\n",
      "Replay buffer size: 2506\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.6622\n",
      "Average policy_loss: 0.5548\n",
      "Average value_loss: 0.1074\n",
      "Replay buffer size: 2599\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.6544\n",
      "Average policy_loss: 0.5499\n",
      "Average value_loss: 0.1045\n",
      "Replay buffer size: 2695\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.6594\n",
      "Average policy_loss: 0.5557\n",
      "Average value_loss: 0.1037\n",
      "Replay buffer size: 2785\n",
      "Time taken: 43.5s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.6604\n",
      "Average policy_loss: 0.5641\n",
      "Average value_loss: 0.0963\n",
      "Replay buffer size: 2876\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.6689\n",
      "Average policy_loss: 0.5649\n",
      "Average value_loss: 0.1040\n",
      "Replay buffer size: 2970\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.6835\n",
      "Average policy_loss: 0.5776\n",
      "Average value_loss: 0.1059\n",
      "Replay buffer size: 3059\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.6681\n",
      "Average policy_loss: 0.5703\n",
      "Average value_loss: 0.0978\n",
      "Replay buffer size: 3153\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.6946\n",
      "Average policy_loss: 0.5992\n",
      "Average value_loss: 0.0953\n",
      "Replay buffer size: 3243\n",
      "Time taken: 48.3s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.6859\n",
      "Average policy_loss: 0.5844\n",
      "Average value_loss: 0.1015\n",
      "Replay buffer size: 3343\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.6908\n",
      "Average policy_loss: 0.5946\n",
      "Average value_loss: 0.0963\n",
      "Replay buffer size: 3440\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.6899\n",
      "Average policy_loss: 0.5898\n",
      "Average value_loss: 0.1000\n",
      "Replay buffer size: 3528\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.6964\n",
      "Average policy_loss: 0.5961\n",
      "Average value_loss: 0.1003\n",
      "Replay buffer size: 3621\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.6885\n",
      "Average policy_loss: 0.5915\n",
      "Average value_loss: 0.0970\n",
      "Replay buffer size: 3714\n",
      "Time taken: 50.7s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.7033\n",
      "Average policy_loss: 0.6057\n",
      "Average value_loss: 0.0976\n",
      "Replay buffer size: 3812\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.7122\n",
      "Average policy_loss: 0.6144\n",
      "Average value_loss: 0.0978\n",
      "Replay buffer size: 3899\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.7252\n",
      "Average policy_loss: 0.6241\n",
      "Average value_loss: 0.1010\n",
      "Replay buffer size: 3992\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.7254\n",
      "Average policy_loss: 0.6220\n",
      "Average value_loss: 0.1033\n",
      "Replay buffer size: 4085\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.7300\n",
      "Average policy_loss: 0.6235\n",
      "Average value_loss: 0.1065\n",
      "Replay buffer size: 4171\n",
      "Time taken: 47.7s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.7234\n",
      "Average policy_loss: 0.6205\n",
      "Average value_loss: 0.1029\n",
      "Replay buffer size: 4259\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.7304\n",
      "Average policy_loss: 0.6247\n",
      "Average value_loss: 0.1057\n",
      "Replay buffer size: 4351\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.7291\n",
      "Average policy_loss: 0.6235\n",
      "Average value_loss: 0.1057\n",
      "Replay buffer size: 4443\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.7593\n",
      "Average policy_loss: 0.6457\n",
      "Average value_loss: 0.1136\n",
      "Replay buffer size: 4525\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.7628\n",
      "Average policy_loss: 0.6453\n",
      "Average value_loss: 0.1175\n",
      "Replay buffer size: 4609\n",
      "Time taken: 55.2s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.7480\n",
      "Average policy_loss: 0.6390\n",
      "Average value_loss: 0.1090\n",
      "Replay buffer size: 4697\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.7593\n",
      "Average policy_loss: 0.6487\n",
      "Average value_loss: 0.1105\n",
      "Replay buffer size: 4781\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.7664\n",
      "Average policy_loss: 0.6508\n",
      "Average value_loss: 0.1157\n",
      "Replay buffer size: 4874\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.7612\n",
      "Average policy_loss: 0.6495\n",
      "Average value_loss: 0.1117\n",
      "Replay buffer size: 4966\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.7647\n",
      "Average policy_loss: 0.6506\n",
      "Average value_loss: 0.1141\n",
      "Replay buffer size: 5054\n",
      "Time taken: 52.6s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.7636\n",
      "Average policy_loss: 0.6506\n",
      "Average value_loss: 0.1130\n",
      "Replay buffer size: 5147\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.7628\n",
      "Average policy_loss: 0.6474\n",
      "Average value_loss: 0.1154\n",
      "Replay buffer size: 5241\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.7587\n",
      "Average policy_loss: 0.6458\n",
      "Average value_loss: 0.1129\n",
      "Replay buffer size: 5336\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.7712\n",
      "Average policy_loss: 0.6575\n",
      "Average value_loss: 0.1137\n",
      "Replay buffer size: 5433\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.7724\n",
      "Average policy_loss: 0.6587\n",
      "Average value_loss: 0.1137\n",
      "Replay buffer size: 5523\n",
      "Time taken: 54.5s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.7673\n",
      "Average policy_loss: 0.6591\n",
      "Average value_loss: 0.1082\n",
      "Replay buffer size: 5611\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.7704\n",
      "Average policy_loss: 0.6612\n",
      "Average value_loss: 0.1091\n",
      "Replay buffer size: 5701\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.7657\n",
      "Average policy_loss: 0.6559\n",
      "Average value_loss: 0.1097\n",
      "Replay buffer size: 5785\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.7733\n",
      "Average policy_loss: 0.6605\n",
      "Average value_loss: 0.1128\n",
      "Replay buffer size: 5874\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.7847\n",
      "Average policy_loss: 0.6732\n",
      "Average value_loss: 0.1116\n",
      "Replay buffer size: 5970\n",
      "Time taken: 54.7s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.7806\n",
      "Average policy_loss: 0.6653\n",
      "Average value_loss: 0.1153\n",
      "Replay buffer size: 6063\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.7850\n",
      "Average policy_loss: 0.6726\n",
      "Average value_loss: 0.1124\n",
      "Replay buffer size: 6151\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.7846\n",
      "Average policy_loss: 0.6727\n",
      "Average value_loss: 0.1119\n",
      "Replay buffer size: 6233\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.7970\n",
      "Average policy_loss: 0.6820\n",
      "Average value_loss: 0.1150\n",
      "Replay buffer size: 6330\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.7810\n",
      "Average policy_loss: 0.6732\n",
      "Average value_loss: 0.1078\n",
      "Replay buffer size: 6423\n",
      "Time taken: 53.6s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.7898\n",
      "Average policy_loss: 0.6750\n",
      "Average value_loss: 0.1148\n",
      "Replay buffer size: 6510\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.7964\n",
      "Average policy_loss: 0.6830\n",
      "Average value_loss: 0.1134\n",
      "Replay buffer size: 6602\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.7956\n",
      "Average policy_loss: 0.6786\n",
      "Average value_loss: 0.1170\n",
      "Replay buffer size: 6691\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.7999\n",
      "Average policy_loss: 0.6852\n",
      "Average value_loss: 0.1148\n",
      "Replay buffer size: 6789\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.7995\n",
      "Average policy_loss: 0.6839\n",
      "Average value_loss: 0.1156\n",
      "Replay buffer size: 6886\n",
      "Time taken: 48.5s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.7871\n",
      "Average policy_loss: 0.6751\n",
      "Average value_loss: 0.1120\n",
      "Replay buffer size: 6981\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.7999\n",
      "Average policy_loss: 0.6879\n",
      "Average value_loss: 0.1120\n",
      "Replay buffer size: 7075\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.8007\n",
      "Average policy_loss: 0.6911\n",
      "Average value_loss: 0.1096\n",
      "Replay buffer size: 7168\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.7956\n",
      "Average policy_loss: 0.6830\n",
      "Average value_loss: 0.1125\n",
      "Replay buffer size: 7266\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.7914\n",
      "Average policy_loss: 0.6783\n",
      "Average value_loss: 0.1131\n",
      "Replay buffer size: 7353\n",
      "Time taken: 53.0s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.8025\n",
      "Average policy_loss: 0.6898\n",
      "Average value_loss: 0.1127\n",
      "Replay buffer size: 7445\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.8020\n",
      "Average policy_loss: 0.6896\n",
      "Average value_loss: 0.1124\n",
      "Replay buffer size: 7535\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.8136\n",
      "Average policy_loss: 0.6970\n",
      "Average value_loss: 0.1166\n",
      "Replay buffer size: 7628\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.8095\n",
      "Average policy_loss: 0.6952\n",
      "Average value_loss: 0.1143\n",
      "Replay buffer size: 7715\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.8113\n",
      "Average policy_loss: 0.7003\n",
      "Average value_loss: 0.1110\n",
      "Replay buffer size: 7809\n",
      "Time taken: 56.8s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.8123\n",
      "Average policy_loss: 0.6985\n",
      "Average value_loss: 0.1138\n",
      "Replay buffer size: 7909\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.8033\n",
      "Average policy_loss: 0.6914\n",
      "Average value_loss: 0.1118\n",
      "Replay buffer size: 7999\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.8124\n",
      "Average policy_loss: 0.6982\n",
      "Average value_loss: 0.1143\n",
      "Replay buffer size: 8085\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.8181\n",
      "Average policy_loss: 0.7054\n",
      "Average value_loss: 0.1127\n",
      "Replay buffer size: 8167\n",
      "Time taken: 18.5s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.8176\n",
      "Average policy_loss: 0.7008\n",
      "Average value_loss: 0.1168\n",
      "Replay buffer size: 8259\n",
      "Time taken: 59.2s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.8133\n",
      "Average policy_loss: 0.7012\n",
      "Average value_loss: 0.1121\n",
      "Replay buffer size: 8351\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.8308\n",
      "Average policy_loss: 0.7186\n",
      "Average value_loss: 0.1122\n",
      "Replay buffer size: 8440\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.8123\n",
      "Average policy_loss: 0.7001\n",
      "Average value_loss: 0.1122\n",
      "Replay buffer size: 8528\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.8101\n",
      "Average policy_loss: 0.6970\n",
      "Average value_loss: 0.1131\n",
      "Replay buffer size: 8623\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.8430\n",
      "Average policy_loss: 0.7260\n",
      "Average value_loss: 0.1170\n",
      "Replay buffer size: 8713\n",
      "Time taken: 58.4s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.8184\n",
      "Average policy_loss: 0.7033\n",
      "Average value_loss: 0.1151\n",
      "Replay buffer size: 8804\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.8221\n",
      "Average policy_loss: 0.7057\n",
      "Average value_loss: 0.1164\n",
      "Replay buffer size: 8900\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.8213\n",
      "Average policy_loss: 0.7075\n",
      "Average value_loss: 0.1138\n",
      "Replay buffer size: 8993\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.8231\n",
      "Average policy_loss: 0.7103\n",
      "Average value_loss: 0.1128\n",
      "Replay buffer size: 9085\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.8346\n",
      "Average policy_loss: 0.7146\n",
      "Average value_loss: 0.1200\n",
      "Replay buffer size: 9179\n",
      "Time taken: 57.3s\n",
      "\n",
      "Training complete! Total time: 0.6h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>iteration_time</td><td>▁▁▁▆▁▅▂▁▂▂▂▂▂▂▆▂▂▂▇▂▂▆▂▂▇▂▂▇▂▂▂▇▂▂▂█▂▂█▂</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▄▃▆▆▆▄▆▅▃▅▆▅▆▇▅█▃▅▅▅▂▂▅▅▃▆▆▄▃▄▆▃▇▆▆▆█▁▄▅</td></tr><tr><td>policy_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>value_loss</td><td>█▃▂▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▂▂▂▂▁▁▂▁▂▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.15</td></tr><tr><td>buffer_size</td><td>9179</td></tr><tr><td>iteration_time</td><td>57.31453</td></tr><tr><td>loss</td><td>0.8346</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>94</td></tr><tr><td>policy_loss</td><td>0.71464</td></tr><tr><td>total_time_hours</td><td>0.59254</td></tr><tr><td>value_loss</td><td>0.11996</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">summer-sweep-9</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/7aae0iuu' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/7aae0iuu</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 24 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_025454-7aae0iuu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y4nwsoge with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00012424623867201575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.7367816761136133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0046441418616425265\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_033034-y4nwsoge</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/y4nwsoge' target=\"_blank\">dashing-sweep-10</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/y4nwsoge' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/y4nwsoge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 2.3955\n",
      "Average policy_loss: 1.5893\n",
      "Average value_loss: 0.8062\n",
      "Replay buffer size: 82\n",
      "Time taken: 7.4s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 2.0477\n",
      "Average policy_loss: 1.3468\n",
      "Average value_loss: 0.7009\n",
      "Replay buffer size: 177\n",
      "Time taken: 9.8s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 2.0626\n",
      "Average policy_loss: 1.4424\n",
      "Average value_loss: 0.6202\n",
      "Replay buffer size: 259\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.8423\n",
      "Average policy_loss: 1.2884\n",
      "Average value_loss: 0.5539\n",
      "Replay buffer size: 356\n",
      "Time taken: 9.4s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 55.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.7554\n",
      "Average policy_loss: 1.2310\n",
      "Average value_loss: 0.5243\n",
      "Replay buffer size: 440\n",
      "Time taken: 39.1s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.7158\n",
      "Average policy_loss: 1.2010\n",
      "Average value_loss: 0.5149\n",
      "Replay buffer size: 528\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.6795\n",
      "Average policy_loss: 1.1865\n",
      "Average value_loss: 0.4930\n",
      "Replay buffer size: 612\n",
      "Time taken: 11.2s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.5876\n",
      "Average policy_loss: 1.1380\n",
      "Average value_loss: 0.4495\n",
      "Replay buffer size: 685\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.5317\n",
      "Average policy_loss: 1.1077\n",
      "Average value_loss: 0.4240\n",
      "Replay buffer size: 765\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.4850\n",
      "Average policy_loss: 1.0982\n",
      "Average value_loss: 0.3868\n",
      "Replay buffer size: 843\n",
      "Time taken: 39.9s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.4675\n",
      "Average policy_loss: 1.0697\n",
      "Average value_loss: 0.3979\n",
      "Replay buffer size: 925\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.4404\n",
      "Average policy_loss: 1.0710\n",
      "Average value_loss: 0.3694\n",
      "Replay buffer size: 1009\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.4190\n",
      "Average policy_loss: 1.0514\n",
      "Average value_loss: 0.3676\n",
      "Replay buffer size: 1101\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.3855\n",
      "Average policy_loss: 1.0269\n",
      "Average value_loss: 0.3586\n",
      "Replay buffer size: 1181\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.3412\n",
      "Average policy_loss: 1.0036\n",
      "Average value_loss: 0.3376\n",
      "Replay buffer size: 1273\n",
      "Time taken: 41.5s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.3365\n",
      "Average policy_loss: 1.0004\n",
      "Average value_loss: 0.3362\n",
      "Replay buffer size: 1363\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.2758\n",
      "Average policy_loss: 0.9568\n",
      "Average value_loss: 0.3189\n",
      "Replay buffer size: 1455\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.2942\n",
      "Average policy_loss: 0.9861\n",
      "Average value_loss: 0.3081\n",
      "Replay buffer size: 1535\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.3060\n",
      "Average policy_loss: 0.9823\n",
      "Average value_loss: 0.3237\n",
      "Replay buffer size: 1628\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.2834\n",
      "Average policy_loss: 0.9585\n",
      "Average value_loss: 0.3249\n",
      "Replay buffer size: 1710\n",
      "Time taken: 44.0s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.2863\n",
      "Average policy_loss: 0.9686\n",
      "Average value_loss: 0.3177\n",
      "Replay buffer size: 1804\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.2615\n",
      "Average policy_loss: 0.9503\n",
      "Average value_loss: 0.3112\n",
      "Replay buffer size: 1890\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.2526\n",
      "Average policy_loss: 0.9457\n",
      "Average value_loss: 0.3069\n",
      "Replay buffer size: 1979\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.2139\n",
      "Average policy_loss: 0.9251\n",
      "Average value_loss: 0.2888\n",
      "Replay buffer size: 2059\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.2153\n",
      "Average policy_loss: 0.9346\n",
      "Average value_loss: 0.2806\n",
      "Replay buffer size: 2140\n",
      "Time taken: 42.5s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.2021\n",
      "Average policy_loss: 0.9218\n",
      "Average value_loss: 0.2802\n",
      "Replay buffer size: 2228\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.2023\n",
      "Average policy_loss: 0.9244\n",
      "Average value_loss: 0.2779\n",
      "Replay buffer size: 2312\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.2083\n",
      "Average policy_loss: 0.9373\n",
      "Average value_loss: 0.2710\n",
      "Replay buffer size: 2400\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.2009\n",
      "Average policy_loss: 0.9224\n",
      "Average value_loss: 0.2785\n",
      "Replay buffer size: 2489\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.1939\n",
      "Average policy_loss: 0.9258\n",
      "Average value_loss: 0.2681\n",
      "Replay buffer size: 2577\n",
      "Time taken: 45.1s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.1927\n",
      "Average policy_loss: 0.9223\n",
      "Average value_loss: 0.2704\n",
      "Replay buffer size: 2671\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.1891\n",
      "Average policy_loss: 0.9142\n",
      "Average value_loss: 0.2749\n",
      "Replay buffer size: 2763\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.1827\n",
      "Average policy_loss: 0.9123\n",
      "Average value_loss: 0.2703\n",
      "Replay buffer size: 2855\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.1482\n",
      "Average policy_loss: 0.8913\n",
      "Average value_loss: 0.2569\n",
      "Replay buffer size: 2953\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.1646\n",
      "Average policy_loss: 0.9011\n",
      "Average value_loss: 0.2635\n",
      "Replay buffer size: 3049\n",
      "Time taken: 49.4s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.1785\n",
      "Average policy_loss: 0.9097\n",
      "Average value_loss: 0.2689\n",
      "Replay buffer size: 3139\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.1440\n",
      "Average policy_loss: 0.8765\n",
      "Average value_loss: 0.2675\n",
      "Replay buffer size: 3228\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.1506\n",
      "Average policy_loss: 0.8834\n",
      "Average value_loss: 0.2672\n",
      "Replay buffer size: 3318\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.1609\n",
      "Average policy_loss: 0.8935\n",
      "Average value_loss: 0.2674\n",
      "Replay buffer size: 3401\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.1515\n",
      "Average policy_loss: 0.8909\n",
      "Average value_loss: 0.2605\n",
      "Replay buffer size: 3493\n",
      "Time taken: 52.8s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.1426\n",
      "Average policy_loss: 0.8873\n",
      "Average value_loss: 0.2552\n",
      "Replay buffer size: 3587\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.1159\n",
      "Average policy_loss: 0.8716\n",
      "Average value_loss: 0.2443\n",
      "Replay buffer size: 3673\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.1325\n",
      "Average policy_loss: 0.8893\n",
      "Average value_loss: 0.2432\n",
      "Replay buffer size: 3763\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.1093\n",
      "Average policy_loss: 0.8661\n",
      "Average value_loss: 0.2433\n",
      "Replay buffer size: 3855\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.1160\n",
      "Average policy_loss: 0.8664\n",
      "Average value_loss: 0.2497\n",
      "Replay buffer size: 3937\n",
      "Time taken: 53.0s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.1025\n",
      "Average policy_loss: 0.8640\n",
      "Average value_loss: 0.2385\n",
      "Replay buffer size: 4029\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.1049\n",
      "Average policy_loss: 0.8684\n",
      "Average value_loss: 0.2365\n",
      "Replay buffer size: 4121\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.1024\n",
      "Average policy_loss: 0.8607\n",
      "Average value_loss: 0.2417\n",
      "Replay buffer size: 4207\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.0868\n",
      "Average policy_loss: 0.8592\n",
      "Average value_loss: 0.2276\n",
      "Replay buffer size: 4293\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.0884\n",
      "Average policy_loss: 0.8572\n",
      "Average value_loss: 0.2312\n",
      "Replay buffer size: 4375\n",
      "Time taken: 51.2s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.0848\n",
      "Average policy_loss: 0.8667\n",
      "Average value_loss: 0.2182\n",
      "Replay buffer size: 4452\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.0828\n",
      "Average policy_loss: 0.8557\n",
      "Average value_loss: 0.2270\n",
      "Replay buffer size: 4542\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.0839\n",
      "Average policy_loss: 0.8652\n",
      "Average value_loss: 0.2187\n",
      "Replay buffer size: 4622\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.0758\n",
      "Average policy_loss: 0.8558\n",
      "Average value_loss: 0.2200\n",
      "Replay buffer size: 4704\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.0767\n",
      "Average policy_loss: 0.8619\n",
      "Average value_loss: 0.2148\n",
      "Replay buffer size: 4786\n",
      "Time taken: 50.8s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.0640\n",
      "Average policy_loss: 0.8490\n",
      "Average value_loss: 0.2149\n",
      "Replay buffer size: 4870\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.0729\n",
      "Average policy_loss: 0.8570\n",
      "Average value_loss: 0.2159\n",
      "Replay buffer size: 4954\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.0613\n",
      "Average policy_loss: 0.8534\n",
      "Average value_loss: 0.2079\n",
      "Replay buffer size: 5028\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.0774\n",
      "Average policy_loss: 0.8657\n",
      "Average value_loss: 0.2117\n",
      "Replay buffer size: 5110\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.0733\n",
      "Average policy_loss: 0.8649\n",
      "Average value_loss: 0.2084\n",
      "Replay buffer size: 5191\n",
      "Time taken: 48.6s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.0844\n",
      "Average policy_loss: 0.8696\n",
      "Average value_loss: 0.2148\n",
      "Replay buffer size: 5274\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.0593\n",
      "Average policy_loss: 0.8589\n",
      "Average value_loss: 0.2004\n",
      "Replay buffer size: 5350\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.0738\n",
      "Average policy_loss: 0.8669\n",
      "Average value_loss: 0.2069\n",
      "Replay buffer size: 5433\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.0681\n",
      "Average policy_loss: 0.8659\n",
      "Average value_loss: 0.2022\n",
      "Replay buffer size: 5520\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.0750\n",
      "Average policy_loss: 0.8712\n",
      "Average value_loss: 0.2037\n",
      "Replay buffer size: 5602\n",
      "Time taken: 50.8s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.0809\n",
      "Average policy_loss: 0.8809\n",
      "Average value_loss: 0.2001\n",
      "Replay buffer size: 5693\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.0992\n",
      "Average policy_loss: 0.8943\n",
      "Average value_loss: 0.2049\n",
      "Replay buffer size: 5776\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.0822\n",
      "Average policy_loss: 0.8795\n",
      "Average value_loss: 0.2027\n",
      "Replay buffer size: 5860\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.0818\n",
      "Average policy_loss: 0.8800\n",
      "Average value_loss: 0.2018\n",
      "Replay buffer size: 5942\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.0849\n",
      "Average policy_loss: 0.8850\n",
      "Average value_loss: 0.1998\n",
      "Replay buffer size: 6025\n",
      "Time taken: 54.1s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.0781\n",
      "Average policy_loss: 0.8798\n",
      "Average value_loss: 0.1984\n",
      "Replay buffer size: 6107\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.0832\n",
      "Average policy_loss: 0.8871\n",
      "Average value_loss: 0.1961\n",
      "Replay buffer size: 6187\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.0852\n",
      "Average policy_loss: 0.8905\n",
      "Average value_loss: 0.1947\n",
      "Replay buffer size: 6275\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.0816\n",
      "Average policy_loss: 0.8837\n",
      "Average value_loss: 0.1979\n",
      "Replay buffer size: 6358\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.0772\n",
      "Average policy_loss: 0.8809\n",
      "Average value_loss: 0.1964\n",
      "Replay buffer size: 6438\n",
      "Time taken: 51.8s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.1048\n",
      "Average policy_loss: 0.9119\n",
      "Average value_loss: 0.1929\n",
      "Replay buffer size: 6515\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.0971\n",
      "Average policy_loss: 0.9038\n",
      "Average value_loss: 0.1933\n",
      "Replay buffer size: 6599\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.0881\n",
      "Average policy_loss: 0.8948\n",
      "Average value_loss: 0.1933\n",
      "Replay buffer size: 6671\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.0877\n",
      "Average policy_loss: 0.8968\n",
      "Average value_loss: 0.1909\n",
      "Replay buffer size: 6749\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.0715\n",
      "Average policy_loss: 0.8852\n",
      "Average value_loss: 0.1863\n",
      "Replay buffer size: 6828\n",
      "Time taken: 51.3s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.0882\n",
      "Average policy_loss: 0.8957\n",
      "Average value_loss: 0.1925\n",
      "Replay buffer size: 6913\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.0831\n",
      "Average policy_loss: 0.8977\n",
      "Average value_loss: 0.1854\n",
      "Replay buffer size: 6995\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.0903\n",
      "Average policy_loss: 0.9020\n",
      "Average value_loss: 0.1883\n",
      "Replay buffer size: 7077\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.0828\n",
      "Average policy_loss: 0.8963\n",
      "Average value_loss: 0.1865\n",
      "Replay buffer size: 7149\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.0927\n",
      "Average policy_loss: 0.9103\n",
      "Average value_loss: 0.1824\n",
      "Replay buffer size: 7229\n",
      "Time taken: 50.2s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.0830\n",
      "Average policy_loss: 0.8981\n",
      "Average value_loss: 0.1850\n",
      "Replay buffer size: 7307\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.0875\n",
      "Average policy_loss: 0.9065\n",
      "Average value_loss: 0.1810\n",
      "Replay buffer size: 7377\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.0853\n",
      "Average policy_loss: 0.9064\n",
      "Average value_loss: 0.1789\n",
      "Replay buffer size: 7454\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.0895\n",
      "Average policy_loss: 0.9043\n",
      "Average value_loss: 0.1853\n",
      "Replay buffer size: 7535\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.0982\n",
      "Average policy_loss: 0.9163\n",
      "Average value_loss: 0.1819\n",
      "Replay buffer size: 7605\n",
      "Time taken: 47.4s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.0842\n",
      "Average policy_loss: 0.9033\n",
      "Average value_loss: 0.1809\n",
      "Replay buffer size: 7678\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.0943\n",
      "Average policy_loss: 0.9146\n",
      "Average value_loss: 0.1797\n",
      "Replay buffer size: 7748\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.0797\n",
      "Average policy_loss: 0.8978\n",
      "Average value_loss: 0.1818\n",
      "Replay buffer size: 7822\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.0749\n",
      "Average policy_loss: 0.8981\n",
      "Average value_loss: 0.1768\n",
      "Replay buffer size: 7902\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.0793\n",
      "Average policy_loss: 0.8996\n",
      "Average value_loss: 0.1796\n",
      "Replay buffer size: 7987\n",
      "Time taken: 48.2s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.0802\n",
      "Average policy_loss: 0.9056\n",
      "Average value_loss: 0.1747\n",
      "Replay buffer size: 8063\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.0918\n",
      "Average policy_loss: 0.9115\n",
      "Average value_loss: 0.1802\n",
      "Replay buffer size: 8140\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.0764\n",
      "Average policy_loss: 0.9066\n",
      "Average value_loss: 0.1698\n",
      "Replay buffer size: 8210\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.0909\n",
      "Average policy_loss: 0.9124\n",
      "Average value_loss: 0.1785\n",
      "Replay buffer size: 8283\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.0713\n",
      "Average policy_loss: 0.8989\n",
      "Average value_loss: 0.1724\n",
      "Replay buffer size: 8361\n",
      "Time taken: 42.3s\n",
      "\n",
      "Training complete! Total time: 0.6h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>iteration_time</td><td>▁▁▆▁▆▂▂▂▂▇▂▂▇▂▂█▂▂▂▂█▂▂▂█▂█▂▂▂▂▂▃▃▂▂▇█▂▇</td></tr><tr><td>loss</td><td>█▆▅▄▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▇▄▅▅▅▃▆▃▅▆▄▅▇█▆▇▆▇▄▅▃▄▅▄▄▄▅▆▄▄▃▃▃▅▄▁▄▁▂▂</td></tr><tr><td>policy_loss</td><td>█▆▅▅▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>value_loss</td><td>█▇▆▅▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.15</td></tr><tr><td>buffer_size</td><td>8361</td></tr><tr><td>iteration_time</td><td>42.31344</td></tr><tr><td>loss</td><td>1.07133</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>78</td></tr><tr><td>policy_loss</td><td>0.89892</td></tr><tr><td>total_time_hours</td><td>0.57367</td></tr><tr><td>value_loss</td><td>0.17241</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dashing-sweep-10</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/y4nwsoge' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/y4nwsoge</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 28 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_033034-y4nwsoge/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kketn5ba with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.010272375296051264\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.34495132894598934\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.08248752377861358\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_040507-kketn5ba</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kketn5ba' target=\"_blank\">copper-sweep-11</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kketn5ba' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kketn5ba</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 3.9463\n",
      "Average policy_loss: 3.3279\n",
      "Average value_loss: 0.6184\n",
      "Replay buffer size: 92\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.2981\n",
      "Average policy_loss: 1.0141\n",
      "Average value_loss: 0.2840\n",
      "Replay buffer size: 178\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.1375\n",
      "Average policy_loss: 0.9540\n",
      "Average value_loss: 0.1835\n",
      "Replay buffer size: 260\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.0854\n",
      "Average policy_loss: 0.9266\n",
      "Average value_loss: 0.1588\n",
      "Replay buffer size: 352\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.0341\n",
      "Average policy_loss: 0.8892\n",
      "Average value_loss: 0.1449\n",
      "Replay buffer size: 446\n",
      "Time taken: 55.1s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.0651\n",
      "Average policy_loss: 0.9043\n",
      "Average value_loss: 0.1608\n",
      "Replay buffer size: 531\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.1009\n",
      "Average policy_loss: 0.9144\n",
      "Average value_loss: 0.1865\n",
      "Replay buffer size: 619\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.1441\n",
      "Average policy_loss: 0.9303\n",
      "Average value_loss: 0.2138\n",
      "Replay buffer size: 699\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.1546\n",
      "Average policy_loss: 0.9292\n",
      "Average value_loss: 0.2254\n",
      "Replay buffer size: 787\n",
      "Time taken: 19.4s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.1697\n",
      "Average policy_loss: 0.9452\n",
      "Average value_loss: 0.2244\n",
      "Replay buffer size: 863\n",
      "Time taken: 51.7s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.1700\n",
      "Average policy_loss: 0.9420\n",
      "Average value_loss: 0.2280\n",
      "Replay buffer size: 935\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.1814\n",
      "Average policy_loss: 0.9559\n",
      "Average value_loss: 0.2255\n",
      "Replay buffer size: 1011\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.1896\n",
      "Average policy_loss: 0.9578\n",
      "Average value_loss: 0.2318\n",
      "Replay buffer size: 1090\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.1903\n",
      "Average policy_loss: 0.9580\n",
      "Average value_loss: 0.2324\n",
      "Replay buffer size: 1170\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.1890\n",
      "Average policy_loss: 0.9572\n",
      "Average value_loss: 0.2318\n",
      "Replay buffer size: 1242\n",
      "Time taken: 44.4s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.1907\n",
      "Average policy_loss: 0.9617\n",
      "Average value_loss: 0.2290\n",
      "Replay buffer size: 1316\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.1823\n",
      "Average policy_loss: 0.9566\n",
      "Average value_loss: 0.2257\n",
      "Replay buffer size: 1386\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.2050\n",
      "Average policy_loss: 0.9547\n",
      "Average value_loss: 0.2503\n",
      "Replay buffer size: 1465\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.2203\n",
      "Average policy_loss: 0.9708\n",
      "Average value_loss: 0.2495\n",
      "Replay buffer size: 1547\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.2219\n",
      "Average policy_loss: 0.9725\n",
      "Average value_loss: 0.2494\n",
      "Replay buffer size: 1636\n",
      "Time taken: 49.2s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.2103\n",
      "Average policy_loss: 0.9647\n",
      "Average value_loss: 0.2456\n",
      "Replay buffer size: 1714\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.2155\n",
      "Average policy_loss: 0.9699\n",
      "Average value_loss: 0.2456\n",
      "Replay buffer size: 1792\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.2168\n",
      "Average policy_loss: 0.9719\n",
      "Average value_loss: 0.2449\n",
      "Replay buffer size: 1875\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.2209\n",
      "Average policy_loss: 0.9777\n",
      "Average value_loss: 0.2432\n",
      "Replay buffer size: 1955\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.2271\n",
      "Average policy_loss: 0.9825\n",
      "Average value_loss: 0.2446\n",
      "Replay buffer size: 2033\n",
      "Time taken: 50.1s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.2152\n",
      "Average policy_loss: 0.9779\n",
      "Average value_loss: 0.2373\n",
      "Replay buffer size: 2105\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.2212\n",
      "Average policy_loss: 0.9818\n",
      "Average value_loss: 0.2394\n",
      "Replay buffer size: 2192\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.2322\n",
      "Average policy_loss: 0.9859\n",
      "Average value_loss: 0.2463\n",
      "Replay buffer size: 2275\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.2323\n",
      "Average policy_loss: 0.9843\n",
      "Average value_loss: 0.2480\n",
      "Replay buffer size: 2351\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 50.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.2235\n",
      "Average policy_loss: 0.9760\n",
      "Average value_loss: 0.2475\n",
      "Replay buffer size: 2438\n",
      "Time taken: 49.3s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.2246\n",
      "Average policy_loss: 0.9779\n",
      "Average value_loss: 0.2466\n",
      "Replay buffer size: 2519\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.2262\n",
      "Average policy_loss: 0.9837\n",
      "Average value_loss: 0.2425\n",
      "Replay buffer size: 2595\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.2407\n",
      "Average policy_loss: 0.9964\n",
      "Average value_loss: 0.2443\n",
      "Replay buffer size: 2676\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.2369\n",
      "Average policy_loss: 0.9891\n",
      "Average value_loss: 0.2478\n",
      "Replay buffer size: 2761\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.2311\n",
      "Average policy_loss: 0.9834\n",
      "Average value_loss: 0.2477\n",
      "Replay buffer size: 2841\n",
      "Time taken: 49.0s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.2168\n",
      "Average policy_loss: 0.9773\n",
      "Average value_loss: 0.2395\n",
      "Replay buffer size: 2925\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.2226\n",
      "Average policy_loss: 0.9800\n",
      "Average value_loss: 0.2425\n",
      "Replay buffer size: 3011\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.2162\n",
      "Average policy_loss: 0.9779\n",
      "Average value_loss: 0.2382\n",
      "Replay buffer size: 3103\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.2156\n",
      "Average policy_loss: 0.9741\n",
      "Average value_loss: 0.2415\n",
      "Replay buffer size: 3187\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.2137\n",
      "Average policy_loss: 0.9766\n",
      "Average value_loss: 0.2371\n",
      "Replay buffer size: 3279\n",
      "Time taken: 53.8s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.2110\n",
      "Average policy_loss: 0.9800\n",
      "Average value_loss: 0.2309\n",
      "Replay buffer size: 3377\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.1990\n",
      "Average policy_loss: 0.9651\n",
      "Average value_loss: 0.2339\n",
      "Replay buffer size: 3472\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.2043\n",
      "Average policy_loss: 0.9719\n",
      "Average value_loss: 0.2324\n",
      "Replay buffer size: 3558\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.2149\n",
      "Average policy_loss: 0.9741\n",
      "Average value_loss: 0.2408\n",
      "Replay buffer size: 3636\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.2124\n",
      "Average policy_loss: 0.9729\n",
      "Average value_loss: 0.2395\n",
      "Replay buffer size: 3718\n",
      "Time taken: 51.3s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.2094\n",
      "Average policy_loss: 0.9729\n",
      "Average value_loss: 0.2365\n",
      "Replay buffer size: 3795\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.2112\n",
      "Average policy_loss: 0.9756\n",
      "Average value_loss: 0.2356\n",
      "Replay buffer size: 3877\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.2113\n",
      "Average policy_loss: 0.9728\n",
      "Average value_loss: 0.2385\n",
      "Replay buffer size: 3959\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.1979\n",
      "Average policy_loss: 0.9652\n",
      "Average value_loss: 0.2326\n",
      "Replay buffer size: 4048\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.2273\n",
      "Average policy_loss: 0.9766\n",
      "Average value_loss: 0.2507\n",
      "Replay buffer size: 4130\n",
      "Time taken: 51.6s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.2047\n",
      "Average policy_loss: 0.9702\n",
      "Average value_loss: 0.2346\n",
      "Replay buffer size: 4209\n",
      "Time taken: 18.5s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.2034\n",
      "Average policy_loss: 0.9687\n",
      "Average value_loss: 0.2347\n",
      "Replay buffer size: 4301\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.2131\n",
      "Average policy_loss: 0.9713\n",
      "Average value_loss: 0.2419\n",
      "Replay buffer size: 4382\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.2088\n",
      "Average policy_loss: 0.9698\n",
      "Average value_loss: 0.2390\n",
      "Replay buffer size: 4470\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 40.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.1962\n",
      "Average policy_loss: 0.9554\n",
      "Average value_loss: 0.2408\n",
      "Replay buffer size: 4566\n",
      "Time taken: 54.1s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.1951\n",
      "Average policy_loss: 0.9562\n",
      "Average value_loss: 0.2389\n",
      "Replay buffer size: 4655\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.2036\n",
      "Average policy_loss: 0.9628\n",
      "Average value_loss: 0.2408\n",
      "Replay buffer size: 4746\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.1986\n",
      "Average policy_loss: 0.9535\n",
      "Average value_loss: 0.2451\n",
      "Replay buffer size: 4837\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.2002\n",
      "Average policy_loss: 0.9561\n",
      "Average value_loss: 0.2442\n",
      "Replay buffer size: 4929\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.1992\n",
      "Average policy_loss: 0.9503\n",
      "Average value_loss: 0.2489\n",
      "Replay buffer size: 5018\n",
      "Time taken: 52.1s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.2051\n",
      "Average policy_loss: 0.9590\n",
      "Average value_loss: 0.2461\n",
      "Replay buffer size: 5111\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.1943\n",
      "Average policy_loss: 0.9557\n",
      "Average value_loss: 0.2386\n",
      "Replay buffer size: 5207\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.1998\n",
      "Average policy_loss: 0.9580\n",
      "Average value_loss: 0.2418\n",
      "Replay buffer size: 5298\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.1963\n",
      "Average policy_loss: 0.9576\n",
      "Average value_loss: 0.2387\n",
      "Replay buffer size: 5386\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.1902\n",
      "Average policy_loss: 0.9547\n",
      "Average value_loss: 0.2355\n",
      "Replay buffer size: 5478\n",
      "Time taken: 56.3s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.1882\n",
      "Average policy_loss: 0.9532\n",
      "Average value_loss: 0.2350\n",
      "Replay buffer size: 5566\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.1984\n",
      "Average policy_loss: 0.9579\n",
      "Average value_loss: 0.2406\n",
      "Replay buffer size: 5652\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.1924\n",
      "Average policy_loss: 0.9542\n",
      "Average value_loss: 0.2382\n",
      "Replay buffer size: 5751\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.1841\n",
      "Average policy_loss: 0.9475\n",
      "Average value_loss: 0.2366\n",
      "Replay buffer size: 5847\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.1813\n",
      "Average policy_loss: 0.9473\n",
      "Average value_loss: 0.2340\n",
      "Replay buffer size: 5938\n",
      "Time taken: 54.8s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.1691\n",
      "Average policy_loss: 0.9379\n",
      "Average value_loss: 0.2312\n",
      "Replay buffer size: 6030\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.1881\n",
      "Average policy_loss: 0.9497\n",
      "Average value_loss: 0.2384\n",
      "Replay buffer size: 6117\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.1675\n",
      "Average policy_loss: 0.9389\n",
      "Average value_loss: 0.2285\n",
      "Replay buffer size: 6209\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.1747\n",
      "Average policy_loss: 0.9433\n",
      "Average value_loss: 0.2314\n",
      "Replay buffer size: 6293\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.1624\n",
      "Average policy_loss: 0.9363\n",
      "Average value_loss: 0.2261\n",
      "Replay buffer size: 6390\n",
      "Time taken: 56.3s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.1529\n",
      "Average policy_loss: 0.9293\n",
      "Average value_loss: 0.2236\n",
      "Replay buffer size: 6483\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.1585\n",
      "Average policy_loss: 0.9373\n",
      "Average value_loss: 0.2213\n",
      "Replay buffer size: 6577\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.1592\n",
      "Average policy_loss: 0.9323\n",
      "Average value_loss: 0.2269\n",
      "Replay buffer size: 6659\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.1536\n",
      "Average policy_loss: 0.9262\n",
      "Average value_loss: 0.2274\n",
      "Replay buffer size: 6751\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.1582\n",
      "Average policy_loss: 0.9304\n",
      "Average value_loss: 0.2279\n",
      "Replay buffer size: 6843\n",
      "Time taken: 55.8s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.1364\n",
      "Average policy_loss: 0.9124\n",
      "Average value_loss: 0.2240\n",
      "Replay buffer size: 6938\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.1437\n",
      "Average policy_loss: 0.9186\n",
      "Average value_loss: 0.2251\n",
      "Replay buffer size: 7024\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.1561\n",
      "Average policy_loss: 0.9327\n",
      "Average value_loss: 0.2234\n",
      "Replay buffer size: 7110\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.1376\n",
      "Average policy_loss: 0.9142\n",
      "Average value_loss: 0.2234\n",
      "Replay buffer size: 7198\n",
      "Time taken: 18.5s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.1397\n",
      "Average policy_loss: 0.9221\n",
      "Average value_loss: 0.2176\n",
      "Replay buffer size: 7292\n",
      "Time taken: 55.0s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.1318\n",
      "Average policy_loss: 0.9135\n",
      "Average value_loss: 0.2183\n",
      "Replay buffer size: 7379\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.1357\n",
      "Average policy_loss: 0.9171\n",
      "Average value_loss: 0.2186\n",
      "Replay buffer size: 7467\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.1248\n",
      "Average policy_loss: 0.9116\n",
      "Average value_loss: 0.2132\n",
      "Replay buffer size: 7552\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.1346\n",
      "Average policy_loss: 0.9169\n",
      "Average value_loss: 0.2177\n",
      "Replay buffer size: 7649\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.1223\n",
      "Average policy_loss: 0.9071\n",
      "Average value_loss: 0.2151\n",
      "Replay buffer size: 7741\n",
      "Time taken: 55.1s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.1235\n",
      "Average policy_loss: 0.9118\n",
      "Average value_loss: 0.2116\n",
      "Replay buffer size: 7832\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.1340\n",
      "Average policy_loss: 0.9155\n",
      "Average value_loss: 0.2184\n",
      "Replay buffer size: 7928\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.1036\n",
      "Average policy_loss: 0.8990\n",
      "Average value_loss: 0.2045\n",
      "Replay buffer size: 8023\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.1267\n",
      "Average policy_loss: 0.9123\n",
      "Average value_loss: 0.2144\n",
      "Replay buffer size: 8119\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.1197\n",
      "Average policy_loss: 0.9058\n",
      "Average value_loss: 0.2139\n",
      "Replay buffer size: 8211\n",
      "Time taken: 54.3s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.1279\n",
      "Average policy_loss: 0.9149\n",
      "Average value_loss: 0.2130\n",
      "Replay buffer size: 8305\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.1120\n",
      "Average policy_loss: 0.9020\n",
      "Average value_loss: 0.2100\n",
      "Replay buffer size: 8394\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.1026\n",
      "Average policy_loss: 0.8944\n",
      "Average value_loss: 0.2082\n",
      "Replay buffer size: 8490\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.1055\n",
      "Average policy_loss: 0.8930\n",
      "Average value_loss: 0.2125\n",
      "Replay buffer size: 8583\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.1119\n",
      "Average policy_loss: 0.8986\n",
      "Average value_loss: 0.2132\n",
      "Replay buffer size: 8677\n",
      "Time taken: 55.4s\n",
      "\n",
      "Training complete! Total time: 0.7h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>iteration_time</td><td>▁▂▂▂▇▁▆▁▁▁▇▂▁▇▇▂▂▂▇▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂█▂▂█▂</td></tr><tr><td>loss</td><td>▁▄▅▆▆▅▇▇▇▇█▇██▇▇▇▆▆▇▇▆▆▆▆▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▄▃▅▂▂▂▃▅▂▂▁▄▆▄▆▁▃▃▃▂▆▅▆▅▅▅▄█▇▃▇▅▇▅▄▆▇█▆▇</td></tr><tr><td>policy_loss</td><td>█▄▃▄▅▅▅▄▅▅▆▆▆▆▇▆▆▆▅▆▅▅▅▄▄▅▄▅▄▄▃▃▃▂▂▂▂▁▂▁</td></tr><tr><td>value_loss</td><td>▁▁▅▆▇▇████▇████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▅▆▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.3</td></tr><tr><td>buffer_size</td><td>8677</td></tr><tr><td>iteration_time</td><td>55.44838</td></tr><tr><td>loss</td><td>1.11185</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>94</td></tr><tr><td>policy_loss</td><td>0.89864</td></tr><tr><td>total_time_hours</td><td>0.66025</td></tr><tr><td>value_loss</td><td>0.21321</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">copper-sweep-11</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kketn5ba' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kketn5ba</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_040507-kketn5ba/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vb24b986 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005962047799779216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: tiny\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.6851834526319077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.031782394509169996\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_044453-vb24b986</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/vb24b986' target=\"_blank\">gallant-sweep-12</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/vb24b986' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/vb24b986</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 2.4657\n",
      "Average policy_loss: 2.0447\n",
      "Average value_loss: 0.4210\n",
      "Replay buffer size: 80\n",
      "Time taken: 6.3s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.8174\n",
      "Average policy_loss: 1.4596\n",
      "Average value_loss: 0.3579\n",
      "Replay buffer size: 160\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.7249\n",
      "Average policy_loss: 1.4595\n",
      "Average value_loss: 0.2654\n",
      "Replay buffer size: 244\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.4822\n",
      "Average policy_loss: 1.2656\n",
      "Average value_loss: 0.2166\n",
      "Replay buffer size: 332\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.2355\n",
      "Average policy_loss: 1.0402\n",
      "Average value_loss: 0.1953\n",
      "Replay buffer size: 424\n",
      "Time taken: 38.7s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.1834\n",
      "Average policy_loss: 0.9885\n",
      "Average value_loss: 0.1949\n",
      "Replay buffer size: 509\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.1300\n",
      "Average policy_loss: 0.9526\n",
      "Average value_loss: 0.1773\n",
      "Replay buffer size: 602\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.0891\n",
      "Average policy_loss: 0.9315\n",
      "Average value_loss: 0.1577\n",
      "Replay buffer size: 693\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.0626\n",
      "Average policy_loss: 0.9206\n",
      "Average value_loss: 0.1419\n",
      "Replay buffer size: 783\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.0548\n",
      "Average policy_loss: 0.9049\n",
      "Average value_loss: 0.1499\n",
      "Replay buffer size: 871\n",
      "Time taken: 37.8s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.0662\n",
      "Average policy_loss: 0.9124\n",
      "Average value_loss: 0.1538\n",
      "Replay buffer size: 957\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.0855\n",
      "Average policy_loss: 0.9143\n",
      "Average value_loss: 0.1712\n",
      "Replay buffer size: 1051\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.1003\n",
      "Average policy_loss: 0.9240\n",
      "Average value_loss: 0.1764\n",
      "Replay buffer size: 1129\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.0917\n",
      "Average policy_loss: 0.9122\n",
      "Average value_loss: 0.1794\n",
      "Replay buffer size: 1220\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.1003\n",
      "Average policy_loss: 0.9252\n",
      "Average value_loss: 0.1751\n",
      "Replay buffer size: 1314\n",
      "Time taken: 37.3s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.0938\n",
      "Average policy_loss: 0.9173\n",
      "Average value_loss: 0.1766\n",
      "Replay buffer size: 1401\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.0931\n",
      "Average policy_loss: 0.9189\n",
      "Average value_loss: 0.1742\n",
      "Replay buffer size: 1490\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.0769\n",
      "Average policy_loss: 0.9115\n",
      "Average value_loss: 0.1654\n",
      "Replay buffer size: 1581\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.0851\n",
      "Average policy_loss: 0.9176\n",
      "Average value_loss: 0.1675\n",
      "Replay buffer size: 1671\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.0836\n",
      "Average policy_loss: 0.9139\n",
      "Average value_loss: 0.1697\n",
      "Replay buffer size: 1757\n",
      "Time taken: 38.1s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.0789\n",
      "Average policy_loss: 0.9170\n",
      "Average value_loss: 0.1618\n",
      "Replay buffer size: 1843\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.0666\n",
      "Average policy_loss: 0.9035\n",
      "Average value_loss: 0.1631\n",
      "Replay buffer size: 1929\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.0569\n",
      "Average policy_loss: 0.8980\n",
      "Average value_loss: 0.1589\n",
      "Replay buffer size: 2023\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.0581\n",
      "Average policy_loss: 0.8969\n",
      "Average value_loss: 0.1612\n",
      "Replay buffer size: 2114\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.0700\n",
      "Average policy_loss: 0.9027\n",
      "Average value_loss: 0.1673\n",
      "Replay buffer size: 2193\n",
      "Time taken: 35.8s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.0653\n",
      "Average policy_loss: 0.9015\n",
      "Average value_loss: 0.1639\n",
      "Replay buffer size: 2284\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.0645\n",
      "Average policy_loss: 0.8990\n",
      "Average value_loss: 0.1655\n",
      "Replay buffer size: 2373\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.0648\n",
      "Average policy_loss: 0.9016\n",
      "Average value_loss: 0.1632\n",
      "Replay buffer size: 2463\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.0469\n",
      "Average policy_loss: 0.8881\n",
      "Average value_loss: 0.1588\n",
      "Replay buffer size: 2544\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.0512\n",
      "Average policy_loss: 0.8906\n",
      "Average value_loss: 0.1607\n",
      "Replay buffer size: 2621\n",
      "Time taken: 35.3s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.0398\n",
      "Average policy_loss: 0.8796\n",
      "Average value_loss: 0.1602\n",
      "Replay buffer size: 2709\n",
      "Time taken: 9.7s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.0452\n",
      "Average policy_loss: 0.8866\n",
      "Average value_loss: 0.1586\n",
      "Replay buffer size: 2800\n",
      "Time taken: 9.5s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.0355\n",
      "Average policy_loss: 0.8782\n",
      "Average value_loss: 0.1573\n",
      "Replay buffer size: 2893\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.0359\n",
      "Average policy_loss: 0.8775\n",
      "Average value_loss: 0.1583\n",
      "Replay buffer size: 2984\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.0389\n",
      "Average policy_loss: 0.8803\n",
      "Average value_loss: 0.1586\n",
      "Replay buffer size: 3062\n",
      "Time taken: 35.7s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.0445\n",
      "Average policy_loss: 0.8871\n",
      "Average value_loss: 0.1574\n",
      "Replay buffer size: 3148\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.0473\n",
      "Average policy_loss: 0.8882\n",
      "Average value_loss: 0.1591\n",
      "Replay buffer size: 3235\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.0418\n",
      "Average policy_loss: 0.8837\n",
      "Average value_loss: 0.1581\n",
      "Replay buffer size: 3323\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.0384\n",
      "Average policy_loss: 0.8866\n",
      "Average value_loss: 0.1518\n",
      "Replay buffer size: 3410\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.0486\n",
      "Average policy_loss: 0.8969\n",
      "Average value_loss: 0.1517\n",
      "Replay buffer size: 3502\n",
      "Time taken: 35.8s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.0487\n",
      "Average policy_loss: 0.8994\n",
      "Average value_loss: 0.1493\n",
      "Replay buffer size: 3583\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.0496\n",
      "Average policy_loss: 0.8980\n",
      "Average value_loss: 0.1515\n",
      "Replay buffer size: 3673\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.0552\n",
      "Average policy_loss: 0.9006\n",
      "Average value_loss: 0.1546\n",
      "Replay buffer size: 3765\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.0457\n",
      "Average policy_loss: 0.8975\n",
      "Average value_loss: 0.1482\n",
      "Replay buffer size: 3862\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.0515\n",
      "Average policy_loss: 0.9003\n",
      "Average value_loss: 0.1512\n",
      "Replay buffer size: 3939\n",
      "Time taken: 38.7s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.0565\n",
      "Average policy_loss: 0.9068\n",
      "Average value_loss: 0.1497\n",
      "Replay buffer size: 4020\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.0511\n",
      "Average policy_loss: 0.9033\n",
      "Average value_loss: 0.1478\n",
      "Replay buffer size: 4116\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.0617\n",
      "Average policy_loss: 0.9143\n",
      "Average value_loss: 0.1473\n",
      "Replay buffer size: 4208\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.0631\n",
      "Average policy_loss: 0.9150\n",
      "Average value_loss: 0.1482\n",
      "Replay buffer size: 4285\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.0621\n",
      "Average policy_loss: 0.9158\n",
      "Average value_loss: 0.1464\n",
      "Replay buffer size: 4376\n",
      "Time taken: 39.3s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.0577\n",
      "Average policy_loss: 0.9143\n",
      "Average value_loss: 0.1434\n",
      "Replay buffer size: 4468\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.0650\n",
      "Average policy_loss: 0.9211\n",
      "Average value_loss: 0.1439\n",
      "Replay buffer size: 4551\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.0689\n",
      "Average policy_loss: 0.9230\n",
      "Average value_loss: 0.1459\n",
      "Replay buffer size: 4638\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.0582\n",
      "Average policy_loss: 0.9140\n",
      "Average value_loss: 0.1443\n",
      "Replay buffer size: 4721\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.0772\n",
      "Average policy_loss: 0.9288\n",
      "Average value_loss: 0.1484\n",
      "Replay buffer size: 4804\n",
      "Time taken: 40.9s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.0729\n",
      "Average policy_loss: 0.9298\n",
      "Average value_loss: 0.1430\n",
      "Replay buffer size: 4888\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.0722\n",
      "Average policy_loss: 0.9308\n",
      "Average value_loss: 0.1414\n",
      "Replay buffer size: 4976\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.0778\n",
      "Average policy_loss: 0.9316\n",
      "Average value_loss: 0.1462\n",
      "Replay buffer size: 5076\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.0596\n",
      "Average policy_loss: 0.9207\n",
      "Average value_loss: 0.1389\n",
      "Replay buffer size: 5170\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.0722\n",
      "Average policy_loss: 0.9297\n",
      "Average value_loss: 0.1425\n",
      "Replay buffer size: 5262\n",
      "Time taken: 40.4s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.0693\n",
      "Average policy_loss: 0.9322\n",
      "Average value_loss: 0.1371\n",
      "Replay buffer size: 5354\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.0697\n",
      "Average policy_loss: 0.9295\n",
      "Average value_loss: 0.1403\n",
      "Replay buffer size: 5442\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.0736\n",
      "Average policy_loss: 0.9341\n",
      "Average value_loss: 0.1395\n",
      "Replay buffer size: 5523\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.0667\n",
      "Average policy_loss: 0.9282\n",
      "Average value_loss: 0.1385\n",
      "Replay buffer size: 5614\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.0828\n",
      "Average policy_loss: 0.9423\n",
      "Average value_loss: 0.1406\n",
      "Replay buffer size: 5700\n",
      "Time taken: 40.6s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.0887\n",
      "Average policy_loss: 0.9482\n",
      "Average value_loss: 0.1405\n",
      "Replay buffer size: 5789\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.0782\n",
      "Average policy_loss: 0.9371\n",
      "Average value_loss: 0.1411\n",
      "Replay buffer size: 5867\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.0739\n",
      "Average policy_loss: 0.9363\n",
      "Average value_loss: 0.1376\n",
      "Replay buffer size: 5959\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.0689\n",
      "Average policy_loss: 0.9343\n",
      "Average value_loss: 0.1347\n",
      "Replay buffer size: 6050\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.0779\n",
      "Average policy_loss: 0.9387\n",
      "Average value_loss: 0.1392\n",
      "Replay buffer size: 6144\n",
      "Time taken: 39.3s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.0780\n",
      "Average policy_loss: 0.9427\n",
      "Average value_loss: 0.1353\n",
      "Replay buffer size: 6237\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.0758\n",
      "Average policy_loss: 0.9399\n",
      "Average value_loss: 0.1359\n",
      "Replay buffer size: 6322\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.0714\n",
      "Average policy_loss: 0.9337\n",
      "Average value_loss: 0.1377\n",
      "Replay buffer size: 6419\n",
      "Time taken: 11.2s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.0730\n",
      "Average policy_loss: 0.9370\n",
      "Average value_loss: 0.1360\n",
      "Replay buffer size: 6505\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.0719\n",
      "Average policy_loss: 0.9375\n",
      "Average value_loss: 0.1344\n",
      "Replay buffer size: 6593\n",
      "Time taken: 39.4s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.0655\n",
      "Average policy_loss: 0.9332\n",
      "Average value_loss: 0.1324\n",
      "Replay buffer size: 6684\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.0729\n",
      "Average policy_loss: 0.9393\n",
      "Average value_loss: 0.1336\n",
      "Replay buffer size: 6769\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.0710\n",
      "Average policy_loss: 0.9407\n",
      "Average value_loss: 0.1303\n",
      "Replay buffer size: 6856\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.0744\n",
      "Average policy_loss: 0.9421\n",
      "Average value_loss: 0.1323\n",
      "Replay buffer size: 6935\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.0741\n",
      "Average policy_loss: 0.9402\n",
      "Average value_loss: 0.1340\n",
      "Replay buffer size: 7026\n",
      "Time taken: 41.1s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.0664\n",
      "Average policy_loss: 0.9338\n",
      "Average value_loss: 0.1327\n",
      "Replay buffer size: 7117\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.0783\n",
      "Average policy_loss: 0.9441\n",
      "Average value_loss: 0.1342\n",
      "Replay buffer size: 7203\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.0650\n",
      "Average policy_loss: 0.9341\n",
      "Average value_loss: 0.1309\n",
      "Replay buffer size: 7290\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.0738\n",
      "Average policy_loss: 0.9411\n",
      "Average value_loss: 0.1327\n",
      "Replay buffer size: 7373\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.0768\n",
      "Average policy_loss: 0.9423\n",
      "Average value_loss: 0.1345\n",
      "Replay buffer size: 7458\n",
      "Time taken: 38.7s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.0754\n",
      "Average policy_loss: 0.9396\n",
      "Average value_loss: 0.1358\n",
      "Replay buffer size: 7544\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.0590\n",
      "Average policy_loss: 0.9285\n",
      "Average value_loss: 0.1305\n",
      "Replay buffer size: 7633\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.0802\n",
      "Average policy_loss: 0.9489\n",
      "Average value_loss: 0.1314\n",
      "Replay buffer size: 7717\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.0654\n",
      "Average policy_loss: 0.9331\n",
      "Average value_loss: 0.1323\n",
      "Replay buffer size: 7803\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.0703\n",
      "Average policy_loss: 0.9417\n",
      "Average value_loss: 0.1286\n",
      "Replay buffer size: 7891\n",
      "Time taken: 39.2s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.0707\n",
      "Average policy_loss: 0.9391\n",
      "Average value_loss: 0.1317\n",
      "Replay buffer size: 7969\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.0614\n",
      "Average policy_loss: 0.9304\n",
      "Average value_loss: 0.1310\n",
      "Replay buffer size: 8065\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.0669\n",
      "Average policy_loss: 0.9362\n",
      "Average value_loss: 0.1307\n",
      "Replay buffer size: 8154\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.0674\n",
      "Average policy_loss: 0.9316\n",
      "Average value_loss: 0.1358\n",
      "Replay buffer size: 8246\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.0708\n",
      "Average policy_loss: 0.9419\n",
      "Average value_loss: 0.1289\n",
      "Replay buffer size: 8328\n",
      "Time taken: 39.6s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.0675\n",
      "Average policy_loss: 0.9395\n",
      "Average value_loss: 0.1280\n",
      "Replay buffer size: 8422\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.0708\n",
      "Average policy_loss: 0.9413\n",
      "Average value_loss: 0.1295\n",
      "Replay buffer size: 8514\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.0664\n",
      "Average policy_loss: 0.9398\n",
      "Average value_loss: 0.1266\n",
      "Replay buffer size: 8606\n",
      "Time taken: 11.2s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.0615\n",
      "Average policy_loss: 0.9349\n",
      "Average value_loss: 0.1266\n",
      "Replay buffer size: 8692\n",
      "Time taken: 11.2s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.0587\n",
      "Average policy_loss: 0.9316\n",
      "Average value_loss: 0.1272\n",
      "Replay buffer size: 8781\n",
      "Time taken: 39.2s\n",
      "\n",
      "Training complete! Total time: 0.5h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>iteration_time</td><td>▁▂▂▂▇▂▂▂▇▁▁▁▁▁▂▁▇▂▂██▂▂█▂▂█▂▂▂▂▂█▂▁▂▂▂▂█</td></tr><tr><td>loss</td><td>█▇▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▂▃▆▆▅▇▆▅▅▄▇▆▅▆▁▆▁▄▆▂▅▃▃▅▆▄▅▆▆█▅▅▂▄▄▃▄▅█▄</td></tr><tr><td>policy_loss</td><td>█▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▃▄▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.15</td></tr><tr><td>buffer_size</td><td>8781</td></tr><tr><td>iteration_time</td><td>39.16082</td></tr><tr><td>loss</td><td>1.05874</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>89</td></tr><tr><td>policy_loss</td><td>0.93158</td></tr><tr><td>total_time_hours</td><td>0.47161</td></tr><tr><td>value_loss</td><td>0.12715</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gallant-sweep-12</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/vb24b986' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/vb24b986</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 22 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_044453-vb24b986/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 644rmirp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0945757029389616\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: medium\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.4647788559355033\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.00010081781918285132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_051316-644rmirp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/644rmirp' target=\"_blank\">winter-sweep-13</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/644rmirp' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/644rmirp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 2.1848\n",
      "Average policy_loss: 1.9661\n",
      "Average value_loss: 0.2186\n",
      "Replay buffer size: 96\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.0595\n",
      "Average policy_loss: 0.8774\n",
      "Average value_loss: 0.1822\n",
      "Replay buffer size: 181\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 0.9821\n",
      "Average policy_loss: 0.8330\n",
      "Average value_loss: 0.1491\n",
      "Replay buffer size: 267\n",
      "Time taken: 18.5s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.9407\n",
      "Average policy_loss: 0.8163\n",
      "Average value_loss: 0.1244\n",
      "Replay buffer size: 364\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.9567\n",
      "Average policy_loss: 0.8425\n",
      "Average value_loss: 0.1142\n",
      "Replay buffer size: 458\n",
      "Time taken: 60.5s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.9851\n",
      "Average policy_loss: 0.8664\n",
      "Average value_loss: 0.1187\n",
      "Replay buffer size: 548\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.9973\n",
      "Average policy_loss: 0.8711\n",
      "Average value_loss: 0.1262\n",
      "Replay buffer size: 640\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.0549\n",
      "Average policy_loss: 0.9049\n",
      "Average value_loss: 0.1501\n",
      "Replay buffer size: 724\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.0398\n",
      "Average policy_loss: 0.8933\n",
      "Average value_loss: 0.1464\n",
      "Replay buffer size: 820\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.0420\n",
      "Average policy_loss: 0.8969\n",
      "Average value_loss: 0.1452\n",
      "Replay buffer size: 912\n",
      "Time taken: 55.5s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.0428\n",
      "Average policy_loss: 0.8962\n",
      "Average value_loss: 0.1466\n",
      "Replay buffer size: 1002\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.0575\n",
      "Average policy_loss: 0.9023\n",
      "Average value_loss: 0.1552\n",
      "Replay buffer size: 1079\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.0700\n",
      "Average policy_loss: 0.9117\n",
      "Average value_loss: 0.1583\n",
      "Replay buffer size: 1163\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.0701\n",
      "Average policy_loss: 0.9060\n",
      "Average value_loss: 0.1641\n",
      "Replay buffer size: 1245\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.0778\n",
      "Average policy_loss: 0.9078\n",
      "Average value_loss: 0.1700\n",
      "Replay buffer size: 1335\n",
      "Time taken: 59.2s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.0812\n",
      "Average policy_loss: 0.9164\n",
      "Average value_loss: 0.1648\n",
      "Replay buffer size: 1431\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.0663\n",
      "Average policy_loss: 0.8993\n",
      "Average value_loss: 0.1670\n",
      "Replay buffer size: 1524\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.0708\n",
      "Average policy_loss: 0.9040\n",
      "Average value_loss: 0.1668\n",
      "Replay buffer size: 1605\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.0731\n",
      "Average policy_loss: 0.9097\n",
      "Average value_loss: 0.1634\n",
      "Replay buffer size: 1694\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.1481\n",
      "Average policy_loss: 0.9480\n",
      "Average value_loss: 0.2001\n",
      "Replay buffer size: 1785\n",
      "Time taken: 57.6s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.1155\n",
      "Average policy_loss: 0.9324\n",
      "Average value_loss: 0.1831\n",
      "Replay buffer size: 1867\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.1107\n",
      "Average policy_loss: 0.9288\n",
      "Average value_loss: 0.1820\n",
      "Replay buffer size: 1960\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.1001\n",
      "Average policy_loss: 0.9174\n",
      "Average value_loss: 0.1828\n",
      "Replay buffer size: 2054\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.1020\n",
      "Average policy_loss: 0.9206\n",
      "Average value_loss: 0.1814\n",
      "Replay buffer size: 2138\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.1136\n",
      "Average policy_loss: 0.9300\n",
      "Average value_loss: 0.1836\n",
      "Replay buffer size: 2229\n",
      "Time taken: 57.7s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.1123\n",
      "Average policy_loss: 0.9276\n",
      "Average value_loss: 0.1847\n",
      "Replay buffer size: 2321\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.1908\n",
      "Average policy_loss: 0.9785\n",
      "Average value_loss: 0.2123\n",
      "Replay buffer size: 2403\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.1067\n",
      "Average policy_loss: 0.9197\n",
      "Average value_loss: 0.1870\n",
      "Replay buffer size: 2499\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.1190\n",
      "Average policy_loss: 0.9312\n",
      "Average value_loss: 0.1878\n",
      "Replay buffer size: 2581\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.1239\n",
      "Average policy_loss: 0.9277\n",
      "Average value_loss: 0.1963\n",
      "Replay buffer size: 2673\n",
      "Time taken: 57.0s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.1191\n",
      "Average policy_loss: 0.9268\n",
      "Average value_loss: 0.1923\n",
      "Replay buffer size: 2758\n",
      "Time taken: 19.3s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.1144\n",
      "Average policy_loss: 0.9278\n",
      "Average value_loss: 0.1866\n",
      "Replay buffer size: 2850\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.1141\n",
      "Average policy_loss: 0.9291\n",
      "Average value_loss: 0.1850\n",
      "Replay buffer size: 2944\n",
      "Time taken: 19.1s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.1013\n",
      "Average policy_loss: 0.9169\n",
      "Average value_loss: 0.1845\n",
      "Replay buffer size: 3036\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.1096\n",
      "Average policy_loss: 0.9222\n",
      "Average value_loss: 0.1874\n",
      "Replay buffer size: 3128\n",
      "Time taken: 56.3s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.1026\n",
      "Average policy_loss: 0.9178\n",
      "Average value_loss: 0.1848\n",
      "Replay buffer size: 3225\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.0817\n",
      "Average policy_loss: 0.9020\n",
      "Average value_loss: 0.1798\n",
      "Replay buffer size: 3313\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.0896\n",
      "Average policy_loss: 0.9089\n",
      "Average value_loss: 0.1808\n",
      "Replay buffer size: 3401\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.0900\n",
      "Average policy_loss: 0.9061\n",
      "Average value_loss: 0.1839\n",
      "Replay buffer size: 3488\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.0904\n",
      "Average policy_loss: 0.9099\n",
      "Average value_loss: 0.1805\n",
      "Replay buffer size: 3574\n",
      "Time taken: 52.9s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.0954\n",
      "Average policy_loss: 0.9117\n",
      "Average value_loss: 0.1837\n",
      "Replay buffer size: 3669\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.0952\n",
      "Average policy_loss: 0.9113\n",
      "Average value_loss: 0.1839\n",
      "Replay buffer size: 3758\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.1044\n",
      "Average policy_loss: 0.9138\n",
      "Average value_loss: 0.1906\n",
      "Replay buffer size: 3843\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.0915\n",
      "Average policy_loss: 0.9057\n",
      "Average value_loss: 0.1858\n",
      "Replay buffer size: 3939\n",
      "Time taken: 19.4s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.0910\n",
      "Average policy_loss: 0.9062\n",
      "Average value_loss: 0.1848\n",
      "Replay buffer size: 4036\n",
      "Time taken: 54.9s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.0840\n",
      "Average policy_loss: 0.8984\n",
      "Average value_loss: 0.1855\n",
      "Replay buffer size: 4132\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.0794\n",
      "Average policy_loss: 0.9009\n",
      "Average value_loss: 0.1785\n",
      "Replay buffer size: 4219\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.0865\n",
      "Average policy_loss: 0.9018\n",
      "Average value_loss: 0.1847\n",
      "Replay buffer size: 4302\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.0862\n",
      "Average policy_loss: 0.9001\n",
      "Average value_loss: 0.1861\n",
      "Replay buffer size: 4387\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.0939\n",
      "Average policy_loss: 0.9008\n",
      "Average value_loss: 0.1931\n",
      "Replay buffer size: 4465\n",
      "Time taken: 58.0s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.0915\n",
      "Average policy_loss: 0.9084\n",
      "Average value_loss: 0.1831\n",
      "Replay buffer size: 4552\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.0966\n",
      "Average policy_loss: 0.9102\n",
      "Average value_loss: 0.1865\n",
      "Replay buffer size: 4640\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.2507\n",
      "Average policy_loss: 1.0344\n",
      "Average value_loss: 0.2163\n",
      "Replay buffer size: 4734\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.1394\n",
      "Average policy_loss: 0.9430\n",
      "Average value_loss: 0.1964\n",
      "Replay buffer size: 4829\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.1107\n",
      "Average policy_loss: 0.9215\n",
      "Average value_loss: 0.1892\n",
      "Replay buffer size: 4919\n",
      "Time taken: 57.4s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.1152\n",
      "Average policy_loss: 0.9212\n",
      "Average value_loss: 0.1940\n",
      "Replay buffer size: 5003\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.1093\n",
      "Average policy_loss: 0.9209\n",
      "Average value_loss: 0.1885\n",
      "Replay buffer size: 5092\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.1234\n",
      "Average policy_loss: 0.9293\n",
      "Average value_loss: 0.1942\n",
      "Replay buffer size: 5177\n",
      "Time taken: 20.8s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.1180\n",
      "Average policy_loss: 0.9230\n",
      "Average value_loss: 0.1951\n",
      "Replay buffer size: 5266\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.1260\n",
      "Average policy_loss: 0.9303\n",
      "Average value_loss: 0.1957\n",
      "Replay buffer size: 5349\n",
      "Time taken: 62.3s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.1185\n",
      "Average policy_loss: 0.9202\n",
      "Average value_loss: 0.1983\n",
      "Replay buffer size: 5430\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.1188\n",
      "Average policy_loss: 0.9246\n",
      "Average value_loss: 0.1943\n",
      "Replay buffer size: 5520\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.1300\n",
      "Average policy_loss: 0.9303\n",
      "Average value_loss: 0.1997\n",
      "Replay buffer size: 5609\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.1339\n",
      "Average policy_loss: 0.9337\n",
      "Average value_loss: 0.2002\n",
      "Replay buffer size: 5693\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.1187\n",
      "Average policy_loss: 0.9209\n",
      "Average value_loss: 0.1977\n",
      "Replay buffer size: 5782\n",
      "Time taken: 56.9s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.1892\n",
      "Average policy_loss: 0.9812\n",
      "Average value_loss: 0.2080\n",
      "Replay buffer size: 5863\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.1213\n",
      "Average policy_loss: 0.9261\n",
      "Average value_loss: 0.1951\n",
      "Replay buffer size: 5947\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.1229\n",
      "Average policy_loss: 0.9299\n",
      "Average value_loss: 0.1930\n",
      "Replay buffer size: 6039\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.1284\n",
      "Average policy_loss: 0.9305\n",
      "Average value_loss: 0.1979\n",
      "Replay buffer size: 6124\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.1160\n",
      "Average policy_loss: 0.9183\n",
      "Average value_loss: 0.1976\n",
      "Replay buffer size: 6213\n",
      "Time taken: 59.3s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.1362\n",
      "Average policy_loss: 0.9280\n",
      "Average value_loss: 0.2081\n",
      "Replay buffer size: 6298\n",
      "Time taken: 19.2s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.1253\n",
      "Average policy_loss: 0.9294\n",
      "Average value_loss: 0.1959\n",
      "Replay buffer size: 6391\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.1164\n",
      "Average policy_loss: 0.9196\n",
      "Average value_loss: 0.1969\n",
      "Replay buffer size: 6476\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.1168\n",
      "Average policy_loss: 0.9283\n",
      "Average value_loss: 0.1885\n",
      "Replay buffer size: 6567\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.1092\n",
      "Average policy_loss: 0.9220\n",
      "Average value_loss: 0.1872\n",
      "Replay buffer size: 6648\n",
      "Time taken: 60.5s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.1166\n",
      "Average policy_loss: 0.9273\n",
      "Average value_loss: 0.1894\n",
      "Replay buffer size: 6741\n",
      "Time taken: 19.3s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.1182\n",
      "Average policy_loss: 0.9243\n",
      "Average value_loss: 0.1939\n",
      "Replay buffer size: 6833\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.1264\n",
      "Average policy_loss: 0.9352\n",
      "Average value_loss: 0.1911\n",
      "Replay buffer size: 6925\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.1124\n",
      "Average policy_loss: 0.9276\n",
      "Average value_loss: 0.1848\n",
      "Replay buffer size: 7016\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.1283\n",
      "Average policy_loss: 0.9335\n",
      "Average value_loss: 0.1948\n",
      "Replay buffer size: 7101\n",
      "Time taken: 60.1s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.1264\n",
      "Average policy_loss: 0.9331\n",
      "Average value_loss: 0.1934\n",
      "Replay buffer size: 7186\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.1262\n",
      "Average policy_loss: 0.9361\n",
      "Average value_loss: 0.1900\n",
      "Replay buffer size: 7280\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.1239\n",
      "Average policy_loss: 0.9321\n",
      "Average value_loss: 0.1918\n",
      "Replay buffer size: 7367\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.1719\n",
      "Average policy_loss: 0.9575\n",
      "Average value_loss: 0.2144\n",
      "Replay buffer size: 7453\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.1330\n",
      "Average policy_loss: 0.9463\n",
      "Average value_loss: 0.1867\n",
      "Replay buffer size: 7546\n",
      "Time taken: 61.6s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.1462\n",
      "Average policy_loss: 0.9504\n",
      "Average value_loss: 0.1958\n",
      "Replay buffer size: 7633\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.1566\n",
      "Average policy_loss: 0.9618\n",
      "Average value_loss: 0.1948\n",
      "Replay buffer size: 7727\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.1363\n",
      "Average policy_loss: 0.9452\n",
      "Average value_loss: 0.1911\n",
      "Replay buffer size: 7815\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.1387\n",
      "Average policy_loss: 0.9477\n",
      "Average value_loss: 0.1911\n",
      "Replay buffer size: 7900\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.2222\n",
      "Average policy_loss: 1.0212\n",
      "Average value_loss: 0.2010\n",
      "Replay buffer size: 7988\n",
      "Time taken: 60.8s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.1590\n",
      "Average policy_loss: 0.9647\n",
      "Average value_loss: 0.1943\n",
      "Replay buffer size: 8070\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.1415\n",
      "Average policy_loss: 0.9539\n",
      "Average value_loss: 0.1876\n",
      "Replay buffer size: 8161\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.1433\n",
      "Average policy_loss: 0.9515\n",
      "Average value_loss: 0.1917\n",
      "Replay buffer size: 8245\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.1470\n",
      "Average policy_loss: 0.9565\n",
      "Average value_loss: 0.1905\n",
      "Replay buffer size: 8318\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.1498\n",
      "Average policy_loss: 0.9617\n",
      "Average value_loss: 0.1881\n",
      "Replay buffer size: 8404\n",
      "Time taken: 60.7s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.1434\n",
      "Average policy_loss: 0.9517\n",
      "Average value_loss: 0.1916\n",
      "Replay buffer size: 8487\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.1445\n",
      "Average policy_loss: 0.9516\n",
      "Average value_loss: 0.1929\n",
      "Replay buffer size: 8574\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.1342\n",
      "Average policy_loss: 0.9446\n",
      "Average value_loss: 0.1896\n",
      "Replay buffer size: 8661\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.1503\n",
      "Average policy_loss: 0.9575\n",
      "Average value_loss: 0.1927\n",
      "Replay buffer size: 8741\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.1418\n",
      "Average policy_loss: 0.9520\n",
      "Average value_loss: 0.1898\n",
      "Replay buffer size: 8822\n",
      "Time taken: 65.5s\n",
      "\n",
      "Training complete! Total time: 0.7h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>iteration_time</td><td>▁▂▂▂▂▁▁▂▁█▂█▁▇▂▇▁▁▇▂█▁▂▇▂▁▂▂▂▂▂▂▂▂▂▁▂█▂▂</td></tr><tr><td>loss</td><td>▂▁▂▃▄▆▅▅▅▅▅▅▅▅▅▅▆▅▅▅▆▅▅▅▇▆▅▆▅▅▆▇▆▆▆█▆▆▆▆</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>█▇▆▂█▅▁▅▆▇▆▁█▁▇▆▄▄▄██▄▂▃▅▅▅▁▂▆▃▆▇▆▃▇▃▁▆▄</td></tr><tr><td>policy_loss</td><td>▁▁▁▃▃▃▄▄▄▄▃▃▃▃▃▃▃▃▂▂▃█▄▃▃▃▄▃▄▃▄▄▄▅▄▅▅▅▄▅</td></tr><tr><td>value_loss</td><td>▂▁▁▃▃▅▅▅▅▆▆█▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▆▇▇▇▆▇▆▇▆▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.2</td></tr><tr><td>buffer_size</td><td>8822</td></tr><tr><td>iteration_time</td><td>65.5283</td></tr><tr><td>loss</td><td>1.14178</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>81</td></tr><tr><td>policy_loss</td><td>0.95197</td></tr><tr><td>total_time_hours</td><td>0.73217</td></tr><tr><td>value_loss</td><td>0.18982</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">winter-sweep-13</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/644rmirp' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/644rmirp</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 24 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_051316-644rmirp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3oqcgwoz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02761871300937066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: small\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.7139143001081747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 4.160840845407718e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_055721-3oqcgwoz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/3oqcgwoz' target=\"_blank\">swift-sweep-14</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/3oqcgwoz' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/3oqcgwoz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.5231\n",
      "Average policy_loss: 0.5507\n",
      "Average value_loss: 0.9723\n",
      "Replay buffer size: 68\n",
      "Time taken: 6.7s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 0.6749\n",
      "Average policy_loss: 0.5917\n",
      "Average value_loss: 0.0832\n",
      "Replay buffer size: 144\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 0.6203\n",
      "Average policy_loss: 0.5457\n",
      "Average value_loss: 0.0746\n",
      "Replay buffer size: 235\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.5995\n",
      "Average policy_loss: 0.5229\n",
      "Average value_loss: 0.0766\n",
      "Replay buffer size: 335\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.5667\n",
      "Average policy_loss: 0.4933\n",
      "Average value_loss: 0.0734\n",
      "Replay buffer size: 427\n",
      "Time taken: 33.1s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.5581\n",
      "Average policy_loss: 0.4921\n",
      "Average value_loss: 0.0660\n",
      "Replay buffer size: 527\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.5304\n",
      "Average policy_loss: 0.4673\n",
      "Average value_loss: 0.0630\n",
      "Replay buffer size: 623\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.5120\n",
      "Average policy_loss: 0.4500\n",
      "Average value_loss: 0.0620\n",
      "Replay buffer size: 722\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.5228\n",
      "Average policy_loss: 0.4513\n",
      "Average value_loss: 0.0716\n",
      "Replay buffer size: 814\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.5117\n",
      "Average policy_loss: 0.4436\n",
      "Average value_loss: 0.0681\n",
      "Replay buffer size: 910\n",
      "Time taken: 39.3s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.5227\n",
      "Average policy_loss: 0.4512\n",
      "Average value_loss: 0.0716\n",
      "Replay buffer size: 1004\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.5015\n",
      "Average policy_loss: 0.4351\n",
      "Average value_loss: 0.0665\n",
      "Replay buffer size: 1100\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.4965\n",
      "Average policy_loss: 0.4341\n",
      "Average value_loss: 0.0624\n",
      "Replay buffer size: 1200\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.4935\n",
      "Average policy_loss: 0.4337\n",
      "Average value_loss: 0.0598\n",
      "Replay buffer size: 1300\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.4822\n",
      "Average policy_loss: 0.4262\n",
      "Average value_loss: 0.0560\n",
      "Replay buffer size: 1400\n",
      "Time taken: 37.5s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.4873\n",
      "Average policy_loss: 0.4312\n",
      "Average value_loss: 0.0560\n",
      "Replay buffer size: 1490\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.4845\n",
      "Average policy_loss: 0.4315\n",
      "Average value_loss: 0.0530\n",
      "Replay buffer size: 1590\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.4772\n",
      "Average policy_loss: 0.4262\n",
      "Average value_loss: 0.0510\n",
      "Replay buffer size: 1690\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.4687\n",
      "Average policy_loss: 0.4200\n",
      "Average value_loss: 0.0487\n",
      "Replay buffer size: 1786\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.4681\n",
      "Average policy_loss: 0.4200\n",
      "Average value_loss: 0.0481\n",
      "Replay buffer size: 1884\n",
      "Time taken: 35.9s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.4662\n",
      "Average policy_loss: 0.4170\n",
      "Average value_loss: 0.0492\n",
      "Replay buffer size: 1982\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.4686\n",
      "Average policy_loss: 0.4192\n",
      "Average value_loss: 0.0494\n",
      "Replay buffer size: 2077\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.4637\n",
      "Average policy_loss: 0.4159\n",
      "Average value_loss: 0.0477\n",
      "Replay buffer size: 2177\n",
      "Time taken: 11.2s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.4617\n",
      "Average policy_loss: 0.4148\n",
      "Average value_loss: 0.0469\n",
      "Replay buffer size: 2273\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.4548\n",
      "Average policy_loss: 0.4065\n",
      "Average value_loss: 0.0483\n",
      "Replay buffer size: 2373\n",
      "Time taken: 36.2s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.4531\n",
      "Average policy_loss: 0.4069\n",
      "Average value_loss: 0.0462\n",
      "Replay buffer size: 2473\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.4576\n",
      "Average policy_loss: 0.4112\n",
      "Average value_loss: 0.0464\n",
      "Replay buffer size: 2573\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.4490\n",
      "Average policy_loss: 0.4039\n",
      "Average value_loss: 0.0452\n",
      "Replay buffer size: 2668\n",
      "Time taken: 10.7s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.4578\n",
      "Average policy_loss: 0.4127\n",
      "Average value_loss: 0.0451\n",
      "Replay buffer size: 2768\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 55.00%, Draw rate = 40.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.4566\n",
      "Average policy_loss: 0.4124\n",
      "Average value_loss: 0.0442\n",
      "Replay buffer size: 2866\n",
      "Time taken: 39.7s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.4612\n",
      "Average policy_loss: 0.4149\n",
      "Average value_loss: 0.0463\n",
      "Replay buffer size: 2960\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.4624\n",
      "Average policy_loss: 0.4161\n",
      "Average value_loss: 0.0463\n",
      "Replay buffer size: 3058\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.4573\n",
      "Average policy_loss: 0.4114\n",
      "Average value_loss: 0.0459\n",
      "Replay buffer size: 3158\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.4602\n",
      "Average policy_loss: 0.4127\n",
      "Average value_loss: 0.0475\n",
      "Replay buffer size: 3253\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.4645\n",
      "Average policy_loss: 0.4159\n",
      "Average value_loss: 0.0486\n",
      "Replay buffer size: 3352\n",
      "Time taken: 41.8s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.4643\n",
      "Average policy_loss: 0.4166\n",
      "Average value_loss: 0.0477\n",
      "Replay buffer size: 3450\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.4624\n",
      "Average policy_loss: 0.4156\n",
      "Average value_loss: 0.0468\n",
      "Replay buffer size: 3550\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.4638\n",
      "Average policy_loss: 0.4167\n",
      "Average value_loss: 0.0471\n",
      "Replay buffer size: 3642\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.4608\n",
      "Average policy_loss: 0.4126\n",
      "Average value_loss: 0.0481\n",
      "Replay buffer size: 3739\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.4653\n",
      "Average policy_loss: 0.4161\n",
      "Average value_loss: 0.0492\n",
      "Replay buffer size: 3833\n",
      "Time taken: 40.4s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.4668\n",
      "Average policy_loss: 0.4187\n",
      "Average value_loss: 0.0482\n",
      "Replay buffer size: 3931\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.4594\n",
      "Average policy_loss: 0.4125\n",
      "Average value_loss: 0.0469\n",
      "Replay buffer size: 4031\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.4688\n",
      "Average policy_loss: 0.4206\n",
      "Average value_loss: 0.0482\n",
      "Replay buffer size: 4125\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.4627\n",
      "Average policy_loss: 0.4169\n",
      "Average value_loss: 0.0457\n",
      "Replay buffer size: 4225\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.4609\n",
      "Average policy_loss: 0.4150\n",
      "Average value_loss: 0.0458\n",
      "Replay buffer size: 4325\n",
      "Time taken: 39.3s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.4604\n",
      "Average policy_loss: 0.4146\n",
      "Average value_loss: 0.0458\n",
      "Replay buffer size: 4417\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.4692\n",
      "Average policy_loss: 0.4222\n",
      "Average value_loss: 0.0471\n",
      "Replay buffer size: 4512\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.4734\n",
      "Average policy_loss: 0.4272\n",
      "Average value_loss: 0.0463\n",
      "Replay buffer size: 4611\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.4723\n",
      "Average policy_loss: 0.4249\n",
      "Average value_loss: 0.0475\n",
      "Replay buffer size: 4706\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.4795\n",
      "Average policy_loss: 0.4324\n",
      "Average value_loss: 0.0471\n",
      "Replay buffer size: 4804\n",
      "Time taken: 42.1s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.4834\n",
      "Average policy_loss: 0.4344\n",
      "Average value_loss: 0.0490\n",
      "Replay buffer size: 4902\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.4842\n",
      "Average policy_loss: 0.4352\n",
      "Average value_loss: 0.0489\n",
      "Replay buffer size: 4995\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.4844\n",
      "Average policy_loss: 0.4364\n",
      "Average value_loss: 0.0480\n",
      "Replay buffer size: 5091\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.4874\n",
      "Average policy_loss: 0.4375\n",
      "Average value_loss: 0.0499\n",
      "Replay buffer size: 5187\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 50.00%, Draw rate = 45.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.4904\n",
      "Average policy_loss: 0.4394\n",
      "Average value_loss: 0.0510\n",
      "Replay buffer size: 5283\n",
      "Time taken: 46.4s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.4878\n",
      "Average policy_loss: 0.4393\n",
      "Average value_loss: 0.0484\n",
      "Replay buffer size: 5376\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.4925\n",
      "Average policy_loss: 0.4429\n",
      "Average value_loss: 0.0495\n",
      "Replay buffer size: 5471\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.4918\n",
      "Average policy_loss: 0.4425\n",
      "Average value_loss: 0.0493\n",
      "Replay buffer size: 5568\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.4960\n",
      "Average policy_loss: 0.4469\n",
      "Average value_loss: 0.0491\n",
      "Replay buffer size: 5668\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.4936\n",
      "Average policy_loss: 0.4448\n",
      "Average value_loss: 0.0489\n",
      "Replay buffer size: 5764\n",
      "Time taken: 42.1s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.5008\n",
      "Average policy_loss: 0.4509\n",
      "Average value_loss: 0.0499\n",
      "Replay buffer size: 5861\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.4896\n",
      "Average policy_loss: 0.4417\n",
      "Average value_loss: 0.0479\n",
      "Replay buffer size: 5960\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.4933\n",
      "Average policy_loss: 0.4420\n",
      "Average value_loss: 0.0512\n",
      "Replay buffer size: 6058\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.4943\n",
      "Average policy_loss: 0.4438\n",
      "Average value_loss: 0.0504\n",
      "Replay buffer size: 6152\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.4962\n",
      "Average policy_loss: 0.4471\n",
      "Average value_loss: 0.0492\n",
      "Replay buffer size: 6248\n",
      "Time taken: 43.1s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.4968\n",
      "Average policy_loss: 0.4460\n",
      "Average value_loss: 0.0508\n",
      "Replay buffer size: 6342\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.5121\n",
      "Average policy_loss: 0.4605\n",
      "Average value_loss: 0.0516\n",
      "Replay buffer size: 6434\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.5004\n",
      "Average policy_loss: 0.4496\n",
      "Average value_loss: 0.0509\n",
      "Replay buffer size: 6526\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.5016\n",
      "Average policy_loss: 0.4518\n",
      "Average value_loss: 0.0498\n",
      "Replay buffer size: 6624\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.4963\n",
      "Average policy_loss: 0.4475\n",
      "Average value_loss: 0.0488\n",
      "Replay buffer size: 6718\n",
      "Time taken: 43.6s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.5043\n",
      "Average policy_loss: 0.4537\n",
      "Average value_loss: 0.0506\n",
      "Replay buffer size: 6816\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.5006\n",
      "Average policy_loss: 0.4504\n",
      "Average value_loss: 0.0502\n",
      "Replay buffer size: 6916\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.5042\n",
      "Average policy_loss: 0.4562\n",
      "Average value_loss: 0.0480\n",
      "Replay buffer size: 7016\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.4993\n",
      "Average policy_loss: 0.4525\n",
      "Average value_loss: 0.0468\n",
      "Replay buffer size: 7113\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.5025\n",
      "Average policy_loss: 0.4539\n",
      "Average value_loss: 0.0485\n",
      "Replay buffer size: 7205\n",
      "Time taken: 42.9s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.4999\n",
      "Average policy_loss: 0.4523\n",
      "Average value_loss: 0.0476\n",
      "Replay buffer size: 7297\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.5012\n",
      "Average policy_loss: 0.4530\n",
      "Average value_loss: 0.0482\n",
      "Replay buffer size: 7397\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.4963\n",
      "Average policy_loss: 0.4479\n",
      "Average value_loss: 0.0485\n",
      "Replay buffer size: 7497\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.4934\n",
      "Average policy_loss: 0.4466\n",
      "Average value_loss: 0.0468\n",
      "Replay buffer size: 7591\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.4996\n",
      "Average policy_loss: 0.4535\n",
      "Average value_loss: 0.0461\n",
      "Replay buffer size: 7687\n",
      "Time taken: 44.3s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.5022\n",
      "Average policy_loss: 0.4538\n",
      "Average value_loss: 0.0484\n",
      "Replay buffer size: 7783\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.4988\n",
      "Average policy_loss: 0.4528\n",
      "Average value_loss: 0.0460\n",
      "Replay buffer size: 7880\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.5053\n",
      "Average policy_loss: 0.4595\n",
      "Average value_loss: 0.0458\n",
      "Replay buffer size: 7976\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.5060\n",
      "Average policy_loss: 0.4590\n",
      "Average value_loss: 0.0470\n",
      "Replay buffer size: 8072\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.4974\n",
      "Average policy_loss: 0.4517\n",
      "Average value_loss: 0.0458\n",
      "Replay buffer size: 8172\n",
      "Time taken: 46.1s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.4989\n",
      "Average policy_loss: 0.4537\n",
      "Average value_loss: 0.0452\n",
      "Replay buffer size: 8270\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.5060\n",
      "Average policy_loss: 0.4605\n",
      "Average value_loss: 0.0455\n",
      "Replay buffer size: 8370\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.5075\n",
      "Average policy_loss: 0.4620\n",
      "Average value_loss: 0.0455\n",
      "Replay buffer size: 8465\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.5074\n",
      "Average policy_loss: 0.4627\n",
      "Average value_loss: 0.0448\n",
      "Replay buffer size: 8564\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.5075\n",
      "Average policy_loss: 0.4616\n",
      "Average value_loss: 0.0459\n",
      "Replay buffer size: 8660\n",
      "Time taken: 44.8s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.5199\n",
      "Average policy_loss: 0.4733\n",
      "Average value_loss: 0.0467\n",
      "Replay buffer size: 8754\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.5155\n",
      "Average policy_loss: 0.4702\n",
      "Average value_loss: 0.0453\n",
      "Replay buffer size: 8852\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.5137\n",
      "Average policy_loss: 0.4684\n",
      "Average value_loss: 0.0453\n",
      "Replay buffer size: 8946\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.5277\n",
      "Average policy_loss: 0.4812\n",
      "Average value_loss: 0.0466\n",
      "Replay buffer size: 9041\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.5161\n",
      "Average policy_loss: 0.4718\n",
      "Average value_loss: 0.0443\n",
      "Replay buffer size: 9140\n",
      "Time taken: 47.3s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.5220\n",
      "Average policy_loss: 0.4769\n",
      "Average value_loss: 0.0451\n",
      "Replay buffer size: 9240\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.5198\n",
      "Average policy_loss: 0.4743\n",
      "Average value_loss: 0.0455\n",
      "Replay buffer size: 9331\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.5214\n",
      "Average policy_loss: 0.4771\n",
      "Average value_loss: 0.0443\n",
      "Replay buffer size: 9428\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.5240\n",
      "Average policy_loss: 0.4775\n",
      "Average value_loss: 0.0464\n",
      "Replay buffer size: 9524\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 50.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.5184\n",
      "Average policy_loss: 0.4719\n",
      "Average value_loss: 0.0464\n",
      "Replay buffer size: 9617\n",
      "Time taken: 47.1s\n",
      "\n",
      "Training complete! Total time: 0.5h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>iteration_time</td><td>▁▅▁▆▁▁▁▁▁▆▁▁▁▇▁▁▁▇▁▁▇▁▁▁▁▁▁▁▁▁▇▂▂▂██▂▂█▂</td></tr><tr><td>loss</td><td>█▇▆▅▅▄▄▄▃▂▂▁▂▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▁▇▆▆█▅██▇▇▇█▇█▇▇█▆██▇█▆▇██▆▇▆▆▆█▇▇▇█▇▇▆▇</td></tr><tr><td>policy_loss</td><td>█▇▅▃▃▂▂▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▄▃▃▃▃▃▃▃▃▄▃▄▄▄▄▄▄▄</td></tr><tr><td>value_loss</td><td>█▆▆▅▄▃▂▂▁▁▂▂▂▁▂▂▁▂▁▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.05</td></tr><tr><td>buffer_size</td><td>9617</td></tr><tr><td>iteration_time</td><td>47.07154</td></tr><tr><td>loss</td><td>0.51835</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>93</td></tr><tr><td>policy_loss</td><td>0.47194</td></tr><tr><td>total_time_hours</td><td>0.49814</td></tr><tr><td>value_loss</td><td>0.04641</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swift-sweep-14</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/3oqcgwoz' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/3oqcgwoz</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 16 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_055721-3oqcgwoz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e0jzbm9x with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05018288995345499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: tiny\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.7387659090520059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005560097255888672\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_062722-e0jzbm9x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/e0jzbm9x' target=\"_blank\">woven-sweep-15</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/e0jzbm9x' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/e0jzbm9x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.4770\n",
      "Average policy_loss: 1.1895\n",
      "Average value_loss: 0.2875\n",
      "Replay buffer size: 92\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.3052\n",
      "Average policy_loss: 1.0978\n",
      "Average value_loss: 0.2074\n",
      "Replay buffer size: 174\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.2803\n",
      "Average policy_loss: 1.0931\n",
      "Average value_loss: 0.1872\n",
      "Replay buffer size: 259\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.1975\n",
      "Average policy_loss: 1.0279\n",
      "Average value_loss: 0.1697\n",
      "Replay buffer size: 353\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.1262\n",
      "Average policy_loss: 0.9721\n",
      "Average value_loss: 0.1541\n",
      "Replay buffer size: 448\n",
      "Time taken: 51.2s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.0903\n",
      "Average policy_loss: 0.9446\n",
      "Average value_loss: 0.1457\n",
      "Replay buffer size: 532\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.0874\n",
      "Average policy_loss: 0.9410\n",
      "Average value_loss: 0.1464\n",
      "Replay buffer size: 619\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.0340\n",
      "Average policy_loss: 0.8938\n",
      "Average value_loss: 0.1402\n",
      "Replay buffer size: 715\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.0354\n",
      "Average policy_loss: 0.8990\n",
      "Average value_loss: 0.1365\n",
      "Replay buffer size: 798\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.0374\n",
      "Average policy_loss: 0.9005\n",
      "Average value_loss: 0.1369\n",
      "Replay buffer size: 882\n",
      "Time taken: 50.8s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.0263\n",
      "Average policy_loss: 0.8863\n",
      "Average value_loss: 0.1399\n",
      "Replay buffer size: 976\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.9987\n",
      "Average policy_loss: 0.8635\n",
      "Average value_loss: 0.1352\n",
      "Replay buffer size: 1067\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.0040\n",
      "Average policy_loss: 0.8729\n",
      "Average value_loss: 0.1311\n",
      "Replay buffer size: 1162\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.9996\n",
      "Average policy_loss: 0.8670\n",
      "Average value_loss: 0.1327\n",
      "Replay buffer size: 1257\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.9814\n",
      "Average policy_loss: 0.8572\n",
      "Average value_loss: 0.1242\n",
      "Replay buffer size: 1350\n",
      "Time taken: 52.5s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.9930\n",
      "Average policy_loss: 0.8682\n",
      "Average value_loss: 0.1248\n",
      "Replay buffer size: 1442\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.9707\n",
      "Average policy_loss: 0.8521\n",
      "Average value_loss: 0.1186\n",
      "Replay buffer size: 1538\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.9715\n",
      "Average policy_loss: 0.8517\n",
      "Average value_loss: 0.1199\n",
      "Replay buffer size: 1628\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.9619\n",
      "Average policy_loss: 0.8462\n",
      "Average value_loss: 0.1157\n",
      "Replay buffer size: 1716\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.9694\n",
      "Average policy_loss: 0.8525\n",
      "Average value_loss: 0.1169\n",
      "Replay buffer size: 1805\n",
      "Time taken: 51.9s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.9537\n",
      "Average policy_loss: 0.8369\n",
      "Average value_loss: 0.1168\n",
      "Replay buffer size: 1900\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.9523\n",
      "Average policy_loss: 0.8413\n",
      "Average value_loss: 0.1110\n",
      "Replay buffer size: 1991\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.9536\n",
      "Average policy_loss: 0.8371\n",
      "Average value_loss: 0.1165\n",
      "Replay buffer size: 2072\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.9415\n",
      "Average policy_loss: 0.8256\n",
      "Average value_loss: 0.1159\n",
      "Replay buffer size: 2168\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.9428\n",
      "Average policy_loss: 0.8279\n",
      "Average value_loss: 0.1150\n",
      "Replay buffer size: 2255\n",
      "Time taken: 50.5s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.9473\n",
      "Average policy_loss: 0.8378\n",
      "Average value_loss: 0.1094\n",
      "Replay buffer size: 2347\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.9549\n",
      "Average policy_loss: 0.8416\n",
      "Average value_loss: 0.1133\n",
      "Replay buffer size: 2433\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.9528\n",
      "Average policy_loss: 0.8337\n",
      "Average value_loss: 0.1190\n",
      "Replay buffer size: 2527\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.9359\n",
      "Average policy_loss: 0.8261\n",
      "Average value_loss: 0.1098\n",
      "Replay buffer size: 2627\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.9422\n",
      "Average policy_loss: 0.8297\n",
      "Average value_loss: 0.1125\n",
      "Replay buffer size: 2712\n",
      "Time taken: 51.0s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.9356\n",
      "Average policy_loss: 0.8227\n",
      "Average value_loss: 0.1128\n",
      "Replay buffer size: 2810\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.9338\n",
      "Average policy_loss: 0.8226\n",
      "Average value_loss: 0.1112\n",
      "Replay buffer size: 2897\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.9522\n",
      "Average policy_loss: 0.8412\n",
      "Average value_loss: 0.1110\n",
      "Replay buffer size: 2976\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.9407\n",
      "Average policy_loss: 0.8281\n",
      "Average value_loss: 0.1126\n",
      "Replay buffer size: 3068\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.9348\n",
      "Average policy_loss: 0.8187\n",
      "Average value_loss: 0.1162\n",
      "Replay buffer size: 3156\n",
      "Time taken: 51.9s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.9341\n",
      "Average policy_loss: 0.8215\n",
      "Average value_loss: 0.1126\n",
      "Replay buffer size: 3248\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.9366\n",
      "Average policy_loss: 0.8208\n",
      "Average value_loss: 0.1159\n",
      "Replay buffer size: 3331\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.9222\n",
      "Average policy_loss: 0.8106\n",
      "Average value_loss: 0.1116\n",
      "Replay buffer size: 3420\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.9232\n",
      "Average policy_loss: 0.8125\n",
      "Average value_loss: 0.1107\n",
      "Replay buffer size: 3507\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.9234\n",
      "Average policy_loss: 0.8109\n",
      "Average value_loss: 0.1125\n",
      "Replay buffer size: 3604\n",
      "Time taken: 50.4s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.9186\n",
      "Average policy_loss: 0.8088\n",
      "Average value_loss: 0.1098\n",
      "Replay buffer size: 3702\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.9084\n",
      "Average policy_loss: 0.7965\n",
      "Average value_loss: 0.1119\n",
      "Replay buffer size: 3798\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.9277\n",
      "Average policy_loss: 0.8212\n",
      "Average value_loss: 0.1066\n",
      "Replay buffer size: 3890\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.9100\n",
      "Average policy_loss: 0.8006\n",
      "Average value_loss: 0.1094\n",
      "Replay buffer size: 3974\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.9235\n",
      "Average policy_loss: 0.8152\n",
      "Average value_loss: 0.1083\n",
      "Replay buffer size: 4063\n",
      "Time taken: 48.2s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.9270\n",
      "Average policy_loss: 0.8169\n",
      "Average value_loss: 0.1101\n",
      "Replay buffer size: 4157\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.9138\n",
      "Average policy_loss: 0.8037\n",
      "Average value_loss: 0.1101\n",
      "Replay buffer size: 4250\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.9156\n",
      "Average policy_loss: 0.8044\n",
      "Average value_loss: 0.1112\n",
      "Replay buffer size: 4346\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.9197\n",
      "Average policy_loss: 0.8129\n",
      "Average value_loss: 0.1069\n",
      "Replay buffer size: 4443\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.9117\n",
      "Average policy_loss: 0.8065\n",
      "Average value_loss: 0.1052\n",
      "Replay buffer size: 4531\n",
      "Time taken: 52.1s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.9060\n",
      "Average policy_loss: 0.7963\n",
      "Average value_loss: 0.1097\n",
      "Replay buffer size: 4620\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.9074\n",
      "Average policy_loss: 0.8009\n",
      "Average value_loss: 0.1066\n",
      "Replay buffer size: 4707\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.9035\n",
      "Average policy_loss: 0.7967\n",
      "Average value_loss: 0.1068\n",
      "Replay buffer size: 4798\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.9099\n",
      "Average policy_loss: 0.8022\n",
      "Average value_loss: 0.1078\n",
      "Replay buffer size: 4885\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.8932\n",
      "Average policy_loss: 0.7857\n",
      "Average value_loss: 0.1074\n",
      "Replay buffer size: 4977\n",
      "Time taken: 50.0s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.8943\n",
      "Average policy_loss: 0.7870\n",
      "Average value_loss: 0.1073\n",
      "Replay buffer size: 5068\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.9169\n",
      "Average policy_loss: 0.8024\n",
      "Average value_loss: 0.1144\n",
      "Replay buffer size: 5150\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.9072\n",
      "Average policy_loss: 0.7999\n",
      "Average value_loss: 0.1073\n",
      "Replay buffer size: 5236\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.9147\n",
      "Average policy_loss: 0.8033\n",
      "Average value_loss: 0.1113\n",
      "Replay buffer size: 5318\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.9069\n",
      "Average policy_loss: 0.8002\n",
      "Average value_loss: 0.1066\n",
      "Replay buffer size: 5410\n",
      "Time taken: 49.2s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.9091\n",
      "Average policy_loss: 0.8008\n",
      "Average value_loss: 0.1083\n",
      "Replay buffer size: 5507\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.9101\n",
      "Average policy_loss: 0.7994\n",
      "Average value_loss: 0.1107\n",
      "Replay buffer size: 5595\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.9072\n",
      "Average policy_loss: 0.7999\n",
      "Average value_loss: 0.1073\n",
      "Replay buffer size: 5683\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.8978\n",
      "Average policy_loss: 0.7903\n",
      "Average value_loss: 0.1074\n",
      "Replay buffer size: 5779\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.9154\n",
      "Average policy_loss: 0.8066\n",
      "Average value_loss: 0.1088\n",
      "Replay buffer size: 5870\n",
      "Time taken: 52.0s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.8952\n",
      "Average policy_loss: 0.7883\n",
      "Average value_loss: 0.1069\n",
      "Replay buffer size: 5963\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.9025\n",
      "Average policy_loss: 0.7980\n",
      "Average value_loss: 0.1045\n",
      "Replay buffer size: 6059\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.8922\n",
      "Average policy_loss: 0.7875\n",
      "Average value_loss: 0.1048\n",
      "Replay buffer size: 6141\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.8999\n",
      "Average policy_loss: 0.7949\n",
      "Average value_loss: 0.1050\n",
      "Replay buffer size: 6240\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.8981\n",
      "Average policy_loss: 0.7904\n",
      "Average value_loss: 0.1077\n",
      "Replay buffer size: 6335\n",
      "Time taken: 50.0s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.8717\n",
      "Average policy_loss: 0.7694\n",
      "Average value_loss: 0.1023\n",
      "Replay buffer size: 6425\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.8961\n",
      "Average policy_loss: 0.7926\n",
      "Average value_loss: 0.1035\n",
      "Replay buffer size: 6514\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.8975\n",
      "Average policy_loss: 0.7908\n",
      "Average value_loss: 0.1068\n",
      "Replay buffer size: 6611\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.8915\n",
      "Average policy_loss: 0.7889\n",
      "Average value_loss: 0.1027\n",
      "Replay buffer size: 6708\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.8739\n",
      "Average policy_loss: 0.7800\n",
      "Average value_loss: 0.0939\n",
      "Replay buffer size: 6804\n",
      "Time taken: 50.4s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.8824\n",
      "Average policy_loss: 0.7759\n",
      "Average value_loss: 0.1066\n",
      "Replay buffer size: 6890\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.8884\n",
      "Average policy_loss: 0.7849\n",
      "Average value_loss: 0.1035\n",
      "Replay buffer size: 6983\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.8881\n",
      "Average policy_loss: 0.7844\n",
      "Average value_loss: 0.1037\n",
      "Replay buffer size: 7064\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.8830\n",
      "Average policy_loss: 0.7802\n",
      "Average value_loss: 0.1028\n",
      "Replay buffer size: 7155\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.8784\n",
      "Average policy_loss: 0.7802\n",
      "Average value_loss: 0.0982\n",
      "Replay buffer size: 7251\n",
      "Time taken: 48.9s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.8884\n",
      "Average policy_loss: 0.7851\n",
      "Average value_loss: 0.1033\n",
      "Replay buffer size: 7342\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.8778\n",
      "Average policy_loss: 0.7781\n",
      "Average value_loss: 0.0997\n",
      "Replay buffer size: 7436\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.8915\n",
      "Average policy_loss: 0.7931\n",
      "Average value_loss: 0.0984\n",
      "Replay buffer size: 7527\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.9022\n",
      "Average policy_loss: 0.8008\n",
      "Average value_loss: 0.1014\n",
      "Replay buffer size: 7621\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.8863\n",
      "Average policy_loss: 0.7866\n",
      "Average value_loss: 0.0997\n",
      "Replay buffer size: 7715\n",
      "Time taken: 49.6s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.8823\n",
      "Average policy_loss: 0.7839\n",
      "Average value_loss: 0.0985\n",
      "Replay buffer size: 7802\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.8855\n",
      "Average policy_loss: 0.7846\n",
      "Average value_loss: 0.1009\n",
      "Replay buffer size: 7898\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.8804\n",
      "Average policy_loss: 0.7836\n",
      "Average value_loss: 0.0968\n",
      "Replay buffer size: 7985\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.8862\n",
      "Average policy_loss: 0.7880\n",
      "Average value_loss: 0.0982\n",
      "Replay buffer size: 8072\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.8864\n",
      "Average policy_loss: 0.7895\n",
      "Average value_loss: 0.0968\n",
      "Replay buffer size: 8163\n",
      "Time taken: 49.7s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.8780\n",
      "Average policy_loss: 0.7780\n",
      "Average value_loss: 0.1001\n",
      "Replay buffer size: 8257\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.8991\n",
      "Average policy_loss: 0.7917\n",
      "Average value_loss: 0.1074\n",
      "Replay buffer size: 8344\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.8834\n",
      "Average policy_loss: 0.7844\n",
      "Average value_loss: 0.0990\n",
      "Replay buffer size: 8441\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.8915\n",
      "Average policy_loss: 0.7876\n",
      "Average value_loss: 0.1038\n",
      "Replay buffer size: 8532\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.8828\n",
      "Average policy_loss: 0.7831\n",
      "Average value_loss: 0.0997\n",
      "Replay buffer size: 8614\n",
      "Time taken: 47.5s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.8761\n",
      "Average policy_loss: 0.7790\n",
      "Average value_loss: 0.0971\n",
      "Replay buffer size: 8703\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.8817\n",
      "Average policy_loss: 0.7816\n",
      "Average value_loss: 0.1001\n",
      "Replay buffer size: 8777\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.8950\n",
      "Average policy_loss: 0.7925\n",
      "Average value_loss: 0.1025\n",
      "Replay buffer size: 8869\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.8927\n",
      "Average policy_loss: 0.7900\n",
      "Average value_loss: 0.1026\n",
      "Replay buffer size: 8963\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.9061\n",
      "Average policy_loss: 0.7998\n",
      "Average value_loss: 0.1062\n",
      "Replay buffer size: 9063\n",
      "Time taken: 49.9s\n",
      "\n",
      "Training complete! Total time: 0.6h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>iteration_time</td><td>▁▁█▁▂▂▂▁█▂▂▂▁█▁█▁▁▁█▁▁▁▁▁▁▁█▁▁█▁▂▁▁▁▁▁▇█</td></tr><tr><td>loss</td><td>█▇▆▄▅▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▆▃▆▇▅▄▇▅▅▇▆█▇▆▃▇▇▇▅▆▅▅▅▆▃▃▆▅▇▆▇▇▇▄▆▅▅▁▆█</td></tr><tr><td>policy_loss</td><td>█▆▅▅▅▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▅▄▄▃▃▂▂▂▂▁▂▂▁▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.2</td></tr><tr><td>buffer_size</td><td>9063</td></tr><tr><td>iteration_time</td><td>49.8879</td></tr><tr><td>loss</td><td>0.90608</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>100</td></tr><tr><td>policy_loss</td><td>0.79984</td></tr><tr><td>total_time_hours</td><td>0.62492</td></tr><tr><td>value_loss</td><td>0.10624</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">woven-sweep-15</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/e0jzbm9x' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/e0jzbm9x</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 16 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_062722-e0jzbm9x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ks9zitvr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0019883099148537905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: tiny\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.3160272671629232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.007373828602539275\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_070502-ks9zitvr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ks9zitvr' target=\"_blank\">lucky-sweep-16</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ks9zitvr' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ks9zitvr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 4.2494\n",
      "Average policy_loss: 3.5353\n",
      "Average value_loss: 0.7141\n",
      "Replay buffer size: 88\n",
      "Time taken: 10.7s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 2.6440\n",
      "Average policy_loss: 2.3606\n",
      "Average value_loss: 0.2833\n",
      "Replay buffer size: 180\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 2.2151\n",
      "Average policy_loss: 1.9039\n",
      "Average value_loss: 0.3112\n",
      "Replay buffer size: 264\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 2.1401\n",
      "Average policy_loss: 1.8578\n",
      "Average value_loss: 0.2822\n",
      "Replay buffer size: 355\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 2.1724\n",
      "Average policy_loss: 1.8410\n",
      "Average value_loss: 0.3314\n",
      "Replay buffer size: 439\n",
      "Time taken: 53.0s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 2.1729\n",
      "Average policy_loss: 1.8198\n",
      "Average value_loss: 0.3531\n",
      "Replay buffer size: 516\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 2.1426\n",
      "Average policy_loss: 1.7807\n",
      "Average value_loss: 0.3619\n",
      "Replay buffer size: 599\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 2.1170\n",
      "Average policy_loss: 1.7600\n",
      "Average value_loss: 0.3570\n",
      "Replay buffer size: 690\n",
      "Time taken: 18.5s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 2.1046\n",
      "Average policy_loss: 1.7390\n",
      "Average value_loss: 0.3656\n",
      "Replay buffer size: 770\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 2.0812\n",
      "Average policy_loss: 1.7220\n",
      "Average value_loss: 0.3592\n",
      "Replay buffer size: 852\n",
      "Time taken: 55.5s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 2.0442\n",
      "Average policy_loss: 1.6756\n",
      "Average value_loss: 0.3686\n",
      "Replay buffer size: 933\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.9947\n",
      "Average policy_loss: 1.6319\n",
      "Average value_loss: 0.3628\n",
      "Replay buffer size: 1022\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.9347\n",
      "Average policy_loss: 1.5674\n",
      "Average value_loss: 0.3673\n",
      "Replay buffer size: 1105\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.8835\n",
      "Average policy_loss: 1.5067\n",
      "Average value_loss: 0.3768\n",
      "Replay buffer size: 1187\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.8376\n",
      "Average policy_loss: 1.4544\n",
      "Average value_loss: 0.3832\n",
      "Replay buffer size: 1265\n",
      "Time taken: 53.2s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.8016\n",
      "Average policy_loss: 1.4119\n",
      "Average value_loss: 0.3897\n",
      "Replay buffer size: 1342\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.7713\n",
      "Average policy_loss: 1.3910\n",
      "Average value_loss: 0.3803\n",
      "Replay buffer size: 1430\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.7547\n",
      "Average policy_loss: 1.3760\n",
      "Average value_loss: 0.3787\n",
      "Replay buffer size: 1513\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.7258\n",
      "Average policy_loss: 1.3600\n",
      "Average value_loss: 0.3659\n",
      "Replay buffer size: 1604\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.7287\n",
      "Average policy_loss: 1.3570\n",
      "Average value_loss: 0.3717\n",
      "Replay buffer size: 1689\n",
      "Time taken: 53.7s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.7110\n",
      "Average policy_loss: 1.3464\n",
      "Average value_loss: 0.3646\n",
      "Replay buffer size: 1777\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.7136\n",
      "Average policy_loss: 1.3531\n",
      "Average value_loss: 0.3605\n",
      "Replay buffer size: 1854\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.6945\n",
      "Average policy_loss: 1.3453\n",
      "Average value_loss: 0.3493\n",
      "Replay buffer size: 1937\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.6790\n",
      "Average policy_loss: 1.3422\n",
      "Average value_loss: 0.3367\n",
      "Replay buffer size: 2023\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.6579\n",
      "Average policy_loss: 1.3333\n",
      "Average value_loss: 0.3245\n",
      "Replay buffer size: 2101\n",
      "Time taken: 53.2s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.6477\n",
      "Average policy_loss: 1.3292\n",
      "Average value_loss: 0.3186\n",
      "Replay buffer size: 2187\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.6128\n",
      "Average policy_loss: 1.3081\n",
      "Average value_loss: 0.3047\n",
      "Replay buffer size: 2269\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.6078\n",
      "Average policy_loss: 1.3110\n",
      "Average value_loss: 0.2968\n",
      "Replay buffer size: 2360\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.5828\n",
      "Average policy_loss: 1.2945\n",
      "Average value_loss: 0.2884\n",
      "Replay buffer size: 2449\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.5846\n",
      "Average policy_loss: 1.3010\n",
      "Average value_loss: 0.2836\n",
      "Replay buffer size: 2538\n",
      "Time taken: 53.3s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.5758\n",
      "Average policy_loss: 1.2927\n",
      "Average value_loss: 0.2831\n",
      "Replay buffer size: 2627\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.5745\n",
      "Average policy_loss: 1.2939\n",
      "Average value_loss: 0.2807\n",
      "Replay buffer size: 2709\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.5700\n",
      "Average policy_loss: 1.2882\n",
      "Average value_loss: 0.2818\n",
      "Replay buffer size: 2794\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.5449\n",
      "Average policy_loss: 1.2777\n",
      "Average value_loss: 0.2672\n",
      "Replay buffer size: 2883\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.5406\n",
      "Average policy_loss: 1.2789\n",
      "Average value_loss: 0.2617\n",
      "Replay buffer size: 2970\n",
      "Time taken: 52.6s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.5402\n",
      "Average policy_loss: 1.2758\n",
      "Average value_loss: 0.2644\n",
      "Replay buffer size: 3052\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.5287\n",
      "Average policy_loss: 1.2707\n",
      "Average value_loss: 0.2580\n",
      "Replay buffer size: 3134\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.5302\n",
      "Average policy_loss: 1.2669\n",
      "Average value_loss: 0.2633\n",
      "Replay buffer size: 3219\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.5277\n",
      "Average policy_loss: 1.2590\n",
      "Average value_loss: 0.2687\n",
      "Replay buffer size: 3303\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.5188\n",
      "Average policy_loss: 1.2565\n",
      "Average value_loss: 0.2623\n",
      "Replay buffer size: 3391\n",
      "Time taken: 52.2s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.5185\n",
      "Average policy_loss: 1.2541\n",
      "Average value_loss: 0.2644\n",
      "Replay buffer size: 3475\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.5154\n",
      "Average policy_loss: 1.2567\n",
      "Average value_loss: 0.2586\n",
      "Replay buffer size: 3563\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.5226\n",
      "Average policy_loss: 1.2546\n",
      "Average value_loss: 0.2680\n",
      "Replay buffer size: 3646\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.5238\n",
      "Average policy_loss: 1.2583\n",
      "Average value_loss: 0.2655\n",
      "Replay buffer size: 3732\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.5072\n",
      "Average policy_loss: 1.2418\n",
      "Average value_loss: 0.2654\n",
      "Replay buffer size: 3808\n",
      "Time taken: 54.0s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.5079\n",
      "Average policy_loss: 1.2418\n",
      "Average value_loss: 0.2661\n",
      "Replay buffer size: 3900\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.4973\n",
      "Average policy_loss: 1.2414\n",
      "Average value_loss: 0.2559\n",
      "Replay buffer size: 3980\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.4935\n",
      "Average policy_loss: 1.2320\n",
      "Average value_loss: 0.2615\n",
      "Replay buffer size: 4076\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.4851\n",
      "Average policy_loss: 1.2270\n",
      "Average value_loss: 0.2582\n",
      "Replay buffer size: 4168\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.4920\n",
      "Average policy_loss: 1.2424\n",
      "Average value_loss: 0.2496\n",
      "Replay buffer size: 4252\n",
      "Time taken: 53.8s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.4848\n",
      "Average policy_loss: 1.2283\n",
      "Average value_loss: 0.2565\n",
      "Replay buffer size: 4330\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.4853\n",
      "Average policy_loss: 1.2304\n",
      "Average value_loss: 0.2549\n",
      "Replay buffer size: 4417\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.4706\n",
      "Average policy_loss: 1.2174\n",
      "Average value_loss: 0.2532\n",
      "Replay buffer size: 4509\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.4815\n",
      "Average policy_loss: 1.2284\n",
      "Average value_loss: 0.2531\n",
      "Replay buffer size: 4600\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.4668\n",
      "Average policy_loss: 1.2149\n",
      "Average value_loss: 0.2519\n",
      "Replay buffer size: 4689\n",
      "Time taken: 55.0s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.4759\n",
      "Average policy_loss: 1.2261\n",
      "Average value_loss: 0.2499\n",
      "Replay buffer size: 4782\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.4664\n",
      "Average policy_loss: 1.2184\n",
      "Average value_loss: 0.2481\n",
      "Replay buffer size: 4871\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.4617\n",
      "Average policy_loss: 1.2129\n",
      "Average value_loss: 0.2488\n",
      "Replay buffer size: 4964\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.4621\n",
      "Average policy_loss: 1.2086\n",
      "Average value_loss: 0.2535\n",
      "Replay buffer size: 5050\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.4615\n",
      "Average policy_loss: 1.2139\n",
      "Average value_loss: 0.2477\n",
      "Replay buffer size: 5137\n",
      "Time taken: 52.7s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.4548\n",
      "Average policy_loss: 1.2092\n",
      "Average value_loss: 0.2457\n",
      "Replay buffer size: 5227\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.4369\n",
      "Average policy_loss: 1.1900\n",
      "Average value_loss: 0.2469\n",
      "Replay buffer size: 5318\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.4555\n",
      "Average policy_loss: 1.2108\n",
      "Average value_loss: 0.2447\n",
      "Replay buffer size: 5411\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.4363\n",
      "Average policy_loss: 1.1954\n",
      "Average value_loss: 0.2409\n",
      "Replay buffer size: 5501\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.4382\n",
      "Average policy_loss: 1.1996\n",
      "Average value_loss: 0.2386\n",
      "Replay buffer size: 5593\n",
      "Time taken: 53.8s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.4319\n",
      "Average policy_loss: 1.1910\n",
      "Average value_loss: 0.2409\n",
      "Replay buffer size: 5677\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.4305\n",
      "Average policy_loss: 1.1859\n",
      "Average value_loss: 0.2446\n",
      "Replay buffer size: 5760\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.4420\n",
      "Average policy_loss: 1.2047\n",
      "Average value_loss: 0.2372\n",
      "Replay buffer size: 5851\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.4285\n",
      "Average policy_loss: 1.1906\n",
      "Average value_loss: 0.2379\n",
      "Replay buffer size: 5941\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.4221\n",
      "Average policy_loss: 1.1877\n",
      "Average value_loss: 0.2344\n",
      "Replay buffer size: 6038\n",
      "Time taken: 54.7s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.4157\n",
      "Average policy_loss: 1.1809\n",
      "Average value_loss: 0.2348\n",
      "Replay buffer size: 6129\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.4119\n",
      "Average policy_loss: 1.1794\n",
      "Average value_loss: 0.2325\n",
      "Replay buffer size: 6211\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.4259\n",
      "Average policy_loss: 1.1878\n",
      "Average value_loss: 0.2381\n",
      "Replay buffer size: 6293\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.4046\n",
      "Average policy_loss: 1.1739\n",
      "Average value_loss: 0.2306\n",
      "Replay buffer size: 6382\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.4145\n",
      "Average policy_loss: 1.1786\n",
      "Average value_loss: 0.2359\n",
      "Replay buffer size: 6468\n",
      "Time taken: 54.5s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.4185\n",
      "Average policy_loss: 1.1808\n",
      "Average value_loss: 0.2377\n",
      "Replay buffer size: 6550\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.4010\n",
      "Average policy_loss: 1.1674\n",
      "Average value_loss: 0.2336\n",
      "Replay buffer size: 6633\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.4072\n",
      "Average policy_loss: 1.1745\n",
      "Average value_loss: 0.2327\n",
      "Replay buffer size: 6723\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.4067\n",
      "Average policy_loss: 1.1757\n",
      "Average value_loss: 0.2310\n",
      "Replay buffer size: 6806\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.4066\n",
      "Average policy_loss: 1.1731\n",
      "Average value_loss: 0.2336\n",
      "Replay buffer size: 6887\n",
      "Time taken: 56.5s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.4037\n",
      "Average policy_loss: 1.1696\n",
      "Average value_loss: 0.2341\n",
      "Replay buffer size: 6972\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.4073\n",
      "Average policy_loss: 1.1753\n",
      "Average value_loss: 0.2321\n",
      "Replay buffer size: 7056\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.4175\n",
      "Average policy_loss: 1.1812\n",
      "Average value_loss: 0.2363\n",
      "Replay buffer size: 7139\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.4210\n",
      "Average policy_loss: 1.1890\n",
      "Average value_loss: 0.2320\n",
      "Replay buffer size: 7225\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.4134\n",
      "Average policy_loss: 1.1789\n",
      "Average value_loss: 0.2345\n",
      "Replay buffer size: 7311\n",
      "Time taken: 56.4s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.4146\n",
      "Average policy_loss: 1.1826\n",
      "Average value_loss: 0.2319\n",
      "Replay buffer size: 7399\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.4227\n",
      "Average policy_loss: 1.1798\n",
      "Average value_loss: 0.2430\n",
      "Replay buffer size: 7483\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.3904\n",
      "Average policy_loss: 1.1588\n",
      "Average value_loss: 0.2316\n",
      "Replay buffer size: 7573\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.4172\n",
      "Average policy_loss: 1.1804\n",
      "Average value_loss: 0.2369\n",
      "Replay buffer size: 7657\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.4069\n",
      "Average policy_loss: 1.1737\n",
      "Average value_loss: 0.2332\n",
      "Replay buffer size: 7742\n",
      "Time taken: 55.1s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.3924\n",
      "Average policy_loss: 1.1586\n",
      "Average value_loss: 0.2338\n",
      "Replay buffer size: 7830\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.4035\n",
      "Average policy_loss: 1.1696\n",
      "Average value_loss: 0.2339\n",
      "Replay buffer size: 7917\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.4078\n",
      "Average policy_loss: 1.1693\n",
      "Average value_loss: 0.2386\n",
      "Replay buffer size: 8001\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.4193\n",
      "Average policy_loss: 1.1822\n",
      "Average value_loss: 0.2371\n",
      "Replay buffer size: 8080\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.4096\n",
      "Average policy_loss: 1.1730\n",
      "Average value_loss: 0.2366\n",
      "Replay buffer size: 8168\n",
      "Time taken: 53.9s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.3904\n",
      "Average policy_loss: 1.1602\n",
      "Average value_loss: 0.2302\n",
      "Replay buffer size: 8262\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.3996\n",
      "Average policy_loss: 1.1650\n",
      "Average value_loss: 0.2346\n",
      "Replay buffer size: 8352\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.4051\n",
      "Average policy_loss: 1.1682\n",
      "Average value_loss: 0.2368\n",
      "Replay buffer size: 8448\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.4017\n",
      "Average policy_loss: 1.1635\n",
      "Average value_loss: 0.2382\n",
      "Replay buffer size: 8530\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.4102\n",
      "Average policy_loss: 1.1759\n",
      "Average value_loss: 0.2343\n",
      "Replay buffer size: 8619\n",
      "Time taken: 57.6s\n",
      "\n",
      "Training complete! Total time: 0.7h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇██</td></tr><tr><td>iteration_time</td><td>▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▇▁█▁▁▁▁▁▁▁█▁▁▁█▁▁▁█▁█</td></tr><tr><td>loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▅▆▄▁▃▂▁▃▅▁▄▃▅▃▅▄▅▄▄▁▆▂▆▆▅▇▆▆█▃▄▆▃▄▄▅▅▂▅█</td></tr><tr><td>policy_loss</td><td>█▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▂▂▃▃▃▃▃▃▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.1</td></tr><tr><td>buffer_size</td><td>8619</td></tr><tr><td>iteration_time</td><td>57.6447</td></tr><tr><td>loss</td><td>1.4102</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>89</td></tr><tr><td>policy_loss</td><td>1.17593</td></tr><tr><td>total_time_hours</td><td>0.68847</td></tr><tr><td>value_loss</td><td>0.23427</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lucky-sweep-16</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ks9zitvr' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ks9zitvr</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_070502-ks9zitvr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0nat9frd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.1410160841635885e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.8072946001422179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0002148860229820879\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_074628-0nat9frd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/0nat9frd' target=\"_blank\">generous-sweep-17</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/0nat9frd' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/0nat9frd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 4.7771\n",
      "Average policy_loss: 3.5850\n",
      "Average value_loss: 1.1921\n",
      "Replay buffer size: 83\n",
      "Time taken: 8.1s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 3.7461\n",
      "Average policy_loss: 2.5813\n",
      "Average value_loss: 1.1648\n",
      "Replay buffer size: 175\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 3.5585\n",
      "Average policy_loss: 2.3939\n",
      "Average value_loss: 1.1646\n",
      "Replay buffer size: 266\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 3.2735\n",
      "Average policy_loss: 2.1197\n",
      "Average value_loss: 1.1538\n",
      "Replay buffer size: 349\n",
      "Time taken: 9.5s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 3.0967\n",
      "Average policy_loss: 1.9705\n",
      "Average value_loss: 1.1262\n",
      "Replay buffer size: 439\n",
      "Time taken: 31.7s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 2.9905\n",
      "Average policy_loss: 1.8884\n",
      "Average value_loss: 1.1021\n",
      "Replay buffer size: 535\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 2.9189\n",
      "Average policy_loss: 1.8257\n",
      "Average value_loss: 1.0933\n",
      "Replay buffer size: 625\n",
      "Time taken: 11.2s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 2.8760\n",
      "Average policy_loss: 1.8055\n",
      "Average value_loss: 1.0705\n",
      "Replay buffer size: 714\n",
      "Time taken: 11.2s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 2.8134\n",
      "Average policy_loss: 1.7383\n",
      "Average value_loss: 1.0750\n",
      "Replay buffer size: 807\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 45.00%, Draw rate = 40.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 2.7563\n",
      "Average policy_loss: 1.6887\n",
      "Average value_loss: 1.0676\n",
      "Replay buffer size: 899\n",
      "Time taken: 38.2s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 2.7267\n",
      "Average policy_loss: 1.6906\n",
      "Average value_loss: 1.0360\n",
      "Replay buffer size: 982\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 2.6434\n",
      "Average policy_loss: 1.6580\n",
      "Average value_loss: 0.9854\n",
      "Replay buffer size: 1071\n",
      "Time taken: 10.7s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 2.5844\n",
      "Average policy_loss: 1.6268\n",
      "Average value_loss: 0.9577\n",
      "Replay buffer size: 1164\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 2.4986\n",
      "Average policy_loss: 1.6066\n",
      "Average value_loss: 0.8920\n",
      "Replay buffer size: 1250\n",
      "Time taken: 10.7s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 2.4284\n",
      "Average policy_loss: 1.6155\n",
      "Average value_loss: 0.8129\n",
      "Replay buffer size: 1336\n",
      "Time taken: 34.9s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 2.3954\n",
      "Average policy_loss: 1.6132\n",
      "Average value_loss: 0.7822\n",
      "Replay buffer size: 1420\n",
      "Time taken: 8.5s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 2.3482\n",
      "Average policy_loss: 1.5979\n",
      "Average value_loss: 0.7503\n",
      "Replay buffer size: 1504\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 2.3169\n",
      "Average policy_loss: 1.5938\n",
      "Average value_loss: 0.7231\n",
      "Replay buffer size: 1591\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 2.2818\n",
      "Average policy_loss: 1.5778\n",
      "Average value_loss: 0.7040\n",
      "Replay buffer size: 1673\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 2.2248\n",
      "Average policy_loss: 1.5398\n",
      "Average value_loss: 0.6850\n",
      "Replay buffer size: 1770\n",
      "Time taken: 33.1s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 2.1869\n",
      "Average policy_loss: 1.5290\n",
      "Average value_loss: 0.6579\n",
      "Replay buffer size: 1866\n",
      "Time taken: 9.5s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 2.1335\n",
      "Average policy_loss: 1.4945\n",
      "Average value_loss: 0.6390\n",
      "Replay buffer size: 1960\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 2.0925\n",
      "Average policy_loss: 1.4704\n",
      "Average value_loss: 0.6221\n",
      "Replay buffer size: 2046\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 2.0452\n",
      "Average policy_loss: 1.4490\n",
      "Average value_loss: 0.5963\n",
      "Replay buffer size: 2135\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 2.0196\n",
      "Average policy_loss: 1.4439\n",
      "Average value_loss: 0.5757\n",
      "Replay buffer size: 2222\n",
      "Time taken: 36.7s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.9789\n",
      "Average policy_loss: 1.4134\n",
      "Average value_loss: 0.5656\n",
      "Replay buffer size: 2309\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.9770\n",
      "Average policy_loss: 1.4200\n",
      "Average value_loss: 0.5571\n",
      "Replay buffer size: 2393\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.9388\n",
      "Average policy_loss: 1.3872\n",
      "Average value_loss: 0.5516\n",
      "Replay buffer size: 2483\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.9219\n",
      "Average policy_loss: 1.3829\n",
      "Average value_loss: 0.5390\n",
      "Replay buffer size: 2571\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.8993\n",
      "Average policy_loss: 1.3672\n",
      "Average value_loss: 0.5320\n",
      "Replay buffer size: 2662\n",
      "Time taken: 37.2s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.9031\n",
      "Average policy_loss: 1.3744\n",
      "Average value_loss: 0.5287\n",
      "Replay buffer size: 2751\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.8658\n",
      "Average policy_loss: 1.3464\n",
      "Average value_loss: 0.5194\n",
      "Replay buffer size: 2849\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.8613\n",
      "Average policy_loss: 1.3435\n",
      "Average value_loss: 0.5178\n",
      "Replay buffer size: 2941\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.8448\n",
      "Average policy_loss: 1.3407\n",
      "Average value_loss: 0.5041\n",
      "Replay buffer size: 3036\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.8289\n",
      "Average policy_loss: 1.3240\n",
      "Average value_loss: 0.5050\n",
      "Replay buffer size: 3128\n",
      "Time taken: 40.3s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.8136\n",
      "Average policy_loss: 1.3183\n",
      "Average value_loss: 0.4953\n",
      "Replay buffer size: 3226\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.8083\n",
      "Average policy_loss: 1.3168\n",
      "Average value_loss: 0.4916\n",
      "Replay buffer size: 3312\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.7889\n",
      "Average policy_loss: 1.3091\n",
      "Average value_loss: 0.4798\n",
      "Replay buffer size: 3407\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.7897\n",
      "Average policy_loss: 1.3093\n",
      "Average value_loss: 0.4803\n",
      "Replay buffer size: 3500\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.7731\n",
      "Average policy_loss: 1.3016\n",
      "Average value_loss: 0.4715\n",
      "Replay buffer size: 3584\n",
      "Time taken: 40.5s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.7536\n",
      "Average policy_loss: 1.2836\n",
      "Average value_loss: 0.4700\n",
      "Replay buffer size: 3679\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.7595\n",
      "Average policy_loss: 1.2958\n",
      "Average value_loss: 0.4636\n",
      "Replay buffer size: 3767\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.7347\n",
      "Average policy_loss: 1.2753\n",
      "Average value_loss: 0.4594\n",
      "Replay buffer size: 3857\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.7418\n",
      "Average policy_loss: 1.2875\n",
      "Average value_loss: 0.4543\n",
      "Replay buffer size: 3949\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.7304\n",
      "Average policy_loss: 1.2784\n",
      "Average value_loss: 0.4520\n",
      "Replay buffer size: 4045\n",
      "Time taken: 41.6s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.7150\n",
      "Average policy_loss: 1.2700\n",
      "Average value_loss: 0.4450\n",
      "Replay buffer size: 4140\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.7167\n",
      "Average policy_loss: 1.2726\n",
      "Average value_loss: 0.4442\n",
      "Replay buffer size: 4222\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.7053\n",
      "Average policy_loss: 1.2680\n",
      "Average value_loss: 0.4373\n",
      "Replay buffer size: 4316\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.6840\n",
      "Average policy_loss: 1.2530\n",
      "Average value_loss: 0.4310\n",
      "Replay buffer size: 4413\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 45.00%, Draw rate = 40.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.6807\n",
      "Average policy_loss: 1.2486\n",
      "Average value_loss: 0.4321\n",
      "Replay buffer size: 4508\n",
      "Time taken: 43.7s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.6754\n",
      "Average policy_loss: 1.2484\n",
      "Average value_loss: 0.4270\n",
      "Replay buffer size: 4603\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.6695\n",
      "Average policy_loss: 1.2484\n",
      "Average value_loss: 0.4210\n",
      "Replay buffer size: 4697\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.6542\n",
      "Average policy_loss: 1.2368\n",
      "Average value_loss: 0.4174\n",
      "Replay buffer size: 4788\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.6580\n",
      "Average policy_loss: 1.2421\n",
      "Average value_loss: 0.4160\n",
      "Replay buffer size: 4882\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.6512\n",
      "Average policy_loss: 1.2386\n",
      "Average value_loss: 0.4126\n",
      "Replay buffer size: 4977\n",
      "Time taken: 43.0s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.6253\n",
      "Average policy_loss: 1.2184\n",
      "Average value_loss: 0.4070\n",
      "Replay buffer size: 5069\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.6186\n",
      "Average policy_loss: 1.2179\n",
      "Average value_loss: 0.4008\n",
      "Replay buffer size: 5165\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.6236\n",
      "Average policy_loss: 1.2245\n",
      "Average value_loss: 0.3991\n",
      "Replay buffer size: 5257\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.6100\n",
      "Average policy_loss: 1.2125\n",
      "Average value_loss: 0.3975\n",
      "Replay buffer size: 5348\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 50.00%, Draw rate = 50.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.6035\n",
      "Average policy_loss: 1.2124\n",
      "Average value_loss: 0.3911\n",
      "Replay buffer size: 5440\n",
      "Time taken: 42.8s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.6086\n",
      "Average policy_loss: 1.2172\n",
      "Average value_loss: 0.3914\n",
      "Replay buffer size: 5534\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.5926\n",
      "Average policy_loss: 1.2034\n",
      "Average value_loss: 0.3892\n",
      "Replay buffer size: 5625\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.6024\n",
      "Average policy_loss: 1.2144\n",
      "Average value_loss: 0.3880\n",
      "Replay buffer size: 5715\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.5901\n",
      "Average policy_loss: 1.2092\n",
      "Average value_loss: 0.3809\n",
      "Replay buffer size: 5810\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.5824\n",
      "Average policy_loss: 1.2060\n",
      "Average value_loss: 0.3764\n",
      "Replay buffer size: 5908\n",
      "Time taken: 43.3s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.5729\n",
      "Average policy_loss: 1.1941\n",
      "Average value_loss: 0.3788\n",
      "Replay buffer size: 5999\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.5703\n",
      "Average policy_loss: 1.1998\n",
      "Average value_loss: 0.3706\n",
      "Replay buffer size: 6093\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.5623\n",
      "Average policy_loss: 1.1909\n",
      "Average value_loss: 0.3714\n",
      "Replay buffer size: 6184\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.5577\n",
      "Average policy_loss: 1.1912\n",
      "Average value_loss: 0.3665\n",
      "Replay buffer size: 6283\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 55.00%, Draw rate = 40.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.5415\n",
      "Average policy_loss: 1.1828\n",
      "Average value_loss: 0.3587\n",
      "Replay buffer size: 6365\n",
      "Time taken: 45.1s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.5403\n",
      "Average policy_loss: 1.1839\n",
      "Average value_loss: 0.3564\n",
      "Replay buffer size: 6463\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.5285\n",
      "Average policy_loss: 1.1744\n",
      "Average value_loss: 0.3541\n",
      "Replay buffer size: 6557\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.5388\n",
      "Average policy_loss: 1.1831\n",
      "Average value_loss: 0.3557\n",
      "Replay buffer size: 6647\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.5305\n",
      "Average policy_loss: 1.1768\n",
      "Average value_loss: 0.3537\n",
      "Replay buffer size: 6738\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.5182\n",
      "Average policy_loss: 1.1696\n",
      "Average value_loss: 0.3486\n",
      "Replay buffer size: 6837\n",
      "Time taken: 45.5s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.5171\n",
      "Average policy_loss: 1.1691\n",
      "Average value_loss: 0.3480\n",
      "Replay buffer size: 6933\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.5169\n",
      "Average policy_loss: 1.1706\n",
      "Average value_loss: 0.3463\n",
      "Replay buffer size: 7024\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.4974\n",
      "Average policy_loss: 1.1592\n",
      "Average value_loss: 0.3382\n",
      "Replay buffer size: 7113\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.4926\n",
      "Average policy_loss: 1.1540\n",
      "Average value_loss: 0.3386\n",
      "Replay buffer size: 7207\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.4981\n",
      "Average policy_loss: 1.1634\n",
      "Average value_loss: 0.3347\n",
      "Replay buffer size: 7294\n",
      "Time taken: 45.0s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.5030\n",
      "Average policy_loss: 1.1705\n",
      "Average value_loss: 0.3326\n",
      "Replay buffer size: 7380\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.4821\n",
      "Average policy_loss: 1.1538\n",
      "Average value_loss: 0.3283\n",
      "Replay buffer size: 7472\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.4794\n",
      "Average policy_loss: 1.1504\n",
      "Average value_loss: 0.3290\n",
      "Replay buffer size: 7557\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.4792\n",
      "Average policy_loss: 1.1570\n",
      "Average value_loss: 0.3222\n",
      "Replay buffer size: 7647\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.4669\n",
      "Average policy_loss: 1.1478\n",
      "Average value_loss: 0.3191\n",
      "Replay buffer size: 7743\n",
      "Time taken: 44.9s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.4708\n",
      "Average policy_loss: 1.1500\n",
      "Average value_loss: 0.3208\n",
      "Replay buffer size: 7841\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.4642\n",
      "Average policy_loss: 1.1454\n",
      "Average value_loss: 0.3187\n",
      "Replay buffer size: 7937\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.4549\n",
      "Average policy_loss: 1.1407\n",
      "Average value_loss: 0.3142\n",
      "Replay buffer size: 8036\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.4496\n",
      "Average policy_loss: 1.1361\n",
      "Average value_loss: 0.3135\n",
      "Replay buffer size: 8129\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.4477\n",
      "Average policy_loss: 1.1406\n",
      "Average value_loss: 0.3071\n",
      "Replay buffer size: 8223\n",
      "Time taken: 45.7s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.4425\n",
      "Average policy_loss: 1.1375\n",
      "Average value_loss: 0.3050\n",
      "Replay buffer size: 8312\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.4357\n",
      "Average policy_loss: 1.1339\n",
      "Average value_loss: 0.3018\n",
      "Replay buffer size: 8407\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.4227\n",
      "Average policy_loss: 1.1224\n",
      "Average value_loss: 0.3003\n",
      "Replay buffer size: 8499\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.4267\n",
      "Average policy_loss: 1.1278\n",
      "Average value_loss: 0.2988\n",
      "Replay buffer size: 8585\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.4222\n",
      "Average policy_loss: 1.1253\n",
      "Average value_loss: 0.2969\n",
      "Replay buffer size: 8675\n",
      "Time taken: 44.2s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.4127\n",
      "Average policy_loss: 1.1210\n",
      "Average value_loss: 0.2917\n",
      "Replay buffer size: 8762\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.4185\n",
      "Average policy_loss: 1.1291\n",
      "Average value_loss: 0.2894\n",
      "Replay buffer size: 8853\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.4195\n",
      "Average policy_loss: 1.1305\n",
      "Average value_loss: 0.2889\n",
      "Replay buffer size: 8945\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.4167\n",
      "Average policy_loss: 1.1227\n",
      "Average value_loss: 0.2940\n",
      "Replay buffer size: 9028\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.4075\n",
      "Average policy_loss: 1.1173\n",
      "Average value_loss: 0.2902\n",
      "Replay buffer size: 9121\n",
      "Time taken: 45.0s\n",
      "\n",
      "Training complete! Total time: 0.5h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iteration_time</td><td>▁▂▁▅▇▁▂▁▆▁▁▂▁▁▁▂▂▂▂▂▂▂▂▇▂█▂█▂▂▂▂█▂▂▂▂█▂▂</td></tr><tr><td>loss</td><td>█▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▁▁▄▇▄▆▁▂▃▃▄▆▅▆▆▁▆▆▆▆▅▅▆▅▄▁▆█▇▅▃▄▇█▆▄▅▃▄▆</td></tr><tr><td>policy_loss</td><td>█▅▅▄▄▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>████▇▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1</td></tr><tr><td>buffer_size</td><td>9121</td></tr><tr><td>iteration_time</td><td>45.02117</td></tr><tr><td>loss</td><td>1.40749</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>93</td></tr><tr><td>policy_loss</td><td>1.11731</td></tr><tr><td>total_time_hours</td><td>0.50462</td></tr><tr><td>value_loss</td><td>0.29018</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">generous-sweep-17</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/0nat9frd' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/0nat9frd</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_074628-0nat9frd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xykl357a with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005121470987175406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: medium\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.1726190103548938\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.007464331859139258\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_081652-xykl357a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/xykl357a' target=\"_blank\">leafy-sweep-18</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/xykl357a' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/xykl357a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 2.3217\n",
      "Average policy_loss: 1.7917\n",
      "Average value_loss: 0.5300\n",
      "Replay buffer size: 97\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.5107\n",
      "Average policy_loss: 1.0388\n",
      "Average value_loss: 0.4719\n",
      "Replay buffer size: 181\n",
      "Time taken: 9.3s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.4252\n",
      "Average policy_loss: 1.0344\n",
      "Average value_loss: 0.3908\n",
      "Replay buffer size: 263\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.3806\n",
      "Average policy_loss: 1.0198\n",
      "Average value_loss: 0.3608\n",
      "Replay buffer size: 350\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.3687\n",
      "Average policy_loss: 1.0100\n",
      "Average value_loss: 0.3588\n",
      "Replay buffer size: 439\n",
      "Time taken: 51.0s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.3435\n",
      "Average policy_loss: 1.0161\n",
      "Average value_loss: 0.3274\n",
      "Replay buffer size: 517\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.3102\n",
      "Average policy_loss: 1.0030\n",
      "Average value_loss: 0.3072\n",
      "Replay buffer size: 597\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.3184\n",
      "Average policy_loss: 1.0045\n",
      "Average value_loss: 0.3139\n",
      "Replay buffer size: 684\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.3001\n",
      "Average policy_loss: 1.0017\n",
      "Average value_loss: 0.2984\n",
      "Replay buffer size: 760\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.2882\n",
      "Average policy_loss: 0.9976\n",
      "Average value_loss: 0.2906\n",
      "Replay buffer size: 846\n",
      "Time taken: 53.3s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.2967\n",
      "Average policy_loss: 1.0051\n",
      "Average value_loss: 0.2917\n",
      "Replay buffer size: 921\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.2929\n",
      "Average policy_loss: 1.0054\n",
      "Average value_loss: 0.2875\n",
      "Replay buffer size: 1003\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.2898\n",
      "Average policy_loss: 1.0010\n",
      "Average value_loss: 0.2889\n",
      "Replay buffer size: 1080\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.2804\n",
      "Average policy_loss: 0.9963\n",
      "Average value_loss: 0.2842\n",
      "Replay buffer size: 1163\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.2734\n",
      "Average policy_loss: 0.9949\n",
      "Average value_loss: 0.2786\n",
      "Replay buffer size: 1243\n",
      "Time taken: 52.6s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.2545\n",
      "Average policy_loss: 0.9853\n",
      "Average value_loss: 0.2692\n",
      "Replay buffer size: 1325\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.2493\n",
      "Average policy_loss: 0.9862\n",
      "Average value_loss: 0.2631\n",
      "Replay buffer size: 1409\n",
      "Time taken: 18.5s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.2306\n",
      "Average policy_loss: 0.9709\n",
      "Average value_loss: 0.2597\n",
      "Replay buffer size: 1501\n",
      "Time taken: 18.5s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.2303\n",
      "Average policy_loss: 0.9727\n",
      "Average value_loss: 0.2576\n",
      "Replay buffer size: 1580\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.2171\n",
      "Average policy_loss: 0.9652\n",
      "Average value_loss: 0.2519\n",
      "Replay buffer size: 1666\n",
      "Time taken: 57.6s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.2054\n",
      "Average policy_loss: 0.9512\n",
      "Average value_loss: 0.2542\n",
      "Replay buffer size: 1755\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.1900\n",
      "Average policy_loss: 0.9402\n",
      "Average value_loss: 0.2498\n",
      "Replay buffer size: 1838\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.1917\n",
      "Average policy_loss: 0.9411\n",
      "Average value_loss: 0.2505\n",
      "Replay buffer size: 1925\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.1831\n",
      "Average policy_loss: 0.9348\n",
      "Average value_loss: 0.2483\n",
      "Replay buffer size: 2013\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.1798\n",
      "Average policy_loss: 0.9306\n",
      "Average value_loss: 0.2491\n",
      "Replay buffer size: 2099\n",
      "Time taken: 61.0s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.1903\n",
      "Average policy_loss: 0.9322\n",
      "Average value_loss: 0.2581\n",
      "Replay buffer size: 2179\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.1776\n",
      "Average policy_loss: 0.9233\n",
      "Average value_loss: 0.2543\n",
      "Replay buffer size: 2263\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.1803\n",
      "Average policy_loss: 0.9245\n",
      "Average value_loss: 0.2557\n",
      "Replay buffer size: 2344\n",
      "Time taken: 19.1s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.1704\n",
      "Average policy_loss: 0.9136\n",
      "Average value_loss: 0.2568\n",
      "Replay buffer size: 2437\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.1660\n",
      "Average policy_loss: 0.9132\n",
      "Average value_loss: 0.2528\n",
      "Replay buffer size: 2517\n",
      "Time taken: 60.3s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.1629\n",
      "Average policy_loss: 0.9084\n",
      "Average value_loss: 0.2545\n",
      "Replay buffer size: 2602\n",
      "Time taken: 19.3s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.1410\n",
      "Average policy_loss: 0.8915\n",
      "Average value_loss: 0.2495\n",
      "Replay buffer size: 2690\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.1525\n",
      "Average policy_loss: 0.8966\n",
      "Average value_loss: 0.2559\n",
      "Replay buffer size: 2777\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.1491\n",
      "Average policy_loss: 0.8887\n",
      "Average value_loss: 0.2603\n",
      "Replay buffer size: 2868\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.1407\n",
      "Average policy_loss: 0.8810\n",
      "Average value_loss: 0.2597\n",
      "Replay buffer size: 2960\n",
      "Time taken: 60.1s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.1355\n",
      "Average policy_loss: 0.8734\n",
      "Average value_loss: 0.2621\n",
      "Replay buffer size: 3050\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.1406\n",
      "Average policy_loss: 0.8741\n",
      "Average value_loss: 0.2665\n",
      "Replay buffer size: 3143\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.1366\n",
      "Average policy_loss: 0.8671\n",
      "Average value_loss: 0.2695\n",
      "Replay buffer size: 3234\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.1423\n",
      "Average policy_loss: 0.8689\n",
      "Average value_loss: 0.2733\n",
      "Replay buffer size: 3326\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.1219\n",
      "Average policy_loss: 0.8562\n",
      "Average value_loss: 0.2656\n",
      "Replay buffer size: 3415\n",
      "Time taken: 59.5s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.1189\n",
      "Average policy_loss: 0.8502\n",
      "Average value_loss: 0.2687\n",
      "Replay buffer size: 3504\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.1142\n",
      "Average policy_loss: 0.8480\n",
      "Average value_loss: 0.2662\n",
      "Replay buffer size: 3592\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.1022\n",
      "Average policy_loss: 0.8399\n",
      "Average value_loss: 0.2623\n",
      "Replay buffer size: 3688\n",
      "Time taken: 18.5s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.0948\n",
      "Average policy_loss: 0.8339\n",
      "Average value_loss: 0.2608\n",
      "Replay buffer size: 3785\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.1006\n",
      "Average policy_loss: 0.8344\n",
      "Average value_loss: 0.2663\n",
      "Replay buffer size: 3864\n",
      "Time taken: 60.7s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.0987\n",
      "Average policy_loss: 0.8328\n",
      "Average value_loss: 0.2658\n",
      "Replay buffer size: 3957\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.0884\n",
      "Average policy_loss: 0.8224\n",
      "Average value_loss: 0.2660\n",
      "Replay buffer size: 4055\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.0856\n",
      "Average policy_loss: 0.8221\n",
      "Average value_loss: 0.2636\n",
      "Replay buffer size: 4145\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.0865\n",
      "Average policy_loss: 0.8244\n",
      "Average value_loss: 0.2621\n",
      "Replay buffer size: 4241\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.0818\n",
      "Average policy_loss: 0.8158\n",
      "Average value_loss: 0.2660\n",
      "Replay buffer size: 4330\n",
      "Time taken: 58.9s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.0727\n",
      "Average policy_loss: 0.8093\n",
      "Average value_loss: 0.2634\n",
      "Replay buffer size: 4428\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.0625\n",
      "Average policy_loss: 0.8011\n",
      "Average value_loss: 0.2614\n",
      "Replay buffer size: 4516\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.0656\n",
      "Average policy_loss: 0.8051\n",
      "Average value_loss: 0.2605\n",
      "Replay buffer size: 4613\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.0562\n",
      "Average policy_loss: 0.7998\n",
      "Average value_loss: 0.2565\n",
      "Replay buffer size: 4709\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.0462\n",
      "Average policy_loss: 0.7946\n",
      "Average value_loss: 0.2516\n",
      "Replay buffer size: 4803\n",
      "Time taken: 56.4s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.0416\n",
      "Average policy_loss: 0.7880\n",
      "Average value_loss: 0.2536\n",
      "Replay buffer size: 4896\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.0392\n",
      "Average policy_loss: 0.7862\n",
      "Average value_loss: 0.2530\n",
      "Replay buffer size: 4983\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.0386\n",
      "Average policy_loss: 0.7834\n",
      "Average value_loss: 0.2552\n",
      "Replay buffer size: 5065\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.0376\n",
      "Average policy_loss: 0.7891\n",
      "Average value_loss: 0.2485\n",
      "Replay buffer size: 5151\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.0376\n",
      "Average policy_loss: 0.7868\n",
      "Average value_loss: 0.2509\n",
      "Replay buffer size: 5234\n",
      "Time taken: 55.3s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.0278\n",
      "Average policy_loss: 0.7791\n",
      "Average value_loss: 0.2487\n",
      "Replay buffer size: 5328\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.0240\n",
      "Average policy_loss: 0.7703\n",
      "Average value_loss: 0.2537\n",
      "Replay buffer size: 5417\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.0271\n",
      "Average policy_loss: 0.7780\n",
      "Average value_loss: 0.2491\n",
      "Replay buffer size: 5517\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.0199\n",
      "Average policy_loss: 0.7722\n",
      "Average value_loss: 0.2477\n",
      "Replay buffer size: 5616\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.0189\n",
      "Average policy_loss: 0.7715\n",
      "Average value_loss: 0.2474\n",
      "Replay buffer size: 5713\n",
      "Time taken: 56.9s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.0147\n",
      "Average policy_loss: 0.7717\n",
      "Average value_loss: 0.2430\n",
      "Replay buffer size: 5801\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.0035\n",
      "Average policy_loss: 0.7622\n",
      "Average value_loss: 0.2413\n",
      "Replay buffer size: 5897\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.0028\n",
      "Average policy_loss: 0.7653\n",
      "Average value_loss: 0.2375\n",
      "Replay buffer size: 5982\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.0050\n",
      "Average policy_loss: 0.7628\n",
      "Average value_loss: 0.2422\n",
      "Replay buffer size: 6073\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.0017\n",
      "Average policy_loss: 0.7630\n",
      "Average value_loss: 0.2388\n",
      "Replay buffer size: 6169\n",
      "Time taken: 58.8s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.9860\n",
      "Average policy_loss: 0.7512\n",
      "Average value_loss: 0.2348\n",
      "Replay buffer size: 6267\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.9844\n",
      "Average policy_loss: 0.7496\n",
      "Average value_loss: 0.2348\n",
      "Replay buffer size: 6362\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.9963\n",
      "Average policy_loss: 0.7574\n",
      "Average value_loss: 0.2388\n",
      "Replay buffer size: 6444\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.9896\n",
      "Average policy_loss: 0.7539\n",
      "Average value_loss: 0.2357\n",
      "Replay buffer size: 6533\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.9896\n",
      "Average policy_loss: 0.7489\n",
      "Average value_loss: 0.2407\n",
      "Replay buffer size: 6615\n",
      "Time taken: 56.7s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.9973\n",
      "Average policy_loss: 0.7568\n",
      "Average value_loss: 0.2405\n",
      "Replay buffer size: 6705\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.9781\n",
      "Average policy_loss: 0.7426\n",
      "Average value_loss: 0.2355\n",
      "Replay buffer size: 6800\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.9790\n",
      "Average policy_loss: 0.7435\n",
      "Average value_loss: 0.2355\n",
      "Replay buffer size: 6892\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.9809\n",
      "Average policy_loss: 0.7478\n",
      "Average value_loss: 0.2331\n",
      "Replay buffer size: 6987\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.9820\n",
      "Average policy_loss: 0.7473\n",
      "Average value_loss: 0.2347\n",
      "Replay buffer size: 7079\n",
      "Time taken: 54.1s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.9839\n",
      "Average policy_loss: 0.7496\n",
      "Average value_loss: 0.2343\n",
      "Replay buffer size: 7163\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.9720\n",
      "Average policy_loss: 0.7405\n",
      "Average value_loss: 0.2315\n",
      "Replay buffer size: 7263\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.9769\n",
      "Average policy_loss: 0.7438\n",
      "Average value_loss: 0.2331\n",
      "Replay buffer size: 7347\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.9721\n",
      "Average policy_loss: 0.7405\n",
      "Average value_loss: 0.2315\n",
      "Replay buffer size: 7439\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.9737\n",
      "Average policy_loss: 0.7378\n",
      "Average value_loss: 0.2359\n",
      "Replay buffer size: 7517\n",
      "Time taken: 54.5s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.9688\n",
      "Average policy_loss: 0.7358\n",
      "Average value_loss: 0.2330\n",
      "Replay buffer size: 7616\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.9639\n",
      "Average policy_loss: 0.7324\n",
      "Average value_loss: 0.2315\n",
      "Replay buffer size: 7702\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.9714\n",
      "Average policy_loss: 0.7402\n",
      "Average value_loss: 0.2311\n",
      "Replay buffer size: 7798\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.9670\n",
      "Average policy_loss: 0.7365\n",
      "Average value_loss: 0.2304\n",
      "Replay buffer size: 7895\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.9590\n",
      "Average policy_loss: 0.7299\n",
      "Average value_loss: 0.2291\n",
      "Replay buffer size: 7988\n",
      "Time taken: 56.2s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.9508\n",
      "Average policy_loss: 0.7221\n",
      "Average value_loss: 0.2288\n",
      "Replay buffer size: 8082\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.9647\n",
      "Average policy_loss: 0.7349\n",
      "Average value_loss: 0.2299\n",
      "Replay buffer size: 8172\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.9697\n",
      "Average policy_loss: 0.7362\n",
      "Average value_loss: 0.2334\n",
      "Replay buffer size: 8262\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.9617\n",
      "Average policy_loss: 0.7304\n",
      "Average value_loss: 0.2313\n",
      "Replay buffer size: 8353\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.9583\n",
      "Average policy_loss: 0.7265\n",
      "Average value_loss: 0.2318\n",
      "Replay buffer size: 8440\n",
      "Time taken: 56.9s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.9532\n",
      "Average policy_loss: 0.7247\n",
      "Average value_loss: 0.2285\n",
      "Replay buffer size: 8524\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.9553\n",
      "Average policy_loss: 0.7246\n",
      "Average value_loss: 0.2307\n",
      "Replay buffer size: 8619\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.9532\n",
      "Average policy_loss: 0.7239\n",
      "Average value_loss: 0.2293\n",
      "Replay buffer size: 8702\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.9502\n",
      "Average policy_loss: 0.7201\n",
      "Average value_loss: 0.2301\n",
      "Replay buffer size: 8785\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.9530\n",
      "Average policy_loss: 0.7238\n",
      "Average value_loss: 0.2293\n",
      "Replay buffer size: 8880\n",
      "Time taken: 55.4s\n",
      "\n",
      "Training complete! Total time: 0.7h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iteration_time</td><td>▁▁▂▂▂▇▂█▂█▂▂▂█▂▂▂▂▂▇▂▂▇▂▂▂▂▂▂▇▂▂▂▇▂▂▂▂▂▂</td></tr><tr><td>loss</td><td>█▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▄▃▅▁▄▁▃▄▆▂▅▃▄▂▄▆▆▆▅▅█▇▅█▆▃▄▅▄▆█▃▅▅▄▂█▇▅▇</td></tr><tr><td>policy_loss</td><td>████▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.3</td></tr><tr><td>buffer_size</td><td>8880</td></tr><tr><td>iteration_time</td><td>55.36618</td></tr><tr><td>loss</td><td>0.95304</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>95</td></tr><tr><td>policy_loss</td><td>0.72379</td></tr><tr><td>total_time_hours</td><td>0.70074</td></tr><tr><td>value_loss</td><td>0.22926</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">leafy-sweep-18</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/xykl357a' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/xykl357a</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_081652-xykl357a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yeiehj82 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05479021497554934\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: tiny\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.12650695874330942\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.004076918710720771\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_085905-yeiehj82</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/yeiehj82' target=\"_blank\">vocal-sweep-19</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/yeiehj82' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/yeiehj82</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.1943\n",
      "Average policy_loss: 0.9016\n",
      "Average value_loss: 0.2926\n",
      "Replay buffer size: 82\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 0.9105\n",
      "Average policy_loss: 0.8376\n",
      "Average value_loss: 0.0730\n",
      "Replay buffer size: 156\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 0.9099\n",
      "Average policy_loss: 0.8510\n",
      "Average value_loss: 0.0589\n",
      "Replay buffer size: 232\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.9117\n",
      "Average policy_loss: 0.8557\n",
      "Average value_loss: 0.0560\n",
      "Replay buffer size: 308\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.0261\n",
      "Average policy_loss: 0.8523\n",
      "Average value_loss: 0.1738\n",
      "Replay buffer size: 388\n",
      "Time taken: 52.5s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.0836\n",
      "Average policy_loss: 0.8833\n",
      "Average value_loss: 0.2003\n",
      "Replay buffer size: 475\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.0783\n",
      "Average policy_loss: 0.8916\n",
      "Average value_loss: 0.1868\n",
      "Replay buffer size: 555\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.0875\n",
      "Average policy_loss: 0.9073\n",
      "Average value_loss: 0.1802\n",
      "Replay buffer size: 631\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.0584\n",
      "Average policy_loss: 0.8797\n",
      "Average value_loss: 0.1787\n",
      "Replay buffer size: 715\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.0615\n",
      "Average policy_loss: 0.8912\n",
      "Average value_loss: 0.1703\n",
      "Replay buffer size: 787\n",
      "Time taken: 45.7s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.0619\n",
      "Average policy_loss: 0.9024\n",
      "Average value_loss: 0.1595\n",
      "Replay buffer size: 859\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.0789\n",
      "Average policy_loss: 0.9014\n",
      "Average value_loss: 0.1775\n",
      "Replay buffer size: 937\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.0809\n",
      "Average policy_loss: 0.9100\n",
      "Average value_loss: 0.1709\n",
      "Replay buffer size: 1006\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.1037\n",
      "Average policy_loss: 0.9168\n",
      "Average value_loss: 0.1870\n",
      "Replay buffer size: 1087\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.1453\n",
      "Average policy_loss: 0.9279\n",
      "Average value_loss: 0.2173\n",
      "Replay buffer size: 1161\n",
      "Time taken: 49.0s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.1526\n",
      "Average policy_loss: 0.9344\n",
      "Average value_loss: 0.2182\n",
      "Replay buffer size: 1233\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.1565\n",
      "Average policy_loss: 0.9320\n",
      "Average value_loss: 0.2245\n",
      "Replay buffer size: 1306\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.1845\n",
      "Average policy_loss: 0.9464\n",
      "Average value_loss: 0.2381\n",
      "Replay buffer size: 1385\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.1862\n",
      "Average policy_loss: 0.9542\n",
      "Average value_loss: 0.2319\n",
      "Replay buffer size: 1451\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.1902\n",
      "Average policy_loss: 0.9549\n",
      "Average value_loss: 0.2353\n",
      "Replay buffer size: 1525\n",
      "Time taken: 48.0s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.1396\n",
      "Average policy_loss: 0.9234\n",
      "Average value_loss: 0.2162\n",
      "Replay buffer size: 1605\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.1674\n",
      "Average policy_loss: 0.9422\n",
      "Average value_loss: 0.2252\n",
      "Replay buffer size: 1676\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.1562\n",
      "Average policy_loss: 0.9371\n",
      "Average value_loss: 0.2191\n",
      "Replay buffer size: 1752\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.1830\n",
      "Average policy_loss: 0.9488\n",
      "Average value_loss: 0.2341\n",
      "Replay buffer size: 1836\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.2375\n",
      "Average policy_loss: 0.9698\n",
      "Average value_loss: 0.2677\n",
      "Replay buffer size: 1917\n",
      "Time taken: 54.2s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.2140\n",
      "Average policy_loss: 0.9546\n",
      "Average value_loss: 0.2594\n",
      "Replay buffer size: 2000\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.2072\n",
      "Average policy_loss: 0.9513\n",
      "Average value_loss: 0.2560\n",
      "Replay buffer size: 2087\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.2489\n",
      "Average policy_loss: 0.9734\n",
      "Average value_loss: 0.2755\n",
      "Replay buffer size: 2166\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.2551\n",
      "Average policy_loss: 0.9808\n",
      "Average value_loss: 0.2743\n",
      "Replay buffer size: 2256\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.2608\n",
      "Average policy_loss: 0.9853\n",
      "Average value_loss: 0.2756\n",
      "Replay buffer size: 2353\n",
      "Time taken: 56.0s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.2707\n",
      "Average policy_loss: 0.9993\n",
      "Average value_loss: 0.2714\n",
      "Replay buffer size: 2443\n",
      "Time taken: 19.3s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.2835\n",
      "Average policy_loss: 1.0005\n",
      "Average value_loss: 0.2830\n",
      "Replay buffer size: 2533\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.2875\n",
      "Average policy_loss: 1.0024\n",
      "Average value_loss: 0.2852\n",
      "Replay buffer size: 2619\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.2916\n",
      "Average policy_loss: 1.0133\n",
      "Average value_loss: 0.2783\n",
      "Replay buffer size: 2703\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.2967\n",
      "Average policy_loss: 1.0100\n",
      "Average value_loss: 0.2867\n",
      "Replay buffer size: 2792\n",
      "Time taken: 60.2s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.2777\n",
      "Average policy_loss: 0.9980\n",
      "Average value_loss: 0.2797\n",
      "Replay buffer size: 2888\n",
      "Time taken: 19.3s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.2794\n",
      "Average policy_loss: 0.9929\n",
      "Average value_loss: 0.2865\n",
      "Replay buffer size: 2967\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.3000\n",
      "Average policy_loss: 1.0009\n",
      "Average value_loss: 0.2991\n",
      "Replay buffer size: 3049\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.2970\n",
      "Average policy_loss: 0.9936\n",
      "Average value_loss: 0.3034\n",
      "Replay buffer size: 3142\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.2946\n",
      "Average policy_loss: 0.9912\n",
      "Average value_loss: 0.3034\n",
      "Replay buffer size: 3233\n",
      "Time taken: 62.5s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.2891\n",
      "Average policy_loss: 0.9888\n",
      "Average value_loss: 0.3003\n",
      "Replay buffer size: 3326\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.2994\n",
      "Average policy_loss: 0.9995\n",
      "Average value_loss: 0.3000\n",
      "Replay buffer size: 3418\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.2936\n",
      "Average policy_loss: 0.9937\n",
      "Average value_loss: 0.2999\n",
      "Replay buffer size: 3510\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.2788\n",
      "Average policy_loss: 0.9866\n",
      "Average value_loss: 0.2922\n",
      "Replay buffer size: 3603\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.2827\n",
      "Average policy_loss: 0.9938\n",
      "Average value_loss: 0.2889\n",
      "Replay buffer size: 3690\n",
      "Time taken: 59.3s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.2674\n",
      "Average policy_loss: 0.9849\n",
      "Average value_loss: 0.2825\n",
      "Replay buffer size: 3790\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.2701\n",
      "Average policy_loss: 0.9784\n",
      "Average value_loss: 0.2917\n",
      "Replay buffer size: 3880\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.2479\n",
      "Average policy_loss: 0.9643\n",
      "Average value_loss: 0.2836\n",
      "Replay buffer size: 3972\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.2536\n",
      "Average policy_loss: 0.9647\n",
      "Average value_loss: 0.2888\n",
      "Replay buffer size: 4060\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.2547\n",
      "Average policy_loss: 0.9702\n",
      "Average value_loss: 0.2845\n",
      "Replay buffer size: 4156\n",
      "Time taken: 58.8s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.2508\n",
      "Average policy_loss: 0.9673\n",
      "Average value_loss: 0.2835\n",
      "Replay buffer size: 4254\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.2375\n",
      "Average policy_loss: 0.9545\n",
      "Average value_loss: 0.2830\n",
      "Replay buffer size: 4347\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.2348\n",
      "Average policy_loss: 0.9622\n",
      "Average value_loss: 0.2725\n",
      "Replay buffer size: 4447\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.2251\n",
      "Average policy_loss: 0.9575\n",
      "Average value_loss: 0.2675\n",
      "Replay buffer size: 4536\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.2393\n",
      "Average policy_loss: 0.9578\n",
      "Average value_loss: 0.2816\n",
      "Replay buffer size: 4628\n",
      "Time taken: 62.9s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.2250\n",
      "Average policy_loss: 0.9489\n",
      "Average value_loss: 0.2761\n",
      "Replay buffer size: 4719\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.2138\n",
      "Average policy_loss: 0.9418\n",
      "Average value_loss: 0.2720\n",
      "Replay buffer size: 4807\n",
      "Time taken: 26.1s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.2226\n",
      "Average policy_loss: 0.9498\n",
      "Average value_loss: 0.2728\n",
      "Replay buffer size: 4899\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.1841\n",
      "Average policy_loss: 0.9195\n",
      "Average value_loss: 0.2645\n",
      "Replay buffer size: 4986\n",
      "Time taken: 22.1s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.2192\n",
      "Average policy_loss: 0.9407\n",
      "Average value_loss: 0.2785\n",
      "Replay buffer size: 5078\n",
      "Time taken: 59.0s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.2338\n",
      "Average policy_loss: 0.9417\n",
      "Average value_loss: 0.2921\n",
      "Replay buffer size: 5159\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.2047\n",
      "Average policy_loss: 0.9294\n",
      "Average value_loss: 0.2753\n",
      "Replay buffer size: 5257\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.2028\n",
      "Average policy_loss: 0.9290\n",
      "Average value_loss: 0.2739\n",
      "Replay buffer size: 5344\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.1943\n",
      "Average policy_loss: 0.9163\n",
      "Average value_loss: 0.2780\n",
      "Replay buffer size: 5438\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.1988\n",
      "Average policy_loss: 0.9243\n",
      "Average value_loss: 0.2745\n",
      "Replay buffer size: 5533\n",
      "Time taken: 59.4s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.1976\n",
      "Average policy_loss: 0.9237\n",
      "Average value_loss: 0.2739\n",
      "Replay buffer size: 5613\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.2110\n",
      "Average policy_loss: 0.9298\n",
      "Average value_loss: 0.2812\n",
      "Replay buffer size: 5710\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.1942\n",
      "Average policy_loss: 0.9139\n",
      "Average value_loss: 0.2804\n",
      "Replay buffer size: 5801\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.1902\n",
      "Average policy_loss: 0.9138\n",
      "Average value_loss: 0.2764\n",
      "Replay buffer size: 5886\n",
      "Time taken: 19.2s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.1856\n",
      "Average policy_loss: 0.9108\n",
      "Average value_loss: 0.2748\n",
      "Replay buffer size: 5974\n",
      "Time taken: 66.6s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.1936\n",
      "Average policy_loss: 0.9202\n",
      "Average value_loss: 0.2733\n",
      "Replay buffer size: 6071\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.1886\n",
      "Average policy_loss: 0.9076\n",
      "Average value_loss: 0.2809\n",
      "Replay buffer size: 6166\n",
      "Time taken: 20.8s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.1939\n",
      "Average policy_loss: 0.9207\n",
      "Average value_loss: 0.2732\n",
      "Replay buffer size: 6252\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.1832\n",
      "Average policy_loss: 0.9102\n",
      "Average value_loss: 0.2729\n",
      "Replay buffer size: 6343\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.1846\n",
      "Average policy_loss: 0.9055\n",
      "Average value_loss: 0.2791\n",
      "Replay buffer size: 6435\n",
      "Time taken: 60.3s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.1902\n",
      "Average policy_loss: 0.9135\n",
      "Average value_loss: 0.2767\n",
      "Replay buffer size: 6522\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.1838\n",
      "Average policy_loss: 0.9072\n",
      "Average value_loss: 0.2766\n",
      "Replay buffer size: 6606\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.1812\n",
      "Average policy_loss: 0.8956\n",
      "Average value_loss: 0.2856\n",
      "Replay buffer size: 6688\n",
      "Time taken: 19.3s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.1735\n",
      "Average policy_loss: 0.8965\n",
      "Average value_loss: 0.2771\n",
      "Replay buffer size: 6772\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.1705\n",
      "Average policy_loss: 0.8942\n",
      "Average value_loss: 0.2763\n",
      "Replay buffer size: 6853\n",
      "Time taken: 58.6s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.1746\n",
      "Average policy_loss: 0.8849\n",
      "Average value_loss: 0.2897\n",
      "Replay buffer size: 6937\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.1864\n",
      "Average policy_loss: 0.8939\n",
      "Average value_loss: 0.2924\n",
      "Replay buffer size: 7028\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.1658\n",
      "Average policy_loss: 0.8868\n",
      "Average value_loss: 0.2790\n",
      "Replay buffer size: 7121\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.1795\n",
      "Average policy_loss: 0.8889\n",
      "Average value_loss: 0.2906\n",
      "Replay buffer size: 7210\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.1730\n",
      "Average policy_loss: 0.8932\n",
      "Average value_loss: 0.2798\n",
      "Replay buffer size: 7303\n",
      "Time taken: 62.8s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.1774\n",
      "Average policy_loss: 0.8994\n",
      "Average value_loss: 0.2781\n",
      "Replay buffer size: 7392\n",
      "Time taken: 19.4s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.1713\n",
      "Average policy_loss: 0.8938\n",
      "Average value_loss: 0.2774\n",
      "Replay buffer size: 7477\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.1910\n",
      "Average policy_loss: 0.9031\n",
      "Average value_loss: 0.2879\n",
      "Replay buffer size: 7553\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.1759\n",
      "Average policy_loss: 0.8931\n",
      "Average value_loss: 0.2828\n",
      "Replay buffer size: 7636\n",
      "Time taken: 19.2s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.1910\n",
      "Average policy_loss: 0.9044\n",
      "Average value_loss: 0.2865\n",
      "Replay buffer size: 7733\n",
      "Time taken: 61.6s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.1689\n",
      "Average policy_loss: 0.8847\n",
      "Average value_loss: 0.2842\n",
      "Replay buffer size: 7822\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.1851\n",
      "Average policy_loss: 0.8934\n",
      "Average value_loss: 0.2917\n",
      "Replay buffer size: 7901\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.1803\n",
      "Average policy_loss: 0.8904\n",
      "Average value_loss: 0.2899\n",
      "Replay buffer size: 7994\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.1797\n",
      "Average policy_loss: 0.8940\n",
      "Average value_loss: 0.2857\n",
      "Replay buffer size: 8090\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.1621\n",
      "Average policy_loss: 0.8848\n",
      "Average value_loss: 0.2773\n",
      "Replay buffer size: 8184\n",
      "Time taken: 60.4s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.1739\n",
      "Average policy_loss: 0.8854\n",
      "Average value_loss: 0.2885\n",
      "Replay buffer size: 8277\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.1608\n",
      "Average policy_loss: 0.8756\n",
      "Average value_loss: 0.2852\n",
      "Replay buffer size: 8372\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.1560\n",
      "Average policy_loss: 0.8737\n",
      "Average value_loss: 0.2824\n",
      "Replay buffer size: 8464\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.1592\n",
      "Average policy_loss: 0.8710\n",
      "Average value_loss: 0.2883\n",
      "Replay buffer size: 8554\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.1582\n",
      "Average policy_loss: 0.8778\n",
      "Average value_loss: 0.2804\n",
      "Replay buffer size: 8632\n",
      "Time taken: 56.8s\n",
      "\n",
      "Training complete! Total time: 0.7h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>iteration_time</td><td>▁▆▂▁▁▁▁▁▆▁▂▂▂▂▂▂▂▂▂▇▂▂▂▂▃▂▂▂▂█▂▂▂▂▂▂▂▇▂▂</td></tr><tr><td>loss</td><td>▆▁▄▄▄▆▆▆▅▆▇▇▇██████▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▃▂▁▃▃▃▁▂▄▅▆▆▆▅▇▆▅█▆▅▆█▅▆▆▆▆█▃▇▅▄▃▅▄▅▆▇▇▆</td></tr><tr><td>policy_loss</td><td>▃▁▃▃▄▆▅▆▇▇███▇▇▇▇▇▇▆▆▆▅▆▆▄▅▄▄▄▃▃▄▃▃▂▂▃▃▂</td></tr><tr><td>value_loss</td><td>▁▁▅▅▄▄▄▆▆▆▇▇▇███▇█▇█▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.2</td></tr><tr><td>buffer_size</td><td>8632</td></tr><tr><td>iteration_time</td><td>56.81119</td></tr><tr><td>loss</td><td>1.15819</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>78</td></tr><tr><td>policy_loss</td><td>0.87782</td></tr><tr><td>total_time_hours</td><td>0.72566</td></tr><tr><td>value_loss</td><td>0.28037</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vocal-sweep-19</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/yeiehj82' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/yeiehj82</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 22 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_085905-yeiehj82/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oru4y97b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 8.561095321660657e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.08079199391530123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.031745478452373875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_094243-oru4y97b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/oru4y97b' target=\"_blank\">mild-sweep-20</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/oru4y97b' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/oru4y97b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 4.4586\n",
      "Average policy_loss: 3.2049\n",
      "Average value_loss: 1.2537\n",
      "Replay buffer size: 86\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 2.9337\n",
      "Average policy_loss: 1.9046\n",
      "Average value_loss: 1.0291\n",
      "Replay buffer size: 178\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 2.6929\n",
      "Average policy_loss: 1.6710\n",
      "Average value_loss: 1.0218\n",
      "Replay buffer size: 264\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 2.4128\n",
      "Average policy_loss: 1.5061\n",
      "Average value_loss: 0.9067\n",
      "Replay buffer size: 342\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 2.2729\n",
      "Average policy_loss: 1.3616\n",
      "Average value_loss: 0.9113\n",
      "Replay buffer size: 433\n",
      "Time taken: 34.8s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 2.1963\n",
      "Average policy_loss: 1.2983\n",
      "Average value_loss: 0.8980\n",
      "Replay buffer size: 521\n",
      "Time taken: 10.7s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 2.0861\n",
      "Average policy_loss: 1.2127\n",
      "Average value_loss: 0.8734\n",
      "Replay buffer size: 610\n",
      "Time taken: 9.5s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.9730\n",
      "Average policy_loss: 1.1106\n",
      "Average value_loss: 0.8623\n",
      "Replay buffer size: 705\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.9474\n",
      "Average policy_loss: 1.0729\n",
      "Average value_loss: 0.8745\n",
      "Replay buffer size: 793\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.8981\n",
      "Average policy_loss: 1.0351\n",
      "Average value_loss: 0.8630\n",
      "Replay buffer size: 892\n",
      "Time taken: 41.8s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.8259\n",
      "Average policy_loss: 0.9898\n",
      "Average value_loss: 0.8362\n",
      "Replay buffer size: 988\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.8040\n",
      "Average policy_loss: 0.9816\n",
      "Average value_loss: 0.8224\n",
      "Replay buffer size: 1078\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.7307\n",
      "Average policy_loss: 0.9387\n",
      "Average value_loss: 0.7920\n",
      "Replay buffer size: 1169\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.6667\n",
      "Average policy_loss: 0.9082\n",
      "Average value_loss: 0.7585\n",
      "Replay buffer size: 1261\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.6366\n",
      "Average policy_loss: 0.8958\n",
      "Average value_loss: 0.7409\n",
      "Replay buffer size: 1357\n",
      "Time taken: 46.1s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.6202\n",
      "Average policy_loss: 0.8853\n",
      "Average value_loss: 0.7349\n",
      "Replay buffer size: 1454\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.6010\n",
      "Average policy_loss: 0.8852\n",
      "Average value_loss: 0.7158\n",
      "Replay buffer size: 1548\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.5562\n",
      "Average policy_loss: 0.8709\n",
      "Average value_loss: 0.6853\n",
      "Replay buffer size: 1641\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.5294\n",
      "Average policy_loss: 0.8562\n",
      "Average value_loss: 0.6732\n",
      "Replay buffer size: 1729\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.5229\n",
      "Average policy_loss: 0.8587\n",
      "Average value_loss: 0.6642\n",
      "Replay buffer size: 1823\n",
      "Time taken: 47.2s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.5032\n",
      "Average policy_loss: 0.8575\n",
      "Average value_loss: 0.6457\n",
      "Replay buffer size: 1919\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.4673\n",
      "Average policy_loss: 0.8435\n",
      "Average value_loss: 0.6238\n",
      "Replay buffer size: 2008\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.4542\n",
      "Average policy_loss: 0.8450\n",
      "Average value_loss: 0.6092\n",
      "Replay buffer size: 2096\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.4034\n",
      "Average policy_loss: 0.8502\n",
      "Average value_loss: 0.5531\n",
      "Replay buffer size: 2181\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.4105\n",
      "Average policy_loss: 0.8725\n",
      "Average value_loss: 0.5380\n",
      "Replay buffer size: 2278\n",
      "Time taken: 55.2s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.3759\n",
      "Average policy_loss: 0.8687\n",
      "Average value_loss: 0.5072\n",
      "Replay buffer size: 2374\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.3939\n",
      "Average policy_loss: 0.8968\n",
      "Average value_loss: 0.4972\n",
      "Replay buffer size: 2467\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.3974\n",
      "Average policy_loss: 0.8982\n",
      "Average value_loss: 0.4991\n",
      "Replay buffer size: 2559\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.3816\n",
      "Average policy_loss: 0.8946\n",
      "Average value_loss: 0.4869\n",
      "Replay buffer size: 2650\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.4017\n",
      "Average policy_loss: 0.9118\n",
      "Average value_loss: 0.4899\n",
      "Replay buffer size: 2738\n",
      "Time taken: 56.6s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.3806\n",
      "Average policy_loss: 0.8983\n",
      "Average value_loss: 0.4823\n",
      "Replay buffer size: 2830\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.3937\n",
      "Average policy_loss: 0.9111\n",
      "Average value_loss: 0.4826\n",
      "Replay buffer size: 2916\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.3796\n",
      "Average policy_loss: 0.9140\n",
      "Average value_loss: 0.4656\n",
      "Replay buffer size: 3012\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.3678\n",
      "Average policy_loss: 0.9128\n",
      "Average value_loss: 0.4549\n",
      "Replay buffer size: 3098\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.3565\n",
      "Average policy_loss: 0.9040\n",
      "Average value_loss: 0.4525\n",
      "Replay buffer size: 3198\n",
      "Time taken: 61.8s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.3582\n",
      "Average policy_loss: 0.9166\n",
      "Average value_loss: 0.4417\n",
      "Replay buffer size: 3286\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.3553\n",
      "Average policy_loss: 0.9180\n",
      "Average value_loss: 0.4373\n",
      "Replay buffer size: 3368\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.3518\n",
      "Average policy_loss: 0.9212\n",
      "Average value_loss: 0.4306\n",
      "Replay buffer size: 3459\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.3617\n",
      "Average policy_loss: 0.9339\n",
      "Average value_loss: 0.4278\n",
      "Replay buffer size: 3549\n",
      "Time taken: 19.1s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 15.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.3664\n",
      "Average policy_loss: 0.9392\n",
      "Average value_loss: 0.4272\n",
      "Replay buffer size: 3639\n",
      "Time taken: 61.2s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.3563\n",
      "Average policy_loss: 0.9289\n",
      "Average value_loss: 0.4274\n",
      "Replay buffer size: 3736\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.3572\n",
      "Average policy_loss: 0.9367\n",
      "Average value_loss: 0.4206\n",
      "Replay buffer size: 3831\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.3430\n",
      "Average policy_loss: 0.9294\n",
      "Average value_loss: 0.4136\n",
      "Replay buffer size: 3929\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.3657\n",
      "Average policy_loss: 0.9425\n",
      "Average value_loss: 0.4232\n",
      "Replay buffer size: 4021\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.3527\n",
      "Average policy_loss: 0.9365\n",
      "Average value_loss: 0.4162\n",
      "Replay buffer size: 4120\n",
      "Time taken: 62.6s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.3563\n",
      "Average policy_loss: 0.9420\n",
      "Average value_loss: 0.4143\n",
      "Replay buffer size: 4213\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.3530\n",
      "Average policy_loss: 0.9438\n",
      "Average value_loss: 0.4093\n",
      "Replay buffer size: 4298\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.3556\n",
      "Average policy_loss: 0.9464\n",
      "Average value_loss: 0.4092\n",
      "Replay buffer size: 4389\n",
      "Time taken: 19.2s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.3614\n",
      "Average policy_loss: 0.9519\n",
      "Average value_loss: 0.4094\n",
      "Replay buffer size: 4482\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.3564\n",
      "Average policy_loss: 0.9511\n",
      "Average value_loss: 0.4053\n",
      "Replay buffer size: 4574\n",
      "Time taken: 63.9s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.3581\n",
      "Average policy_loss: 0.9548\n",
      "Average value_loss: 0.4033\n",
      "Replay buffer size: 4666\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.3610\n",
      "Average policy_loss: 0.9565\n",
      "Average value_loss: 0.4045\n",
      "Replay buffer size: 4751\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.3438\n",
      "Average policy_loss: 0.9440\n",
      "Average value_loss: 0.3998\n",
      "Replay buffer size: 4845\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.3507\n",
      "Average policy_loss: 0.9518\n",
      "Average value_loss: 0.3989\n",
      "Replay buffer size: 4937\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 15.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.3451\n",
      "Average policy_loss: 0.9524\n",
      "Average value_loss: 0.3926\n",
      "Replay buffer size: 5032\n",
      "Time taken: 62.5s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.3443\n",
      "Average policy_loss: 0.9504\n",
      "Average value_loss: 0.3939\n",
      "Replay buffer size: 5113\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.3476\n",
      "Average policy_loss: 0.9533\n",
      "Average value_loss: 0.3943\n",
      "Replay buffer size: 5204\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.3428\n",
      "Average policy_loss: 0.9528\n",
      "Average value_loss: 0.3901\n",
      "Replay buffer size: 5290\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.3446\n",
      "Average policy_loss: 0.9581\n",
      "Average value_loss: 0.3866\n",
      "Replay buffer size: 5382\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.3420\n",
      "Average policy_loss: 0.9621\n",
      "Average value_loss: 0.3800\n",
      "Replay buffer size: 5472\n",
      "Time taken: 63.2s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.3390\n",
      "Average policy_loss: 0.9583\n",
      "Average value_loss: 0.3807\n",
      "Replay buffer size: 5567\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.3459\n",
      "Average policy_loss: 0.9693\n",
      "Average value_loss: 0.3767\n",
      "Replay buffer size: 5653\n",
      "Time taken: 20.8s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.3409\n",
      "Average policy_loss: 0.9651\n",
      "Average value_loss: 0.3758\n",
      "Replay buffer size: 5744\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.3427\n",
      "Average policy_loss: 0.9646\n",
      "Average value_loss: 0.3780\n",
      "Replay buffer size: 5844\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.3400\n",
      "Average policy_loss: 0.9659\n",
      "Average value_loss: 0.3742\n",
      "Replay buffer size: 5932\n",
      "Time taken: 64.3s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.3432\n",
      "Average policy_loss: 0.9656\n",
      "Average value_loss: 0.3775\n",
      "Replay buffer size: 6021\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.3258\n",
      "Average policy_loss: 0.9642\n",
      "Average value_loss: 0.3615\n",
      "Replay buffer size: 6115\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.3213\n",
      "Average policy_loss: 0.9582\n",
      "Average value_loss: 0.3631\n",
      "Replay buffer size: 6211\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.3352\n",
      "Average policy_loss: 0.9690\n",
      "Average value_loss: 0.3662\n",
      "Replay buffer size: 6301\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 15.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.3255\n",
      "Average policy_loss: 0.9637\n",
      "Average value_loss: 0.3617\n",
      "Replay buffer size: 6388\n",
      "Time taken: 65.7s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.3224\n",
      "Average policy_loss: 0.9605\n",
      "Average value_loss: 0.3619\n",
      "Replay buffer size: 6483\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.3313\n",
      "Average policy_loss: 0.9665\n",
      "Average value_loss: 0.3648\n",
      "Replay buffer size: 6567\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.3364\n",
      "Average policy_loss: 0.9703\n",
      "Average value_loss: 0.3661\n",
      "Replay buffer size: 6655\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.3426\n",
      "Average policy_loss: 0.9766\n",
      "Average value_loss: 0.3660\n",
      "Replay buffer size: 6746\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.3327\n",
      "Average policy_loss: 0.9696\n",
      "Average value_loss: 0.3630\n",
      "Replay buffer size: 6833\n",
      "Time taken: 66.1s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.3313\n",
      "Average policy_loss: 0.9728\n",
      "Average value_loss: 0.3586\n",
      "Replay buffer size: 6921\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.3348\n",
      "Average policy_loss: 0.9741\n",
      "Average value_loss: 0.3607\n",
      "Replay buffer size: 7006\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.3323\n",
      "Average policy_loss: 0.9771\n",
      "Average value_loss: 0.3552\n",
      "Replay buffer size: 7088\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.3375\n",
      "Average policy_loss: 0.9799\n",
      "Average value_loss: 0.3576\n",
      "Replay buffer size: 7173\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.3490\n",
      "Average policy_loss: 0.9874\n",
      "Average value_loss: 0.3616\n",
      "Replay buffer size: 7260\n",
      "Time taken: 67.3s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.3332\n",
      "Average policy_loss: 0.9811\n",
      "Average value_loss: 0.3521\n",
      "Replay buffer size: 7354\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.3371\n",
      "Average policy_loss: 0.9848\n",
      "Average value_loss: 0.3522\n",
      "Replay buffer size: 7448\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.3317\n",
      "Average policy_loss: 0.9794\n",
      "Average value_loss: 0.3522\n",
      "Replay buffer size: 7539\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.3304\n",
      "Average policy_loss: 0.9804\n",
      "Average value_loss: 0.3501\n",
      "Replay buffer size: 7634\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.3413\n",
      "Average policy_loss: 0.9882\n",
      "Average value_loss: 0.3531\n",
      "Replay buffer size: 7728\n",
      "Time taken: 65.0s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.3339\n",
      "Average policy_loss: 0.9811\n",
      "Average value_loss: 0.3529\n",
      "Replay buffer size: 7811\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.3303\n",
      "Average policy_loss: 0.9797\n",
      "Average value_loss: 0.3507\n",
      "Replay buffer size: 7905\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.3331\n",
      "Average policy_loss: 0.9855\n",
      "Average value_loss: 0.3476\n",
      "Replay buffer size: 7987\n",
      "Time taken: 23.3s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.3349\n",
      "Average policy_loss: 0.9863\n",
      "Average value_loss: 0.3487\n",
      "Replay buffer size: 8079\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.3357\n",
      "Average policy_loss: 0.9889\n",
      "Average value_loss: 0.3468\n",
      "Replay buffer size: 8167\n",
      "Time taken: 68.0s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.3387\n",
      "Average policy_loss: 0.9921\n",
      "Average value_loss: 0.3465\n",
      "Replay buffer size: 8249\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.3289\n",
      "Average policy_loss: 0.9826\n",
      "Average value_loss: 0.3463\n",
      "Replay buffer size: 8339\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.3321\n",
      "Average policy_loss: 0.9842\n",
      "Average value_loss: 0.3479\n",
      "Replay buffer size: 8423\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.3401\n",
      "Average policy_loss: 0.9886\n",
      "Average value_loss: 0.3515\n",
      "Replay buffer size: 8500\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.3404\n",
      "Average policy_loss: 0.9926\n",
      "Average value_loss: 0.3478\n",
      "Replay buffer size: 8592\n",
      "Time taken: 70.3s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.3475\n",
      "Average policy_loss: 1.0000\n",
      "Average value_loss: 0.3475\n",
      "Replay buffer size: 8683\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.3432\n",
      "Average policy_loss: 0.9984\n",
      "Average value_loss: 0.3448\n",
      "Replay buffer size: 8760\n",
      "Time taken: 23.3s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.3472\n",
      "Average policy_loss: 1.0054\n",
      "Average value_loss: 0.3419\n",
      "Replay buffer size: 8836\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.3373\n",
      "Average policy_loss: 0.9957\n",
      "Average value_loss: 0.3416\n",
      "Replay buffer size: 8925\n",
      "Time taken: 23.2s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.3406\n",
      "Average policy_loss: 0.9987\n",
      "Average value_loss: 0.3418\n",
      "Replay buffer size: 9016\n",
      "Time taken: 69.2s\n",
      "\n",
      "Training complete! Total time: 0.7h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iteration_time</td><td>▁▁▁▁▁▁▁▁▁▁▆▂▂▂▆▇▇▂▇▂▂▂▂▇▂▂▂▂▇▂▃▂█▂▂▃▂█▃▃</td></tr><tr><td>loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▆▂▅▅▇▅▅▇█▅▇▇▆▆▄▆▇▂▅▅█▅▆▅▄▅▅▄▅▄▆▆▅▆▃▃▅▃▁▁</td></tr><tr><td>policy_loss</td><td>█▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▅▅▅▅▄▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.2</td></tr><tr><td>buffer_size</td><td>9016</td></tr><tr><td>iteration_time</td><td>69.21698</td></tr><tr><td>loss</td><td>1.34059</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>91</td></tr><tr><td>policy_loss</td><td>0.99875</td></tr><tr><td>total_time_hours</td><td>0.73921</td></tr><tr><td>value_loss</td><td>0.34184</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mild-sweep-20</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/oru4y97b' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/oru4y97b</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 24 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_094243-oru4y97b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2bm423gu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0014886639470558932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.6612738967432795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.026467512654139595\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_102714-2bm423gu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/2bm423gu' target=\"_blank\">fast-sweep-21</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/2bm423gu' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/2bm423gu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 3.4477\n",
      "Average policy_loss: 2.6571\n",
      "Average value_loss: 0.7906\n",
      "Replay buffer size: 96\n",
      "Time taken: 8.5s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.6079\n",
      "Average policy_loss: 1.1647\n",
      "Average value_loss: 0.4432\n",
      "Replay buffer size: 171\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.4513\n",
      "Average policy_loss: 1.0917\n",
      "Average value_loss: 0.3597\n",
      "Replay buffer size: 255\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.3455\n",
      "Average policy_loss: 1.0253\n",
      "Average value_loss: 0.3202\n",
      "Replay buffer size: 349\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.3076\n",
      "Average policy_loss: 1.0248\n",
      "Average value_loss: 0.2829\n",
      "Replay buffer size: 444\n",
      "Time taken: 46.2s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.3316\n",
      "Average policy_loss: 1.0600\n",
      "Average value_loss: 0.2716\n",
      "Replay buffer size: 525\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.2982\n",
      "Average policy_loss: 1.0697\n",
      "Average value_loss: 0.2285\n",
      "Replay buffer size: 609\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.3114\n",
      "Average policy_loss: 1.1024\n",
      "Average value_loss: 0.2090\n",
      "Replay buffer size: 695\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.3183\n",
      "Average policy_loss: 1.1246\n",
      "Average value_loss: 0.1937\n",
      "Replay buffer size: 769\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.3176\n",
      "Average policy_loss: 1.1394\n",
      "Average value_loss: 0.1782\n",
      "Replay buffer size: 841\n",
      "Time taken: 43.1s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.3108\n",
      "Average policy_loss: 1.1408\n",
      "Average value_loss: 0.1700\n",
      "Replay buffer size: 915\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.3184\n",
      "Average policy_loss: 1.1525\n",
      "Average value_loss: 0.1659\n",
      "Replay buffer size: 990\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.3368\n",
      "Average policy_loss: 1.1555\n",
      "Average value_loss: 0.1812\n",
      "Replay buffer size: 1066\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.3699\n",
      "Average policy_loss: 1.1887\n",
      "Average value_loss: 0.1812\n",
      "Replay buffer size: 1145\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.3528\n",
      "Average policy_loss: 1.1763\n",
      "Average value_loss: 0.1764\n",
      "Replay buffer size: 1214\n",
      "Time taken: 45.9s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.3569\n",
      "Average policy_loss: 1.1785\n",
      "Average value_loss: 0.1784\n",
      "Replay buffer size: 1291\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.3624\n",
      "Average policy_loss: 1.1744\n",
      "Average value_loss: 0.1880\n",
      "Replay buffer size: 1373\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.3538\n",
      "Average policy_loss: 1.1697\n",
      "Average value_loss: 0.1842\n",
      "Replay buffer size: 1456\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.3437\n",
      "Average policy_loss: 1.1650\n",
      "Average value_loss: 0.1787\n",
      "Replay buffer size: 1544\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.3534\n",
      "Average policy_loss: 1.1616\n",
      "Average value_loss: 0.1918\n",
      "Replay buffer size: 1631\n",
      "Time taken: 49.9s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.3398\n",
      "Average policy_loss: 1.1552\n",
      "Average value_loss: 0.1845\n",
      "Replay buffer size: 1727\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.3208\n",
      "Average policy_loss: 1.1402\n",
      "Average value_loss: 0.1806\n",
      "Replay buffer size: 1815\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.3137\n",
      "Average policy_loss: 1.1375\n",
      "Average value_loss: 0.1762\n",
      "Replay buffer size: 1907\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.2962\n",
      "Average policy_loss: 1.1250\n",
      "Average value_loss: 0.1712\n",
      "Replay buffer size: 1994\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.2906\n",
      "Average policy_loss: 1.1196\n",
      "Average value_loss: 0.1710\n",
      "Replay buffer size: 2080\n",
      "Time taken: 48.4s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.2647\n",
      "Average policy_loss: 1.0972\n",
      "Average value_loss: 0.1675\n",
      "Replay buffer size: 2171\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.2772\n",
      "Average policy_loss: 1.1080\n",
      "Average value_loss: 0.1692\n",
      "Replay buffer size: 2261\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.2604\n",
      "Average policy_loss: 1.0986\n",
      "Average value_loss: 0.1618\n",
      "Replay buffer size: 2351\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.2531\n",
      "Average policy_loss: 1.0874\n",
      "Average value_loss: 0.1657\n",
      "Replay buffer size: 2431\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.2547\n",
      "Average policy_loss: 1.0903\n",
      "Average value_loss: 0.1644\n",
      "Replay buffer size: 2514\n",
      "Time taken: 51.4s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.2495\n",
      "Average policy_loss: 1.0856\n",
      "Average value_loss: 0.1639\n",
      "Replay buffer size: 2603\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.2337\n",
      "Average policy_loss: 1.0706\n",
      "Average value_loss: 0.1631\n",
      "Replay buffer size: 2691\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.2232\n",
      "Average policy_loss: 1.0604\n",
      "Average value_loss: 0.1628\n",
      "Replay buffer size: 2778\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.2189\n",
      "Average policy_loss: 1.0608\n",
      "Average value_loss: 0.1580\n",
      "Replay buffer size: 2872\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.2145\n",
      "Average policy_loss: 1.0541\n",
      "Average value_loss: 0.1604\n",
      "Replay buffer size: 2968\n",
      "Time taken: 51.6s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.2098\n",
      "Average policy_loss: 1.0493\n",
      "Average value_loss: 0.1605\n",
      "Replay buffer size: 3050\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.2065\n",
      "Average policy_loss: 1.0415\n",
      "Average value_loss: 0.1650\n",
      "Replay buffer size: 3139\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.2188\n",
      "Average policy_loss: 1.0592\n",
      "Average value_loss: 0.1595\n",
      "Replay buffer size: 3226\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.2010\n",
      "Average policy_loss: 1.0411\n",
      "Average value_loss: 0.1599\n",
      "Replay buffer size: 3316\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.2028\n",
      "Average policy_loss: 1.0420\n",
      "Average value_loss: 0.1608\n",
      "Replay buffer size: 3404\n",
      "Time taken: 51.5s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.1913\n",
      "Average policy_loss: 1.0313\n",
      "Average value_loss: 0.1600\n",
      "Replay buffer size: 3495\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.1713\n",
      "Average policy_loss: 1.0189\n",
      "Average value_loss: 0.1525\n",
      "Replay buffer size: 3590\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.1756\n",
      "Average policy_loss: 1.0201\n",
      "Average value_loss: 0.1555\n",
      "Replay buffer size: 3685\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.1642\n",
      "Average policy_loss: 1.0144\n",
      "Average value_loss: 0.1498\n",
      "Replay buffer size: 3772\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.1644\n",
      "Average policy_loss: 1.0146\n",
      "Average value_loss: 0.1498\n",
      "Replay buffer size: 3867\n",
      "Time taken: 53.1s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.1655\n",
      "Average policy_loss: 1.0182\n",
      "Average value_loss: 0.1474\n",
      "Replay buffer size: 3956\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.1649\n",
      "Average policy_loss: 1.0168\n",
      "Average value_loss: 0.1481\n",
      "Replay buffer size: 4044\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.1654\n",
      "Average policy_loss: 1.0148\n",
      "Average value_loss: 0.1507\n",
      "Replay buffer size: 4127\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.1542\n",
      "Average policy_loss: 1.0032\n",
      "Average value_loss: 0.1510\n",
      "Replay buffer size: 4219\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.1587\n",
      "Average policy_loss: 1.0081\n",
      "Average value_loss: 0.1506\n",
      "Replay buffer size: 4306\n",
      "Time taken: 52.8s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.1686\n",
      "Average policy_loss: 1.0154\n",
      "Average value_loss: 0.1532\n",
      "Replay buffer size: 4391\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.1484\n",
      "Average policy_loss: 0.9975\n",
      "Average value_loss: 0.1509\n",
      "Replay buffer size: 4483\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.1453\n",
      "Average policy_loss: 0.9979\n",
      "Average value_loss: 0.1473\n",
      "Replay buffer size: 4578\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.1408\n",
      "Average policy_loss: 0.9882\n",
      "Average value_loss: 0.1526\n",
      "Replay buffer size: 4670\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.1409\n",
      "Average policy_loss: 0.9910\n",
      "Average value_loss: 0.1499\n",
      "Replay buffer size: 4757\n",
      "Time taken: 53.2s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.1293\n",
      "Average policy_loss: 0.9809\n",
      "Average value_loss: 0.1485\n",
      "Replay buffer size: 4842\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.1412\n",
      "Average policy_loss: 0.9956\n",
      "Average value_loss: 0.1456\n",
      "Replay buffer size: 4934\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.1335\n",
      "Average policy_loss: 0.9861\n",
      "Average value_loss: 0.1473\n",
      "Replay buffer size: 5011\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.1400\n",
      "Average policy_loss: 0.9900\n",
      "Average value_loss: 0.1501\n",
      "Replay buffer size: 5100\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.1380\n",
      "Average policy_loss: 0.9897\n",
      "Average value_loss: 0.1483\n",
      "Replay buffer size: 5194\n",
      "Time taken: 52.3s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.1190\n",
      "Average policy_loss: 0.9727\n",
      "Average value_loss: 0.1464\n",
      "Replay buffer size: 5290\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.1234\n",
      "Average policy_loss: 0.9761\n",
      "Average value_loss: 0.1473\n",
      "Replay buffer size: 5374\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.1268\n",
      "Average policy_loss: 0.9819\n",
      "Average value_loss: 0.1449\n",
      "Replay buffer size: 5465\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.1201\n",
      "Average policy_loss: 0.9741\n",
      "Average value_loss: 0.1460\n",
      "Replay buffer size: 5551\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.1146\n",
      "Average policy_loss: 0.9713\n",
      "Average value_loss: 0.1433\n",
      "Replay buffer size: 5640\n",
      "Time taken: 53.3s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.1177\n",
      "Average policy_loss: 0.9722\n",
      "Average value_loss: 0.1455\n",
      "Replay buffer size: 5730\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.1234\n",
      "Average policy_loss: 0.9821\n",
      "Average value_loss: 0.1413\n",
      "Replay buffer size: 5826\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.1261\n",
      "Average policy_loss: 0.9807\n",
      "Average value_loss: 0.1454\n",
      "Replay buffer size: 5920\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.1140\n",
      "Average policy_loss: 0.9755\n",
      "Average value_loss: 0.1385\n",
      "Replay buffer size: 6011\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.1110\n",
      "Average policy_loss: 0.9695\n",
      "Average value_loss: 0.1414\n",
      "Replay buffer size: 6102\n",
      "Time taken: 55.5s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.1159\n",
      "Average policy_loss: 0.9667\n",
      "Average value_loss: 0.1492\n",
      "Replay buffer size: 6183\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.1136\n",
      "Average policy_loss: 0.9739\n",
      "Average value_loss: 0.1397\n",
      "Replay buffer size: 6278\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.1205\n",
      "Average policy_loss: 0.9733\n",
      "Average value_loss: 0.1473\n",
      "Replay buffer size: 6368\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.1211\n",
      "Average policy_loss: 0.9752\n",
      "Average value_loss: 0.1459\n",
      "Replay buffer size: 6455\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.1128\n",
      "Average policy_loss: 0.9701\n",
      "Average value_loss: 0.1427\n",
      "Replay buffer size: 6548\n",
      "Time taken: 53.8s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.1123\n",
      "Average policy_loss: 0.9717\n",
      "Average value_loss: 0.1407\n",
      "Replay buffer size: 6641\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.1035\n",
      "Average policy_loss: 0.9565\n",
      "Average value_loss: 0.1470\n",
      "Replay buffer size: 6737\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.0937\n",
      "Average policy_loss: 0.9556\n",
      "Average value_loss: 0.1381\n",
      "Replay buffer size: 6832\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.1068\n",
      "Average policy_loss: 0.9643\n",
      "Average value_loss: 0.1426\n",
      "Replay buffer size: 6914\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.1025\n",
      "Average policy_loss: 0.9564\n",
      "Average value_loss: 0.1461\n",
      "Replay buffer size: 7002\n",
      "Time taken: 54.2s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.0979\n",
      "Average policy_loss: 0.9557\n",
      "Average value_loss: 0.1423\n",
      "Replay buffer size: 7090\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.1073\n",
      "Average policy_loss: 0.9664\n",
      "Average value_loss: 0.1409\n",
      "Replay buffer size: 7186\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.0919\n",
      "Average policy_loss: 0.9512\n",
      "Average value_loss: 0.1408\n",
      "Replay buffer size: 7269\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.0848\n",
      "Average policy_loss: 0.9473\n",
      "Average value_loss: 0.1374\n",
      "Replay buffer size: 7366\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.1030\n",
      "Average policy_loss: 0.9604\n",
      "Average value_loss: 0.1426\n",
      "Replay buffer size: 7457\n",
      "Time taken: 55.0s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.1038\n",
      "Average policy_loss: 0.9562\n",
      "Average value_loss: 0.1475\n",
      "Replay buffer size: 7549\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.0887\n",
      "Average policy_loss: 0.9498\n",
      "Average value_loss: 0.1390\n",
      "Replay buffer size: 7645\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.0995\n",
      "Average policy_loss: 0.9547\n",
      "Average value_loss: 0.1447\n",
      "Replay buffer size: 7735\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.0895\n",
      "Average policy_loss: 0.9461\n",
      "Average value_loss: 0.1434\n",
      "Replay buffer size: 7825\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.0801\n",
      "Average policy_loss: 0.9433\n",
      "Average value_loss: 0.1369\n",
      "Replay buffer size: 7918\n",
      "Time taken: 52.3s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.0945\n",
      "Average policy_loss: 0.9535\n",
      "Average value_loss: 0.1409\n",
      "Replay buffer size: 8006\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.1054\n",
      "Average policy_loss: 0.9593\n",
      "Average value_loss: 0.1461\n",
      "Replay buffer size: 8091\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.0870\n",
      "Average policy_loss: 0.9472\n",
      "Average value_loss: 0.1397\n",
      "Replay buffer size: 8187\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.0950\n",
      "Average policy_loss: 0.9517\n",
      "Average value_loss: 0.1433\n",
      "Replay buffer size: 8272\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.0806\n",
      "Average policy_loss: 0.9427\n",
      "Average value_loss: 0.1380\n",
      "Replay buffer size: 8364\n",
      "Time taken: 54.4s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.0820\n",
      "Average policy_loss: 0.9360\n",
      "Average value_loss: 0.1460\n",
      "Replay buffer size: 8460\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.0702\n",
      "Average policy_loss: 0.9303\n",
      "Average value_loss: 0.1399\n",
      "Replay buffer size: 8554\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.0727\n",
      "Average policy_loss: 0.9361\n",
      "Average value_loss: 0.1366\n",
      "Replay buffer size: 8635\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.0868\n",
      "Average policy_loss: 0.9478\n",
      "Average value_loss: 0.1390\n",
      "Replay buffer size: 8728\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.0748\n",
      "Average policy_loss: 0.9289\n",
      "Average value_loss: 0.1459\n",
      "Replay buffer size: 8816\n",
      "Time taken: 54.1s\n",
      "\n",
      "Training complete! Total time: 0.6h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>iteration_time</td><td>▁▂▂▇▂▇▂▂▂█▂▂▂▂▂▂▂██▂█▃▂▂▂▂▂█▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>loss</td><td>█▅▆▅▆▆▅▄▄▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▃▇▂▂▃▁▃▅▆▅▅▆▄▅▅▅▆▇▇▅▅▇█▅▇▆▇▇▆▅▆▆▅█▇█▆▆▅▇</td></tr><tr><td>policy_loss</td><td>▆▆▆▇▇████▇▆▆▅▅▅▅▄▅▄▄▃▂▃▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.35</td></tr><tr><td>buffer_size</td><td>8816</td></tr><tr><td>iteration_time</td><td>54.08804</td></tr><tr><td>loss</td><td>1.0748</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>88</td></tr><tr><td>policy_loss</td><td>0.92887</td></tr><tr><td>total_time_hours</td><td>0.64344</td></tr><tr><td>value_loss</td><td>0.14592</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-sweep-21</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/2bm423gu' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/2bm423gu</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_102714-2bm423gu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yz2wd6tn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01229218191847406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.5681225822304464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.04645816210044651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_110602-yz2wd6tn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/yz2wd6tn' target=\"_blank\">upbeat-sweep-22</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/yz2wd6tn' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/yz2wd6tn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.0360\n",
      "Average policy_loss: 0.9106\n",
      "Average value_loss: 0.1254\n",
      "Replay buffer size: 76\n",
      "Time taken: 6.0s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 0.4916\n",
      "Average policy_loss: 0.4552\n",
      "Average value_loss: 0.0364\n",
      "Replay buffer size: 154\n",
      "Time taken: 7.2s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 0.4778\n",
      "Average policy_loss: 0.4616\n",
      "Average value_loss: 0.0163\n",
      "Replay buffer size: 236\n",
      "Time taken: 8.3s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.5162\n",
      "Average policy_loss: 0.5035\n",
      "Average value_loss: 0.0127\n",
      "Replay buffer size: 312\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.6043\n",
      "Average policy_loss: 0.5641\n",
      "Average value_loss: 0.0401\n",
      "Replay buffer size: 393\n",
      "Time taken: 37.6s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.6935\n",
      "Average policy_loss: 0.6188\n",
      "Average value_loss: 0.0747\n",
      "Replay buffer size: 480\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.7781\n",
      "Average policy_loss: 0.6670\n",
      "Average value_loss: 0.1111\n",
      "Replay buffer size: 571\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.8294\n",
      "Average policy_loss: 0.7169\n",
      "Average value_loss: 0.1125\n",
      "Replay buffer size: 655\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.8643\n",
      "Average policy_loss: 0.7424\n",
      "Average value_loss: 0.1219\n",
      "Replay buffer size: 739\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.8756\n",
      "Average policy_loss: 0.7533\n",
      "Average value_loss: 0.1223\n",
      "Replay buffer size: 837\n",
      "Time taken: 42.7s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.8924\n",
      "Average policy_loss: 0.7565\n",
      "Average value_loss: 0.1359\n",
      "Replay buffer size: 925\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.8909\n",
      "Average policy_loss: 0.7529\n",
      "Average value_loss: 0.1380\n",
      "Replay buffer size: 1015\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.8975\n",
      "Average policy_loss: 0.7591\n",
      "Average value_loss: 0.1384\n",
      "Replay buffer size: 1103\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.8909\n",
      "Average policy_loss: 0.7576\n",
      "Average value_loss: 0.1333\n",
      "Replay buffer size: 1193\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 100.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.8924\n",
      "Average policy_loss: 0.7538\n",
      "Average value_loss: 0.1386\n",
      "Replay buffer size: 1289\n",
      "Time taken: 45.0s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.8978\n",
      "Average policy_loss: 0.7530\n",
      "Average value_loss: 0.1447\n",
      "Replay buffer size: 1381\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.8819\n",
      "Average policy_loss: 0.7400\n",
      "Average value_loss: 0.1419\n",
      "Replay buffer size: 1477\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.8894\n",
      "Average policy_loss: 0.7490\n",
      "Average value_loss: 0.1403\n",
      "Replay buffer size: 1559\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.8722\n",
      "Average policy_loss: 0.7353\n",
      "Average value_loss: 0.1369\n",
      "Replay buffer size: 1651\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 100.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.8682\n",
      "Average policy_loss: 0.7301\n",
      "Average value_loss: 0.1380\n",
      "Replay buffer size: 1744\n",
      "Time taken: 45.0s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.8772\n",
      "Average policy_loss: 0.7313\n",
      "Average value_loss: 0.1459\n",
      "Replay buffer size: 1835\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.8764\n",
      "Average policy_loss: 0.7288\n",
      "Average value_loss: 0.1476\n",
      "Replay buffer size: 1930\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.8821\n",
      "Average policy_loss: 0.7327\n",
      "Average value_loss: 0.1494\n",
      "Replay buffer size: 2025\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.8716\n",
      "Average policy_loss: 0.7236\n",
      "Average value_loss: 0.1480\n",
      "Replay buffer size: 2110\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 100.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.8697\n",
      "Average policy_loss: 0.7234\n",
      "Average value_loss: 0.1463\n",
      "Replay buffer size: 2204\n",
      "Time taken: 41.7s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.8618\n",
      "Average policy_loss: 0.7173\n",
      "Average value_loss: 0.1445\n",
      "Replay buffer size: 2302\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.8525\n",
      "Average policy_loss: 0.7103\n",
      "Average value_loss: 0.1421\n",
      "Replay buffer size: 2401\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.8613\n",
      "Average policy_loss: 0.7141\n",
      "Average value_loss: 0.1472\n",
      "Replay buffer size: 2492\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.8603\n",
      "Average policy_loss: 0.7105\n",
      "Average value_loss: 0.1498\n",
      "Replay buffer size: 2581\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.8506\n",
      "Average policy_loss: 0.7046\n",
      "Average value_loss: 0.1460\n",
      "Replay buffer size: 2671\n",
      "Time taken: 42.8s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.8483\n",
      "Average policy_loss: 0.7012\n",
      "Average value_loss: 0.1470\n",
      "Replay buffer size: 2766\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.8449\n",
      "Average policy_loss: 0.6993\n",
      "Average value_loss: 0.1456\n",
      "Replay buffer size: 2854\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.8409\n",
      "Average policy_loss: 0.6973\n",
      "Average value_loss: 0.1436\n",
      "Replay buffer size: 2951\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.8426\n",
      "Average policy_loss: 0.6984\n",
      "Average value_loss: 0.1442\n",
      "Replay buffer size: 3046\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.8428\n",
      "Average policy_loss: 0.6969\n",
      "Average value_loss: 0.1459\n",
      "Replay buffer size: 3133\n",
      "Time taken: 44.8s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.8315\n",
      "Average policy_loss: 0.6913\n",
      "Average value_loss: 0.1402\n",
      "Replay buffer size: 3224\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.8355\n",
      "Average policy_loss: 0.6953\n",
      "Average value_loss: 0.1402\n",
      "Replay buffer size: 3320\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.8300\n",
      "Average policy_loss: 0.6896\n",
      "Average value_loss: 0.1404\n",
      "Replay buffer size: 3414\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.8266\n",
      "Average policy_loss: 0.6860\n",
      "Average value_loss: 0.1405\n",
      "Replay buffer size: 3503\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.8280\n",
      "Average policy_loss: 0.6853\n",
      "Average value_loss: 0.1427\n",
      "Replay buffer size: 3593\n",
      "Time taken: 41.2s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.8253\n",
      "Average policy_loss: 0.6851\n",
      "Average value_loss: 0.1402\n",
      "Replay buffer size: 3687\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.8216\n",
      "Average policy_loss: 0.6826\n",
      "Average value_loss: 0.1390\n",
      "Replay buffer size: 3783\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.8289\n",
      "Average policy_loss: 0.6850\n",
      "Average value_loss: 0.1438\n",
      "Replay buffer size: 3871\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.8224\n",
      "Average policy_loss: 0.6831\n",
      "Average value_loss: 0.1392\n",
      "Replay buffer size: 3967\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 100.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.8139\n",
      "Average policy_loss: 0.6765\n",
      "Average value_loss: 0.1374\n",
      "Replay buffer size: 4067\n",
      "Time taken: 42.8s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.8140\n",
      "Average policy_loss: 0.6788\n",
      "Average value_loss: 0.1352\n",
      "Replay buffer size: 4161\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.8052\n",
      "Average policy_loss: 0.6709\n",
      "Average value_loss: 0.1343\n",
      "Replay buffer size: 4258\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.7963\n",
      "Average policy_loss: 0.6654\n",
      "Average value_loss: 0.1310\n",
      "Replay buffer size: 4354\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.8043\n",
      "Average policy_loss: 0.6713\n",
      "Average value_loss: 0.1330\n",
      "Replay buffer size: 4439\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.8111\n",
      "Average policy_loss: 0.6749\n",
      "Average value_loss: 0.1362\n",
      "Replay buffer size: 4529\n",
      "Time taken: 43.4s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.8076\n",
      "Average policy_loss: 0.6755\n",
      "Average value_loss: 0.1322\n",
      "Replay buffer size: 4617\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.8041\n",
      "Average policy_loss: 0.6722\n",
      "Average value_loss: 0.1319\n",
      "Replay buffer size: 4713\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.8055\n",
      "Average policy_loss: 0.6736\n",
      "Average value_loss: 0.1319\n",
      "Replay buffer size: 4812\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.8014\n",
      "Average policy_loss: 0.6741\n",
      "Average value_loss: 0.1273\n",
      "Replay buffer size: 4906\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.7980\n",
      "Average policy_loss: 0.6729\n",
      "Average value_loss: 0.1251\n",
      "Replay buffer size: 5002\n",
      "Time taken: 43.2s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.7993\n",
      "Average policy_loss: 0.6710\n",
      "Average value_loss: 0.1283\n",
      "Replay buffer size: 5089\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.8009\n",
      "Average policy_loss: 0.6705\n",
      "Average value_loss: 0.1304\n",
      "Replay buffer size: 5173\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.8058\n",
      "Average policy_loss: 0.6712\n",
      "Average value_loss: 0.1346\n",
      "Replay buffer size: 5263\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.7947\n",
      "Average policy_loss: 0.6656\n",
      "Average value_loss: 0.1291\n",
      "Replay buffer size: 5361\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.8033\n",
      "Average policy_loss: 0.6698\n",
      "Average value_loss: 0.1335\n",
      "Replay buffer size: 5453\n",
      "Time taken: 44.2s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.7975\n",
      "Average policy_loss: 0.6690\n",
      "Average value_loss: 0.1285\n",
      "Replay buffer size: 5551\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.8067\n",
      "Average policy_loss: 0.6728\n",
      "Average value_loss: 0.1338\n",
      "Replay buffer size: 5645\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.7998\n",
      "Average policy_loss: 0.6711\n",
      "Average value_loss: 0.1287\n",
      "Replay buffer size: 5736\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.7958\n",
      "Average policy_loss: 0.6681\n",
      "Average value_loss: 0.1278\n",
      "Replay buffer size: 5829\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.7952\n",
      "Average policy_loss: 0.6672\n",
      "Average value_loss: 0.1280\n",
      "Replay buffer size: 5917\n",
      "Time taken: 47.8s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.7948\n",
      "Average policy_loss: 0.6645\n",
      "Average value_loss: 0.1303\n",
      "Replay buffer size: 6011\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.7898\n",
      "Average policy_loss: 0.6628\n",
      "Average value_loss: 0.1270\n",
      "Replay buffer size: 6099\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.7955\n",
      "Average policy_loss: 0.6691\n",
      "Average value_loss: 0.1264\n",
      "Replay buffer size: 6192\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.7956\n",
      "Average policy_loss: 0.6643\n",
      "Average value_loss: 0.1313\n",
      "Replay buffer size: 6273\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.7989\n",
      "Average policy_loss: 0.6694\n",
      "Average value_loss: 0.1294\n",
      "Replay buffer size: 6371\n",
      "Time taken: 46.8s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.7981\n",
      "Average policy_loss: 0.6689\n",
      "Average value_loss: 0.1292\n",
      "Replay buffer size: 6458\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.7966\n",
      "Average policy_loss: 0.6655\n",
      "Average value_loss: 0.1311\n",
      "Replay buffer size: 6543\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.7915\n",
      "Average policy_loss: 0.6625\n",
      "Average value_loss: 0.1290\n",
      "Replay buffer size: 6632\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.8016\n",
      "Average policy_loss: 0.6660\n",
      "Average value_loss: 0.1356\n",
      "Replay buffer size: 6721\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.7916\n",
      "Average policy_loss: 0.6632\n",
      "Average value_loss: 0.1284\n",
      "Replay buffer size: 6817\n",
      "Time taken: 45.3s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.7922\n",
      "Average policy_loss: 0.6638\n",
      "Average value_loss: 0.1284\n",
      "Replay buffer size: 6914\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.7829\n",
      "Average policy_loss: 0.6576\n",
      "Average value_loss: 0.1253\n",
      "Replay buffer size: 7007\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.7875\n",
      "Average policy_loss: 0.6610\n",
      "Average value_loss: 0.1265\n",
      "Replay buffer size: 7096\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.7850\n",
      "Average policy_loss: 0.6600\n",
      "Average value_loss: 0.1251\n",
      "Replay buffer size: 7190\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.7794\n",
      "Average policy_loss: 0.6554\n",
      "Average value_loss: 0.1240\n",
      "Replay buffer size: 7284\n",
      "Time taken: 47.1s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.7873\n",
      "Average policy_loss: 0.6596\n",
      "Average value_loss: 0.1277\n",
      "Replay buffer size: 7383\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.7901\n",
      "Average policy_loss: 0.6627\n",
      "Average value_loss: 0.1274\n",
      "Replay buffer size: 7476\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.7846\n",
      "Average policy_loss: 0.6590\n",
      "Average value_loss: 0.1256\n",
      "Replay buffer size: 7564\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.7858\n",
      "Average policy_loss: 0.6580\n",
      "Average value_loss: 0.1278\n",
      "Replay buffer size: 7657\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.7810\n",
      "Average policy_loss: 0.6555\n",
      "Average value_loss: 0.1255\n",
      "Replay buffer size: 7751\n",
      "Time taken: 47.2s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.7756\n",
      "Average policy_loss: 0.6529\n",
      "Average value_loss: 0.1226\n",
      "Replay buffer size: 7849\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.7758\n",
      "Average policy_loss: 0.6501\n",
      "Average value_loss: 0.1257\n",
      "Replay buffer size: 7940\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.7819\n",
      "Average policy_loss: 0.6570\n",
      "Average value_loss: 0.1248\n",
      "Replay buffer size: 8034\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.7869\n",
      "Average policy_loss: 0.6598\n",
      "Average value_loss: 0.1271\n",
      "Replay buffer size: 8125\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.7842\n",
      "Average policy_loss: 0.6574\n",
      "Average value_loss: 0.1268\n",
      "Replay buffer size: 8212\n",
      "Time taken: 47.0s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.7795\n",
      "Average policy_loss: 0.6538\n",
      "Average value_loss: 0.1258\n",
      "Replay buffer size: 8307\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.7796\n",
      "Average policy_loss: 0.6520\n",
      "Average value_loss: 0.1276\n",
      "Replay buffer size: 8402\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.7775\n",
      "Average policy_loss: 0.6512\n",
      "Average value_loss: 0.1263\n",
      "Replay buffer size: 8491\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.7779\n",
      "Average policy_loss: 0.6534\n",
      "Average value_loss: 0.1244\n",
      "Replay buffer size: 8589\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.7751\n",
      "Average policy_loss: 0.6524\n",
      "Average value_loss: 0.1227\n",
      "Replay buffer size: 8682\n",
      "Time taken: 45.9s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.7718\n",
      "Average policy_loss: 0.6499\n",
      "Average value_loss: 0.1220\n",
      "Replay buffer size: 8778\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.7762\n",
      "Average policy_loss: 0.6528\n",
      "Average value_loss: 0.1234\n",
      "Replay buffer size: 8867\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.7814\n",
      "Average policy_loss: 0.6536\n",
      "Average value_loss: 0.1277\n",
      "Replay buffer size: 8952\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.7746\n",
      "Average policy_loss: 0.6514\n",
      "Average value_loss: 0.1232\n",
      "Replay buffer size: 9045\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 100.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.7774\n",
      "Average policy_loss: 0.6526\n",
      "Average value_loss: 0.1248\n",
      "Replay buffer size: 9135\n",
      "Time taken: 47.2s\n",
      "\n",
      "Training complete! Total time: 0.6h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>iteration_time</td><td>▁▂▂▂▇▃▂▂▂▂▂▇▂▂█▃▂▂▇▂▂▇▂▇▂▃▂▃█▂█▂█▃▂█▂█▂▂</td></tr><tr><td>loss</td><td>▁▁▂▅▆█████▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▃▁▃▆▃▅▅▇▆▃▇▇█▇▇▆▇▅▇▆▄▅▅▆▇█▆▆▅▆▄▅▅▇▆▅▆█▆▆</td></tr><tr><td>policy_loss</td><td>▁▂▃▆▇█████▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅</td></tr><tr><td>value_loss</td><td>▁▂▄▆▇█████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.1</td></tr><tr><td>buffer_size</td><td>9135</td></tr><tr><td>iteration_time</td><td>47.24488</td></tr><tr><td>loss</td><td>0.77742</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>90</td></tr><tr><td>policy_loss</td><td>0.65264</td></tr><tr><td>total_time_hours</td><td>0.57339</td></tr><tr><td>value_loss</td><td>0.12478</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">upbeat-sweep-22</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/yz2wd6tn' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/yz2wd6tn</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_110602-yz2wd6tn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vq97zk6d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00013596003118112012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.8880805620409284\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001514571740597795\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_114034-vq97zk6d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/vq97zk6d' target=\"_blank\">worthy-sweep-23</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/vq97zk6d' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/vq97zk6d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 2.2991\n",
      "Average policy_loss: 0.4488\n",
      "Average value_loss: 1.8504\n",
      "Replay buffer size: 80\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 2.5716\n",
      "Average policy_loss: 0.7104\n",
      "Average value_loss: 1.8612\n",
      "Replay buffer size: 153\n",
      "Time taken: 9.7s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 2.5229\n",
      "Average policy_loss: 0.7118\n",
      "Average value_loss: 1.8111\n",
      "Replay buffer size: 223\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 2.3448\n",
      "Average policy_loss: 0.6821\n",
      "Average value_loss: 1.6626\n",
      "Replay buffer size: 309\n",
      "Time taken: 9.3s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 10.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 2.2634\n",
      "Average policy_loss: 0.6648\n",
      "Average value_loss: 1.5986\n",
      "Replay buffer size: 396\n",
      "Time taken: 28.2s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 2.1248\n",
      "Average policy_loss: 0.5924\n",
      "Average value_loss: 1.5324\n",
      "Replay buffer size: 492\n",
      "Time taken: 9.8s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 2.0907\n",
      "Average policy_loss: 0.5867\n",
      "Average value_loss: 1.5040\n",
      "Replay buffer size: 578\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.8697\n",
      "Average policy_loss: 0.5405\n",
      "Average value_loss: 1.3291\n",
      "Replay buffer size: 675\n",
      "Time taken: 8.7s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.4149\n",
      "Average policy_loss: 0.7501\n",
      "Average value_loss: 0.6647\n",
      "Replay buffer size: 757\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.3031\n",
      "Average policy_loss: 0.7579\n",
      "Average value_loss: 0.5452\n",
      "Replay buffer size: 848\n",
      "Time taken: 49.0s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.3247\n",
      "Average policy_loss: 0.7826\n",
      "Average value_loss: 0.5421\n",
      "Replay buffer size: 938\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.3351\n",
      "Average policy_loss: 0.8013\n",
      "Average value_loss: 0.5338\n",
      "Replay buffer size: 1026\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.2872\n",
      "Average policy_loss: 0.8146\n",
      "Average value_loss: 0.4725\n",
      "Replay buffer size: 1102\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.2584\n",
      "Average policy_loss: 0.8376\n",
      "Average value_loss: 0.4208\n",
      "Replay buffer size: 1178\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.2027\n",
      "Average policy_loss: 0.8480\n",
      "Average value_loss: 0.3546\n",
      "Replay buffer size: 1248\n",
      "Time taken: 47.9s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.1684\n",
      "Average policy_loss: 0.8480\n",
      "Average value_loss: 0.3204\n",
      "Replay buffer size: 1320\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.1470\n",
      "Average policy_loss: 0.8511\n",
      "Average value_loss: 0.2959\n",
      "Replay buffer size: 1388\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.1283\n",
      "Average policy_loss: 0.8479\n",
      "Average value_loss: 0.2804\n",
      "Replay buffer size: 1454\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.1162\n",
      "Average policy_loss: 0.8504\n",
      "Average value_loss: 0.2658\n",
      "Replay buffer size: 1528\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.1076\n",
      "Average policy_loss: 0.8526\n",
      "Average value_loss: 0.2550\n",
      "Replay buffer size: 1594\n",
      "Time taken: 39.3s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.0908\n",
      "Average policy_loss: 0.8464\n",
      "Average value_loss: 0.2444\n",
      "Replay buffer size: 1668\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.0953\n",
      "Average policy_loss: 0.8591\n",
      "Average value_loss: 0.2361\n",
      "Replay buffer size: 1736\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.0844\n",
      "Average policy_loss: 0.8571\n",
      "Average value_loss: 0.2273\n",
      "Replay buffer size: 1805\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.0835\n",
      "Average policy_loss: 0.8640\n",
      "Average value_loss: 0.2195\n",
      "Replay buffer size: 1881\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.0688\n",
      "Average policy_loss: 0.8537\n",
      "Average value_loss: 0.2151\n",
      "Replay buffer size: 1951\n",
      "Time taken: 42.7s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.0665\n",
      "Average policy_loss: 0.8498\n",
      "Average value_loss: 0.2167\n",
      "Replay buffer size: 2023\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.0639\n",
      "Average policy_loss: 0.8506\n",
      "Average value_loss: 0.2134\n",
      "Replay buffer size: 2101\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.0545\n",
      "Average policy_loss: 0.8473\n",
      "Average value_loss: 0.2071\n",
      "Replay buffer size: 2183\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.0526\n",
      "Average policy_loss: 0.8464\n",
      "Average value_loss: 0.2063\n",
      "Replay buffer size: 2264\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.0545\n",
      "Average policy_loss: 0.8470\n",
      "Average value_loss: 0.2075\n",
      "Replay buffer size: 2347\n",
      "Time taken: 50.0s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.0524\n",
      "Average policy_loss: 0.8469\n",
      "Average value_loss: 0.2056\n",
      "Replay buffer size: 2435\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.0456\n",
      "Average policy_loss: 0.8414\n",
      "Average value_loss: 0.2042\n",
      "Replay buffer size: 2525\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.0439\n",
      "Average policy_loss: 0.8416\n",
      "Average value_loss: 0.2023\n",
      "Replay buffer size: 2618\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.0313\n",
      "Average policy_loss: 0.8330\n",
      "Average value_loss: 0.1982\n",
      "Replay buffer size: 2706\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.0306\n",
      "Average policy_loss: 0.8320\n",
      "Average value_loss: 0.1986\n",
      "Replay buffer size: 2792\n",
      "Time taken: 47.8s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.0426\n",
      "Average policy_loss: 0.8435\n",
      "Average value_loss: 0.1991\n",
      "Replay buffer size: 2872\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.0421\n",
      "Average policy_loss: 0.8427\n",
      "Average value_loss: 0.1994\n",
      "Replay buffer size: 2954\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.0460\n",
      "Average policy_loss: 0.8466\n",
      "Average value_loss: 0.1994\n",
      "Replay buffer size: 3040\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.0400\n",
      "Average policy_loss: 0.8442\n",
      "Average value_loss: 0.1958\n",
      "Replay buffer size: 3130\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.0424\n",
      "Average policy_loss: 0.8449\n",
      "Average value_loss: 0.1975\n",
      "Replay buffer size: 3207\n",
      "Time taken: 42.2s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.0395\n",
      "Average policy_loss: 0.8448\n",
      "Average value_loss: 0.1947\n",
      "Replay buffer size: 3285\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.0362\n",
      "Average policy_loss: 0.8445\n",
      "Average value_loss: 0.1918\n",
      "Replay buffer size: 3365\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.0358\n",
      "Average policy_loss: 0.8444\n",
      "Average value_loss: 0.1913\n",
      "Replay buffer size: 3435\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.0399\n",
      "Average policy_loss: 0.8524\n",
      "Average value_loss: 0.1874\n",
      "Replay buffer size: 3515\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 40.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.0367\n",
      "Average policy_loss: 0.8476\n",
      "Average value_loss: 0.1891\n",
      "Replay buffer size: 3583\n",
      "Time taken: 47.3s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.0316\n",
      "Average policy_loss: 0.8462\n",
      "Average value_loss: 0.1854\n",
      "Replay buffer size: 3659\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.0281\n",
      "Average policy_loss: 0.8420\n",
      "Average value_loss: 0.1860\n",
      "Replay buffer size: 3728\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.0333\n",
      "Average policy_loss: 0.8466\n",
      "Average value_loss: 0.1866\n",
      "Replay buffer size: 3796\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.0320\n",
      "Average policy_loss: 0.8463\n",
      "Average value_loss: 0.1857\n",
      "Replay buffer size: 3878\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.0279\n",
      "Average policy_loss: 0.8434\n",
      "Average value_loss: 0.1844\n",
      "Replay buffer size: 3968\n",
      "Time taken: 48.4s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.0261\n",
      "Average policy_loss: 0.8436\n",
      "Average value_loss: 0.1824\n",
      "Replay buffer size: 4044\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.0272\n",
      "Average policy_loss: 0.8480\n",
      "Average value_loss: 0.1792\n",
      "Replay buffer size: 4122\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.0259\n",
      "Average policy_loss: 0.8465\n",
      "Average value_loss: 0.1794\n",
      "Replay buffer size: 4198\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.0261\n",
      "Average policy_loss: 0.8501\n",
      "Average value_loss: 0.1760\n",
      "Replay buffer size: 4276\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.0262\n",
      "Average policy_loss: 0.8515\n",
      "Average value_loss: 0.1747\n",
      "Replay buffer size: 4356\n",
      "Time taken: 51.0s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.0208\n",
      "Average policy_loss: 0.8470\n",
      "Average value_loss: 0.1739\n",
      "Replay buffer size: 4445\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.0210\n",
      "Average policy_loss: 0.8471\n",
      "Average value_loss: 0.1739\n",
      "Replay buffer size: 4525\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.0232\n",
      "Average policy_loss: 0.8481\n",
      "Average value_loss: 0.1751\n",
      "Replay buffer size: 4600\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.0262\n",
      "Average policy_loss: 0.8505\n",
      "Average value_loss: 0.1757\n",
      "Replay buffer size: 4679\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.0238\n",
      "Average policy_loss: 0.8485\n",
      "Average value_loss: 0.1754\n",
      "Replay buffer size: 4752\n",
      "Time taken: 49.6s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.0222\n",
      "Average policy_loss: 0.8495\n",
      "Average value_loss: 0.1727\n",
      "Replay buffer size: 4828\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.0254\n",
      "Average policy_loss: 0.8530\n",
      "Average value_loss: 0.1724\n",
      "Replay buffer size: 4906\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.0224\n",
      "Average policy_loss: 0.8500\n",
      "Average value_loss: 0.1724\n",
      "Replay buffer size: 4984\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.0241\n",
      "Average policy_loss: 0.8529\n",
      "Average value_loss: 0.1711\n",
      "Replay buffer size: 5062\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.0266\n",
      "Average policy_loss: 0.8548\n",
      "Average value_loss: 0.1718\n",
      "Replay buffer size: 5135\n",
      "Time taken: 50.1s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.0228\n",
      "Average policy_loss: 0.8530\n",
      "Average value_loss: 0.1698\n",
      "Replay buffer size: 5217\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.0262\n",
      "Average policy_loss: 0.8565\n",
      "Average value_loss: 0.1697\n",
      "Replay buffer size: 5288\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.0228\n",
      "Average policy_loss: 0.8519\n",
      "Average value_loss: 0.1709\n",
      "Replay buffer size: 5380\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.0265\n",
      "Average policy_loss: 0.8550\n",
      "Average value_loss: 0.1715\n",
      "Replay buffer size: 5468\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.0255\n",
      "Average policy_loss: 0.8540\n",
      "Average value_loss: 0.1715\n",
      "Replay buffer size: 5548\n",
      "Time taken: 47.5s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.0256\n",
      "Average policy_loss: 0.8545\n",
      "Average value_loss: 0.1711\n",
      "Replay buffer size: 5623\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.0262\n",
      "Average policy_loss: 0.8561\n",
      "Average value_loss: 0.1700\n",
      "Replay buffer size: 5705\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.0281\n",
      "Average policy_loss: 0.8596\n",
      "Average value_loss: 0.1685\n",
      "Replay buffer size: 5775\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.0209\n",
      "Average policy_loss: 0.8537\n",
      "Average value_loss: 0.1672\n",
      "Replay buffer size: 5847\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.0271\n",
      "Average policy_loss: 0.8579\n",
      "Average value_loss: 0.1693\n",
      "Replay buffer size: 5929\n",
      "Time taken: 49.9s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.0168\n",
      "Average policy_loss: 0.8510\n",
      "Average value_loss: 0.1658\n",
      "Replay buffer size: 6007\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.0224\n",
      "Average policy_loss: 0.8565\n",
      "Average value_loss: 0.1659\n",
      "Replay buffer size: 6082\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.0180\n",
      "Average policy_loss: 0.8537\n",
      "Average value_loss: 0.1644\n",
      "Replay buffer size: 6158\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.0203\n",
      "Average policy_loss: 0.8555\n",
      "Average value_loss: 0.1649\n",
      "Replay buffer size: 6232\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.0215\n",
      "Average policy_loss: 0.8553\n",
      "Average value_loss: 0.1661\n",
      "Replay buffer size: 6316\n",
      "Time taken: 50.5s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.0180\n",
      "Average policy_loss: 0.8525\n",
      "Average value_loss: 0.1655\n",
      "Replay buffer size: 6400\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.0184\n",
      "Average policy_loss: 0.8550\n",
      "Average value_loss: 0.1634\n",
      "Replay buffer size: 6480\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.0175\n",
      "Average policy_loss: 0.8521\n",
      "Average value_loss: 0.1654\n",
      "Replay buffer size: 6565\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.0114\n",
      "Average policy_loss: 0.8477\n",
      "Average value_loss: 0.1637\n",
      "Replay buffer size: 6645\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.0149\n",
      "Average policy_loss: 0.8519\n",
      "Average value_loss: 0.1630\n",
      "Replay buffer size: 6727\n",
      "Time taken: 50.5s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.0106\n",
      "Average policy_loss: 0.8491\n",
      "Average value_loss: 0.1615\n",
      "Replay buffer size: 6809\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.0131\n",
      "Average policy_loss: 0.8527\n",
      "Average value_loss: 0.1604\n",
      "Replay buffer size: 6893\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.0141\n",
      "Average policy_loss: 0.8532\n",
      "Average value_loss: 0.1610\n",
      "Replay buffer size: 6966\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.0107\n",
      "Average policy_loss: 0.8460\n",
      "Average value_loss: 0.1647\n",
      "Replay buffer size: 7051\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.0121\n",
      "Average policy_loss: 0.8484\n",
      "Average value_loss: 0.1637\n",
      "Replay buffer size: 7135\n",
      "Time taken: 51.2s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.0123\n",
      "Average policy_loss: 0.8497\n",
      "Average value_loss: 0.1626\n",
      "Replay buffer size: 7210\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.0152\n",
      "Average policy_loss: 0.8491\n",
      "Average value_loss: 0.1661\n",
      "Replay buffer size: 7293\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.0134\n",
      "Average policy_loss: 0.8500\n",
      "Average value_loss: 0.1634\n",
      "Replay buffer size: 7377\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.0164\n",
      "Average policy_loss: 0.8503\n",
      "Average value_loss: 0.1662\n",
      "Replay buffer size: 7459\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.0122\n",
      "Average policy_loss: 0.8490\n",
      "Average value_loss: 0.1632\n",
      "Replay buffer size: 7544\n",
      "Time taken: 52.4s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.0140\n",
      "Average policy_loss: 0.8503\n",
      "Average value_loss: 0.1637\n",
      "Replay buffer size: 7634\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.0127\n",
      "Average policy_loss: 0.8497\n",
      "Average value_loss: 0.1630\n",
      "Replay buffer size: 7718\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.0174\n",
      "Average policy_loss: 0.8510\n",
      "Average value_loss: 0.1664\n",
      "Replay buffer size: 7803\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.0092\n",
      "Average policy_loss: 0.8447\n",
      "Average value_loss: 0.1645\n",
      "Replay buffer size: 7892\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.0100\n",
      "Average policy_loss: 0.8448\n",
      "Average value_loss: 0.1652\n",
      "Replay buffer size: 7984\n",
      "Time taken: 55.3s\n",
      "\n",
      "Training complete! Total time: 0.6h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iteration_time</td><td>▁▁▁▇▂▂▆▂▂▂▂▂▇▂▂▆▂▂▂▂▂▂▂█▂▂▂▂▇▂▂██▂▂▂▂█▂▃</td></tr><tr><td>loss</td><td>██▇▆▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▄▃▆█▆▁▁▁▁▃▅▅▅▆▇▅▄▁▂▅▃▄▄▃▃▃▅▆▄▃▃▄▅▅▅▃▅▅▅▆</td></tr><tr><td>policy_loss</td><td>▄▂▂▁▆███████████████████████████████████</td></tr><tr><td>value_loss</td><td>██▇▆▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.3</td></tr><tr><td>buffer_size</td><td>7984</td></tr><tr><td>iteration_time</td><td>55.2597</td></tr><tr><td>loss</td><td>1.01005</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>92</td></tr><tr><td>policy_loss</td><td>0.84481</td></tr><tr><td>total_time_hours</td><td>0.58627</td></tr><tr><td>value_loss</td><td>0.16523</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worthy-sweep-23</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/vq97zk6d' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/vq97zk6d</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 26 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_114034-vq97zk6d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 73dqea8j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002385870068881881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.26828062571952627\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0003903107761078536\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_121554-73dqea8j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/73dqea8j' target=\"_blank\">honest-sweep-24</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/73dqea8j' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/73dqea8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 4.1539\n",
      "Average policy_loss: 2.2329\n",
      "Average value_loss: 1.9209\n",
      "Replay buffer size: 75\n",
      "Time taken: 7.1s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 3.1055\n",
      "Average policy_loss: 1.1805\n",
      "Average value_loss: 1.9249\n",
      "Replay buffer size: 155\n",
      "Time taken: 6.3s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 2.9063\n",
      "Average policy_loss: 0.8979\n",
      "Average value_loss: 2.0084\n",
      "Replay buffer size: 243\n",
      "Time taken: 6.4s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 2.8751\n",
      "Average policy_loss: 0.8541\n",
      "Average value_loss: 2.0210\n",
      "Replay buffer size: 319\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 2.8265\n",
      "Average policy_loss: 0.8517\n",
      "Average value_loss: 1.9747\n",
      "Replay buffer size: 387\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 2.8242\n",
      "Average policy_loss: 0.8273\n",
      "Average value_loss: 1.9969\n",
      "Replay buffer size: 459\n",
      "Time taken: 7.4s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 2.8198\n",
      "Average policy_loss: 0.8360\n",
      "Average value_loss: 1.9837\n",
      "Replay buffer size: 523\n",
      "Time taken: 6.9s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 2.7920\n",
      "Average policy_loss: 0.8145\n",
      "Average value_loss: 1.9775\n",
      "Replay buffer size: 597\n",
      "Time taken: 7.3s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 2.7712\n",
      "Average policy_loss: 0.7917\n",
      "Average value_loss: 1.9794\n",
      "Replay buffer size: 668\n",
      "Time taken: 7.1s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 2.7501\n",
      "Average policy_loss: 0.7680\n",
      "Average value_loss: 1.9821\n",
      "Replay buffer size: 740\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 2.7365\n",
      "Average policy_loss: 0.7611\n",
      "Average value_loss: 1.9754\n",
      "Replay buffer size: 816\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 2.7393\n",
      "Average policy_loss: 0.7525\n",
      "Average value_loss: 1.9867\n",
      "Replay buffer size: 896\n",
      "Time taken: 7.7s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 2.6859\n",
      "Average policy_loss: 0.7240\n",
      "Average value_loss: 1.9619\n",
      "Replay buffer size: 970\n",
      "Time taken: 7.1s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 2.6372\n",
      "Average policy_loss: 0.7036\n",
      "Average value_loss: 1.9336\n",
      "Replay buffer size: 1048\n",
      "Time taken: 7.6s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 2.6864\n",
      "Average policy_loss: 0.7118\n",
      "Average value_loss: 1.9746\n",
      "Replay buffer size: 1126\n",
      "Time taken: 25.4s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 2.6482\n",
      "Average policy_loss: 0.6933\n",
      "Average value_loss: 1.9549\n",
      "Replay buffer size: 1203\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 2.6385\n",
      "Average policy_loss: 0.6731\n",
      "Average value_loss: 1.9654\n",
      "Replay buffer size: 1287\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 2.6403\n",
      "Average policy_loss: 0.6661\n",
      "Average value_loss: 1.9742\n",
      "Replay buffer size: 1366\n",
      "Time taken: 7.3s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 2.6042\n",
      "Average policy_loss: 0.6506\n",
      "Average value_loss: 1.9535\n",
      "Replay buffer size: 1445\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 2.6136\n",
      "Average policy_loss: 0.6431\n",
      "Average value_loss: 1.9705\n",
      "Replay buffer size: 1522\n",
      "Time taken: 25.7s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.6782\n",
      "Average policy_loss: 0.6702\n",
      "Average value_loss: 1.0080\n",
      "Replay buffer size: 1604\n",
      "Time taken: 7.4s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.3770\n",
      "Average policy_loss: 0.7321\n",
      "Average value_loss: 0.6450\n",
      "Replay buffer size: 1691\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.2577\n",
      "Average policy_loss: 0.7546\n",
      "Average value_loss: 0.5031\n",
      "Replay buffer size: 1778\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.1686\n",
      "Average policy_loss: 0.7988\n",
      "Average value_loss: 0.3698\n",
      "Replay buffer size: 1858\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 40.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.1599\n",
      "Average policy_loss: 0.8020\n",
      "Average value_loss: 0.3579\n",
      "Replay buffer size: 1938\n",
      "Time taken: 35.6s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.1422\n",
      "Average policy_loss: 0.8106\n",
      "Average value_loss: 0.3316\n",
      "Replay buffer size: 2017\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.1455\n",
      "Average policy_loss: 0.8212\n",
      "Average value_loss: 0.3243\n",
      "Replay buffer size: 2089\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.1608\n",
      "Average policy_loss: 0.8329\n",
      "Average value_loss: 0.3279\n",
      "Replay buffer size: 2160\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.1535\n",
      "Average policy_loss: 0.8362\n",
      "Average value_loss: 0.3173\n",
      "Replay buffer size: 2236\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.1692\n",
      "Average policy_loss: 0.8478\n",
      "Average value_loss: 0.3214\n",
      "Replay buffer size: 2317\n",
      "Time taken: 36.8s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.1970\n",
      "Average policy_loss: 0.8664\n",
      "Average value_loss: 0.3307\n",
      "Replay buffer size: 2390\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.1774\n",
      "Average policy_loss: 0.8604\n",
      "Average value_loss: 0.3170\n",
      "Replay buffer size: 2468\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.1492\n",
      "Average policy_loss: 0.8569\n",
      "Average value_loss: 0.2923\n",
      "Replay buffer size: 2539\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.1611\n",
      "Average policy_loss: 0.8661\n",
      "Average value_loss: 0.2950\n",
      "Replay buffer size: 2615\n",
      "Time taken: 9.8s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.1680\n",
      "Average policy_loss: 0.8745\n",
      "Average value_loss: 0.2935\n",
      "Replay buffer size: 2695\n",
      "Time taken: 35.5s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.1753\n",
      "Average policy_loss: 0.8764\n",
      "Average value_loss: 0.2990\n",
      "Replay buffer size: 2777\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.1942\n",
      "Average policy_loss: 0.8895\n",
      "Average value_loss: 0.3047\n",
      "Replay buffer size: 2852\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.1769\n",
      "Average policy_loss: 0.8813\n",
      "Average value_loss: 0.2956\n",
      "Replay buffer size: 2928\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.1801\n",
      "Average policy_loss: 0.8839\n",
      "Average value_loss: 0.2962\n",
      "Replay buffer size: 3004\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 55.00%, Draw rate = 40.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.1887\n",
      "Average policy_loss: 0.8955\n",
      "Average value_loss: 0.2932\n",
      "Replay buffer size: 3076\n",
      "Time taken: 41.1s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.1723\n",
      "Average policy_loss: 0.8887\n",
      "Average value_loss: 0.2836\n",
      "Replay buffer size: 3152\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.1855\n",
      "Average policy_loss: 0.8986\n",
      "Average value_loss: 0.2868\n",
      "Replay buffer size: 3220\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.1546\n",
      "Average policy_loss: 0.8846\n",
      "Average value_loss: 0.2700\n",
      "Replay buffer size: 3288\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.1624\n",
      "Average policy_loss: 0.8908\n",
      "Average value_loss: 0.2716\n",
      "Replay buffer size: 3366\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.1622\n",
      "Average policy_loss: 0.8816\n",
      "Average value_loss: 0.2806\n",
      "Replay buffer size: 3447\n",
      "Time taken: 38.5s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.1695\n",
      "Average policy_loss: 0.8914\n",
      "Average value_loss: 0.2781\n",
      "Replay buffer size: 3527\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.1704\n",
      "Average policy_loss: 0.8908\n",
      "Average value_loss: 0.2796\n",
      "Replay buffer size: 3611\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.1584\n",
      "Average policy_loss: 0.8876\n",
      "Average value_loss: 0.2708\n",
      "Replay buffer size: 3683\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.1619\n",
      "Average policy_loss: 0.8940\n",
      "Average value_loss: 0.2679\n",
      "Replay buffer size: 3761\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.1638\n",
      "Average policy_loss: 0.8948\n",
      "Average value_loss: 0.2690\n",
      "Replay buffer size: 3838\n",
      "Time taken: 40.5s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.1675\n",
      "Average policy_loss: 0.8992\n",
      "Average value_loss: 0.2682\n",
      "Replay buffer size: 3926\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.1653\n",
      "Average policy_loss: 0.8959\n",
      "Average value_loss: 0.2693\n",
      "Replay buffer size: 4011\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.1766\n",
      "Average policy_loss: 0.9055\n",
      "Average value_loss: 0.2711\n",
      "Replay buffer size: 4083\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.1565\n",
      "Average policy_loss: 0.8946\n",
      "Average value_loss: 0.2619\n",
      "Replay buffer size: 4157\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.1698\n",
      "Average policy_loss: 0.9031\n",
      "Average value_loss: 0.2667\n",
      "Replay buffer size: 4241\n",
      "Time taken: 43.9s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.1670\n",
      "Average policy_loss: 0.8961\n",
      "Average value_loss: 0.2708\n",
      "Replay buffer size: 4320\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.1724\n",
      "Average policy_loss: 0.8998\n",
      "Average value_loss: 0.2727\n",
      "Replay buffer size: 4411\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.1682\n",
      "Average policy_loss: 0.9017\n",
      "Average value_loss: 0.2664\n",
      "Replay buffer size: 4492\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.1772\n",
      "Average policy_loss: 0.9120\n",
      "Average value_loss: 0.2652\n",
      "Replay buffer size: 4584\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.1863\n",
      "Average policy_loss: 0.9126\n",
      "Average value_loss: 0.2737\n",
      "Replay buffer size: 4676\n",
      "Time taken: 43.0s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.1798\n",
      "Average policy_loss: 0.9101\n",
      "Average value_loss: 0.2697\n",
      "Replay buffer size: 4760\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.1756\n",
      "Average policy_loss: 0.9083\n",
      "Average value_loss: 0.2672\n",
      "Replay buffer size: 4838\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.1693\n",
      "Average policy_loss: 0.9103\n",
      "Average value_loss: 0.2590\n",
      "Replay buffer size: 4918\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.1664\n",
      "Average policy_loss: 0.9077\n",
      "Average value_loss: 0.2587\n",
      "Replay buffer size: 4994\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.1653\n",
      "Average policy_loss: 0.9055\n",
      "Average value_loss: 0.2597\n",
      "Replay buffer size: 5072\n",
      "Time taken: 40.5s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.1704\n",
      "Average policy_loss: 0.9141\n",
      "Average value_loss: 0.2563\n",
      "Replay buffer size: 5152\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.1686\n",
      "Average policy_loss: 0.9055\n",
      "Average value_loss: 0.2631\n",
      "Replay buffer size: 5233\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.1731\n",
      "Average policy_loss: 0.9118\n",
      "Average value_loss: 0.2613\n",
      "Replay buffer size: 5323\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.1654\n",
      "Average policy_loss: 0.9041\n",
      "Average value_loss: 0.2614\n",
      "Replay buffer size: 5395\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.1618\n",
      "Average policy_loss: 0.9031\n",
      "Average value_loss: 0.2587\n",
      "Replay buffer size: 5479\n",
      "Time taken: 41.0s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.1696\n",
      "Average policy_loss: 0.9070\n",
      "Average value_loss: 0.2627\n",
      "Replay buffer size: 5553\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.1660\n",
      "Average policy_loss: 0.9060\n",
      "Average value_loss: 0.2600\n",
      "Replay buffer size: 5629\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.1532\n",
      "Average policy_loss: 0.8967\n",
      "Average value_loss: 0.2565\n",
      "Replay buffer size: 5704\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.1628\n",
      "Average policy_loss: 0.9017\n",
      "Average value_loss: 0.2610\n",
      "Replay buffer size: 5776\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.1494\n",
      "Average policy_loss: 0.8940\n",
      "Average value_loss: 0.2554\n",
      "Replay buffer size: 5864\n",
      "Time taken: 41.9s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.1452\n",
      "Average policy_loss: 0.8892\n",
      "Average value_loss: 0.2560\n",
      "Replay buffer size: 5940\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.1497\n",
      "Average policy_loss: 0.8856\n",
      "Average value_loss: 0.2641\n",
      "Replay buffer size: 6028\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.1549\n",
      "Average policy_loss: 0.8920\n",
      "Average value_loss: 0.2628\n",
      "Replay buffer size: 6116\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.1519\n",
      "Average policy_loss: 0.8840\n",
      "Average value_loss: 0.2679\n",
      "Replay buffer size: 6195\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.1511\n",
      "Average policy_loss: 0.8885\n",
      "Average value_loss: 0.2626\n",
      "Replay buffer size: 6271\n",
      "Time taken: 42.0s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.1663\n",
      "Average policy_loss: 0.8954\n",
      "Average value_loss: 0.2709\n",
      "Replay buffer size: 6350\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.1427\n",
      "Average policy_loss: 0.8830\n",
      "Average value_loss: 0.2597\n",
      "Replay buffer size: 6432\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.1442\n",
      "Average policy_loss: 0.8854\n",
      "Average value_loss: 0.2588\n",
      "Replay buffer size: 6508\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.1405\n",
      "Average policy_loss: 0.8788\n",
      "Average value_loss: 0.2617\n",
      "Replay buffer size: 6586\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.1429\n",
      "Average policy_loss: 0.8843\n",
      "Average value_loss: 0.2585\n",
      "Replay buffer size: 6662\n",
      "Time taken: 42.5s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.1286\n",
      "Average policy_loss: 0.8663\n",
      "Average value_loss: 0.2623\n",
      "Replay buffer size: 6745\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.1397\n",
      "Average policy_loss: 0.8771\n",
      "Average value_loss: 0.2626\n",
      "Replay buffer size: 6829\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.1359\n",
      "Average policy_loss: 0.8786\n",
      "Average value_loss: 0.2573\n",
      "Replay buffer size: 6917\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.1398\n",
      "Average policy_loss: 0.8755\n",
      "Average value_loss: 0.2643\n",
      "Replay buffer size: 7001\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.1271\n",
      "Average policy_loss: 0.8680\n",
      "Average value_loss: 0.2591\n",
      "Replay buffer size: 7088\n",
      "Time taken: 43.0s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.1434\n",
      "Average policy_loss: 0.8790\n",
      "Average value_loss: 0.2644\n",
      "Replay buffer size: 7169\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.1459\n",
      "Average policy_loss: 0.8779\n",
      "Average value_loss: 0.2680\n",
      "Replay buffer size: 7256\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.1338\n",
      "Average policy_loss: 0.8622\n",
      "Average value_loss: 0.2716\n",
      "Replay buffer size: 7343\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.1439\n",
      "Average policy_loss: 0.8744\n",
      "Average value_loss: 0.2695\n",
      "Replay buffer size: 7431\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.1342\n",
      "Average policy_loss: 0.8626\n",
      "Average value_loss: 0.2716\n",
      "Replay buffer size: 7523\n",
      "Time taken: 42.6s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.1296\n",
      "Average policy_loss: 0.8624\n",
      "Average value_loss: 0.2672\n",
      "Replay buffer size: 7613\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.1309\n",
      "Average policy_loss: 0.8609\n",
      "Average value_loss: 0.2701\n",
      "Replay buffer size: 7710\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.1221\n",
      "Average policy_loss: 0.8541\n",
      "Average value_loss: 0.2680\n",
      "Replay buffer size: 7802\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.1261\n",
      "Average policy_loss: 0.8565\n",
      "Average value_loss: 0.2696\n",
      "Replay buffer size: 7891\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.1244\n",
      "Average policy_loss: 0.8542\n",
      "Average value_loss: 0.2703\n",
      "Replay buffer size: 7983\n",
      "Time taken: 45.2s\n",
      "\n",
      "Training complete! Total time: 0.5h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>iteration_time</td><td>▁▁▄▁▁▁▁▁▁▁▂▆▂▂▂▂▂▂▇▂▇▂▂▂█▂▂▂▂▂▇▂▂▇▂▂▂▂██</td></tr><tr><td>loss</td><td>█▆▅▅▅▅▅▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▅▃▁▂▅▄▇▅▅▄▂▅▄▅▃▃▁▁▄▂▇▂▃▄▆▅▂▃▃▂▇▇▄▅▇▅▇▇▇█</td></tr><tr><td>policy_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>value_loss</td><td>██████████▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.1</td></tr><tr><td>buffer_size</td><td>7983</td></tr><tr><td>iteration_time</td><td>45.17246</td></tr><tr><td>loss</td><td>1.12444</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>92</td></tr><tr><td>policy_loss</td><td>0.85419</td></tr><tr><td>total_time_hours</td><td>0.45503</td></tr><tr><td>value_loss</td><td>0.27025</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">honest-sweep-24</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/73dqea8j' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/73dqea8j</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 24 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_121554-73dqea8j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 26e7scze with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.029235095700522375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: medium\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.9913142554881128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.003936729881848898\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_124320-26e7scze</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/26e7scze' target=\"_blank\">mild-sweep-25</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/26e7scze' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/26e7scze</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 0.6400\n",
      "Average policy_loss: 0.3219\n",
      "Average value_loss: 0.3181\n",
      "Replay buffer size: 96\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 0.3296\n",
      "Average policy_loss: 0.2741\n",
      "Average value_loss: 0.0555\n",
      "Replay buffer size: 193\n",
      "Time taken: 8.8s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 0.5481\n",
      "Average policy_loss: 0.4491\n",
      "Average value_loss: 0.0990\n",
      "Replay buffer size: 282\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.6115\n",
      "Average policy_loss: 0.5261\n",
      "Average value_loss: 0.0854\n",
      "Replay buffer size: 376\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.7651\n",
      "Average policy_loss: 0.6510\n",
      "Average value_loss: 0.1141\n",
      "Replay buffer size: 464\n",
      "Time taken: 59.0s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.8148\n",
      "Average policy_loss: 0.7093\n",
      "Average value_loss: 0.1055\n",
      "Replay buffer size: 562\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.8842\n",
      "Average policy_loss: 0.7730\n",
      "Average value_loss: 0.1112\n",
      "Replay buffer size: 644\n",
      "Time taken: 19.3s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.9176\n",
      "Average policy_loss: 0.8046\n",
      "Average value_loss: 0.1130\n",
      "Replay buffer size: 731\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.9593\n",
      "Average policy_loss: 0.8485\n",
      "Average value_loss: 0.1107\n",
      "Replay buffer size: 822\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 40.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.9887\n",
      "Average policy_loss: 0.8757\n",
      "Average value_loss: 0.1130\n",
      "Replay buffer size: 908\n",
      "Time taken: 60.9s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.0081\n",
      "Average policy_loss: 0.8965\n",
      "Average value_loss: 0.1117\n",
      "Replay buffer size: 991\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.0376\n",
      "Average policy_loss: 0.9275\n",
      "Average value_loss: 0.1101\n",
      "Replay buffer size: 1083\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.0511\n",
      "Average policy_loss: 0.9423\n",
      "Average value_loss: 0.1088\n",
      "Replay buffer size: 1166\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.0781\n",
      "Average policy_loss: 0.9680\n",
      "Average value_loss: 0.1100\n",
      "Replay buffer size: 1243\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.0955\n",
      "Average policy_loss: 0.9872\n",
      "Average value_loss: 0.1082\n",
      "Replay buffer size: 1332\n",
      "Time taken: 63.0s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.0974\n",
      "Average policy_loss: 0.9839\n",
      "Average value_loss: 0.1134\n",
      "Replay buffer size: 1417\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.1170\n",
      "Average policy_loss: 1.0070\n",
      "Average value_loss: 0.1100\n",
      "Replay buffer size: 1506\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.1243\n",
      "Average policy_loss: 1.0169\n",
      "Average value_loss: 0.1074\n",
      "Replay buffer size: 1597\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.1087\n",
      "Average policy_loss: 0.9988\n",
      "Average value_loss: 0.1100\n",
      "Replay buffer size: 1683\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.1171\n",
      "Average policy_loss: 1.0095\n",
      "Average value_loss: 0.1077\n",
      "Replay buffer size: 1770\n",
      "Time taken: 62.5s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.1234\n",
      "Average policy_loss: 1.0126\n",
      "Average value_loss: 0.1108\n",
      "Replay buffer size: 1860\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.1360\n",
      "Average policy_loss: 1.0140\n",
      "Average value_loss: 0.1220\n",
      "Replay buffer size: 1936\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.1424\n",
      "Average policy_loss: 1.0280\n",
      "Average value_loss: 0.1144\n",
      "Replay buffer size: 2014\n",
      "Time taken: 19.1s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.1406\n",
      "Average policy_loss: 1.0218\n",
      "Average value_loss: 0.1188\n",
      "Replay buffer size: 2100\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.1453\n",
      "Average policy_loss: 1.0264\n",
      "Average value_loss: 0.1189\n",
      "Replay buffer size: 2180\n",
      "Time taken: 63.9s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.1540\n",
      "Average policy_loss: 1.0295\n",
      "Average value_loss: 0.1244\n",
      "Replay buffer size: 2265\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.1680\n",
      "Average policy_loss: 1.0479\n",
      "Average value_loss: 0.1200\n",
      "Replay buffer size: 2343\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.1589\n",
      "Average policy_loss: 1.0336\n",
      "Average value_loss: 0.1253\n",
      "Replay buffer size: 2434\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.1652\n",
      "Average policy_loss: 1.0353\n",
      "Average value_loss: 0.1299\n",
      "Replay buffer size: 2512\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.1683\n",
      "Average policy_loss: 1.0425\n",
      "Average value_loss: 0.1259\n",
      "Replay buffer size: 2605\n",
      "Time taken: 69.1s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.1675\n",
      "Average policy_loss: 1.0388\n",
      "Average value_loss: 0.1287\n",
      "Replay buffer size: 2689\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.1767\n",
      "Average policy_loss: 1.0458\n",
      "Average value_loss: 0.1309\n",
      "Replay buffer size: 2762\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.1773\n",
      "Average policy_loss: 1.0467\n",
      "Average value_loss: 0.1307\n",
      "Replay buffer size: 2852\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.1814\n",
      "Average policy_loss: 1.0463\n",
      "Average value_loss: 0.1352\n",
      "Replay buffer size: 2927\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.1887\n",
      "Average policy_loss: 1.0539\n",
      "Average value_loss: 0.1348\n",
      "Replay buffer size: 3001\n",
      "Time taken: 62.9s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.1959\n",
      "Average policy_loss: 1.0606\n",
      "Average value_loss: 0.1353\n",
      "Replay buffer size: 3083\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.1873\n",
      "Average policy_loss: 1.0538\n",
      "Average value_loss: 0.1335\n",
      "Replay buffer size: 3160\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.2029\n",
      "Average policy_loss: 1.0684\n",
      "Average value_loss: 0.1345\n",
      "Replay buffer size: 3254\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.2104\n",
      "Average policy_loss: 1.0776\n",
      "Average value_loss: 0.1328\n",
      "Replay buffer size: 3340\n",
      "Time taken: 19.2s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.2007\n",
      "Average policy_loss: 1.0572\n",
      "Average value_loss: 0.1435\n",
      "Replay buffer size: 3426\n",
      "Time taken: 65.2s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.1898\n",
      "Average policy_loss: 1.0526\n",
      "Average value_loss: 0.1372\n",
      "Replay buffer size: 3507\n",
      "Time taken: 19.2s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.1812\n",
      "Average policy_loss: 1.0466\n",
      "Average value_loss: 0.1346\n",
      "Replay buffer size: 3584\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.1869\n",
      "Average policy_loss: 1.0518\n",
      "Average value_loss: 0.1351\n",
      "Replay buffer size: 3673\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.1986\n",
      "Average policy_loss: 1.0640\n",
      "Average value_loss: 0.1346\n",
      "Replay buffer size: 3767\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.1916\n",
      "Average policy_loss: 1.0544\n",
      "Average value_loss: 0.1372\n",
      "Replay buffer size: 3844\n",
      "Time taken: 60.8s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.1732\n",
      "Average policy_loss: 1.0320\n",
      "Average value_loss: 0.1413\n",
      "Replay buffer size: 3928\n",
      "Time taken: 19.1s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.2076\n",
      "Average policy_loss: 1.0615\n",
      "Average value_loss: 0.1461\n",
      "Replay buffer size: 4019\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.1881\n",
      "Average policy_loss: 1.0533\n",
      "Average value_loss: 0.1348\n",
      "Replay buffer size: 4105\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.1894\n",
      "Average policy_loss: 1.0452\n",
      "Average value_loss: 0.1442\n",
      "Replay buffer size: 4198\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.1812\n",
      "Average policy_loss: 1.0434\n",
      "Average value_loss: 0.1378\n",
      "Replay buffer size: 4295\n",
      "Time taken: 60.7s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.1822\n",
      "Average policy_loss: 1.0498\n",
      "Average value_loss: 0.1324\n",
      "Replay buffer size: 4377\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.1786\n",
      "Average policy_loss: 1.0384\n",
      "Average value_loss: 0.1402\n",
      "Replay buffer size: 4470\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.1858\n",
      "Average policy_loss: 1.0483\n",
      "Average value_loss: 0.1375\n",
      "Replay buffer size: 4563\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.1886\n",
      "Average policy_loss: 1.0525\n",
      "Average value_loss: 0.1360\n",
      "Replay buffer size: 4656\n",
      "Time taken: 22.4s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.1779\n",
      "Average policy_loss: 1.0450\n",
      "Average value_loss: 0.1329\n",
      "Replay buffer size: 4747\n",
      "Time taken: 65.6s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.1745\n",
      "Average policy_loss: 1.0354\n",
      "Average value_loss: 0.1391\n",
      "Replay buffer size: 4832\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.1618\n",
      "Average policy_loss: 1.0314\n",
      "Average value_loss: 0.1304\n",
      "Replay buffer size: 4924\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.1783\n",
      "Average policy_loss: 1.0432\n",
      "Average value_loss: 0.1351\n",
      "Replay buffer size: 5013\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.1677\n",
      "Average policy_loss: 1.0365\n",
      "Average value_loss: 0.1311\n",
      "Replay buffer size: 5099\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.1733\n",
      "Average policy_loss: 1.0402\n",
      "Average value_loss: 0.1331\n",
      "Replay buffer size: 5187\n",
      "Time taken: 63.5s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.1672\n",
      "Average policy_loss: 1.0333\n",
      "Average value_loss: 0.1339\n",
      "Replay buffer size: 5269\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.1600\n",
      "Average policy_loss: 1.0262\n",
      "Average value_loss: 0.1337\n",
      "Replay buffer size: 5357\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.1740\n",
      "Average policy_loss: 1.0398\n",
      "Average value_loss: 0.1342\n",
      "Replay buffer size: 5444\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.1737\n",
      "Average policy_loss: 1.0388\n",
      "Average value_loss: 0.1349\n",
      "Replay buffer size: 5530\n",
      "Time taken: 22.1s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.1674\n",
      "Average policy_loss: 1.0375\n",
      "Average value_loss: 0.1300\n",
      "Replay buffer size: 5618\n",
      "Time taken: 64.8s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.1580\n",
      "Average policy_loss: 1.0244\n",
      "Average value_loss: 0.1337\n",
      "Replay buffer size: 5712\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.1465\n",
      "Average policy_loss: 1.0137\n",
      "Average value_loss: 0.1327\n",
      "Replay buffer size: 5794\n",
      "Time taken: 19.3s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.1570\n",
      "Average policy_loss: 1.0299\n",
      "Average value_loss: 0.1270\n",
      "Replay buffer size: 5882\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.1697\n",
      "Average policy_loss: 1.0380\n",
      "Average value_loss: 0.1318\n",
      "Replay buffer size: 5963\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.1789\n",
      "Average policy_loss: 1.0451\n",
      "Average value_loss: 0.1338\n",
      "Replay buffer size: 6049\n",
      "Time taken: 64.3s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.1597\n",
      "Average policy_loss: 1.0264\n",
      "Average value_loss: 0.1333\n",
      "Replay buffer size: 6141\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.1607\n",
      "Average policy_loss: 1.0276\n",
      "Average value_loss: 0.1331\n",
      "Replay buffer size: 6228\n",
      "Time taken: 19.1s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.1452\n",
      "Average policy_loss: 1.0156\n",
      "Average value_loss: 0.1296\n",
      "Replay buffer size: 6314\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.1500\n",
      "Average policy_loss: 1.0214\n",
      "Average value_loss: 0.1286\n",
      "Replay buffer size: 6390\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.1582\n",
      "Average policy_loss: 1.0246\n",
      "Average value_loss: 0.1336\n",
      "Replay buffer size: 6475\n",
      "Time taken: 63.3s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.1530\n",
      "Average policy_loss: 1.0192\n",
      "Average value_loss: 0.1338\n",
      "Replay buffer size: 6564\n",
      "Time taken: 19.1s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.1599\n",
      "Average policy_loss: 1.0257\n",
      "Average value_loss: 0.1342\n",
      "Replay buffer size: 6652\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.1690\n",
      "Average policy_loss: 1.0342\n",
      "Average value_loss: 0.1348\n",
      "Replay buffer size: 6738\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.1539\n",
      "Average policy_loss: 1.0272\n",
      "Average value_loss: 0.1267\n",
      "Replay buffer size: 6826\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.1461\n",
      "Average policy_loss: 1.0147\n",
      "Average value_loss: 0.1314\n",
      "Replay buffer size: 6911\n",
      "Time taken: 65.2s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.1478\n",
      "Average policy_loss: 1.0153\n",
      "Average value_loss: 0.1325\n",
      "Replay buffer size: 7002\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.1587\n",
      "Average policy_loss: 1.0253\n",
      "Average value_loss: 0.1334\n",
      "Replay buffer size: 7087\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.1625\n",
      "Average policy_loss: 1.0268\n",
      "Average value_loss: 0.1356\n",
      "Replay buffer size: 7168\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.1625\n",
      "Average policy_loss: 1.0281\n",
      "Average value_loss: 0.1344\n",
      "Replay buffer size: 7254\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.1398\n",
      "Average policy_loss: 1.0089\n",
      "Average value_loss: 0.1309\n",
      "Replay buffer size: 7346\n",
      "Time taken: 66.3s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.1507\n",
      "Average policy_loss: 1.0238\n",
      "Average value_loss: 0.1269\n",
      "Replay buffer size: 7442\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.1418\n",
      "Average policy_loss: 1.0086\n",
      "Average value_loss: 0.1332\n",
      "Replay buffer size: 7536\n",
      "Time taken: 22.4s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.1336\n",
      "Average policy_loss: 1.0039\n",
      "Average value_loss: 0.1296\n",
      "Replay buffer size: 7622\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.1288\n",
      "Average policy_loss: 1.0032\n",
      "Average value_loss: 0.1256\n",
      "Replay buffer size: 7716\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.1461\n",
      "Average policy_loss: 1.0143\n",
      "Average value_loss: 0.1317\n",
      "Replay buffer size: 7804\n",
      "Time taken: 65.3s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.1483\n",
      "Average policy_loss: 1.0178\n",
      "Average value_loss: 0.1304\n",
      "Replay buffer size: 7887\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.1221\n",
      "Average policy_loss: 0.9970\n",
      "Average value_loss: 0.1251\n",
      "Replay buffer size: 7975\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.1409\n",
      "Average policy_loss: 1.0131\n",
      "Average value_loss: 0.1278\n",
      "Replay buffer size: 8070\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.1291\n",
      "Average policy_loss: 0.9996\n",
      "Average value_loss: 0.1296\n",
      "Replay buffer size: 8168\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.1375\n",
      "Average policy_loss: 1.0086\n",
      "Average value_loss: 0.1289\n",
      "Replay buffer size: 8257\n",
      "Time taken: 69.3s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.1454\n",
      "Average policy_loss: 1.0112\n",
      "Average value_loss: 0.1342\n",
      "Replay buffer size: 8342\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.1372\n",
      "Average policy_loss: 1.0077\n",
      "Average value_loss: 0.1295\n",
      "Replay buffer size: 8430\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.1321\n",
      "Average policy_loss: 1.0036\n",
      "Average value_loss: 0.1285\n",
      "Replay buffer size: 8516\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.1300\n",
      "Average policy_loss: 1.0056\n",
      "Average value_loss: 0.1243\n",
      "Replay buffer size: 8604\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.1310\n",
      "Average policy_loss: 1.0041\n",
      "Average value_loss: 0.1269\n",
      "Replay buffer size: 8694\n",
      "Time taken: 68.0s\n",
      "\n",
      "Training complete! Total time: 0.8h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>iteration_time</td><td>▁▁▇▂▂▂▂█▃█▂█▂▂▂▂▃█▇▂█▂▃▂▂█▂▂▂██▃▂█▃▃▃▂▃▂</td></tr><tr><td>loss</td><td>▁▃▃▄▄▇▇▇▇▇▇▇▇▇████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▅▅▄▆▂▄▅▆▂▇▁▁▂▇▅▅▇▄▆▅▇▇▄▅▅▅▅▅▅▅▅▄▆▅▆▅▄▇█▆</td></tr><tr><td>policy_loss</td><td>▁▁▆▆▇▇▇▇█████████████████████████████▇▇▇</td></tr><tr><td>value_loss</td><td>█▁▂▂▃▃▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.3</td></tr><tr><td>buffer_size</td><td>8694</td></tr><tr><td>iteration_time</td><td>68.04538</td></tr><tr><td>loss</td><td>1.13098</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>90</td></tr><tr><td>policy_loss</td><td>1.00409</td></tr><tr><td>total_time_hours</td><td>0.8042</td></tr><tr><td>value_loss</td><td>0.12689</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mild-sweep-25</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/26e7scze' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/26e7scze</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_124320-26e7scze/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ayk0zy83 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.047491153348280475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: medium\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.9863737655778184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0002199847613275889\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_133141-ayk0zy83</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ayk0zy83' target=\"_blank\">quiet-sweep-26</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ayk0zy83' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ayk0zy83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.8021\n",
      "Average policy_loss: 1.3621\n",
      "Average value_loss: 0.4400\n",
      "Replay buffer size: 76\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 0.9213\n",
      "Average policy_loss: 0.8083\n",
      "Average value_loss: 0.1130\n",
      "Replay buffer size: 156\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 0.7974\n",
      "Average policy_loss: 0.6849\n",
      "Average value_loss: 0.1125\n",
      "Replay buffer size: 249\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.8301\n",
      "Average policy_loss: 0.7173\n",
      "Average value_loss: 0.1128\n",
      "Replay buffer size: 336\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.8272\n",
      "Average policy_loss: 0.7187\n",
      "Average value_loss: 0.1085\n",
      "Replay buffer size: 427\n",
      "Time taken: 43.1s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.8012\n",
      "Average policy_loss: 0.6984\n",
      "Average value_loss: 0.1027\n",
      "Replay buffer size: 519\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.7781\n",
      "Average policy_loss: 0.6851\n",
      "Average value_loss: 0.0930\n",
      "Replay buffer size: 611\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.7596\n",
      "Average policy_loss: 0.6736\n",
      "Average value_loss: 0.0860\n",
      "Replay buffer size: 707\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.7475\n",
      "Average policy_loss: 0.6651\n",
      "Average value_loss: 0.0824\n",
      "Replay buffer size: 797\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.7598\n",
      "Average policy_loss: 0.6743\n",
      "Average value_loss: 0.0856\n",
      "Replay buffer size: 890\n",
      "Time taken: 40.6s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.7602\n",
      "Average policy_loss: 0.6760\n",
      "Average value_loss: 0.0842\n",
      "Replay buffer size: 981\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.7403\n",
      "Average policy_loss: 0.6606\n",
      "Average value_loss: 0.0797\n",
      "Replay buffer size: 1076\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.7311\n",
      "Average policy_loss: 0.6515\n",
      "Average value_loss: 0.0796\n",
      "Replay buffer size: 1170\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.7313\n",
      "Average policy_loss: 0.6545\n",
      "Average value_loss: 0.0768\n",
      "Replay buffer size: 1262\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.7312\n",
      "Average policy_loss: 0.6552\n",
      "Average value_loss: 0.0760\n",
      "Replay buffer size: 1355\n",
      "Time taken: 43.8s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.7359\n",
      "Average policy_loss: 0.6615\n",
      "Average value_loss: 0.0744\n",
      "Replay buffer size: 1452\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.7214\n",
      "Average policy_loss: 0.6473\n",
      "Average value_loss: 0.0741\n",
      "Replay buffer size: 1549\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.7242\n",
      "Average policy_loss: 0.6511\n",
      "Average value_loss: 0.0731\n",
      "Replay buffer size: 1640\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.7209\n",
      "Average policy_loss: 0.6499\n",
      "Average value_loss: 0.0710\n",
      "Replay buffer size: 1731\n",
      "Time taken: 11.2s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.7246\n",
      "Average policy_loss: 0.6480\n",
      "Average value_loss: 0.0766\n",
      "Replay buffer size: 1821\n",
      "Time taken: 42.9s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.7266\n",
      "Average policy_loss: 0.6545\n",
      "Average value_loss: 0.0722\n",
      "Replay buffer size: 1908\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.7148\n",
      "Average policy_loss: 0.6438\n",
      "Average value_loss: 0.0711\n",
      "Replay buffer size: 2006\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.7173\n",
      "Average policy_loss: 0.6492\n",
      "Average value_loss: 0.0682\n",
      "Replay buffer size: 2106\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.7275\n",
      "Average policy_loss: 0.6569\n",
      "Average value_loss: 0.0706\n",
      "Replay buffer size: 2199\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.7291\n",
      "Average policy_loss: 0.6601\n",
      "Average value_loss: 0.0691\n",
      "Replay buffer size: 2289\n",
      "Time taken: 44.3s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.7333\n",
      "Average policy_loss: 0.6639\n",
      "Average value_loss: 0.0695\n",
      "Replay buffer size: 2378\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.7230\n",
      "Average policy_loss: 0.6564\n",
      "Average value_loss: 0.0666\n",
      "Replay buffer size: 2478\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.7213\n",
      "Average policy_loss: 0.6558\n",
      "Average value_loss: 0.0654\n",
      "Replay buffer size: 2574\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.7321\n",
      "Average policy_loss: 0.6646\n",
      "Average value_loss: 0.0674\n",
      "Replay buffer size: 2666\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.7246\n",
      "Average policy_loss: 0.6573\n",
      "Average value_loss: 0.0673\n",
      "Replay buffer size: 2760\n",
      "Time taken: 43.1s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.7306\n",
      "Average policy_loss: 0.6615\n",
      "Average value_loss: 0.0691\n",
      "Replay buffer size: 2846\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.7310\n",
      "Average policy_loss: 0.6654\n",
      "Average value_loss: 0.0656\n",
      "Replay buffer size: 2938\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.7221\n",
      "Average policy_loss: 0.6575\n",
      "Average value_loss: 0.0646\n",
      "Replay buffer size: 3032\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.7189\n",
      "Average policy_loss: 0.6573\n",
      "Average value_loss: 0.0617\n",
      "Replay buffer size: 3132\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.7252\n",
      "Average policy_loss: 0.6618\n",
      "Average value_loss: 0.0634\n",
      "Replay buffer size: 3221\n",
      "Time taken: 43.4s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.7334\n",
      "Average policy_loss: 0.6651\n",
      "Average value_loss: 0.0683\n",
      "Replay buffer size: 3310\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.7383\n",
      "Average policy_loss: 0.6702\n",
      "Average value_loss: 0.0682\n",
      "Replay buffer size: 3404\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.7398\n",
      "Average policy_loss: 0.6738\n",
      "Average value_loss: 0.0659\n",
      "Replay buffer size: 3487\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.7470\n",
      "Average policy_loss: 0.6771\n",
      "Average value_loss: 0.0699\n",
      "Replay buffer size: 3576\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.7469\n",
      "Average policy_loss: 0.6795\n",
      "Average value_loss: 0.0673\n",
      "Replay buffer size: 3670\n",
      "Time taken: 44.6s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.7450\n",
      "Average policy_loss: 0.6785\n",
      "Average value_loss: 0.0666\n",
      "Replay buffer size: 3766\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.7432\n",
      "Average policy_loss: 0.6773\n",
      "Average value_loss: 0.0659\n",
      "Replay buffer size: 3855\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.7416\n",
      "Average policy_loss: 0.6745\n",
      "Average value_loss: 0.0671\n",
      "Replay buffer size: 3948\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.7456\n",
      "Average policy_loss: 0.6779\n",
      "Average value_loss: 0.0677\n",
      "Replay buffer size: 4038\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.7512\n",
      "Average policy_loss: 0.6846\n",
      "Average value_loss: 0.0666\n",
      "Replay buffer size: 4129\n",
      "Time taken: 44.0s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.7492\n",
      "Average policy_loss: 0.6821\n",
      "Average value_loss: 0.0671\n",
      "Replay buffer size: 4216\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.7513\n",
      "Average policy_loss: 0.6851\n",
      "Average value_loss: 0.0662\n",
      "Replay buffer size: 4311\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.7567\n",
      "Average policy_loss: 0.6887\n",
      "Average value_loss: 0.0680\n",
      "Replay buffer size: 4397\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.7521\n",
      "Average policy_loss: 0.6834\n",
      "Average value_loss: 0.0686\n",
      "Replay buffer size: 4495\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.7434\n",
      "Average policy_loss: 0.6794\n",
      "Average value_loss: 0.0640\n",
      "Replay buffer size: 4587\n",
      "Time taken: 44.0s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.7492\n",
      "Average policy_loss: 0.6839\n",
      "Average value_loss: 0.0653\n",
      "Replay buffer size: 4676\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.7571\n",
      "Average policy_loss: 0.6890\n",
      "Average value_loss: 0.0680\n",
      "Replay buffer size: 4758\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.7512\n",
      "Average policy_loss: 0.6819\n",
      "Average value_loss: 0.0693\n",
      "Replay buffer size: 4850\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.7546\n",
      "Average policy_loss: 0.6873\n",
      "Average value_loss: 0.0673\n",
      "Replay buffer size: 4944\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.7553\n",
      "Average policy_loss: 0.6897\n",
      "Average value_loss: 0.0657\n",
      "Replay buffer size: 5036\n",
      "Time taken: 44.4s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.7558\n",
      "Average policy_loss: 0.6871\n",
      "Average value_loss: 0.0686\n",
      "Replay buffer size: 5127\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.7526\n",
      "Average policy_loss: 0.6853\n",
      "Average value_loss: 0.0673\n",
      "Replay buffer size: 5213\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.7517\n",
      "Average policy_loss: 0.6852\n",
      "Average value_loss: 0.0665\n",
      "Replay buffer size: 5305\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.7519\n",
      "Average policy_loss: 0.6848\n",
      "Average value_loss: 0.0670\n",
      "Replay buffer size: 5398\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.7550\n",
      "Average policy_loss: 0.6849\n",
      "Average value_loss: 0.0701\n",
      "Replay buffer size: 5487\n",
      "Time taken: 45.6s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.7526\n",
      "Average policy_loss: 0.6843\n",
      "Average value_loss: 0.0683\n",
      "Replay buffer size: 5577\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.7607\n",
      "Average policy_loss: 0.6920\n",
      "Average value_loss: 0.0687\n",
      "Replay buffer size: 5670\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.7611\n",
      "Average policy_loss: 0.6910\n",
      "Average value_loss: 0.0701\n",
      "Replay buffer size: 5762\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.7643\n",
      "Average policy_loss: 0.6946\n",
      "Average value_loss: 0.0696\n",
      "Replay buffer size: 5847\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.7634\n",
      "Average policy_loss: 0.6926\n",
      "Average value_loss: 0.0708\n",
      "Replay buffer size: 5939\n",
      "Time taken: 47.2s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.7609\n",
      "Average policy_loss: 0.6911\n",
      "Average value_loss: 0.0698\n",
      "Replay buffer size: 6029\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.7666\n",
      "Average policy_loss: 0.6963\n",
      "Average value_loss: 0.0703\n",
      "Replay buffer size: 6123\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.7674\n",
      "Average policy_loss: 0.6984\n",
      "Average value_loss: 0.0690\n",
      "Replay buffer size: 6215\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.7705\n",
      "Average policy_loss: 0.7010\n",
      "Average value_loss: 0.0695\n",
      "Replay buffer size: 6307\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.7706\n",
      "Average policy_loss: 0.7001\n",
      "Average value_loss: 0.0705\n",
      "Replay buffer size: 6391\n",
      "Time taken: 44.2s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.7797\n",
      "Average policy_loss: 0.7105\n",
      "Average value_loss: 0.0692\n",
      "Replay buffer size: 6484\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.7750\n",
      "Average policy_loss: 0.7033\n",
      "Average value_loss: 0.0716\n",
      "Replay buffer size: 6577\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.7783\n",
      "Average policy_loss: 0.7083\n",
      "Average value_loss: 0.0700\n",
      "Replay buffer size: 6674\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.7731\n",
      "Average policy_loss: 0.7038\n",
      "Average value_loss: 0.0693\n",
      "Replay buffer size: 6767\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.7735\n",
      "Average policy_loss: 0.7048\n",
      "Average value_loss: 0.0686\n",
      "Replay buffer size: 6860\n",
      "Time taken: 47.8s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.7864\n",
      "Average policy_loss: 0.7132\n",
      "Average value_loss: 0.0732\n",
      "Replay buffer size: 6943\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.7811\n",
      "Average policy_loss: 0.7104\n",
      "Average value_loss: 0.0707\n",
      "Replay buffer size: 7039\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.7767\n",
      "Average policy_loss: 0.7053\n",
      "Average value_loss: 0.0714\n",
      "Replay buffer size: 7131\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.7753\n",
      "Average policy_loss: 0.7059\n",
      "Average value_loss: 0.0694\n",
      "Replay buffer size: 7226\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.7769\n",
      "Average policy_loss: 0.7067\n",
      "Average value_loss: 0.0702\n",
      "Replay buffer size: 7326\n",
      "Time taken: 47.5s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.7763\n",
      "Average policy_loss: 0.7069\n",
      "Average value_loss: 0.0694\n",
      "Replay buffer size: 7422\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.7828\n",
      "Average policy_loss: 0.7124\n",
      "Average value_loss: 0.0704\n",
      "Replay buffer size: 7511\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.7768\n",
      "Average policy_loss: 0.7087\n",
      "Average value_loss: 0.0681\n",
      "Replay buffer size: 7603\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.7769\n",
      "Average policy_loss: 0.7079\n",
      "Average value_loss: 0.0690\n",
      "Replay buffer size: 7700\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.7796\n",
      "Average policy_loss: 0.7084\n",
      "Average value_loss: 0.0712\n",
      "Replay buffer size: 7795\n",
      "Time taken: 47.8s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.7883\n",
      "Average policy_loss: 0.7168\n",
      "Average value_loss: 0.0715\n",
      "Replay buffer size: 7893\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.7827\n",
      "Average policy_loss: 0.7133\n",
      "Average value_loss: 0.0694\n",
      "Replay buffer size: 7986\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.7850\n",
      "Average policy_loss: 0.7154\n",
      "Average value_loss: 0.0696\n",
      "Replay buffer size: 8082\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.7890\n",
      "Average policy_loss: 0.7190\n",
      "Average value_loss: 0.0700\n",
      "Replay buffer size: 8176\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.7887\n",
      "Average policy_loss: 0.7185\n",
      "Average value_loss: 0.0702\n",
      "Replay buffer size: 8259\n",
      "Time taken: 50.3s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.7924\n",
      "Average policy_loss: 0.7214\n",
      "Average value_loss: 0.0711\n",
      "Replay buffer size: 8352\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.7915\n",
      "Average policy_loss: 0.7208\n",
      "Average value_loss: 0.0707\n",
      "Replay buffer size: 8436\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.7916\n",
      "Average policy_loss: 0.7195\n",
      "Average value_loss: 0.0722\n",
      "Replay buffer size: 8531\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.7932\n",
      "Average policy_loss: 0.7220\n",
      "Average value_loss: 0.0712\n",
      "Replay buffer size: 8622\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.8018\n",
      "Average policy_loss: 0.7303\n",
      "Average value_loss: 0.0715\n",
      "Replay buffer size: 8707\n",
      "Time taken: 48.2s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.8027\n",
      "Average policy_loss: 0.7277\n",
      "Average value_loss: 0.0749\n",
      "Replay buffer size: 8796\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.7944\n",
      "Average policy_loss: 0.7213\n",
      "Average value_loss: 0.0731\n",
      "Replay buffer size: 8886\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.8035\n",
      "Average policy_loss: 0.7304\n",
      "Average value_loss: 0.0731\n",
      "Replay buffer size: 8974\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.7971\n",
      "Average policy_loss: 0.7269\n",
      "Average value_loss: 0.0702\n",
      "Replay buffer size: 9067\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.8001\n",
      "Average policy_loss: 0.7287\n",
      "Average value_loss: 0.0714\n",
      "Replay buffer size: 9158\n",
      "Time taken: 46.8s\n",
      "\n",
      "Training complete! Total time: 0.6h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iteration_time</td><td>▁▂▂▂▂▇▂▂▇▂▂▇▂▂▂▂▂▂▇▂▂▂▂▂▇▂▂▂▂▂██▂▂▂█▂▂▂█</td></tr><tr><td>loss</td><td>▆█▆▄▂▁▁▁▁▂▁▂▁▂▂▁▂▃▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▁▅▅▇▅▆▅▅█▄▆▃▄▂▄▄▅▅▆▅▄▅▆▅▅▅▅▂▆▆▇▅▇▅▇▆▇▆▆▆</td></tr><tr><td>policy_loss</td><td>▆▄▂▂▂▂▂▁▂▁▂▂▃▂▃▄▄▄▄▄▄▄▄▄▄▅▅▅▆▇▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>value_loss</td><td>▇█▆▅▄▃▄▃▂▃▁▂▂▂▂▂▃▁▁▂▃▂▂▂▃▃▃▃▃▄▃▄▃▃▃▃▃▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.05</td></tr><tr><td>buffer_size</td><td>9158</td></tr><tr><td>iteration_time</td><td>46.8017</td></tr><tr><td>loss</td><td>0.8001</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>91</td></tr><tr><td>policy_loss</td><td>0.72872</td></tr><tr><td>total_time_hours</td><td>0.56217</td></tr><tr><td>value_loss</td><td>0.07138</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">quiet-sweep-26</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ayk0zy83' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ayk0zy83</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 16 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_133141-ayk0zy83/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8qwv1rqb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0020321793649479615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: medium\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.4303273080956088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 3.63682262421725e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_140531-8qwv1rqb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/8qwv1rqb' target=\"_blank\">warm-sweep-27</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/8qwv1rqb' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/8qwv1rqb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 2.6525\n",
      "Average policy_loss: 1.9260\n",
      "Average value_loss: 0.7265\n",
      "Replay buffer size: 79\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.8049\n",
      "Average policy_loss: 1.3595\n",
      "Average value_loss: 0.4455\n",
      "Replay buffer size: 169\n",
      "Time taken: 10.7s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.5119\n",
      "Average policy_loss: 1.1763\n",
      "Average value_loss: 0.3357\n",
      "Replay buffer size: 247\n",
      "Time taken: 8.8s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.3536\n",
      "Average policy_loss: 1.0821\n",
      "Average value_loss: 0.2715\n",
      "Replay buffer size: 321\n",
      "Time taken: 8.7s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.2294\n",
      "Average policy_loss: 0.9828\n",
      "Average value_loss: 0.2466\n",
      "Replay buffer size: 407\n",
      "Time taken: 29.8s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.1680\n",
      "Average policy_loss: 0.9358\n",
      "Average value_loss: 0.2322\n",
      "Replay buffer size: 479\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.1040\n",
      "Average policy_loss: 0.9010\n",
      "Average value_loss: 0.2030\n",
      "Replay buffer size: 555\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.0561\n",
      "Average policy_loss: 0.8668\n",
      "Average value_loss: 0.1893\n",
      "Replay buffer size: 631\n",
      "Time taken: 7.9s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.0300\n",
      "Average policy_loss: 0.8500\n",
      "Average value_loss: 0.1801\n",
      "Replay buffer size: 701\n",
      "Time taken: 7.2s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.0021\n",
      "Average policy_loss: 0.8212\n",
      "Average value_loss: 0.1809\n",
      "Replay buffer size: 775\n",
      "Time taken: 27.0s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.9714\n",
      "Average policy_loss: 0.8046\n",
      "Average value_loss: 0.1668\n",
      "Replay buffer size: 851\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.9585\n",
      "Average policy_loss: 0.7943\n",
      "Average value_loss: 0.1642\n",
      "Replay buffer size: 933\n",
      "Time taken: 7.9s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.9468\n",
      "Average policy_loss: 0.7818\n",
      "Average value_loss: 0.1651\n",
      "Replay buffer size: 1017\n",
      "Time taken: 6.9s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.9200\n",
      "Average policy_loss: 0.7663\n",
      "Average value_loss: 0.1537\n",
      "Replay buffer size: 1081\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 67 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.9109\n",
      "Average policy_loss: 0.7568\n",
      "Average value_loss: 0.1541\n",
      "Replay buffer size: 1148\n",
      "Time taken: 24.1s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.8935\n",
      "Average policy_loss: 0.7385\n",
      "Average value_loss: 0.1550\n",
      "Replay buffer size: 1212\n",
      "Time taken: 6.7s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.8941\n",
      "Average policy_loss: 0.7414\n",
      "Average value_loss: 0.1528\n",
      "Replay buffer size: 1288\n",
      "Time taken: 7.1s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.8822\n",
      "Average policy_loss: 0.7347\n",
      "Average value_loss: 0.1475\n",
      "Replay buffer size: 1350\n",
      "Time taken: 6.7s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.8730\n",
      "Average policy_loss: 0.7328\n",
      "Average value_loss: 0.1402\n",
      "Replay buffer size: 1416\n",
      "Time taken: 6.7s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.8634\n",
      "Average policy_loss: 0.7233\n",
      "Average value_loss: 0.1401\n",
      "Replay buffer size: 1492\n",
      "Time taken: 23.2s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.8485\n",
      "Average policy_loss: 0.7082\n",
      "Average value_loss: 0.1403\n",
      "Replay buffer size: 1570\n",
      "Time taken: 7.2s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.8430\n",
      "Average policy_loss: 0.7081\n",
      "Average value_loss: 0.1349\n",
      "Replay buffer size: 1638\n",
      "Time taken: 6.5s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.8361\n",
      "Average policy_loss: 0.7017\n",
      "Average value_loss: 0.1344\n",
      "Replay buffer size: 1712\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.8360\n",
      "Average policy_loss: 0.7033\n",
      "Average value_loss: 0.1328\n",
      "Replay buffer size: 1780\n",
      "Time taken: 6.9s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.8290\n",
      "Average policy_loss: 0.6991\n",
      "Average value_loss: 0.1299\n",
      "Replay buffer size: 1846\n",
      "Time taken: 23.6s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 67 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.8396\n",
      "Average policy_loss: 0.7024\n",
      "Average value_loss: 0.1371\n",
      "Replay buffer size: 1913\n",
      "Time taken: 7.1s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.8392\n",
      "Average policy_loss: 0.7026\n",
      "Average value_loss: 0.1366\n",
      "Replay buffer size: 1985\n",
      "Time taken: 7.3s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.8302\n",
      "Average policy_loss: 0.6953\n",
      "Average value_loss: 0.1348\n",
      "Replay buffer size: 2049\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.8234\n",
      "Average policy_loss: 0.6883\n",
      "Average value_loss: 0.1350\n",
      "Replay buffer size: 2119\n",
      "Time taken: 7.2s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.8253\n",
      "Average policy_loss: 0.6892\n",
      "Average value_loss: 0.1361\n",
      "Replay buffer size: 2190\n",
      "Time taken: 24.0s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.8259\n",
      "Average policy_loss: 0.6892\n",
      "Average value_loss: 0.1366\n",
      "Replay buffer size: 2266\n",
      "Time taken: 7.2s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.8216\n",
      "Average policy_loss: 0.6927\n",
      "Average value_loss: 0.1288\n",
      "Replay buffer size: 2330\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.8197\n",
      "Average policy_loss: 0.6924\n",
      "Average value_loss: 0.1273\n",
      "Replay buffer size: 2400\n",
      "Time taken: 7.4s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.8168\n",
      "Average policy_loss: 0.6906\n",
      "Average value_loss: 0.1263\n",
      "Replay buffer size: 2470\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.8090\n",
      "Average policy_loss: 0.6832\n",
      "Average value_loss: 0.1258\n",
      "Replay buffer size: 2540\n",
      "Time taken: 23.8s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.8014\n",
      "Average policy_loss: 0.6796\n",
      "Average value_loss: 0.1219\n",
      "Replay buffer size: 2606\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.7961\n",
      "Average policy_loss: 0.6791\n",
      "Average value_loss: 0.1170\n",
      "Replay buffer size: 2674\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.7899\n",
      "Average policy_loss: 0.6748\n",
      "Average value_loss: 0.1151\n",
      "Replay buffer size: 2742\n",
      "Time taken: 7.1s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.7876\n",
      "Average policy_loss: 0.6729\n",
      "Average value_loss: 0.1147\n",
      "Replay buffer size: 2808\n",
      "Time taken: 7.4s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.7842\n",
      "Average policy_loss: 0.6730\n",
      "Average value_loss: 0.1112\n",
      "Replay buffer size: 2886\n",
      "Time taken: 23.9s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.7819\n",
      "Average policy_loss: 0.6726\n",
      "Average value_loss: 0.1093\n",
      "Replay buffer size: 2952\n",
      "Time taken: 7.4s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.7748\n",
      "Average policy_loss: 0.6672\n",
      "Average value_loss: 0.1075\n",
      "Replay buffer size: 3018\n",
      "Time taken: 6.6s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.7829\n",
      "Average policy_loss: 0.6770\n",
      "Average value_loss: 0.1060\n",
      "Replay buffer size: 3087\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.7759\n",
      "Average policy_loss: 0.6696\n",
      "Average value_loss: 0.1063\n",
      "Replay buffer size: 3161\n",
      "Time taken: 7.8s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.7696\n",
      "Average policy_loss: 0.6672\n",
      "Average value_loss: 0.1024\n",
      "Replay buffer size: 3237\n",
      "Time taken: 25.3s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.7690\n",
      "Average policy_loss: 0.6668\n",
      "Average value_loss: 0.1022\n",
      "Replay buffer size: 3301\n",
      "Time taken: 6.2s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.7702\n",
      "Average policy_loss: 0.6679\n",
      "Average value_loss: 0.1023\n",
      "Replay buffer size: 3365\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.7624\n",
      "Average policy_loss: 0.6633\n",
      "Average value_loss: 0.0991\n",
      "Replay buffer size: 3431\n",
      "Time taken: 6.2s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 65 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.7670\n",
      "Average policy_loss: 0.6676\n",
      "Average value_loss: 0.0994\n",
      "Replay buffer size: 3496\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.7602\n",
      "Average policy_loss: 0.6618\n",
      "Average value_loss: 0.0984\n",
      "Replay buffer size: 3572\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.7615\n",
      "Average policy_loss: 0.6663\n",
      "Average value_loss: 0.0952\n",
      "Replay buffer size: 3646\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.7575\n",
      "Average policy_loss: 0.6627\n",
      "Average value_loss: 0.0948\n",
      "Replay buffer size: 3714\n",
      "Time taken: 6.4s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 67 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.7559\n",
      "Average policy_loss: 0.6583\n",
      "Average value_loss: 0.0976\n",
      "Replay buffer size: 3781\n",
      "Time taken: 6.0s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.7575\n",
      "Average policy_loss: 0.6601\n",
      "Average value_loss: 0.0975\n",
      "Replay buffer size: 3853\n",
      "Time taken: 6.4s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.7540\n",
      "Average policy_loss: 0.6607\n",
      "Average value_loss: 0.0933\n",
      "Replay buffer size: 3921\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.7560\n",
      "Average policy_loss: 0.6613\n",
      "Average value_loss: 0.0947\n",
      "Replay buffer size: 3987\n",
      "Time taken: 6.2s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.7526\n",
      "Average policy_loss: 0.6582\n",
      "Average value_loss: 0.0944\n",
      "Replay buffer size: 4051\n",
      "Time taken: 5.4s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.7580\n",
      "Average policy_loss: 0.6630\n",
      "Average value_loss: 0.0950\n",
      "Replay buffer size: 4122\n",
      "Time taken: 6.3s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.7390\n",
      "Average policy_loss: 0.6487\n",
      "Average value_loss: 0.0903\n",
      "Replay buffer size: 4190\n",
      "Time taken: 6.2s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.7488\n",
      "Average policy_loss: 0.6571\n",
      "Average value_loss: 0.0917\n",
      "Replay buffer size: 4258\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.7428\n",
      "Average policy_loss: 0.6542\n",
      "Average value_loss: 0.0887\n",
      "Replay buffer size: 4326\n",
      "Time taken: 6.2s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.7365\n",
      "Average policy_loss: 0.6471\n",
      "Average value_loss: 0.0894\n",
      "Replay buffer size: 4392\n",
      "Time taken: 6.0s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.7351\n",
      "Average policy_loss: 0.6466\n",
      "Average value_loss: 0.0885\n",
      "Replay buffer size: 4468\n",
      "Time taken: 5.9s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 65 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.7486\n",
      "Average policy_loss: 0.6564\n",
      "Average value_loss: 0.0922\n",
      "Replay buffer size: 4533\n",
      "Time taken: 6.0s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.7496\n",
      "Average policy_loss: 0.6586\n",
      "Average value_loss: 0.0911\n",
      "Replay buffer size: 4597\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.7375\n",
      "Average policy_loss: 0.6467\n",
      "Average value_loss: 0.0908\n",
      "Replay buffer size: 4671\n",
      "Time taken: 6.5s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.7430\n",
      "Average policy_loss: 0.6520\n",
      "Average value_loss: 0.0910\n",
      "Replay buffer size: 4737\n",
      "Time taken: 6.0s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.7410\n",
      "Average policy_loss: 0.6512\n",
      "Average value_loss: 0.0898\n",
      "Replay buffer size: 4803\n",
      "Time taken: 6.2s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.7430\n",
      "Average policy_loss: 0.6554\n",
      "Average value_loss: 0.0875\n",
      "Replay buffer size: 4877\n",
      "Time taken: 6.0s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.7402\n",
      "Average policy_loss: 0.6523\n",
      "Average value_loss: 0.0878\n",
      "Replay buffer size: 4947\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.7445\n",
      "Average policy_loss: 0.6568\n",
      "Average value_loss: 0.0876\n",
      "Replay buffer size: 5019\n",
      "Time taken: 6.4s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.7321\n",
      "Average policy_loss: 0.6478\n",
      "Average value_loss: 0.0843\n",
      "Replay buffer size: 5085\n",
      "Time taken: 6.2s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.7504\n",
      "Average policy_loss: 0.6621\n",
      "Average value_loss: 0.0884\n",
      "Replay buffer size: 5158\n",
      "Time taken: 7.2s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.7467\n",
      "Average policy_loss: 0.6557\n",
      "Average value_loss: 0.0910\n",
      "Replay buffer size: 5232\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.7519\n",
      "Average policy_loss: 0.6607\n",
      "Average value_loss: 0.0913\n",
      "Replay buffer size: 5307\n",
      "Time taken: 23.6s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.7600\n",
      "Average policy_loss: 0.6661\n",
      "Average value_loss: 0.0939\n",
      "Replay buffer size: 5385\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.7547\n",
      "Average policy_loss: 0.6638\n",
      "Average value_loss: 0.0909\n",
      "Replay buffer size: 5465\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.7606\n",
      "Average policy_loss: 0.6639\n",
      "Average value_loss: 0.0967\n",
      "Replay buffer size: 5552\n",
      "Time taken: 7.2s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.7660\n",
      "Average policy_loss: 0.6671\n",
      "Average value_loss: 0.0989\n",
      "Replay buffer size: 5650\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.7777\n",
      "Average policy_loss: 0.6746\n",
      "Average value_loss: 0.1032\n",
      "Replay buffer size: 5745\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.7817\n",
      "Average policy_loss: 0.6759\n",
      "Average value_loss: 0.1059\n",
      "Replay buffer size: 5839\n",
      "Time taken: 6.7s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.7909\n",
      "Average policy_loss: 0.6841\n",
      "Average value_loss: 0.1067\n",
      "Replay buffer size: 5938\n",
      "Time taken: 7.4s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.8019\n",
      "Average policy_loss: 0.6892\n",
      "Average value_loss: 0.1127\n",
      "Replay buffer size: 6037\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.8101\n",
      "Average policy_loss: 0.6958\n",
      "Average value_loss: 0.1143\n",
      "Replay buffer size: 6124\n",
      "Time taken: 8.1s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.8057\n",
      "Average policy_loss: 0.6904\n",
      "Average value_loss: 0.1154\n",
      "Replay buffer size: 6218\n",
      "Time taken: 27.5s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.8145\n",
      "Average policy_loss: 0.6982\n",
      "Average value_loss: 0.1164\n",
      "Replay buffer size: 6304\n",
      "Time taken: 8.5s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.8297\n",
      "Average policy_loss: 0.7072\n",
      "Average value_loss: 0.1225\n",
      "Replay buffer size: 6395\n",
      "Time taken: 8.6s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.8339\n",
      "Average policy_loss: 0.7122\n",
      "Average value_loss: 0.1217\n",
      "Replay buffer size: 6483\n",
      "Time taken: 8.6s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.8408\n",
      "Average policy_loss: 0.7166\n",
      "Average value_loss: 0.1242\n",
      "Replay buffer size: 6579\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.8370\n",
      "Average policy_loss: 0.7136\n",
      "Average value_loss: 0.1234\n",
      "Replay buffer size: 6679\n",
      "Time taken: 29.6s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.8438\n",
      "Average policy_loss: 0.7203\n",
      "Average value_loss: 0.1235\n",
      "Replay buffer size: 6769\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.8487\n",
      "Average policy_loss: 0.7218\n",
      "Average value_loss: 0.1269\n",
      "Replay buffer size: 6858\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.8553\n",
      "Average policy_loss: 0.7287\n",
      "Average value_loss: 0.1266\n",
      "Replay buffer size: 6943\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.8580\n",
      "Average policy_loss: 0.7286\n",
      "Average value_loss: 0.1294\n",
      "Replay buffer size: 7037\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.8632\n",
      "Average policy_loss: 0.7327\n",
      "Average value_loss: 0.1306\n",
      "Replay buffer size: 7133\n",
      "Time taken: 31.3s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.8714\n",
      "Average policy_loss: 0.7405\n",
      "Average value_loss: 0.1309\n",
      "Replay buffer size: 7220\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.8697\n",
      "Average policy_loss: 0.7363\n",
      "Average value_loss: 0.1334\n",
      "Replay buffer size: 7310\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.8690\n",
      "Average policy_loss: 0.7408\n",
      "Average value_loss: 0.1282\n",
      "Replay buffer size: 7404\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.8829\n",
      "Average policy_loss: 0.7498\n",
      "Average value_loss: 0.1330\n",
      "Replay buffer size: 7493\n",
      "Time taken: 10.7s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.8651\n",
      "Average policy_loss: 0.7351\n",
      "Average value_loss: 0.1299\n",
      "Replay buffer size: 7585\n",
      "Time taken: 30.9s\n",
      "\n",
      "Training complete! Total time: 0.3h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iteration_time</td><td>▂▃▂▂▂█▁▁▁▁▁▁▁▁▁▇▁▁▁▁▆▁▁▆▁▁▁▁▅▁▁▁▁▁▁▁█▂▂▂</td></tr><tr><td>loss</td><td>█▆▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▆▃▆▃▅▂▁▃▁▄▃▂▁▂▃▂▃▂▁▂▃▃▁▁▃▂▂▃▁▂▁▃▆█▇▆▆▇█▇</td></tr><tr><td>policy_loss</td><td>█▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>value_loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.1</td></tr><tr><td>buffer_size</td><td>7585</td></tr><tr><td>iteration_time</td><td>30.93466</td></tr><tr><td>loss</td><td>0.86507</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>92</td></tr><tr><td>policy_loss</td><td>0.73515</td></tr><tr><td>total_time_hours</td><td>0.30319</td></tr><tr><td>value_loss</td><td>0.12993</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">warm-sweep-27</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/8qwv1rqb' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/8qwv1rqb</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_140531-8qwv1rqb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uxn9jdci with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02483559543936108\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.2423451955306365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0016108255576352908\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_142351-uxn9jdci</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/uxn9jdci' target=\"_blank\">generous-sweep-28</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/uxn9jdci' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/uxn9jdci</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 67 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 4.7442\n",
      "Average policy_loss: 2.9705\n",
      "Average value_loss: 1.7736\n",
      "Replay buffer size: 67\n",
      "Time taken: 6.9s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 2.6594\n",
      "Average policy_loss: 1.1409\n",
      "Average value_loss: 1.5185\n",
      "Replay buffer size: 155\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.7759\n",
      "Average policy_loss: 0.9291\n",
      "Average value_loss: 0.8468\n",
      "Replay buffer size: 234\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.2040\n",
      "Average policy_loss: 0.9248\n",
      "Average value_loss: 0.2791\n",
      "Replay buffer size: 320\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.2646\n",
      "Average policy_loss: 0.9700\n",
      "Average value_loss: 0.2946\n",
      "Replay buffer size: 393\n",
      "Time taken: 41.1s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.2719\n",
      "Average policy_loss: 0.9541\n",
      "Average value_loss: 0.3178\n",
      "Replay buffer size: 471\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.2748\n",
      "Average policy_loss: 0.9762\n",
      "Average value_loss: 0.2987\n",
      "Replay buffer size: 551\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.2541\n",
      "Average policy_loss: 0.9722\n",
      "Average value_loss: 0.2819\n",
      "Replay buffer size: 631\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.2712\n",
      "Average policy_loss: 0.9618\n",
      "Average value_loss: 0.3094\n",
      "Replay buffer size: 718\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.2878\n",
      "Average policy_loss: 0.9743\n",
      "Average value_loss: 0.3134\n",
      "Replay buffer size: 801\n",
      "Time taken: 42.1s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.2808\n",
      "Average policy_loss: 0.9774\n",
      "Average value_loss: 0.3034\n",
      "Replay buffer size: 893\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.2706\n",
      "Average policy_loss: 0.9615\n",
      "Average value_loss: 0.3092\n",
      "Replay buffer size: 981\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.2906\n",
      "Average policy_loss: 0.9621\n",
      "Average value_loss: 0.3285\n",
      "Replay buffer size: 1071\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.2735\n",
      "Average policy_loss: 0.9599\n",
      "Average value_loss: 0.3135\n",
      "Replay buffer size: 1159\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.2515\n",
      "Average policy_loss: 0.9463\n",
      "Average value_loss: 0.3052\n",
      "Replay buffer size: 1258\n",
      "Time taken: 50.4s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.2292\n",
      "Average policy_loss: 0.9337\n",
      "Average value_loss: 0.2955\n",
      "Replay buffer size: 1346\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.2228\n",
      "Average policy_loss: 0.9216\n",
      "Average value_loss: 0.3012\n",
      "Replay buffer size: 1438\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.2126\n",
      "Average policy_loss: 0.9191\n",
      "Average value_loss: 0.2936\n",
      "Replay buffer size: 1519\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.1993\n",
      "Average policy_loss: 0.9103\n",
      "Average value_loss: 0.2890\n",
      "Replay buffer size: 1614\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.1890\n",
      "Average policy_loss: 0.9039\n",
      "Average value_loss: 0.2851\n",
      "Replay buffer size: 1710\n",
      "Time taken: 53.0s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.1806\n",
      "Average policy_loss: 0.8973\n",
      "Average value_loss: 0.2834\n",
      "Replay buffer size: 1797\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.1786\n",
      "Average policy_loss: 0.8911\n",
      "Average value_loss: 0.2875\n",
      "Replay buffer size: 1894\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.1612\n",
      "Average policy_loss: 0.8778\n",
      "Average value_loss: 0.2834\n",
      "Replay buffer size: 1981\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.1369\n",
      "Average policy_loss: 0.8620\n",
      "Average value_loss: 0.2749\n",
      "Replay buffer size: 2079\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.1261\n",
      "Average policy_loss: 0.8609\n",
      "Average value_loss: 0.2652\n",
      "Replay buffer size: 2173\n",
      "Time taken: 49.6s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.1115\n",
      "Average policy_loss: 0.8506\n",
      "Average value_loss: 0.2609\n",
      "Replay buffer size: 2266\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.1067\n",
      "Average policy_loss: 0.8439\n",
      "Average value_loss: 0.2628\n",
      "Replay buffer size: 2359\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.0999\n",
      "Average policy_loss: 0.8367\n",
      "Average value_loss: 0.2633\n",
      "Replay buffer size: 2451\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.0884\n",
      "Average policy_loss: 0.8330\n",
      "Average value_loss: 0.2554\n",
      "Replay buffer size: 2541\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.0840\n",
      "Average policy_loss: 0.8293\n",
      "Average value_loss: 0.2547\n",
      "Replay buffer size: 2637\n",
      "Time taken: 47.8s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.0747\n",
      "Average policy_loss: 0.8221\n",
      "Average value_loss: 0.2526\n",
      "Replay buffer size: 2727\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.0615\n",
      "Average policy_loss: 0.8100\n",
      "Average value_loss: 0.2515\n",
      "Replay buffer size: 2818\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.0644\n",
      "Average policy_loss: 0.8138\n",
      "Average value_loss: 0.2506\n",
      "Replay buffer size: 2909\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.0561\n",
      "Average policy_loss: 0.8033\n",
      "Average value_loss: 0.2528\n",
      "Replay buffer size: 2994\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.0652\n",
      "Average policy_loss: 0.8096\n",
      "Average value_loss: 0.2556\n",
      "Replay buffer size: 3085\n",
      "Time taken: 48.5s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.0448\n",
      "Average policy_loss: 0.8008\n",
      "Average value_loss: 0.2440\n",
      "Replay buffer size: 3184\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.0275\n",
      "Average policy_loss: 0.7862\n",
      "Average value_loss: 0.2413\n",
      "Replay buffer size: 3279\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.0175\n",
      "Average policy_loss: 0.7840\n",
      "Average value_loss: 0.2335\n",
      "Replay buffer size: 3375\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.0267\n",
      "Average policy_loss: 0.7932\n",
      "Average value_loss: 0.2336\n",
      "Replay buffer size: 3469\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.0193\n",
      "Average policy_loss: 0.7836\n",
      "Average value_loss: 0.2357\n",
      "Replay buffer size: 3563\n",
      "Time taken: 46.3s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.0134\n",
      "Average policy_loss: 0.7841\n",
      "Average value_loss: 0.2293\n",
      "Replay buffer size: 3657\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.0015\n",
      "Average policy_loss: 0.7764\n",
      "Average value_loss: 0.2250\n",
      "Replay buffer size: 3754\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.0034\n",
      "Average policy_loss: 0.7752\n",
      "Average value_loss: 0.2282\n",
      "Replay buffer size: 3849\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.0016\n",
      "Average policy_loss: 0.7694\n",
      "Average value_loss: 0.2322\n",
      "Replay buffer size: 3943\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.9798\n",
      "Average policy_loss: 0.7556\n",
      "Average value_loss: 0.2242\n",
      "Replay buffer size: 4036\n",
      "Time taken: 47.1s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.9815\n",
      "Average policy_loss: 0.7611\n",
      "Average value_loss: 0.2204\n",
      "Replay buffer size: 4133\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.9777\n",
      "Average policy_loss: 0.7641\n",
      "Average value_loss: 0.2136\n",
      "Replay buffer size: 4233\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.9661\n",
      "Average policy_loss: 0.7537\n",
      "Average value_loss: 0.2124\n",
      "Replay buffer size: 4323\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.9670\n",
      "Average policy_loss: 0.7553\n",
      "Average value_loss: 0.2117\n",
      "Replay buffer size: 4415\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 55.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.9657\n",
      "Average policy_loss: 0.7514\n",
      "Average value_loss: 0.2144\n",
      "Replay buffer size: 4508\n",
      "Time taken: 46.4s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.9737\n",
      "Average policy_loss: 0.7582\n",
      "Average value_loss: 0.2155\n",
      "Replay buffer size: 4604\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.9447\n",
      "Average policy_loss: 0.7395\n",
      "Average value_loss: 0.2052\n",
      "Replay buffer size: 4694\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.9736\n",
      "Average policy_loss: 0.7628\n",
      "Average value_loss: 0.2108\n",
      "Replay buffer size: 4787\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.9734\n",
      "Average policy_loss: 0.7537\n",
      "Average value_loss: 0.2197\n",
      "Replay buffer size: 4871\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.9454\n",
      "Average policy_loss: 0.7412\n",
      "Average value_loss: 0.2042\n",
      "Replay buffer size: 4965\n",
      "Time taken: 47.2s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.9596\n",
      "Average policy_loss: 0.7502\n",
      "Average value_loss: 0.2094\n",
      "Replay buffer size: 5058\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.9485\n",
      "Average policy_loss: 0.7401\n",
      "Average value_loss: 0.2084\n",
      "Replay buffer size: 5158\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.9522\n",
      "Average policy_loss: 0.7524\n",
      "Average value_loss: 0.1997\n",
      "Replay buffer size: 5246\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.9340\n",
      "Average policy_loss: 0.7334\n",
      "Average value_loss: 0.2006\n",
      "Replay buffer size: 5333\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.9377\n",
      "Average policy_loss: 0.7344\n",
      "Average value_loss: 0.2033\n",
      "Replay buffer size: 5426\n",
      "Time taken: 45.8s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.9277\n",
      "Average policy_loss: 0.7281\n",
      "Average value_loss: 0.1996\n",
      "Replay buffer size: 5521\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.9425\n",
      "Average policy_loss: 0.7409\n",
      "Average value_loss: 0.2016\n",
      "Replay buffer size: 5610\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.9359\n",
      "Average policy_loss: 0.7346\n",
      "Average value_loss: 0.2013\n",
      "Replay buffer size: 5706\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.9339\n",
      "Average policy_loss: 0.7348\n",
      "Average value_loss: 0.1990\n",
      "Replay buffer size: 5792\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.9202\n",
      "Average policy_loss: 0.7242\n",
      "Average value_loss: 0.1960\n",
      "Replay buffer size: 5888\n",
      "Time taken: 43.6s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.9226\n",
      "Average policy_loss: 0.7279\n",
      "Average value_loss: 0.1947\n",
      "Replay buffer size: 5986\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.9198\n",
      "Average policy_loss: 0.7270\n",
      "Average value_loss: 0.1927\n",
      "Replay buffer size: 6074\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.9192\n",
      "Average policy_loss: 0.7242\n",
      "Average value_loss: 0.1949\n",
      "Replay buffer size: 6165\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.9199\n",
      "Average policy_loss: 0.7213\n",
      "Average value_loss: 0.1986\n",
      "Replay buffer size: 6258\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.9090\n",
      "Average policy_loss: 0.7169\n",
      "Average value_loss: 0.1920\n",
      "Replay buffer size: 6350\n",
      "Time taken: 44.4s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.9080\n",
      "Average policy_loss: 0.7134\n",
      "Average value_loss: 0.1945\n",
      "Replay buffer size: 6444\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.9053\n",
      "Average policy_loss: 0.7149\n",
      "Average value_loss: 0.1904\n",
      "Replay buffer size: 6538\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.9130\n",
      "Average policy_loss: 0.7204\n",
      "Average value_loss: 0.1926\n",
      "Replay buffer size: 6628\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.9021\n",
      "Average policy_loss: 0.7107\n",
      "Average value_loss: 0.1914\n",
      "Replay buffer size: 6725\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.9220\n",
      "Average policy_loss: 0.7285\n",
      "Average value_loss: 0.1935\n",
      "Replay buffer size: 6821\n",
      "Time taken: 50.6s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.9148\n",
      "Average policy_loss: 0.7231\n",
      "Average value_loss: 0.1917\n",
      "Replay buffer size: 6915\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.9083\n",
      "Average policy_loss: 0.7165\n",
      "Average value_loss: 0.1918\n",
      "Replay buffer size: 7002\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.8954\n",
      "Average policy_loss: 0.7105\n",
      "Average value_loss: 0.1848\n",
      "Replay buffer size: 7102\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.9132\n",
      "Average policy_loss: 0.7238\n",
      "Average value_loss: 0.1894\n",
      "Replay buffer size: 7198\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.8975\n",
      "Average policy_loss: 0.7129\n",
      "Average value_loss: 0.1845\n",
      "Replay buffer size: 7298\n",
      "Time taken: 46.1s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.9013\n",
      "Average policy_loss: 0.7154\n",
      "Average value_loss: 0.1860\n",
      "Replay buffer size: 7393\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.9051\n",
      "Average policy_loss: 0.7190\n",
      "Average value_loss: 0.1861\n",
      "Replay buffer size: 7489\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.9018\n",
      "Average policy_loss: 0.7156\n",
      "Average value_loss: 0.1862\n",
      "Replay buffer size: 7580\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.8872\n",
      "Average policy_loss: 0.7080\n",
      "Average value_loss: 0.1792\n",
      "Replay buffer size: 7674\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.9047\n",
      "Average policy_loss: 0.7209\n",
      "Average value_loss: 0.1838\n",
      "Replay buffer size: 7758\n",
      "Time taken: 44.8s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.8909\n",
      "Average policy_loss: 0.7100\n",
      "Average value_loss: 0.1809\n",
      "Replay buffer size: 7853\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.8985\n",
      "Average policy_loss: 0.7179\n",
      "Average value_loss: 0.1806\n",
      "Replay buffer size: 7945\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.8935\n",
      "Average policy_loss: 0.7145\n",
      "Average value_loss: 0.1790\n",
      "Replay buffer size: 8045\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.8874\n",
      "Average policy_loss: 0.7076\n",
      "Average value_loss: 0.1798\n",
      "Replay buffer size: 8142\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.9267\n",
      "Average policy_loss: 0.7354\n",
      "Average value_loss: 0.1912\n",
      "Replay buffer size: 8241\n",
      "Time taken: 50.1s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.8897\n",
      "Average policy_loss: 0.7176\n",
      "Average value_loss: 0.1721\n",
      "Replay buffer size: 8337\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.8783\n",
      "Average policy_loss: 0.7037\n",
      "Average value_loss: 0.1746\n",
      "Replay buffer size: 8431\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.8854\n",
      "Average policy_loss: 0.7073\n",
      "Average value_loss: 0.1781\n",
      "Replay buffer size: 8518\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.8767\n",
      "Average policy_loss: 0.7045\n",
      "Average value_loss: 0.1722\n",
      "Replay buffer size: 8615\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.8766\n",
      "Average policy_loss: 0.7036\n",
      "Average value_loss: 0.1730\n",
      "Replay buffer size: 8710\n",
      "Time taken: 44.4s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.8692\n",
      "Average policy_loss: 0.6965\n",
      "Average value_loss: 0.1727\n",
      "Replay buffer size: 8796\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.8774\n",
      "Average policy_loss: 0.7048\n",
      "Average value_loss: 0.1726\n",
      "Replay buffer size: 8896\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.8676\n",
      "Average policy_loss: 0.6962\n",
      "Average value_loss: 0.1714\n",
      "Replay buffer size: 8987\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.8693\n",
      "Average policy_loss: 0.7027\n",
      "Average value_loss: 0.1666\n",
      "Replay buffer size: 9083\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.8843\n",
      "Average policy_loss: 0.7069\n",
      "Average value_loss: 0.1774\n",
      "Replay buffer size: 9175\n",
      "Time taken: 45.6s\n",
      "\n",
      "Training complete! Total time: 0.6h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>iteration_time</td><td>▆▁▆▂▂▂▂█▂▂▂▂▂▂▂▁▁▁▁▇▇▁▁▁▁▁▁▁▁█▁▁▇▁▁▂▂▁▁▇</td></tr><tr><td>loss</td><td>█▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▁▁▁▄▂▅▄█▆▇▆▆▅▅▆▆▅▅▅▆▆█▄▇▃▇▆▆▅▇▆█▇▇▆▇█▄▃▅</td></tr><tr><td>policy_loss</td><td>▇▇██▇▆▆▆▅▄▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▁▂▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▄▂▁▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.1</td></tr><tr><td>buffer_size</td><td>9175</td></tr><tr><td>iteration_time</td><td>45.60673</td></tr><tr><td>loss</td><td>0.8843</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>92</td></tr><tr><td>policy_loss</td><td>0.70691</td></tr><tr><td>total_time_hours</td><td>0.56158</td></tr><tr><td>value_loss</td><td>0.17739</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">generous-sweep-28</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/uxn9jdci' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/uxn9jdci</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_142351-uxn9jdci/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ftta8ltu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.109139092490841e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: small\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.926134885910707\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.7826581663215916e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_145743-ftta8ltu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ftta8ltu' target=\"_blank\">solar-sweep-29</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ftta8ltu' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ftta8ltu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 8.0444\n",
      "Average policy_loss: 6.4361\n",
      "Average value_loss: 1.6083\n",
      "Replay buffer size: 77\n",
      "Time taken: 7.3s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 6.7415\n",
      "Average policy_loss: 5.4957\n",
      "Average value_loss: 1.2459\n",
      "Replay buffer size: 164\n",
      "Time taken: 6.6s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 5.4759\n",
      "Average policy_loss: 4.4173\n",
      "Average value_loss: 1.0586\n",
      "Replay buffer size: 250\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 4.8456\n",
      "Average policy_loss: 3.9345\n",
      "Average value_loss: 0.9111\n",
      "Replay buffer size: 342\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 4.6761\n",
      "Average policy_loss: 3.7679\n",
      "Average value_loss: 0.9083\n",
      "Replay buffer size: 435\n",
      "Time taken: 26.9s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 4.3382\n",
      "Average policy_loss: 3.4481\n",
      "Average value_loss: 0.8901\n",
      "Replay buffer size: 520\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 3.9743\n",
      "Average policy_loss: 3.1227\n",
      "Average value_loss: 0.8516\n",
      "Replay buffer size: 608\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 3.7570\n",
      "Average policy_loss: 2.9066\n",
      "Average value_loss: 0.8504\n",
      "Replay buffer size: 694\n",
      "Time taken: 7.9s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 3.6453\n",
      "Average policy_loss: 2.8129\n",
      "Average value_loss: 0.8324\n",
      "Replay buffer size: 778\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 3.3627\n",
      "Average policy_loss: 2.5560\n",
      "Average value_loss: 0.8067\n",
      "Replay buffer size: 863\n",
      "Time taken: 27.9s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 3.2227\n",
      "Average policy_loss: 2.4291\n",
      "Average value_loss: 0.7936\n",
      "Replay buffer size: 948\n",
      "Time taken: 8.3s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 3.1415\n",
      "Average policy_loss: 2.3325\n",
      "Average value_loss: 0.8090\n",
      "Replay buffer size: 1033\n",
      "Time taken: 8.1s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 3.0002\n",
      "Average policy_loss: 2.2131\n",
      "Average value_loss: 0.7871\n",
      "Replay buffer size: 1125\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 2.9024\n",
      "Average policy_loss: 2.1409\n",
      "Average value_loss: 0.7615\n",
      "Replay buffer size: 1203\n",
      "Time taken: 8.3s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 2.7838\n",
      "Average policy_loss: 2.0555\n",
      "Average value_loss: 0.7283\n",
      "Replay buffer size: 1285\n",
      "Time taken: 31.8s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 2.7116\n",
      "Average policy_loss: 1.9842\n",
      "Average value_loss: 0.7274\n",
      "Replay buffer size: 1372\n",
      "Time taken: 9.5s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 2.6320\n",
      "Average policy_loss: 1.9318\n",
      "Average value_loss: 0.7002\n",
      "Replay buffer size: 1444\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 2.5982\n",
      "Average policy_loss: 1.9131\n",
      "Average value_loss: 0.6851\n",
      "Replay buffer size: 1524\n",
      "Time taken: 9.5s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 2.5615\n",
      "Average policy_loss: 1.8753\n",
      "Average value_loss: 0.6862\n",
      "Replay buffer size: 1607\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 2.5472\n",
      "Average policy_loss: 1.8629\n",
      "Average value_loss: 0.6843\n",
      "Replay buffer size: 1698\n",
      "Time taken: 31.5s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 2.4794\n",
      "Average policy_loss: 1.8221\n",
      "Average value_loss: 0.6573\n",
      "Replay buffer size: 1787\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 2.4934\n",
      "Average policy_loss: 1.8455\n",
      "Average value_loss: 0.6478\n",
      "Replay buffer size: 1874\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 2.4534\n",
      "Average policy_loss: 1.8071\n",
      "Average value_loss: 0.6464\n",
      "Replay buffer size: 1962\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 2.4091\n",
      "Average policy_loss: 1.7875\n",
      "Average value_loss: 0.6217\n",
      "Replay buffer size: 2054\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 2.3909\n",
      "Average policy_loss: 1.7834\n",
      "Average value_loss: 0.6075\n",
      "Replay buffer size: 2146\n",
      "Time taken: 34.9s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 2.3616\n",
      "Average policy_loss: 1.7757\n",
      "Average value_loss: 0.5859\n",
      "Replay buffer size: 2238\n",
      "Time taken: 11.2s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 2.3100\n",
      "Average policy_loss: 1.7452\n",
      "Average value_loss: 0.5648\n",
      "Replay buffer size: 2315\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 2.3173\n",
      "Average policy_loss: 1.7677\n",
      "Average value_loss: 0.5496\n",
      "Replay buffer size: 2398\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 2.2875\n",
      "Average policy_loss: 1.7348\n",
      "Average value_loss: 0.5528\n",
      "Replay buffer size: 2480\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 2.2485\n",
      "Average policy_loss: 1.7055\n",
      "Average value_loss: 0.5430\n",
      "Replay buffer size: 2570\n",
      "Time taken: 37.8s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 2.2183\n",
      "Average policy_loss: 1.6987\n",
      "Average value_loss: 0.5196\n",
      "Replay buffer size: 2664\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 2.1930\n",
      "Average policy_loss: 1.6971\n",
      "Average value_loss: 0.4958\n",
      "Replay buffer size: 2744\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 2.1720\n",
      "Average policy_loss: 1.6846\n",
      "Average value_loss: 0.4874\n",
      "Replay buffer size: 2836\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 2.1564\n",
      "Average policy_loss: 1.6813\n",
      "Average value_loss: 0.4751\n",
      "Replay buffer size: 2918\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 2.1311\n",
      "Average policy_loss: 1.6641\n",
      "Average value_loss: 0.4670\n",
      "Replay buffer size: 2990\n",
      "Time taken: 36.6s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 2.1026\n",
      "Average policy_loss: 1.6464\n",
      "Average value_loss: 0.4562\n",
      "Replay buffer size: 3082\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 2.0906\n",
      "Average policy_loss: 1.6470\n",
      "Average value_loss: 0.4437\n",
      "Replay buffer size: 3173\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 2.0550\n",
      "Average policy_loss: 1.6263\n",
      "Average value_loss: 0.4286\n",
      "Replay buffer size: 3254\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 2.0301\n",
      "Average policy_loss: 1.6168\n",
      "Average value_loss: 0.4133\n",
      "Replay buffer size: 3329\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 2.0258\n",
      "Average policy_loss: 1.6231\n",
      "Average value_loss: 0.4027\n",
      "Replay buffer size: 3417\n",
      "Time taken: 39.0s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 2.0023\n",
      "Average policy_loss: 1.6092\n",
      "Average value_loss: 0.3931\n",
      "Replay buffer size: 3506\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.9903\n",
      "Average policy_loss: 1.5976\n",
      "Average value_loss: 0.3927\n",
      "Replay buffer size: 3590\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.9914\n",
      "Average policy_loss: 1.6070\n",
      "Average value_loss: 0.3844\n",
      "Replay buffer size: 3678\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.9578\n",
      "Average policy_loss: 1.5884\n",
      "Average value_loss: 0.3694\n",
      "Replay buffer size: 3766\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.9866\n",
      "Average policy_loss: 1.6195\n",
      "Average value_loss: 0.3670\n",
      "Replay buffer size: 3843\n",
      "Time taken: 39.9s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.9411\n",
      "Average policy_loss: 1.5760\n",
      "Average value_loss: 0.3651\n",
      "Replay buffer size: 3937\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.9520\n",
      "Average policy_loss: 1.5910\n",
      "Average value_loss: 0.3611\n",
      "Replay buffer size: 4018\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.9202\n",
      "Average policy_loss: 1.5730\n",
      "Average value_loss: 0.3472\n",
      "Replay buffer size: 4112\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.8908\n",
      "Average policy_loss: 1.5548\n",
      "Average value_loss: 0.3360\n",
      "Replay buffer size: 4200\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.9075\n",
      "Average policy_loss: 1.5701\n",
      "Average value_loss: 0.3374\n",
      "Replay buffer size: 4287\n",
      "Time taken: 38.1s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.8831\n",
      "Average policy_loss: 1.5501\n",
      "Average value_loss: 0.3330\n",
      "Replay buffer size: 4379\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.8568\n",
      "Average policy_loss: 1.5375\n",
      "Average value_loss: 0.3193\n",
      "Replay buffer size: 4461\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.8624\n",
      "Average policy_loss: 1.5459\n",
      "Average value_loss: 0.3165\n",
      "Replay buffer size: 4553\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.8393\n",
      "Average policy_loss: 1.5311\n",
      "Average value_loss: 0.3082\n",
      "Replay buffer size: 4646\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.8171\n",
      "Average policy_loss: 1.5053\n",
      "Average value_loss: 0.3118\n",
      "Replay buffer size: 4735\n",
      "Time taken: 36.8s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.8264\n",
      "Average policy_loss: 1.5327\n",
      "Average value_loss: 0.2937\n",
      "Replay buffer size: 4827\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.8198\n",
      "Average policy_loss: 1.5186\n",
      "Average value_loss: 0.3012\n",
      "Replay buffer size: 4916\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.7844\n",
      "Average policy_loss: 1.5033\n",
      "Average value_loss: 0.2811\n",
      "Replay buffer size: 5010\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.7966\n",
      "Average policy_loss: 1.5036\n",
      "Average value_loss: 0.2930\n",
      "Replay buffer size: 5099\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.7550\n",
      "Average policy_loss: 1.4796\n",
      "Average value_loss: 0.2754\n",
      "Replay buffer size: 5191\n",
      "Time taken: 38.5s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.7495\n",
      "Average policy_loss: 1.4767\n",
      "Average value_loss: 0.2727\n",
      "Replay buffer size: 5284\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.7363\n",
      "Average policy_loss: 1.4721\n",
      "Average value_loss: 0.2642\n",
      "Replay buffer size: 5376\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.7550\n",
      "Average policy_loss: 1.4854\n",
      "Average value_loss: 0.2696\n",
      "Replay buffer size: 5469\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.7324\n",
      "Average policy_loss: 1.4744\n",
      "Average value_loss: 0.2580\n",
      "Replay buffer size: 5552\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.7301\n",
      "Average policy_loss: 1.4682\n",
      "Average value_loss: 0.2619\n",
      "Replay buffer size: 5636\n",
      "Time taken: 38.1s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.7143\n",
      "Average policy_loss: 1.4555\n",
      "Average value_loss: 0.2588\n",
      "Replay buffer size: 5728\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.6980\n",
      "Average policy_loss: 1.4428\n",
      "Average value_loss: 0.2553\n",
      "Replay buffer size: 5819\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.6805\n",
      "Average policy_loss: 1.4317\n",
      "Average value_loss: 0.2488\n",
      "Replay buffer size: 5904\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.6938\n",
      "Average policy_loss: 1.4407\n",
      "Average value_loss: 0.2531\n",
      "Replay buffer size: 6000\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.6823\n",
      "Average policy_loss: 1.4253\n",
      "Average value_loss: 0.2570\n",
      "Replay buffer size: 6087\n",
      "Time taken: 41.6s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.6784\n",
      "Average policy_loss: 1.4332\n",
      "Average value_loss: 0.2452\n",
      "Replay buffer size: 6181\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.6720\n",
      "Average policy_loss: 1.4268\n",
      "Average value_loss: 0.2452\n",
      "Replay buffer size: 6276\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.6678\n",
      "Average policy_loss: 1.4258\n",
      "Average value_loss: 0.2420\n",
      "Replay buffer size: 6367\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.6341\n",
      "Average policy_loss: 1.3915\n",
      "Average value_loss: 0.2427\n",
      "Replay buffer size: 6458\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.6407\n",
      "Average policy_loss: 1.3963\n",
      "Average value_loss: 0.2444\n",
      "Replay buffer size: 6544\n",
      "Time taken: 44.5s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.6490\n",
      "Average policy_loss: 1.4087\n",
      "Average value_loss: 0.2402\n",
      "Replay buffer size: 6629\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.6207\n",
      "Average policy_loss: 1.3843\n",
      "Average value_loss: 0.2364\n",
      "Replay buffer size: 6723\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.6086\n",
      "Average policy_loss: 1.3769\n",
      "Average value_loss: 0.2317\n",
      "Replay buffer size: 6807\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.6103\n",
      "Average policy_loss: 1.3751\n",
      "Average value_loss: 0.2352\n",
      "Replay buffer size: 6890\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.6106\n",
      "Average policy_loss: 1.3749\n",
      "Average value_loss: 0.2357\n",
      "Replay buffer size: 6979\n",
      "Time taken: 43.0s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.6014\n",
      "Average policy_loss: 1.3731\n",
      "Average value_loss: 0.2283\n",
      "Replay buffer size: 7070\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.5992\n",
      "Average policy_loss: 1.3619\n",
      "Average value_loss: 0.2373\n",
      "Replay buffer size: 7161\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.5937\n",
      "Average policy_loss: 1.3640\n",
      "Average value_loss: 0.2297\n",
      "Replay buffer size: 7250\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.5955\n",
      "Average policy_loss: 1.3651\n",
      "Average value_loss: 0.2305\n",
      "Replay buffer size: 7345\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.5936\n",
      "Average policy_loss: 1.3599\n",
      "Average value_loss: 0.2337\n",
      "Replay buffer size: 7434\n",
      "Time taken: 42.0s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.5685\n",
      "Average policy_loss: 1.3430\n",
      "Average value_loss: 0.2255\n",
      "Replay buffer size: 7515\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.5599\n",
      "Average policy_loss: 1.3342\n",
      "Average value_loss: 0.2257\n",
      "Replay buffer size: 7604\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.5546\n",
      "Average policy_loss: 1.3314\n",
      "Average value_loss: 0.2232\n",
      "Replay buffer size: 7694\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.5620\n",
      "Average policy_loss: 1.3407\n",
      "Average value_loss: 0.2213\n",
      "Replay buffer size: 7783\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.5541\n",
      "Average policy_loss: 1.3396\n",
      "Average value_loss: 0.2144\n",
      "Replay buffer size: 7878\n",
      "Time taken: 41.5s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.5519\n",
      "Average policy_loss: 1.3346\n",
      "Average value_loss: 0.2173\n",
      "Replay buffer size: 7971\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.5516\n",
      "Average policy_loss: 1.3267\n",
      "Average value_loss: 0.2250\n",
      "Replay buffer size: 8056\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.5300\n",
      "Average policy_loss: 1.3071\n",
      "Average value_loss: 0.2229\n",
      "Replay buffer size: 8133\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.5208\n",
      "Average policy_loss: 1.3095\n",
      "Average value_loss: 0.2113\n",
      "Replay buffer size: 8218\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.5256\n",
      "Average policy_loss: 1.3118\n",
      "Average value_loss: 0.2138\n",
      "Replay buffer size: 8308\n",
      "Time taken: 45.2s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.5203\n",
      "Average policy_loss: 1.3106\n",
      "Average value_loss: 0.2097\n",
      "Replay buffer size: 8404\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.5110\n",
      "Average policy_loss: 1.3050\n",
      "Average value_loss: 0.2060\n",
      "Replay buffer size: 8502\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.5050\n",
      "Average policy_loss: 1.2959\n",
      "Average value_loss: 0.2091\n",
      "Replay buffer size: 8589\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.5178\n",
      "Average policy_loss: 1.3019\n",
      "Average value_loss: 0.2158\n",
      "Replay buffer size: 8687\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.4896\n",
      "Average policy_loss: 1.2831\n",
      "Average value_loss: 0.2064\n",
      "Replay buffer size: 8786\n",
      "Time taken: 41.1s\n",
      "\n",
      "Training complete! Total time: 0.5h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>iteration_time</td><td>▁▁▁▅▁▅▁▁▁▂▂▂▂▇▂▂▂▂▂▂▂▂▂▇▂▂▇▂▂▂▂█▂▂▂▂▂▂▂▂</td></tr><tr><td>loss</td><td>█▅▄▄▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▁▅▄▄▄▇▅▂▇▇▇▃▇▆▂▅▄▅▁▇▇▇▇▅▇▃▄▄▇▆▄▆▆█▂▆▅█▄█</td></tr><tr><td>policy_loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▇▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.1</td></tr><tr><td>buffer_size</td><td>8786</td></tr><tr><td>iteration_time</td><td>41.12503</td></tr><tr><td>loss</td><td>1.48959</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>99</td></tr><tr><td>policy_loss</td><td>1.28315</td></tr><tr><td>total_time_hours</td><td>0.46678</td></tr><tr><td>value_loss</td><td>0.20644</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-29</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ftta8ltu' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ftta8ltu</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 26 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_145743-ftta8ltu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 10qsugl9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0010217147467280667\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: tiny\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.6649995855674485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.010690439823965388\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_152553-10qsugl9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/10qsugl9' target=\"_blank\">daily-sweep-30</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/10qsugl9' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/10qsugl9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 3.6845\n",
      "Average policy_loss: 3.0000\n",
      "Average value_loss: 0.6845\n",
      "Replay buffer size: 73\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 2.5685\n",
      "Average policy_loss: 2.1418\n",
      "Average value_loss: 0.4267\n",
      "Replay buffer size: 151\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 2.3544\n",
      "Average policy_loss: 2.0077\n",
      "Average value_loss: 0.3467\n",
      "Replay buffer size: 234\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 2.2420\n",
      "Average policy_loss: 1.9863\n",
      "Average value_loss: 0.2557\n",
      "Replay buffer size: 331\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 2.2147\n",
      "Average policy_loss: 1.9533\n",
      "Average value_loss: 0.2614\n",
      "Replay buffer size: 414\n",
      "Time taken: 41.1s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 2.1800\n",
      "Average policy_loss: 1.9175\n",
      "Average value_loss: 0.2625\n",
      "Replay buffer size: 493\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 2.1547\n",
      "Average policy_loss: 1.9002\n",
      "Average value_loss: 0.2545\n",
      "Replay buffer size: 576\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 2.1208\n",
      "Average policy_loss: 1.8815\n",
      "Average value_loss: 0.2393\n",
      "Replay buffer size: 660\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 2.1018\n",
      "Average policy_loss: 1.8747\n",
      "Average value_loss: 0.2272\n",
      "Replay buffer size: 741\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 2.0548\n",
      "Average policy_loss: 1.8424\n",
      "Average value_loss: 0.2124\n",
      "Replay buffer size: 825\n",
      "Time taken: 44.3s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 2.0301\n",
      "Average policy_loss: 1.8233\n",
      "Average value_loss: 0.2068\n",
      "Replay buffer size: 911\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.9871\n",
      "Average policy_loss: 1.7880\n",
      "Average value_loss: 0.1991\n",
      "Replay buffer size: 995\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.9294\n",
      "Average policy_loss: 1.7373\n",
      "Average value_loss: 0.1921\n",
      "Replay buffer size: 1080\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.8728\n",
      "Average policy_loss: 1.6856\n",
      "Average value_loss: 0.1872\n",
      "Replay buffer size: 1166\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.8251\n",
      "Average policy_loss: 1.6304\n",
      "Average value_loss: 0.1947\n",
      "Replay buffer size: 1244\n",
      "Time taken: 46.1s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.7816\n",
      "Average policy_loss: 1.5782\n",
      "Average value_loss: 0.2034\n",
      "Replay buffer size: 1318\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.7242\n",
      "Average policy_loss: 1.5240\n",
      "Average value_loss: 0.2002\n",
      "Replay buffer size: 1395\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.6579\n",
      "Average policy_loss: 1.4637\n",
      "Average value_loss: 0.1941\n",
      "Replay buffer size: 1481\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.5823\n",
      "Average policy_loss: 1.3971\n",
      "Average value_loss: 0.1852\n",
      "Replay buffer size: 1571\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.5255\n",
      "Average policy_loss: 1.3368\n",
      "Average value_loss: 0.1887\n",
      "Replay buffer size: 1642\n",
      "Time taken: 43.1s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.4602\n",
      "Average policy_loss: 1.2739\n",
      "Average value_loss: 0.1864\n",
      "Replay buffer size: 1729\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.4023\n",
      "Average policy_loss: 1.2128\n",
      "Average value_loss: 0.1895\n",
      "Replay buffer size: 1818\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.3622\n",
      "Average policy_loss: 1.1772\n",
      "Average value_loss: 0.1849\n",
      "Replay buffer size: 1910\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.3377\n",
      "Average policy_loss: 1.1525\n",
      "Average value_loss: 0.1852\n",
      "Replay buffer size: 1987\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.3110\n",
      "Average policy_loss: 1.1342\n",
      "Average value_loss: 0.1768\n",
      "Replay buffer size: 2085\n",
      "Time taken: 41.1s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.2922\n",
      "Average policy_loss: 1.1198\n",
      "Average value_loss: 0.1724\n",
      "Replay buffer size: 2169\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.2770\n",
      "Average policy_loss: 1.1077\n",
      "Average value_loss: 0.1692\n",
      "Replay buffer size: 2259\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.2640\n",
      "Average policy_loss: 1.0965\n",
      "Average value_loss: 0.1675\n",
      "Replay buffer size: 2344\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.2542\n",
      "Average policy_loss: 1.0886\n",
      "Average value_loss: 0.1656\n",
      "Replay buffer size: 2434\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.2339\n",
      "Average policy_loss: 1.0731\n",
      "Average value_loss: 0.1608\n",
      "Replay buffer size: 2525\n",
      "Time taken: 38.8s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.2236\n",
      "Average policy_loss: 1.0643\n",
      "Average value_loss: 0.1593\n",
      "Replay buffer size: 2613\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.2105\n",
      "Average policy_loss: 1.0527\n",
      "Average value_loss: 0.1578\n",
      "Replay buffer size: 2703\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.1960\n",
      "Average policy_loss: 1.0395\n",
      "Average value_loss: 0.1564\n",
      "Replay buffer size: 2792\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.1855\n",
      "Average policy_loss: 1.0341\n",
      "Average value_loss: 0.1514\n",
      "Replay buffer size: 2882\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.1775\n",
      "Average policy_loss: 1.0232\n",
      "Average value_loss: 0.1543\n",
      "Replay buffer size: 2971\n",
      "Time taken: 38.9s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.1722\n",
      "Average policy_loss: 1.0191\n",
      "Average value_loss: 0.1532\n",
      "Replay buffer size: 3056\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.1621\n",
      "Average policy_loss: 1.0115\n",
      "Average value_loss: 0.1506\n",
      "Replay buffer size: 3140\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.1521\n",
      "Average policy_loss: 1.0041\n",
      "Average value_loss: 0.1480\n",
      "Replay buffer size: 3228\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.1406\n",
      "Average policy_loss: 0.9932\n",
      "Average value_loss: 0.1475\n",
      "Replay buffer size: 3327\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.1325\n",
      "Average policy_loss: 0.9877\n",
      "Average value_loss: 0.1448\n",
      "Replay buffer size: 3415\n",
      "Time taken: 38.2s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.1324\n",
      "Average policy_loss: 0.9867\n",
      "Average value_loss: 0.1457\n",
      "Replay buffer size: 3498\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.1283\n",
      "Average policy_loss: 0.9841\n",
      "Average value_loss: 0.1442\n",
      "Replay buffer size: 3598\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.1101\n",
      "Average policy_loss: 0.9703\n",
      "Average value_loss: 0.1398\n",
      "Replay buffer size: 3691\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.1092\n",
      "Average policy_loss: 0.9671\n",
      "Average value_loss: 0.1421\n",
      "Replay buffer size: 3785\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.1024\n",
      "Average policy_loss: 0.9620\n",
      "Average value_loss: 0.1404\n",
      "Replay buffer size: 3873\n",
      "Time taken: 41.1s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.0962\n",
      "Average policy_loss: 0.9569\n",
      "Average value_loss: 0.1393\n",
      "Replay buffer size: 3963\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.0925\n",
      "Average policy_loss: 0.9536\n",
      "Average value_loss: 0.1389\n",
      "Replay buffer size: 4052\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.0860\n",
      "Average policy_loss: 0.9469\n",
      "Average value_loss: 0.1391\n",
      "Replay buffer size: 4146\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.0850\n",
      "Average policy_loss: 0.9477\n",
      "Average value_loss: 0.1373\n",
      "Replay buffer size: 4233\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.0818\n",
      "Average policy_loss: 0.9459\n",
      "Average value_loss: 0.1359\n",
      "Replay buffer size: 4328\n",
      "Time taken: 42.0s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.0767\n",
      "Average policy_loss: 0.9408\n",
      "Average value_loss: 0.1359\n",
      "Replay buffer size: 4416\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.0774\n",
      "Average policy_loss: 0.9406\n",
      "Average value_loss: 0.1368\n",
      "Replay buffer size: 4497\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.0755\n",
      "Average policy_loss: 0.9399\n",
      "Average value_loss: 0.1355\n",
      "Replay buffer size: 4575\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.0693\n",
      "Average policy_loss: 0.9336\n",
      "Average value_loss: 0.1357\n",
      "Replay buffer size: 4666\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.0736\n",
      "Average policy_loss: 0.9344\n",
      "Average value_loss: 0.1392\n",
      "Replay buffer size: 4752\n",
      "Time taken: 43.4s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.0743\n",
      "Average policy_loss: 0.9368\n",
      "Average value_loss: 0.1375\n",
      "Replay buffer size: 4842\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.0701\n",
      "Average policy_loss: 0.9327\n",
      "Average value_loss: 0.1373\n",
      "Replay buffer size: 4936\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.0667\n",
      "Average policy_loss: 0.9288\n",
      "Average value_loss: 0.1379\n",
      "Replay buffer size: 5016\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.0710\n",
      "Average policy_loss: 0.9326\n",
      "Average value_loss: 0.1384\n",
      "Replay buffer size: 5101\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.0674\n",
      "Average policy_loss: 0.9284\n",
      "Average value_loss: 0.1391\n",
      "Replay buffer size: 5197\n",
      "Time taken: 44.3s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.0627\n",
      "Average policy_loss: 0.9246\n",
      "Average value_loss: 0.1381\n",
      "Replay buffer size: 5289\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.0573\n",
      "Average policy_loss: 0.9230\n",
      "Average value_loss: 0.1343\n",
      "Replay buffer size: 5380\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.0637\n",
      "Average policy_loss: 0.9250\n",
      "Average value_loss: 0.1387\n",
      "Replay buffer size: 5469\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.0632\n",
      "Average policy_loss: 0.9259\n",
      "Average value_loss: 0.1373\n",
      "Replay buffer size: 5555\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.0630\n",
      "Average policy_loss: 0.9265\n",
      "Average value_loss: 0.1365\n",
      "Replay buffer size: 5641\n",
      "Time taken: 40.0s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.0563\n",
      "Average policy_loss: 0.9224\n",
      "Average value_loss: 0.1339\n",
      "Replay buffer size: 5727\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.0568\n",
      "Average policy_loss: 0.9214\n",
      "Average value_loss: 0.1355\n",
      "Replay buffer size: 5821\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.0623\n",
      "Average policy_loss: 0.9261\n",
      "Average value_loss: 0.1362\n",
      "Replay buffer size: 5909\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.0606\n",
      "Average policy_loss: 0.9252\n",
      "Average value_loss: 0.1354\n",
      "Replay buffer size: 5999\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.0527\n",
      "Average policy_loss: 0.9186\n",
      "Average value_loss: 0.1341\n",
      "Replay buffer size: 6089\n",
      "Time taken: 43.2s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.0542\n",
      "Average policy_loss: 0.9206\n",
      "Average value_loss: 0.1336\n",
      "Replay buffer size: 6177\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.0516\n",
      "Average policy_loss: 0.9188\n",
      "Average value_loss: 0.1327\n",
      "Replay buffer size: 6270\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.0537\n",
      "Average policy_loss: 0.9190\n",
      "Average value_loss: 0.1346\n",
      "Replay buffer size: 6353\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.0521\n",
      "Average policy_loss: 0.9169\n",
      "Average value_loss: 0.1352\n",
      "Replay buffer size: 6435\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.0467\n",
      "Average policy_loss: 0.9144\n",
      "Average value_loss: 0.1323\n",
      "Replay buffer size: 6527\n",
      "Time taken: 42.0s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.0528\n",
      "Average policy_loss: 0.9166\n",
      "Average value_loss: 0.1362\n",
      "Replay buffer size: 6605\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.0579\n",
      "Average policy_loss: 0.9219\n",
      "Average value_loss: 0.1360\n",
      "Replay buffer size: 6690\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.0605\n",
      "Average policy_loss: 0.9247\n",
      "Average value_loss: 0.1358\n",
      "Replay buffer size: 6776\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.0565\n",
      "Average policy_loss: 0.9210\n",
      "Average value_loss: 0.1355\n",
      "Replay buffer size: 6869\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.0566\n",
      "Average policy_loss: 0.9192\n",
      "Average value_loss: 0.1374\n",
      "Replay buffer size: 6963\n",
      "Time taken: 41.9s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.0569\n",
      "Average policy_loss: 0.9218\n",
      "Average value_loss: 0.1351\n",
      "Replay buffer size: 7044\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.0507\n",
      "Average policy_loss: 0.9156\n",
      "Average value_loss: 0.1351\n",
      "Replay buffer size: 7134\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.0554\n",
      "Average policy_loss: 0.9193\n",
      "Average value_loss: 0.1361\n",
      "Replay buffer size: 7222\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.0591\n",
      "Average policy_loss: 0.9213\n",
      "Average value_loss: 0.1378\n",
      "Replay buffer size: 7309\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.0507\n",
      "Average policy_loss: 0.9117\n",
      "Average value_loss: 0.1389\n",
      "Replay buffer size: 7401\n",
      "Time taken: 43.2s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.0566\n",
      "Average policy_loss: 0.9172\n",
      "Average value_loss: 0.1394\n",
      "Replay buffer size: 7491\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.0524\n",
      "Average policy_loss: 0.9142\n",
      "Average value_loss: 0.1382\n",
      "Replay buffer size: 7583\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.0517\n",
      "Average policy_loss: 0.9132\n",
      "Average value_loss: 0.1386\n",
      "Replay buffer size: 7669\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.0491\n",
      "Average policy_loss: 0.9111\n",
      "Average value_loss: 0.1380\n",
      "Replay buffer size: 7761\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.0475\n",
      "Average policy_loss: 0.9102\n",
      "Average value_loss: 0.1373\n",
      "Replay buffer size: 7853\n",
      "Time taken: 41.4s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.0438\n",
      "Average policy_loss: 0.9065\n",
      "Average value_loss: 0.1373\n",
      "Replay buffer size: 7950\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.0414\n",
      "Average policy_loss: 0.9059\n",
      "Average value_loss: 0.1354\n",
      "Replay buffer size: 8043\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.0461\n",
      "Average policy_loss: 0.9090\n",
      "Average value_loss: 0.1371\n",
      "Replay buffer size: 8127\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.0464\n",
      "Average policy_loss: 0.9100\n",
      "Average value_loss: 0.1364\n",
      "Replay buffer size: 8213\n",
      "Time taken: 12.6s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.0363\n",
      "Average policy_loss: 0.9024\n",
      "Average value_loss: 0.1339\n",
      "Replay buffer size: 8310\n",
      "Time taken: 42.1s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.0348\n",
      "Average policy_loss: 0.8998\n",
      "Average value_loss: 0.1350\n",
      "Replay buffer size: 8399\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.0392\n",
      "Average policy_loss: 0.9036\n",
      "Average value_loss: 0.1356\n",
      "Replay buffer size: 8482\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.0406\n",
      "Average policy_loss: 0.9065\n",
      "Average value_loss: 0.1341\n",
      "Replay buffer size: 8578\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.0339\n",
      "Average policy_loss: 0.8998\n",
      "Average value_loss: 0.1341\n",
      "Replay buffer size: 8667\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.0365\n",
      "Average policy_loss: 0.9037\n",
      "Average value_loss: 0.1328\n",
      "Replay buffer size: 8748\n",
      "Time taken: 41.9s\n",
      "\n",
      "Training complete! Total time: 0.5h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>iteration_time</td><td>▁▁▇▁▁▁▁▂█▁▁▇▁▂▇▁▁▁▁▁▁▁▁█▁▇▁▇▁▇▁▁▇▁▇▇▁▁▁▇</td></tr><tr><td>loss</td><td>█▅▄▄▄▄▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▂▃█▄▄▄▅▃▂▃▁▅▇▃▆▆▆▅▇▇▇▆▄▃▅▅▆▆▆▆▄▇▃▄▆▆▇██▄</td></tr><tr><td>policy_loss</td><td>███▇▇▅▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▅▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.2</td></tr><tr><td>buffer_size</td><td>8748</td></tr><tr><td>iteration_time</td><td>41.92131</td></tr><tr><td>loss</td><td>1.03647</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>81</td></tr><tr><td>policy_loss</td><td>0.90368</td></tr><tr><td>total_time_hours</td><td>0.52395</td></tr><tr><td>value_loss</td><td>0.13279</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">daily-sweep-30</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/10qsugl9' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/10qsugl9</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 16 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_152553-10qsugl9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rhoncaaa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.004629519546244667\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: tiny\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.32978566188767966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0004577065567619913\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_155728-rhoncaaa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/rhoncaaa' target=\"_blank\">blooming-sweep-31</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/rhoncaaa' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/rhoncaaa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.5976\n",
      "Average policy_loss: 0.9821\n",
      "Average value_loss: 0.6156\n",
      "Replay buffer size: 88\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.3040\n",
      "Average policy_loss: 1.0403\n",
      "Average value_loss: 0.2638\n",
      "Replay buffer size: 177\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.3654\n",
      "Average policy_loss: 1.0353\n",
      "Average value_loss: 0.3301\n",
      "Replay buffer size: 253\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.3271\n",
      "Average policy_loss: 1.0106\n",
      "Average value_loss: 0.3165\n",
      "Replay buffer size: 322\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.2373\n",
      "Average policy_loss: 0.9566\n",
      "Average value_loss: 0.2808\n",
      "Replay buffer size: 401\n",
      "Time taken: 31.2s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.1864\n",
      "Average policy_loss: 0.9325\n",
      "Average value_loss: 0.2539\n",
      "Replay buffer size: 475\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.1391\n",
      "Average policy_loss: 0.9036\n",
      "Average value_loss: 0.2355\n",
      "Replay buffer size: 549\n",
      "Time taken: 6.9s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.1070\n",
      "Average policy_loss: 0.8947\n",
      "Average value_loss: 0.2123\n",
      "Replay buffer size: 622\n",
      "Time taken: 6.9s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.0664\n",
      "Average policy_loss: 0.8691\n",
      "Average value_loss: 0.1973\n",
      "Replay buffer size: 694\n",
      "Time taken: 6.5s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.0340\n",
      "Average policy_loss: 0.8519\n",
      "Average value_loss: 0.1821\n",
      "Replay buffer size: 766\n",
      "Time taken: 23.8s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.0093\n",
      "Average policy_loss: 0.8328\n",
      "Average value_loss: 0.1764\n",
      "Replay buffer size: 846\n",
      "Time taken: 7.1s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.9902\n",
      "Average policy_loss: 0.8279\n",
      "Average value_loss: 0.1623\n",
      "Replay buffer size: 920\n",
      "Time taken: 7.3s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.9607\n",
      "Average policy_loss: 0.8078\n",
      "Average value_loss: 0.1529\n",
      "Replay buffer size: 988\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.9389\n",
      "Average policy_loss: 0.7938\n",
      "Average value_loss: 0.1450\n",
      "Replay buffer size: 1056\n",
      "Time taken: 6.1s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.9527\n",
      "Average policy_loss: 0.7996\n",
      "Average value_loss: 0.1531\n",
      "Replay buffer size: 1133\n",
      "Time taken: 24.8s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.9470\n",
      "Average policy_loss: 0.7976\n",
      "Average value_loss: 0.1494\n",
      "Replay buffer size: 1209\n",
      "Time taken: 7.1s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.9203\n",
      "Average policy_loss: 0.7807\n",
      "Average value_loss: 0.1397\n",
      "Replay buffer size: 1279\n",
      "Time taken: 6.0s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.9193\n",
      "Average policy_loss: 0.7759\n",
      "Average value_loss: 0.1434\n",
      "Replay buffer size: 1359\n",
      "Time taken: 5.9s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.9024\n",
      "Average policy_loss: 0.7642\n",
      "Average value_loss: 0.1382\n",
      "Replay buffer size: 1433\n",
      "Time taken: 6.5s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.8863\n",
      "Average policy_loss: 0.7544\n",
      "Average value_loss: 0.1319\n",
      "Replay buffer size: 1501\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.8761\n",
      "Average policy_loss: 0.7499\n",
      "Average value_loss: 0.1262\n",
      "Replay buffer size: 1569\n",
      "Time taken: 5.6s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.8781\n",
      "Average policy_loss: 0.7498\n",
      "Average value_loss: 0.1284\n",
      "Replay buffer size: 1644\n",
      "Time taken: 5.9s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.8725\n",
      "Average policy_loss: 0.7436\n",
      "Average value_loss: 0.1289\n",
      "Replay buffer size: 1715\n",
      "Time taken: 6.3s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.8793\n",
      "Average policy_loss: 0.7409\n",
      "Average value_loss: 0.1385\n",
      "Replay buffer size: 1784\n",
      "Time taken: 6.3s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.8633\n",
      "Average policy_loss: 0.7319\n",
      "Average value_loss: 0.1314\n",
      "Replay buffer size: 1854\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.8579\n",
      "Average policy_loss: 0.7298\n",
      "Average value_loss: 0.1281\n",
      "Replay buffer size: 1934\n",
      "Time taken: 6.1s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 65 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.8586\n",
      "Average policy_loss: 0.7262\n",
      "Average value_loss: 0.1324\n",
      "Replay buffer size: 1999\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.8567\n",
      "Average policy_loss: 0.7232\n",
      "Average value_loss: 0.1335\n",
      "Replay buffer size: 2070\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.8623\n",
      "Average policy_loss: 0.7236\n",
      "Average value_loss: 0.1387\n",
      "Replay buffer size: 2151\n",
      "Time taken: 6.3s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.8632\n",
      "Average policy_loss: 0.7287\n",
      "Average value_loss: 0.1345\n",
      "Replay buffer size: 2227\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.8551\n",
      "Average policy_loss: 0.7273\n",
      "Average value_loss: 0.1278\n",
      "Replay buffer size: 2301\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.8565\n",
      "Average policy_loss: 0.7260\n",
      "Average value_loss: 0.1305\n",
      "Replay buffer size: 2377\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.8615\n",
      "Average policy_loss: 0.7311\n",
      "Average value_loss: 0.1304\n",
      "Replay buffer size: 2448\n",
      "Time taken: 6.6s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.8569\n",
      "Average policy_loss: 0.7199\n",
      "Average value_loss: 0.1370\n",
      "Replay buffer size: 2519\n",
      "Time taken: 5.6s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.8498\n",
      "Average policy_loss: 0.7182\n",
      "Average value_loss: 0.1316\n",
      "Replay buffer size: 2595\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.8355\n",
      "Average policy_loss: 0.7087\n",
      "Average value_loss: 0.1268\n",
      "Replay buffer size: 2671\n",
      "Time taken: 6.0s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.8378\n",
      "Average policy_loss: 0.7100\n",
      "Average value_loss: 0.1277\n",
      "Replay buffer size: 2739\n",
      "Time taken: 6.4s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 62 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.8204\n",
      "Average policy_loss: 0.7038\n",
      "Average value_loss: 0.1165\n",
      "Replay buffer size: 2801\n",
      "Time taken: 6.6s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.8345\n",
      "Average policy_loss: 0.7145\n",
      "Average value_loss: 0.1199\n",
      "Replay buffer size: 2871\n",
      "Time taken: 6.7s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.8286\n",
      "Average policy_loss: 0.7088\n",
      "Average value_loss: 0.1198\n",
      "Replay buffer size: 2943\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.8220\n",
      "Average policy_loss: 0.7057\n",
      "Average value_loss: 0.1163\n",
      "Replay buffer size: 3015\n",
      "Time taken: 6.3s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.8157\n",
      "Average policy_loss: 0.7012\n",
      "Average value_loss: 0.1145\n",
      "Replay buffer size: 3085\n",
      "Time taken: 6.6s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.8195\n",
      "Average policy_loss: 0.7050\n",
      "Average value_loss: 0.1145\n",
      "Replay buffer size: 3157\n",
      "Time taken: 6.3s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.8166\n",
      "Average policy_loss: 0.7032\n",
      "Average value_loss: 0.1134\n",
      "Replay buffer size: 3225\n",
      "Time taken: 5.5s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.8061\n",
      "Average policy_loss: 0.6930\n",
      "Average value_loss: 0.1131\n",
      "Replay buffer size: 3294\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.8039\n",
      "Average policy_loss: 0.6933\n",
      "Average value_loss: 0.1106\n",
      "Replay buffer size: 3366\n",
      "Time taken: 5.7s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.8046\n",
      "Average policy_loss: 0.6987\n",
      "Average value_loss: 0.1058\n",
      "Replay buffer size: 3436\n",
      "Time taken: 6.3s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.8045\n",
      "Average policy_loss: 0.6964\n",
      "Average value_loss: 0.1081\n",
      "Replay buffer size: 3516\n",
      "Time taken: 5.2s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.7929\n",
      "Average policy_loss: 0.6901\n",
      "Average value_loss: 0.1028\n",
      "Replay buffer size: 3596\n",
      "Time taken: 5.3s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.7977\n",
      "Average policy_loss: 0.6912\n",
      "Average value_loss: 0.1066\n",
      "Replay buffer size: 3672\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.7843\n",
      "Average policy_loss: 0.6823\n",
      "Average value_loss: 0.1020\n",
      "Replay buffer size: 3742\n",
      "Time taken: 5.6s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.7871\n",
      "Average policy_loss: 0.6823\n",
      "Average value_loss: 0.1048\n",
      "Replay buffer size: 3819\n",
      "Time taken: 6.0s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.7925\n",
      "Average policy_loss: 0.6867\n",
      "Average value_loss: 0.1058\n",
      "Replay buffer size: 3887\n",
      "Time taken: 6.3s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.7860\n",
      "Average policy_loss: 0.6851\n",
      "Average value_loss: 0.1009\n",
      "Replay buffer size: 3955\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 40.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.7853\n",
      "Average policy_loss: 0.6859\n",
      "Average value_loss: 0.0994\n",
      "Replay buffer size: 4029\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.7823\n",
      "Average policy_loss: 0.6793\n",
      "Average value_loss: 0.1030\n",
      "Replay buffer size: 4103\n",
      "Time taken: 5.9s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.7893\n",
      "Average policy_loss: 0.6865\n",
      "Average value_loss: 0.1028\n",
      "Replay buffer size: 4176\n",
      "Time taken: 5.3s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.7991\n",
      "Average policy_loss: 0.6900\n",
      "Average value_loss: 0.1091\n",
      "Replay buffer size: 4255\n",
      "Time taken: 6.5s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.7912\n",
      "Average policy_loss: 0.6832\n",
      "Average value_loss: 0.1080\n",
      "Replay buffer size: 4325\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.7820\n",
      "Average policy_loss: 0.6795\n",
      "Average value_loss: 0.1025\n",
      "Replay buffer size: 4401\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.7869\n",
      "Average policy_loss: 0.6812\n",
      "Average value_loss: 0.1057\n",
      "Replay buffer size: 4477\n",
      "Time taken: 5.3s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.7753\n",
      "Average policy_loss: 0.6765\n",
      "Average value_loss: 0.0988\n",
      "Replay buffer size: 4545\n",
      "Time taken: 4.6s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.7683\n",
      "Average policy_loss: 0.6686\n",
      "Average value_loss: 0.0997\n",
      "Replay buffer size: 4615\n",
      "Time taken: 5.3s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.7674\n",
      "Average policy_loss: 0.6718\n",
      "Average value_loss: 0.0956\n",
      "Replay buffer size: 4687\n",
      "Time taken: 5.6s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.7681\n",
      "Average policy_loss: 0.6727\n",
      "Average value_loss: 0.0954\n",
      "Replay buffer size: 4759\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.7638\n",
      "Average policy_loss: 0.6686\n",
      "Average value_loss: 0.0952\n",
      "Replay buffer size: 4835\n",
      "Time taken: 4.8s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.7568\n",
      "Average policy_loss: 0.6639\n",
      "Average value_loss: 0.0929\n",
      "Replay buffer size: 4909\n",
      "Time taken: 4.5s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.7621\n",
      "Average policy_loss: 0.6693\n",
      "Average value_loss: 0.0927\n",
      "Replay buffer size: 4981\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.7565\n",
      "Average policy_loss: 0.6664\n",
      "Average value_loss: 0.0901\n",
      "Replay buffer size: 5051\n",
      "Time taken: 4.6s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.7494\n",
      "Average policy_loss: 0.6608\n",
      "Average value_loss: 0.0885\n",
      "Replay buffer size: 5121\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.7413\n",
      "Average policy_loss: 0.6570\n",
      "Average value_loss: 0.0843\n",
      "Replay buffer size: 5195\n",
      "Time taken: 5.4s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.7501\n",
      "Average policy_loss: 0.6587\n",
      "Average value_loss: 0.0914\n",
      "Replay buffer size: 5267\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.7418\n",
      "Average policy_loss: 0.6558\n",
      "Average value_loss: 0.0860\n",
      "Replay buffer size: 5337\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.7474\n",
      "Average policy_loss: 0.6627\n",
      "Average value_loss: 0.0846\n",
      "Replay buffer size: 5407\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.7455\n",
      "Average policy_loss: 0.6625\n",
      "Average value_loss: 0.0830\n",
      "Replay buffer size: 5471\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.7398\n",
      "Average policy_loss: 0.6528\n",
      "Average value_loss: 0.0871\n",
      "Replay buffer size: 5539\n",
      "Time taken: 4.3s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.7391\n",
      "Average policy_loss: 0.6533\n",
      "Average value_loss: 0.0858\n",
      "Replay buffer size: 5613\n",
      "Time taken: 4.8s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.7449\n",
      "Average policy_loss: 0.6618\n",
      "Average value_loss: 0.0832\n",
      "Replay buffer size: 5681\n",
      "Time taken: 4.9s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.7413\n",
      "Average policy_loss: 0.6567\n",
      "Average value_loss: 0.0846\n",
      "Replay buffer size: 5755\n",
      "Time taken: 5.2s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.7274\n",
      "Average policy_loss: 0.6479\n",
      "Average value_loss: 0.0795\n",
      "Replay buffer size: 5829\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.7250\n",
      "Average policy_loss: 0.6484\n",
      "Average value_loss: 0.0766\n",
      "Replay buffer size: 5903\n",
      "Time taken: 5.8s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.7348\n",
      "Average policy_loss: 0.6549\n",
      "Average value_loss: 0.0799\n",
      "Replay buffer size: 5973\n",
      "Time taken: 5.6s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.7303\n",
      "Average policy_loss: 0.6531\n",
      "Average value_loss: 0.0772\n",
      "Replay buffer size: 6051\n",
      "Time taken: 5.9s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.7270\n",
      "Average policy_loss: 0.6471\n",
      "Average value_loss: 0.0799\n",
      "Replay buffer size: 6123\n",
      "Time taken: 5.4s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.7172\n",
      "Average policy_loss: 0.6415\n",
      "Average value_loss: 0.0757\n",
      "Replay buffer size: 6191\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.7374\n",
      "Average policy_loss: 0.6530\n",
      "Average value_loss: 0.0844\n",
      "Replay buffer size: 6264\n",
      "Time taken: 5.4s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.7276\n",
      "Average policy_loss: 0.6471\n",
      "Average value_loss: 0.0805\n",
      "Replay buffer size: 6334\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.7191\n",
      "Average policy_loss: 0.6395\n",
      "Average value_loss: 0.0796\n",
      "Replay buffer size: 6410\n",
      "Time taken: 5.6s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.7267\n",
      "Average policy_loss: 0.6501\n",
      "Average value_loss: 0.0766\n",
      "Replay buffer size: 6480\n",
      "Time taken: 5.7s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.7304\n",
      "Average policy_loss: 0.6491\n",
      "Average value_loss: 0.0812\n",
      "Replay buffer size: 6549\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.7264\n",
      "Average policy_loss: 0.6484\n",
      "Average value_loss: 0.0780\n",
      "Replay buffer size: 6623\n",
      "Time taken: 5.3s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.7232\n",
      "Average policy_loss: 0.6471\n",
      "Average value_loss: 0.0761\n",
      "Replay buffer size: 6699\n",
      "Time taken: 5.9s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.7247\n",
      "Average policy_loss: 0.6473\n",
      "Average value_loss: 0.0774\n",
      "Replay buffer size: 6769\n",
      "Time taken: 4.9s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.7146\n",
      "Average policy_loss: 0.6420\n",
      "Average value_loss: 0.0726\n",
      "Replay buffer size: 6835\n",
      "Time taken: 4.9s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.7165\n",
      "Average policy_loss: 0.6432\n",
      "Average value_loss: 0.0734\n",
      "Replay buffer size: 6907\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.7062\n",
      "Average policy_loss: 0.6362\n",
      "Average value_loss: 0.0700\n",
      "Replay buffer size: 6977\n",
      "Time taken: 4.9s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.7040\n",
      "Average policy_loss: 0.6349\n",
      "Average value_loss: 0.0691\n",
      "Replay buffer size: 7049\n",
      "Time taken: 5.1s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.7211\n",
      "Average policy_loss: 0.6495\n",
      "Average value_loss: 0.0716\n",
      "Replay buffer size: 7125\n",
      "Time taken: 4.7s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.7151\n",
      "Average policy_loss: 0.6423\n",
      "Average value_loss: 0.0728\n",
      "Replay buffer size: 7195\n",
      "Time taken: 5.2s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.7058\n",
      "Average policy_loss: 0.6357\n",
      "Average value_loss: 0.0701\n",
      "Replay buffer size: 7263\n",
      "Time taken: 20.1s\n",
      "\n",
      "Training complete! Total time: 0.3h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>iteration_time</td><td>█▂▆▂▂▂▆▁▁▅▂▆▂▂▂▆▁▁▅▁▅▁▁▁▁▁▁▅▁▁▁▁▅▁▅▁▁▁▁▁</td></tr><tr><td>loss</td><td>██▇▆▅▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>█▄▃▃▃▂▅▄▂▄▅▁▃▄▃▄▂▂▂▂▂▂▅▂▄▂▄▄▂▃▂▂▄▂▅▂▄▂▄▂</td></tr><tr><td>policy_loss</td><td>▇██▇▇▆▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.3</td></tr><tr><td>buffer_size</td><td>7263</td></tr><tr><td>iteration_time</td><td>20.13669</td></tr><tr><td>loss</td><td>0.70583</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>68</td></tr><tr><td>policy_loss</td><td>0.63569</td></tr><tr><td>total_time_hours</td><td>0.25518</td></tr><tr><td>value_loss</td><td>0.07014</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">blooming-sweep-31</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/rhoncaaa' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/rhoncaaa</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_155728-rhoncaaa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1f3f9wiy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008878857214719207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.9520662692903116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0390967120950752\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_161253-1f3f9wiy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1f3f9wiy' target=\"_blank\">hopeful-sweep-32</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1f3f9wiy' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1f3f9wiy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.4744\n",
      "Average policy_loss: 0.8146\n",
      "Average value_loss: 0.6599\n",
      "Replay buffer size: 87\n",
      "Time taken: 8.7s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 0.9705\n",
      "Average policy_loss: 0.4430\n",
      "Average value_loss: 0.5274\n",
      "Replay buffer size: 185\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 0.7537\n",
      "Average policy_loss: 0.3918\n",
      "Average value_loss: 0.3619\n",
      "Replay buffer size: 282\n",
      "Time taken: 7.6s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.6205\n",
      "Average policy_loss: 0.3468\n",
      "Average value_loss: 0.2737\n",
      "Replay buffer size: 382\n",
      "Time taken: 6.7s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.5983\n",
      "Average policy_loss: 0.3498\n",
      "Average value_loss: 0.2485\n",
      "Replay buffer size: 482\n",
      "Time taken: 25.1s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.5589\n",
      "Average policy_loss: 0.3333\n",
      "Average value_loss: 0.2256\n",
      "Replay buffer size: 580\n",
      "Time taken: 6.9s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.5410\n",
      "Average policy_loss: 0.3292\n",
      "Average value_loss: 0.2118\n",
      "Replay buffer size: 676\n",
      "Time taken: 6.8s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.5302\n",
      "Average policy_loss: 0.3255\n",
      "Average value_loss: 0.2047\n",
      "Replay buffer size: 774\n",
      "Time taken: 7.5s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.5108\n",
      "Average policy_loss: 0.3200\n",
      "Average value_loss: 0.1908\n",
      "Replay buffer size: 873\n",
      "Time taken: 7.2s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.5294\n",
      "Average policy_loss: 0.3633\n",
      "Average value_loss: 0.1661\n",
      "Replay buffer size: 960\n",
      "Time taken: 29.3s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.4856\n",
      "Average policy_loss: 0.3866\n",
      "Average value_loss: 0.0990\n",
      "Replay buffer size: 1040\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.5295\n",
      "Average policy_loss: 0.4260\n",
      "Average value_loss: 0.1035\n",
      "Replay buffer size: 1118\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.5502\n",
      "Average policy_loss: 0.4524\n",
      "Average value_loss: 0.0978\n",
      "Replay buffer size: 1188\n",
      "Time taken: 8.5s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.5624\n",
      "Average policy_loss: 0.4697\n",
      "Average value_loss: 0.0927\n",
      "Replay buffer size: 1264\n",
      "Time taken: 9.4s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.5933\n",
      "Average policy_loss: 0.4966\n",
      "Average value_loss: 0.0967\n",
      "Replay buffer size: 1339\n",
      "Time taken: 33.5s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.6006\n",
      "Average policy_loss: 0.5079\n",
      "Average value_loss: 0.0927\n",
      "Replay buffer size: 1413\n",
      "Time taken: 9.8s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.6172\n",
      "Average policy_loss: 0.5219\n",
      "Average value_loss: 0.0953\n",
      "Replay buffer size: 1484\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.6280\n",
      "Average policy_loss: 0.5326\n",
      "Average value_loss: 0.0954\n",
      "Replay buffer size: 1552\n",
      "Time taken: 9.5s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.6297\n",
      "Average policy_loss: 0.5409\n",
      "Average value_loss: 0.0888\n",
      "Replay buffer size: 1630\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.6353\n",
      "Average policy_loss: 0.5451\n",
      "Average value_loss: 0.0902\n",
      "Replay buffer size: 1703\n",
      "Time taken: 31.2s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.6445\n",
      "Average policy_loss: 0.5563\n",
      "Average value_loss: 0.0882\n",
      "Replay buffer size: 1773\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.6472\n",
      "Average policy_loss: 0.5637\n",
      "Average value_loss: 0.0835\n",
      "Replay buffer size: 1848\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.6520\n",
      "Average policy_loss: 0.5664\n",
      "Average value_loss: 0.0856\n",
      "Replay buffer size: 1925\n",
      "Time taken: 8.8s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.6542\n",
      "Average policy_loss: 0.5705\n",
      "Average value_loss: 0.0837\n",
      "Replay buffer size: 2001\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.6639\n",
      "Average policy_loss: 0.5798\n",
      "Average value_loss: 0.0841\n",
      "Replay buffer size: 2073\n",
      "Time taken: 29.3s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.6709\n",
      "Average policy_loss: 0.5850\n",
      "Average value_loss: 0.0859\n",
      "Replay buffer size: 2144\n",
      "Time taken: 9.4s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.6761\n",
      "Average policy_loss: 0.5889\n",
      "Average value_loss: 0.0872\n",
      "Replay buffer size: 2225\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.6808\n",
      "Average policy_loss: 0.5938\n",
      "Average value_loss: 0.0870\n",
      "Replay buffer size: 2291\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.6900\n",
      "Average policy_loss: 0.5966\n",
      "Average value_loss: 0.0934\n",
      "Replay buffer size: 2362\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.6913\n",
      "Average policy_loss: 0.6020\n",
      "Average value_loss: 0.0893\n",
      "Replay buffer size: 2434\n",
      "Time taken: 30.0s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.7000\n",
      "Average policy_loss: 0.6079\n",
      "Average value_loss: 0.0921\n",
      "Replay buffer size: 2505\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.7086\n",
      "Average policy_loss: 0.6131\n",
      "Average value_loss: 0.0955\n",
      "Replay buffer size: 2579\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.7105\n",
      "Average policy_loss: 0.6141\n",
      "Average value_loss: 0.0964\n",
      "Replay buffer size: 2649\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.7067\n",
      "Average policy_loss: 0.6154\n",
      "Average value_loss: 0.0913\n",
      "Replay buffer size: 2719\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.7173\n",
      "Average policy_loss: 0.6215\n",
      "Average value_loss: 0.0958\n",
      "Replay buffer size: 2799\n",
      "Time taken: 30.6s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.7214\n",
      "Average policy_loss: 0.6223\n",
      "Average value_loss: 0.0991\n",
      "Replay buffer size: 2883\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.7209\n",
      "Average policy_loss: 0.6252\n",
      "Average value_loss: 0.0957\n",
      "Replay buffer size: 2959\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.7276\n",
      "Average policy_loss: 0.6273\n",
      "Average value_loss: 0.1004\n",
      "Replay buffer size: 3032\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.7343\n",
      "Average policy_loss: 0.6290\n",
      "Average value_loss: 0.1053\n",
      "Replay buffer size: 3109\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.7298\n",
      "Average policy_loss: 0.6277\n",
      "Average value_loss: 0.1021\n",
      "Replay buffer size: 3187\n",
      "Time taken: 30.9s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.7312\n",
      "Average policy_loss: 0.6320\n",
      "Average value_loss: 0.0992\n",
      "Replay buffer size: 3267\n",
      "Time taken: 9.4s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.7316\n",
      "Average policy_loss: 0.6329\n",
      "Average value_loss: 0.0987\n",
      "Replay buffer size: 3339\n",
      "Time taken: 8.6s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.7349\n",
      "Average policy_loss: 0.6352\n",
      "Average value_loss: 0.0997\n",
      "Replay buffer size: 3418\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.7294\n",
      "Average policy_loss: 0.6334\n",
      "Average value_loss: 0.0961\n",
      "Replay buffer size: 3490\n",
      "Time taken: 8.1s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.7296\n",
      "Average policy_loss: 0.6337\n",
      "Average value_loss: 0.0960\n",
      "Replay buffer size: 3564\n",
      "Time taken: 30.9s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.7343\n",
      "Average policy_loss: 0.6373\n",
      "Average value_loss: 0.0970\n",
      "Replay buffer size: 3635\n",
      "Time taken: 8.7s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.7417\n",
      "Average policy_loss: 0.6410\n",
      "Average value_loss: 0.1007\n",
      "Replay buffer size: 3712\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.7376\n",
      "Average policy_loss: 0.6394\n",
      "Average value_loss: 0.0982\n",
      "Replay buffer size: 3782\n",
      "Time taken: 8.8s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.7370\n",
      "Average policy_loss: 0.6377\n",
      "Average value_loss: 0.0993\n",
      "Replay buffer size: 3855\n",
      "Time taken: 9.7s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.7372\n",
      "Average policy_loss: 0.6406\n",
      "Average value_loss: 0.0965\n",
      "Replay buffer size: 3929\n",
      "Time taken: 31.0s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.7380\n",
      "Average policy_loss: 0.6416\n",
      "Average value_loss: 0.0964\n",
      "Replay buffer size: 4001\n",
      "Time taken: 7.6s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.7363\n",
      "Average policy_loss: 0.6404\n",
      "Average value_loss: 0.0958\n",
      "Replay buffer size: 4073\n",
      "Time taken: 7.6s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.7359\n",
      "Average policy_loss: 0.6434\n",
      "Average value_loss: 0.0925\n",
      "Replay buffer size: 4147\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.7298\n",
      "Average policy_loss: 0.6374\n",
      "Average value_loss: 0.0924\n",
      "Replay buffer size: 4225\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.7278\n",
      "Average policy_loss: 0.6378\n",
      "Average value_loss: 0.0901\n",
      "Replay buffer size: 4301\n",
      "Time taken: 31.1s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.7310\n",
      "Average policy_loss: 0.6397\n",
      "Average value_loss: 0.0913\n",
      "Replay buffer size: 4369\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.7395\n",
      "Average policy_loss: 0.6481\n",
      "Average value_loss: 0.0914\n",
      "Replay buffer size: 4439\n",
      "Time taken: 9.5s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.7321\n",
      "Average policy_loss: 0.6409\n",
      "Average value_loss: 0.0912\n",
      "Replay buffer size: 4507\n",
      "Time taken: 8.7s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.7340\n",
      "Average policy_loss: 0.6455\n",
      "Average value_loss: 0.0885\n",
      "Replay buffer size: 4582\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.7380\n",
      "Average policy_loss: 0.6480\n",
      "Average value_loss: 0.0900\n",
      "Replay buffer size: 4653\n",
      "Time taken: 31.3s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.7421\n",
      "Average policy_loss: 0.6494\n",
      "Average value_loss: 0.0927\n",
      "Replay buffer size: 4729\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.7335\n",
      "Average policy_loss: 0.6442\n",
      "Average value_loss: 0.0893\n",
      "Replay buffer size: 4799\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.7364\n",
      "Average policy_loss: 0.6478\n",
      "Average value_loss: 0.0885\n",
      "Replay buffer size: 4867\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.7401\n",
      "Average policy_loss: 0.6521\n",
      "Average value_loss: 0.0880\n",
      "Replay buffer size: 4941\n",
      "Time taken: 8.5s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.7355\n",
      "Average policy_loss: 0.6477\n",
      "Average value_loss: 0.0878\n",
      "Replay buffer size: 5013\n",
      "Time taken: 31.3s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.7349\n",
      "Average policy_loss: 0.6476\n",
      "Average value_loss: 0.0872\n",
      "Replay buffer size: 5088\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.7402\n",
      "Average policy_loss: 0.6519\n",
      "Average value_loss: 0.0882\n",
      "Replay buffer size: 5165\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.7404\n",
      "Average policy_loss: 0.6519\n",
      "Average value_loss: 0.0886\n",
      "Replay buffer size: 5239\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.7394\n",
      "Average policy_loss: 0.6528\n",
      "Average value_loss: 0.0866\n",
      "Replay buffer size: 5307\n",
      "Time taken: 8.7s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.7347\n",
      "Average policy_loss: 0.6470\n",
      "Average value_loss: 0.0877\n",
      "Replay buffer size: 5375\n",
      "Time taken: 31.6s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.7377\n",
      "Average policy_loss: 0.6502\n",
      "Average value_loss: 0.0875\n",
      "Replay buffer size: 5445\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.7435\n",
      "Average policy_loss: 0.6539\n",
      "Average value_loss: 0.0896\n",
      "Replay buffer size: 5522\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.7376\n",
      "Average policy_loss: 0.6515\n",
      "Average value_loss: 0.0861\n",
      "Replay buffer size: 5598\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.7343\n",
      "Average policy_loss: 0.6478\n",
      "Average value_loss: 0.0865\n",
      "Replay buffer size: 5674\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.7382\n",
      "Average policy_loss: 0.6502\n",
      "Average value_loss: 0.0880\n",
      "Replay buffer size: 5744\n",
      "Time taken: 31.3s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.7397\n",
      "Average policy_loss: 0.6527\n",
      "Average value_loss: 0.0870\n",
      "Replay buffer size: 5821\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.7394\n",
      "Average policy_loss: 0.6533\n",
      "Average value_loss: 0.0861\n",
      "Replay buffer size: 5903\n",
      "Time taken: 8.3s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.7410\n",
      "Average policy_loss: 0.6527\n",
      "Average value_loss: 0.0883\n",
      "Replay buffer size: 5981\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.7357\n",
      "Average policy_loss: 0.6491\n",
      "Average value_loss: 0.0866\n",
      "Replay buffer size: 6055\n",
      "Time taken: 9.4s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 64 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.7427\n",
      "Average policy_loss: 0.6562\n",
      "Average value_loss: 0.0865\n",
      "Replay buffer size: 6119\n",
      "Time taken: 30.1s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.7394\n",
      "Average policy_loss: 0.6523\n",
      "Average value_loss: 0.0871\n",
      "Replay buffer size: 6191\n",
      "Time taken: 8.8s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.7408\n",
      "Average policy_loss: 0.6558\n",
      "Average value_loss: 0.0850\n",
      "Replay buffer size: 6265\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.7372\n",
      "Average policy_loss: 0.6522\n",
      "Average value_loss: 0.0851\n",
      "Replay buffer size: 6336\n",
      "Time taken: 9.3s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.7420\n",
      "Average policy_loss: 0.6575\n",
      "Average value_loss: 0.0844\n",
      "Replay buffer size: 6410\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.7408\n",
      "Average policy_loss: 0.6553\n",
      "Average value_loss: 0.0855\n",
      "Replay buffer size: 6480\n",
      "Time taken: 29.2s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.7381\n",
      "Average policy_loss: 0.6544\n",
      "Average value_loss: 0.0837\n",
      "Replay buffer size: 6558\n",
      "Time taken: 8.7s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.7425\n",
      "Average policy_loss: 0.6587\n",
      "Average value_loss: 0.0838\n",
      "Replay buffer size: 6632\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.7403\n",
      "Average policy_loss: 0.6552\n",
      "Average value_loss: 0.0851\n",
      "Replay buffer size: 6709\n",
      "Time taken: 8.8s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.7375\n",
      "Average policy_loss: 0.6546\n",
      "Average value_loss: 0.0829\n",
      "Replay buffer size: 6785\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.7434\n",
      "Average policy_loss: 0.6573\n",
      "Average value_loss: 0.0861\n",
      "Replay buffer size: 6856\n",
      "Time taken: 31.1s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.7422\n",
      "Average policy_loss: 0.6566\n",
      "Average value_loss: 0.0856\n",
      "Replay buffer size: 6928\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.7419\n",
      "Average policy_loss: 0.6569\n",
      "Average value_loss: 0.0851\n",
      "Replay buffer size: 6996\n",
      "Time taken: 8.1s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.7433\n",
      "Average policy_loss: 0.6568\n",
      "Average value_loss: 0.0864\n",
      "Replay buffer size: 7072\n",
      "Time taken: 7.7s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.7429\n",
      "Average policy_loss: 0.6586\n",
      "Average value_loss: 0.0844\n",
      "Replay buffer size: 7150\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.7436\n",
      "Average policy_loss: 0.6589\n",
      "Average value_loss: 0.0847\n",
      "Replay buffer size: 7228\n",
      "Time taken: 28.9s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.7370\n",
      "Average policy_loss: 0.6529\n",
      "Average value_loss: 0.0841\n",
      "Replay buffer size: 7298\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.7380\n",
      "Average policy_loss: 0.6548\n",
      "Average value_loss: 0.0832\n",
      "Replay buffer size: 7370\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.7401\n",
      "Average policy_loss: 0.6577\n",
      "Average value_loss: 0.0824\n",
      "Replay buffer size: 7452\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.7420\n",
      "Average policy_loss: 0.6563\n",
      "Average value_loss: 0.0857\n",
      "Replay buffer size: 7526\n",
      "Time taken: 9.3s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.7419\n",
      "Average policy_loss: 0.6581\n",
      "Average value_loss: 0.0838\n",
      "Replay buffer size: 7598\n",
      "Time taken: 30.8s\n",
      "\n",
      "Training complete! Total time: 0.4h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>iteration_time</td><td>▂▁▁▁▆▁▂▂▂█▂▇▂▂█▂██▂▁▂█▁▁██▁█▂▂▂▂▂▁▂▂▂▁▇█</td></tr><tr><td>loss</td><td>█▄▂▂▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▅██▇▅▄▂▃▃▃▃▄▃▂▄▂▃▄▃▃▂▂▂▃▄▂▂▄▃▂▁▃▂▃▂▃▂▃▅▃</td></tr><tr><td>policy_loss</td><td>█▂▁▁▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>value_loss</td><td>█▆▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.1</td></tr><tr><td>buffer_size</td><td>7598</td></tr><tr><td>iteration_time</td><td>30.82473</td></tr><tr><td>loss</td><td>0.7419</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>72</td></tr><tr><td>policy_loss</td><td>0.65811</td></tr><tr><td>total_time_hours</td><td>0.36438</td></tr><tr><td>value_loss</td><td>0.08379</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hopeful-sweep-32</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1f3f9wiy' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1f3f9wiy</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 22 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_161253-1f3f9wiy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ffl4ob5w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0015000292643164077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.3952874363751031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.012888957366713936\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_163452-ffl4ob5w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ffl4ob5w' target=\"_blank\">summer-sweep-33</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ffl4ob5w' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ffl4ob5w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 2.9375\n",
      "Average policy_loss: 2.1361\n",
      "Average value_loss: 0.8014\n",
      "Replay buffer size: 88\n",
      "Time taken: 8.1s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.7517\n",
      "Average policy_loss: 1.2343\n",
      "Average value_loss: 0.5174\n",
      "Replay buffer size: 172\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.4744\n",
      "Average policy_loss: 1.0674\n",
      "Average value_loss: 0.4070\n",
      "Replay buffer size: 258\n",
      "Time taken: 6.9s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.4237\n",
      "Average policy_loss: 1.0310\n",
      "Average value_loss: 0.3927\n",
      "Replay buffer size: 341\n",
      "Time taken: 6.9s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.3150\n",
      "Average policy_loss: 0.9778\n",
      "Average value_loss: 0.3372\n",
      "Replay buffer size: 435\n",
      "Time taken: 28.1s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.2233\n",
      "Average policy_loss: 0.9309\n",
      "Average value_loss: 0.2924\n",
      "Replay buffer size: 531\n",
      "Time taken: 8.3s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.2138\n",
      "Average policy_loss: 0.9421\n",
      "Average value_loss: 0.2717\n",
      "Replay buffer size: 616\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.1911\n",
      "Average policy_loss: 0.9469\n",
      "Average value_loss: 0.2443\n",
      "Replay buffer size: 697\n",
      "Time taken: 9.3s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.1518\n",
      "Average policy_loss: 0.9184\n",
      "Average value_loss: 0.2334\n",
      "Replay buffer size: 782\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.1276\n",
      "Average policy_loss: 0.9088\n",
      "Average value_loss: 0.2188\n",
      "Replay buffer size: 873\n",
      "Time taken: 36.9s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.1054\n",
      "Average policy_loss: 0.8972\n",
      "Average value_loss: 0.2082\n",
      "Replay buffer size: 963\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.0711\n",
      "Average policy_loss: 0.8764\n",
      "Average value_loss: 0.1947\n",
      "Replay buffer size: 1055\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.0336\n",
      "Average policy_loss: 0.8498\n",
      "Average value_loss: 0.1838\n",
      "Replay buffer size: 1150\n",
      "Time taken: 11.2s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.0141\n",
      "Average policy_loss: 0.8381\n",
      "Average value_loss: 0.1760\n",
      "Replay buffer size: 1238\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.0329\n",
      "Average policy_loss: 0.8495\n",
      "Average value_loss: 0.1834\n",
      "Replay buffer size: 1322\n",
      "Time taken: 40.6s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.0092\n",
      "Average policy_loss: 0.8291\n",
      "Average value_loss: 0.1801\n",
      "Replay buffer size: 1408\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.9822\n",
      "Average policy_loss: 0.8168\n",
      "Average value_loss: 0.1654\n",
      "Replay buffer size: 1503\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.9972\n",
      "Average policy_loss: 0.8290\n",
      "Average value_loss: 0.1682\n",
      "Replay buffer size: 1596\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.9730\n",
      "Average policy_loss: 0.8129\n",
      "Average value_loss: 0.1601\n",
      "Replay buffer size: 1689\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.9796\n",
      "Average policy_loss: 0.8144\n",
      "Average value_loss: 0.1652\n",
      "Replay buffer size: 1781\n",
      "Time taken: 41.3s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.9768\n",
      "Average policy_loss: 0.8127\n",
      "Average value_loss: 0.1640\n",
      "Replay buffer size: 1868\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.9647\n",
      "Average policy_loss: 0.8066\n",
      "Average value_loss: 0.1581\n",
      "Replay buffer size: 1958\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.9742\n",
      "Average policy_loss: 0.8148\n",
      "Average value_loss: 0.1594\n",
      "Replay buffer size: 2047\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.9744\n",
      "Average policy_loss: 0.8077\n",
      "Average value_loss: 0.1668\n",
      "Replay buffer size: 2132\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 100.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.9685\n",
      "Average policy_loss: 0.8042\n",
      "Average value_loss: 0.1642\n",
      "Replay buffer size: 2227\n",
      "Time taken: 43.0s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.9703\n",
      "Average policy_loss: 0.8067\n",
      "Average value_loss: 0.1636\n",
      "Replay buffer size: 2323\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.9732\n",
      "Average policy_loss: 0.8049\n",
      "Average value_loss: 0.1683\n",
      "Replay buffer size: 2417\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.9604\n",
      "Average policy_loss: 0.7982\n",
      "Average value_loss: 0.1622\n",
      "Replay buffer size: 2511\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.9719\n",
      "Average policy_loss: 0.8102\n",
      "Average value_loss: 0.1617\n",
      "Replay buffer size: 2607\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.9472\n",
      "Average policy_loss: 0.7870\n",
      "Average value_loss: 0.1602\n",
      "Replay buffer size: 2689\n",
      "Time taken: 44.4s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.9715\n",
      "Average policy_loss: 0.8074\n",
      "Average value_loss: 0.1641\n",
      "Replay buffer size: 2776\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.9693\n",
      "Average policy_loss: 0.8034\n",
      "Average value_loss: 0.1659\n",
      "Replay buffer size: 2863\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.9711\n",
      "Average policy_loss: 0.8023\n",
      "Average value_loss: 0.1688\n",
      "Replay buffer size: 2953\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.9661\n",
      "Average policy_loss: 0.8068\n",
      "Average value_loss: 0.1593\n",
      "Replay buffer size: 3050\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.9633\n",
      "Average policy_loss: 0.8051\n",
      "Average value_loss: 0.1582\n",
      "Replay buffer size: 3137\n",
      "Time taken: 44.4s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.9655\n",
      "Average policy_loss: 0.8102\n",
      "Average value_loss: 0.1552\n",
      "Replay buffer size: 3233\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.9532\n",
      "Average policy_loss: 0.7935\n",
      "Average value_loss: 0.1597\n",
      "Replay buffer size: 3319\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.9556\n",
      "Average policy_loss: 0.7943\n",
      "Average value_loss: 0.1613\n",
      "Replay buffer size: 3412\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.9709\n",
      "Average policy_loss: 0.8090\n",
      "Average value_loss: 0.1619\n",
      "Replay buffer size: 3497\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.9510\n",
      "Average policy_loss: 0.7895\n",
      "Average value_loss: 0.1615\n",
      "Replay buffer size: 3587\n",
      "Time taken: 45.1s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.9542\n",
      "Average policy_loss: 0.7926\n",
      "Average value_loss: 0.1616\n",
      "Replay buffer size: 3687\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.9751\n",
      "Average policy_loss: 0.8146\n",
      "Average value_loss: 0.1604\n",
      "Replay buffer size: 3778\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.9512\n",
      "Average policy_loss: 0.7946\n",
      "Average value_loss: 0.1566\n",
      "Replay buffer size: 3866\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.9654\n",
      "Average policy_loss: 0.8105\n",
      "Average value_loss: 0.1549\n",
      "Replay buffer size: 3963\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.9687\n",
      "Average policy_loss: 0.8132\n",
      "Average value_loss: 0.1555\n",
      "Replay buffer size: 4054\n",
      "Time taken: 47.0s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.9530\n",
      "Average policy_loss: 0.7996\n",
      "Average value_loss: 0.1534\n",
      "Replay buffer size: 4141\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.9709\n",
      "Average policy_loss: 0.8085\n",
      "Average value_loss: 0.1624\n",
      "Replay buffer size: 4229\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.9523\n",
      "Average policy_loss: 0.7953\n",
      "Average value_loss: 0.1570\n",
      "Replay buffer size: 4319\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.9596\n",
      "Average policy_loss: 0.7986\n",
      "Average value_loss: 0.1610\n",
      "Replay buffer size: 4408\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.9595\n",
      "Average policy_loss: 0.8022\n",
      "Average value_loss: 0.1573\n",
      "Replay buffer size: 4504\n",
      "Time taken: 46.3s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.9657\n",
      "Average policy_loss: 0.8100\n",
      "Average value_loss: 0.1557\n",
      "Replay buffer size: 4577\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.9564\n",
      "Average policy_loss: 0.7976\n",
      "Average value_loss: 0.1588\n",
      "Replay buffer size: 4667\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.9712\n",
      "Average policy_loss: 0.8117\n",
      "Average value_loss: 0.1594\n",
      "Replay buffer size: 4752\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.9530\n",
      "Average policy_loss: 0.7961\n",
      "Average value_loss: 0.1569\n",
      "Replay buffer size: 4841\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.9615\n",
      "Average policy_loss: 0.8021\n",
      "Average value_loss: 0.1594\n",
      "Replay buffer size: 4934\n",
      "Time taken: 45.0s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.9705\n",
      "Average policy_loss: 0.8146\n",
      "Average value_loss: 0.1559\n",
      "Replay buffer size: 5031\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.9512\n",
      "Average policy_loss: 0.7983\n",
      "Average value_loss: 0.1529\n",
      "Replay buffer size: 5126\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.9541\n",
      "Average policy_loss: 0.8003\n",
      "Average value_loss: 0.1538\n",
      "Replay buffer size: 5212\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.9603\n",
      "Average policy_loss: 0.8023\n",
      "Average value_loss: 0.1580\n",
      "Replay buffer size: 5303\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.9510\n",
      "Average policy_loss: 0.7893\n",
      "Average value_loss: 0.1617\n",
      "Replay buffer size: 5399\n",
      "Time taken: 42.7s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.9416\n",
      "Average policy_loss: 0.7843\n",
      "Average value_loss: 0.1573\n",
      "Replay buffer size: 5490\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.9532\n",
      "Average policy_loss: 0.7936\n",
      "Average value_loss: 0.1596\n",
      "Replay buffer size: 5576\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.9584\n",
      "Average policy_loss: 0.7952\n",
      "Average value_loss: 0.1633\n",
      "Replay buffer size: 5673\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.9635\n",
      "Average policy_loss: 0.8001\n",
      "Average value_loss: 0.1634\n",
      "Replay buffer size: 5754\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.9519\n",
      "Average policy_loss: 0.7935\n",
      "Average value_loss: 0.1584\n",
      "Replay buffer size: 5837\n",
      "Time taken: 43.5s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.9506\n",
      "Average policy_loss: 0.7934\n",
      "Average value_loss: 0.1572\n",
      "Replay buffer size: 5926\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.9559\n",
      "Average policy_loss: 0.8021\n",
      "Average value_loss: 0.1538\n",
      "Replay buffer size: 6022\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.9545\n",
      "Average policy_loss: 0.7963\n",
      "Average value_loss: 0.1582\n",
      "Replay buffer size: 6105\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.9509\n",
      "Average policy_loss: 0.7862\n",
      "Average value_loss: 0.1647\n",
      "Replay buffer size: 6198\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.9617\n",
      "Average policy_loss: 0.8015\n",
      "Average value_loss: 0.1601\n",
      "Replay buffer size: 6285\n",
      "Time taken: 46.2s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.9612\n",
      "Average policy_loss: 0.8055\n",
      "Average value_loss: 0.1557\n",
      "Replay buffer size: 6383\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.9586\n",
      "Average policy_loss: 0.8031\n",
      "Average value_loss: 0.1555\n",
      "Replay buffer size: 6472\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.9502\n",
      "Average policy_loss: 0.7898\n",
      "Average value_loss: 0.1604\n",
      "Replay buffer size: 6563\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.9494\n",
      "Average policy_loss: 0.7928\n",
      "Average value_loss: 0.1566\n",
      "Replay buffer size: 6659\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.9671\n",
      "Average policy_loss: 0.8039\n",
      "Average value_loss: 0.1632\n",
      "Replay buffer size: 6748\n",
      "Time taken: 46.1s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.9500\n",
      "Average policy_loss: 0.7917\n",
      "Average value_loss: 0.1583\n",
      "Replay buffer size: 6833\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.9474\n",
      "Average policy_loss: 0.7908\n",
      "Average value_loss: 0.1566\n",
      "Replay buffer size: 6926\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.9492\n",
      "Average policy_loss: 0.7940\n",
      "Average value_loss: 0.1552\n",
      "Replay buffer size: 7016\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.9636\n",
      "Average policy_loss: 0.8043\n",
      "Average value_loss: 0.1593\n",
      "Replay buffer size: 7097\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.9542\n",
      "Average policy_loss: 0.7965\n",
      "Average value_loss: 0.1577\n",
      "Replay buffer size: 7193\n",
      "Time taken: 45.5s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.9516\n",
      "Average policy_loss: 0.7957\n",
      "Average value_loss: 0.1560\n",
      "Replay buffer size: 7276\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.9587\n",
      "Average policy_loss: 0.7996\n",
      "Average value_loss: 0.1591\n",
      "Replay buffer size: 7364\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.9604\n",
      "Average policy_loss: 0.8008\n",
      "Average value_loss: 0.1596\n",
      "Replay buffer size: 7453\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.9594\n",
      "Average policy_loss: 0.8004\n",
      "Average value_loss: 0.1589\n",
      "Replay buffer size: 7547\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.9561\n",
      "Average policy_loss: 0.7969\n",
      "Average value_loss: 0.1592\n",
      "Replay buffer size: 7634\n",
      "Time taken: 46.2s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.9519\n",
      "Average policy_loss: 0.7993\n",
      "Average value_loss: 0.1526\n",
      "Replay buffer size: 7727\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.9449\n",
      "Average policy_loss: 0.7886\n",
      "Average value_loss: 0.1564\n",
      "Replay buffer size: 7821\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.9640\n",
      "Average policy_loss: 0.8079\n",
      "Average value_loss: 0.1561\n",
      "Replay buffer size: 7902\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.9658\n",
      "Average policy_loss: 0.8073\n",
      "Average value_loss: 0.1586\n",
      "Replay buffer size: 7996\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.9708\n",
      "Average policy_loss: 0.8109\n",
      "Average value_loss: 0.1599\n",
      "Replay buffer size: 8093\n",
      "Time taken: 47.0s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.9540\n",
      "Average policy_loss: 0.7980\n",
      "Average value_loss: 0.1560\n",
      "Replay buffer size: 8186\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.9504\n",
      "Average policy_loss: 0.7921\n",
      "Average value_loss: 0.1583\n",
      "Replay buffer size: 8277\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.9589\n",
      "Average policy_loss: 0.8006\n",
      "Average value_loss: 0.1583\n",
      "Replay buffer size: 8362\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.9499\n",
      "Average policy_loss: 0.7969\n",
      "Average value_loss: 0.1530\n",
      "Replay buffer size: 8457\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.9583\n",
      "Average policy_loss: 0.8055\n",
      "Average value_loss: 0.1528\n",
      "Replay buffer size: 8548\n",
      "Time taken: 45.4s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.9598\n",
      "Average policy_loss: 0.7987\n",
      "Average value_loss: 0.1611\n",
      "Replay buffer size: 8644\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.9571\n",
      "Average policy_loss: 0.7975\n",
      "Average value_loss: 0.1596\n",
      "Replay buffer size: 8731\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.9526\n",
      "Average policy_loss: 0.7944\n",
      "Average value_loss: 0.1581\n",
      "Replay buffer size: 8821\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.9499\n",
      "Average policy_loss: 0.7933\n",
      "Average value_loss: 0.1566\n",
      "Replay buffer size: 8907\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.9488\n",
      "Average policy_loss: 0.7922\n",
      "Average value_loss: 0.1565\n",
      "Replay buffer size: 8999\n",
      "Time taken: 45.8s\n",
      "\n",
      "Training complete! Total time: 0.5h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>iteration_time</td><td>▁▆▂▁▂▂▇▂▂▂▂█▂█▂▂▂▂▂▂▂▇▂▂▇▂▂█▂▂▂▂█▂▂▂█▂▂▂</td></tr><tr><td>loss</td><td>█▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▆▇▄▃▄▄▇▆▆▅▇▆▇▃▅▅▆▅█▅▅▅▅▁▅▅▆▇▅▇▇▅▆▃▅▆▃▇▇▅</td></tr><tr><td>policy_loss</td><td>█▅▃▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.2</td></tr><tr><td>buffer_size</td><td>8999</td></tr><tr><td>iteration_time</td><td>45.84922</td></tr><tr><td>loss</td><td>0.94875</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>92</td></tr><tr><td>policy_loss</td><td>0.79222</td></tr><tr><td>total_time_hours</td><td>0.53194</td></tr><tr><td>value_loss</td><td>0.15653</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">summer-sweep-33</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ffl4ob5w' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ffl4ob5w</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_163452-ffl4ob5w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kjddt8wi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.029538367363252747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.42492449765990126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 2.0992703840682736e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_170654-kjddt8wi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kjddt8wi' target=\"_blank\">wandering-sweep-34</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kjddt8wi' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kjddt8wi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 3.8967\n",
      "Average policy_loss: 2.0433\n",
      "Average value_loss: 1.8534\n",
      "Replay buffer size: 70\n",
      "Time taken: 8.1s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 2.5259\n",
      "Average policy_loss: 0.5460\n",
      "Average value_loss: 1.9799\n",
      "Replay buffer size: 140\n",
      "Time taken: 7.2s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.2712\n",
      "Average policy_loss: 0.5238\n",
      "Average value_loss: 0.7474\n",
      "Replay buffer size: 210\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.0647\n",
      "Average policy_loss: 0.7428\n",
      "Average value_loss: 0.3219\n",
      "Replay buffer size: 285\n",
      "Time taken: 9.8s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.1038\n",
      "Average policy_loss: 0.7910\n",
      "Average value_loss: 0.3128\n",
      "Replay buffer size: 363\n",
      "Time taken: 34.7s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.0707\n",
      "Average policy_loss: 0.7604\n",
      "Average value_loss: 0.3103\n",
      "Replay buffer size: 439\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.0702\n",
      "Average policy_loss: 0.7599\n",
      "Average value_loss: 0.3103\n",
      "Replay buffer size: 520\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.0790\n",
      "Average policy_loss: 0.7821\n",
      "Average value_loss: 0.2970\n",
      "Replay buffer size: 601\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.0500\n",
      "Average policy_loss: 0.7639\n",
      "Average value_loss: 0.2861\n",
      "Replay buffer size: 677\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.0201\n",
      "Average policy_loss: 0.7647\n",
      "Average value_loss: 0.2554\n",
      "Replay buffer size: 751\n",
      "Time taken: 36.2s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.0147\n",
      "Average policy_loss: 0.7766\n",
      "Average value_loss: 0.2381\n",
      "Replay buffer size: 825\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.0386\n",
      "Average policy_loss: 0.7886\n",
      "Average value_loss: 0.2500\n",
      "Replay buffer size: 894\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.0389\n",
      "Average policy_loss: 0.7943\n",
      "Average value_loss: 0.2446\n",
      "Replay buffer size: 964\n",
      "Time taken: 9.3s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.0048\n",
      "Average policy_loss: 0.7851\n",
      "Average value_loss: 0.2197\n",
      "Replay buffer size: 1036\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.9877\n",
      "Average policy_loss: 0.7748\n",
      "Average value_loss: 0.2129\n",
      "Replay buffer size: 1106\n",
      "Time taken: 31.7s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.0035\n",
      "Average policy_loss: 0.7877\n",
      "Average value_loss: 0.2158\n",
      "Replay buffer size: 1176\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.9765\n",
      "Average policy_loss: 0.7739\n",
      "Average value_loss: 0.2026\n",
      "Replay buffer size: 1254\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 65 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.9774\n",
      "Average policy_loss: 0.7724\n",
      "Average value_loss: 0.2051\n",
      "Replay buffer size: 1319\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.0137\n",
      "Average policy_loss: 0.7938\n",
      "Average value_loss: 0.2199\n",
      "Replay buffer size: 1394\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.9946\n",
      "Average policy_loss: 0.7808\n",
      "Average value_loss: 0.2139\n",
      "Replay buffer size: 1467\n",
      "Time taken: 31.9s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.9918\n",
      "Average policy_loss: 0.7794\n",
      "Average value_loss: 0.2124\n",
      "Replay buffer size: 1537\n",
      "Time taken: 9.8s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.9865\n",
      "Average policy_loss: 0.7847\n",
      "Average value_loss: 0.2017\n",
      "Replay buffer size: 1614\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.9929\n",
      "Average policy_loss: 0.7964\n",
      "Average value_loss: 0.1965\n",
      "Replay buffer size: 1692\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.9918\n",
      "Average policy_loss: 0.7928\n",
      "Average value_loss: 0.1990\n",
      "Replay buffer size: 1772\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.9884\n",
      "Average policy_loss: 0.7986\n",
      "Average value_loss: 0.1898\n",
      "Replay buffer size: 1845\n",
      "Time taken: 39.0s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.0157\n",
      "Average policy_loss: 0.8222\n",
      "Average value_loss: 0.1935\n",
      "Replay buffer size: 1935\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.9923\n",
      "Average policy_loss: 0.8086\n",
      "Average value_loss: 0.1837\n",
      "Replay buffer size: 2017\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.0277\n",
      "Average policy_loss: 0.8273\n",
      "Average value_loss: 0.2004\n",
      "Replay buffer size: 2098\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.0101\n",
      "Average policy_loss: 0.8123\n",
      "Average value_loss: 0.1978\n",
      "Replay buffer size: 2190\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.0199\n",
      "Average policy_loss: 0.8242\n",
      "Average value_loss: 0.1958\n",
      "Replay buffer size: 2285\n",
      "Time taken: 39.8s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.9897\n",
      "Average policy_loss: 0.7942\n",
      "Average value_loss: 0.1955\n",
      "Replay buffer size: 2377\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.0001\n",
      "Average policy_loss: 0.7913\n",
      "Average value_loss: 0.2088\n",
      "Replay buffer size: 2474\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.0070\n",
      "Average policy_loss: 0.7958\n",
      "Average value_loss: 0.2112\n",
      "Replay buffer size: 2563\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.9909\n",
      "Average policy_loss: 0.7860\n",
      "Average value_loss: 0.2049\n",
      "Replay buffer size: 2658\n",
      "Time taken: 9.8s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.9903\n",
      "Average policy_loss: 0.7876\n",
      "Average value_loss: 0.2027\n",
      "Replay buffer size: 2751\n",
      "Time taken: 37.8s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.9944\n",
      "Average policy_loss: 0.7852\n",
      "Average value_loss: 0.2091\n",
      "Replay buffer size: 2845\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.9832\n",
      "Average policy_loss: 0.7786\n",
      "Average value_loss: 0.2046\n",
      "Replay buffer size: 2942\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.9788\n",
      "Average policy_loss: 0.7660\n",
      "Average value_loss: 0.2128\n",
      "Replay buffer size: 3034\n",
      "Time taken: 8.8s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.9708\n",
      "Average policy_loss: 0.7577\n",
      "Average value_loss: 0.2131\n",
      "Replay buffer size: 3129\n",
      "Time taken: 9.3s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.9575\n",
      "Average policy_loss: 0.7476\n",
      "Average value_loss: 0.2099\n",
      "Replay buffer size: 3228\n",
      "Time taken: 37.1s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.9716\n",
      "Average policy_loss: 0.7595\n",
      "Average value_loss: 0.2121\n",
      "Replay buffer size: 3328\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.9470\n",
      "Average policy_loss: 0.7395\n",
      "Average value_loss: 0.2075\n",
      "Replay buffer size: 3425\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.9392\n",
      "Average policy_loss: 0.7311\n",
      "Average value_loss: 0.2081\n",
      "Replay buffer size: 3524\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.9372\n",
      "Average policy_loss: 0.7293\n",
      "Average value_loss: 0.2079\n",
      "Replay buffer size: 3622\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.9221\n",
      "Average policy_loss: 0.7237\n",
      "Average value_loss: 0.1985\n",
      "Replay buffer size: 3722\n",
      "Time taken: 37.2s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.9045\n",
      "Average policy_loss: 0.7085\n",
      "Average value_loss: 0.1960\n",
      "Replay buffer size: 3822\n",
      "Time taken: 9.3s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.9095\n",
      "Average policy_loss: 0.7100\n",
      "Average value_loss: 0.1995\n",
      "Replay buffer size: 3919\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.9154\n",
      "Average policy_loss: 0.7157\n",
      "Average value_loss: 0.1997\n",
      "Replay buffer size: 4019\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.9041\n",
      "Average policy_loss: 0.7083\n",
      "Average value_loss: 0.1958\n",
      "Replay buffer size: 4118\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.8931\n",
      "Average policy_loss: 0.6976\n",
      "Average value_loss: 0.1955\n",
      "Replay buffer size: 4218\n",
      "Time taken: 35.8s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.8831\n",
      "Average policy_loss: 0.6914\n",
      "Average value_loss: 0.1917\n",
      "Replay buffer size: 4314\n",
      "Time taken: 8.8s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.8732\n",
      "Average policy_loss: 0.6793\n",
      "Average value_loss: 0.1939\n",
      "Replay buffer size: 4413\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.8767\n",
      "Average policy_loss: 0.6823\n",
      "Average value_loss: 0.1944\n",
      "Replay buffer size: 4505\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.8717\n",
      "Average policy_loss: 0.6833\n",
      "Average value_loss: 0.1884\n",
      "Replay buffer size: 4597\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.8494\n",
      "Average policy_loss: 0.6669\n",
      "Average value_loss: 0.1824\n",
      "Replay buffer size: 4697\n",
      "Time taken: 37.9s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.8543\n",
      "Average policy_loss: 0.6666\n",
      "Average value_loss: 0.1878\n",
      "Replay buffer size: 4794\n",
      "Time taken: 8.6s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.8324\n",
      "Average policy_loss: 0.6535\n",
      "Average value_loss: 0.1789\n",
      "Replay buffer size: 4888\n",
      "Time taken: 9.4s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.8381\n",
      "Average policy_loss: 0.6585\n",
      "Average value_loss: 0.1796\n",
      "Replay buffer size: 4988\n",
      "Time taken: 9.4s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.8558\n",
      "Average policy_loss: 0.6703\n",
      "Average value_loss: 0.1854\n",
      "Replay buffer size: 5086\n",
      "Time taken: 8.5s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.8446\n",
      "Average policy_loss: 0.6597\n",
      "Average value_loss: 0.1850\n",
      "Replay buffer size: 5186\n",
      "Time taken: 35.6s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.8388\n",
      "Average policy_loss: 0.6576\n",
      "Average value_loss: 0.1812\n",
      "Replay buffer size: 5281\n",
      "Time taken: 9.7s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.8314\n",
      "Average policy_loss: 0.6516\n",
      "Average value_loss: 0.1798\n",
      "Replay buffer size: 5381\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.8338\n",
      "Average policy_loss: 0.6522\n",
      "Average value_loss: 0.1816\n",
      "Replay buffer size: 5477\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.8177\n",
      "Average policy_loss: 0.6397\n",
      "Average value_loss: 0.1781\n",
      "Replay buffer size: 5575\n",
      "Time taken: 8.5s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.8299\n",
      "Average policy_loss: 0.6495\n",
      "Average value_loss: 0.1804\n",
      "Replay buffer size: 5668\n",
      "Time taken: 36.3s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.8000\n",
      "Average policy_loss: 0.6280\n",
      "Average value_loss: 0.1719\n",
      "Replay buffer size: 5764\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.7940\n",
      "Average policy_loss: 0.6237\n",
      "Average value_loss: 0.1703\n",
      "Replay buffer size: 5857\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.8081\n",
      "Average policy_loss: 0.6354\n",
      "Average value_loss: 0.1727\n",
      "Replay buffer size: 5953\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.8026\n",
      "Average policy_loss: 0.6340\n",
      "Average value_loss: 0.1685\n",
      "Replay buffer size: 6045\n",
      "Time taken: 8.6s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.8121\n",
      "Average policy_loss: 0.6388\n",
      "Average value_loss: 0.1733\n",
      "Replay buffer size: 6143\n",
      "Time taken: 38.9s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.8036\n",
      "Average policy_loss: 0.6370\n",
      "Average value_loss: 0.1665\n",
      "Replay buffer size: 6235\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.8101\n",
      "Average policy_loss: 0.6370\n",
      "Average value_loss: 0.1731\n",
      "Replay buffer size: 6322\n",
      "Time taken: 9.8s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.7858\n",
      "Average policy_loss: 0.6172\n",
      "Average value_loss: 0.1686\n",
      "Replay buffer size: 6413\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.7783\n",
      "Average policy_loss: 0.6120\n",
      "Average value_loss: 0.1662\n",
      "Replay buffer size: 6500\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.7849\n",
      "Average policy_loss: 0.6179\n",
      "Average value_loss: 0.1671\n",
      "Replay buffer size: 6599\n",
      "Time taken: 36.8s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.7886\n",
      "Average policy_loss: 0.6206\n",
      "Average value_loss: 0.1681\n",
      "Replay buffer size: 6697\n",
      "Time taken: 8.6s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.7965\n",
      "Average policy_loss: 0.6274\n",
      "Average value_loss: 0.1690\n",
      "Replay buffer size: 6793\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.7908\n",
      "Average policy_loss: 0.6206\n",
      "Average value_loss: 0.1702\n",
      "Replay buffer size: 6889\n",
      "Time taken: 9.7s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.7709\n",
      "Average policy_loss: 0.6101\n",
      "Average value_loss: 0.1608\n",
      "Replay buffer size: 6988\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.7746\n",
      "Average policy_loss: 0.6088\n",
      "Average value_loss: 0.1658\n",
      "Replay buffer size: 7083\n",
      "Time taken: 37.7s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.7619\n",
      "Average policy_loss: 0.5997\n",
      "Average value_loss: 0.1622\n",
      "Replay buffer size: 7179\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.7715\n",
      "Average policy_loss: 0.6068\n",
      "Average value_loss: 0.1647\n",
      "Replay buffer size: 7274\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.7740\n",
      "Average policy_loss: 0.6132\n",
      "Average value_loss: 0.1608\n",
      "Replay buffer size: 7369\n",
      "Time taken: 8.7s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.7743\n",
      "Average policy_loss: 0.6099\n",
      "Average value_loss: 0.1644\n",
      "Replay buffer size: 7465\n",
      "Time taken: 9.3s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.7586\n",
      "Average policy_loss: 0.6013\n",
      "Average value_loss: 0.1573\n",
      "Replay buffer size: 7561\n",
      "Time taken: 37.4s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.7531\n",
      "Average policy_loss: 0.5997\n",
      "Average value_loss: 0.1534\n",
      "Replay buffer size: 7657\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.7535\n",
      "Average policy_loss: 0.5964\n",
      "Average value_loss: 0.1571\n",
      "Replay buffer size: 7751\n",
      "Time taken: 9.5s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.7631\n",
      "Average policy_loss: 0.6037\n",
      "Average value_loss: 0.1594\n",
      "Replay buffer size: 7847\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.7481\n",
      "Average policy_loss: 0.5909\n",
      "Average value_loss: 0.1572\n",
      "Replay buffer size: 7947\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.7363\n",
      "Average policy_loss: 0.5787\n",
      "Average value_loss: 0.1576\n",
      "Replay buffer size: 8044\n",
      "Time taken: 37.1s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.7363\n",
      "Average policy_loss: 0.5824\n",
      "Average value_loss: 0.1539\n",
      "Replay buffer size: 8144\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.7450\n",
      "Average policy_loss: 0.5922\n",
      "Average value_loss: 0.1529\n",
      "Replay buffer size: 8236\n",
      "Time taken: 8.7s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.7543\n",
      "Average policy_loss: 0.5968\n",
      "Average value_loss: 0.1575\n",
      "Replay buffer size: 8326\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.7433\n",
      "Average policy_loss: 0.5900\n",
      "Average value_loss: 0.1533\n",
      "Replay buffer size: 8421\n",
      "Time taken: 9.3s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.7604\n",
      "Average policy_loss: 0.6037\n",
      "Average value_loss: 0.1567\n",
      "Replay buffer size: 8519\n",
      "Time taken: 37.9s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.7385\n",
      "Average policy_loss: 0.5829\n",
      "Average value_loss: 0.1556\n",
      "Replay buffer size: 8619\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.7179\n",
      "Average policy_loss: 0.5715\n",
      "Average value_loss: 0.1464\n",
      "Replay buffer size: 8709\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.7308\n",
      "Average policy_loss: 0.5810\n",
      "Average value_loss: 0.1498\n",
      "Replay buffer size: 8799\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.7345\n",
      "Average policy_loss: 0.5849\n",
      "Average value_loss: 0.1496\n",
      "Replay buffer size: 8897\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.7429\n",
      "Average policy_loss: 0.5893\n",
      "Average value_loss: 0.1537\n",
      "Replay buffer size: 8991\n",
      "Time taken: 37.4s\n",
      "\n",
      "Training complete! Total time: 0.4h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>iteration_time</td><td>▁▂▂▁▁▆▁▁▆▂▂█▁▂▂▁▁▁▁▁▁▁█▁▁▁▁▁▇▁▁▁█▁▁▇▁▁▁▁</td></tr><tr><td>loss</td><td>█▅▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▁▂▁▁▂▃▃▂▇▆▇▆▇▇██▇███▆▇██▇▇▆█▅▆█▇█▇▇█▇██▆</td></tr><tr><td>policy_loss</td><td>█▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.05</td></tr><tr><td>buffer_size</td><td>8991</td></tr><tr><td>iteration_time</td><td>37.39099</td></tr><tr><td>loss</td><td>0.74295</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>94</td></tr><tr><td>policy_loss</td><td>0.58928</td></tr><tr><td>total_time_hours</td><td>0.41761</td></tr><tr><td>value_loss</td><td>0.15366</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wandering-sweep-34</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kjddt8wi' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/kjddt8wi</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_170654-kjddt8wi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gndt3i61 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004107382254549766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: tiny\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.44418547824738286\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.00026423209834333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_173207-gndt3i61</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/gndt3i61' target=\"_blank\">robust-sweep-35</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/gndt3i61' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/gndt3i61</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 4.5694\n",
      "Average policy_loss: 3.2988\n",
      "Average value_loss: 1.2707\n",
      "Replay buffer size: 85\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 3.4527\n",
      "Average policy_loss: 2.4851\n",
      "Average value_loss: 0.9676\n",
      "Replay buffer size: 181\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 2.8954\n",
      "Average policy_loss: 2.1035\n",
      "Average value_loss: 0.7919\n",
      "Replay buffer size: 266\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 2.6452\n",
      "Average policy_loss: 1.9694\n",
      "Average value_loss: 0.6757\n",
      "Replay buffer size: 358\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 2.4428\n",
      "Average policy_loss: 1.8804\n",
      "Average value_loss: 0.5624\n",
      "Replay buffer size: 445\n",
      "Time taken: 62.1s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 2.3245\n",
      "Average policy_loss: 1.8425\n",
      "Average value_loss: 0.4821\n",
      "Replay buffer size: 534\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 2.2539\n",
      "Average policy_loss: 1.8123\n",
      "Average value_loss: 0.4416\n",
      "Replay buffer size: 616\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 2.1993\n",
      "Average policy_loss: 1.7923\n",
      "Average value_loss: 0.4070\n",
      "Replay buffer size: 695\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 2.1548\n",
      "Average policy_loss: 1.7635\n",
      "Average value_loss: 0.3913\n",
      "Replay buffer size: 775\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 2.1264\n",
      "Average policy_loss: 1.7617\n",
      "Average value_loss: 0.3647\n",
      "Replay buffer size: 861\n",
      "Time taken: 73.1s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 2.0967\n",
      "Average policy_loss: 1.7444\n",
      "Average value_loss: 0.3523\n",
      "Replay buffer size: 950\n",
      "Time taken: 24.1s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 2.0817\n",
      "Average policy_loss: 1.7340\n",
      "Average value_loss: 0.3477\n",
      "Replay buffer size: 1032\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 2.0670\n",
      "Average policy_loss: 1.7249\n",
      "Average value_loss: 0.3421\n",
      "Replay buffer size: 1119\n",
      "Time taken: 24.2s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 2.0400\n",
      "Average policy_loss: 1.7157\n",
      "Average value_loss: 0.3243\n",
      "Replay buffer size: 1211\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 2.0251\n",
      "Average policy_loss: 1.7056\n",
      "Average value_loss: 0.3194\n",
      "Replay buffer size: 1294\n",
      "Time taken: 73.3s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 2.0025\n",
      "Average policy_loss: 1.6897\n",
      "Average value_loss: 0.3128\n",
      "Replay buffer size: 1383\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.9891\n",
      "Average policy_loss: 1.6780\n",
      "Average value_loss: 0.3111\n",
      "Replay buffer size: 1467\n",
      "Time taken: 23.1s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.9658\n",
      "Average policy_loss: 1.6682\n",
      "Average value_loss: 0.2976\n",
      "Replay buffer size: 1559\n",
      "Time taken: 23.7s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.9464\n",
      "Average policy_loss: 1.6543\n",
      "Average value_loss: 0.2921\n",
      "Replay buffer size: 1650\n",
      "Time taken: 23.9s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.9165\n",
      "Average policy_loss: 1.6373\n",
      "Average value_loss: 0.2792\n",
      "Replay buffer size: 1744\n",
      "Time taken: 74.5s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.8947\n",
      "Average policy_loss: 1.6243\n",
      "Average value_loss: 0.2704\n",
      "Replay buffer size: 1834\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.8747\n",
      "Average policy_loss: 1.6037\n",
      "Average value_loss: 0.2710\n",
      "Replay buffer size: 1925\n",
      "Time taken: 23.8s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.8562\n",
      "Average policy_loss: 1.5882\n",
      "Average value_loss: 0.2680\n",
      "Replay buffer size: 2009\n",
      "Time taken: 24.1s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.8305\n",
      "Average policy_loss: 1.5625\n",
      "Average value_loss: 0.2680\n",
      "Replay buffer size: 2097\n",
      "Time taken: 24.5s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.8092\n",
      "Average policy_loss: 1.5464\n",
      "Average value_loss: 0.2628\n",
      "Replay buffer size: 2188\n",
      "Time taken: 72.8s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.7864\n",
      "Average policy_loss: 1.5288\n",
      "Average value_loss: 0.2575\n",
      "Replay buffer size: 2278\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.7645\n",
      "Average policy_loss: 1.5128\n",
      "Average value_loss: 0.2517\n",
      "Replay buffer size: 2366\n",
      "Time taken: 23.1s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.7417\n",
      "Average policy_loss: 1.4898\n",
      "Average value_loss: 0.2518\n",
      "Replay buffer size: 2453\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.7135\n",
      "Average policy_loss: 1.4659\n",
      "Average value_loss: 0.2476\n",
      "Replay buffer size: 2539\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.6973\n",
      "Average policy_loss: 1.4513\n",
      "Average value_loss: 0.2460\n",
      "Replay buffer size: 2627\n",
      "Time taken: 68.1s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.6656\n",
      "Average policy_loss: 1.4219\n",
      "Average value_loss: 0.2437\n",
      "Replay buffer size: 2716\n",
      "Time taken: 23.1s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.6378\n",
      "Average policy_loss: 1.3990\n",
      "Average value_loss: 0.2388\n",
      "Replay buffer size: 2810\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.6050\n",
      "Average policy_loss: 1.3723\n",
      "Average value_loss: 0.2327\n",
      "Replay buffer size: 2904\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.5879\n",
      "Average policy_loss: 1.3564\n",
      "Average value_loss: 0.2315\n",
      "Replay buffer size: 2992\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.5558\n",
      "Average policy_loss: 1.3265\n",
      "Average value_loss: 0.2293\n",
      "Replay buffer size: 3079\n",
      "Time taken: 70.8s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.5303\n",
      "Average policy_loss: 1.3081\n",
      "Average value_loss: 0.2222\n",
      "Replay buffer size: 3174\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.5106\n",
      "Average policy_loss: 1.2876\n",
      "Average value_loss: 0.2230\n",
      "Replay buffer size: 3264\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.4984\n",
      "Average policy_loss: 1.2762\n",
      "Average value_loss: 0.2222\n",
      "Replay buffer size: 3355\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.4623\n",
      "Average policy_loss: 1.2491\n",
      "Average value_loss: 0.2133\n",
      "Replay buffer size: 3451\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.4409\n",
      "Average policy_loss: 1.2255\n",
      "Average value_loss: 0.2154\n",
      "Replay buffer size: 3543\n",
      "Time taken: 70.5s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.4116\n",
      "Average policy_loss: 1.2034\n",
      "Average value_loss: 0.2082\n",
      "Replay buffer size: 3643\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.3927\n",
      "Average policy_loss: 1.1876\n",
      "Average value_loss: 0.2052\n",
      "Replay buffer size: 3737\n",
      "Time taken: 23.0s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.3809\n",
      "Average policy_loss: 1.1713\n",
      "Average value_loss: 0.2096\n",
      "Replay buffer size: 3826\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.3534\n",
      "Average policy_loss: 1.1506\n",
      "Average value_loss: 0.2028\n",
      "Replay buffer size: 3922\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.3470\n",
      "Average policy_loss: 1.1408\n",
      "Average value_loss: 0.2061\n",
      "Replay buffer size: 4009\n",
      "Time taken: 69.4s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.3242\n",
      "Average policy_loss: 1.1225\n",
      "Average value_loss: 0.2017\n",
      "Replay buffer size: 4097\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.3133\n",
      "Average policy_loss: 1.1123\n",
      "Average value_loss: 0.2010\n",
      "Replay buffer size: 4192\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.2930\n",
      "Average policy_loss: 1.0953\n",
      "Average value_loss: 0.1976\n",
      "Replay buffer size: 4281\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.2739\n",
      "Average policy_loss: 1.0780\n",
      "Average value_loss: 0.1959\n",
      "Replay buffer size: 4372\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.2661\n",
      "Average policy_loss: 1.0738\n",
      "Average value_loss: 0.1923\n",
      "Replay buffer size: 4468\n",
      "Time taken: 70.7s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.2381\n",
      "Average policy_loss: 1.0514\n",
      "Average value_loss: 0.1867\n",
      "Replay buffer size: 4560\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.2263\n",
      "Average policy_loss: 1.0400\n",
      "Average value_loss: 0.1862\n",
      "Replay buffer size: 4654\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.2139\n",
      "Average policy_loss: 1.0278\n",
      "Average value_loss: 0.1861\n",
      "Replay buffer size: 4745\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.2070\n",
      "Average policy_loss: 1.0178\n",
      "Average value_loss: 0.1891\n",
      "Replay buffer size: 4837\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.1900\n",
      "Average policy_loss: 1.0045\n",
      "Average value_loss: 0.1855\n",
      "Replay buffer size: 4926\n",
      "Time taken: 70.6s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.1861\n",
      "Average policy_loss: 1.0024\n",
      "Average value_loss: 0.1837\n",
      "Replay buffer size: 5022\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.1610\n",
      "Average policy_loss: 0.9860\n",
      "Average value_loss: 0.1750\n",
      "Replay buffer size: 5116\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.1617\n",
      "Average policy_loss: 0.9828\n",
      "Average value_loss: 0.1789\n",
      "Replay buffer size: 5202\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.1435\n",
      "Average policy_loss: 0.9702\n",
      "Average value_loss: 0.1734\n",
      "Replay buffer size: 5300\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.1368\n",
      "Average policy_loss: 0.9628\n",
      "Average value_loss: 0.1740\n",
      "Replay buffer size: 5396\n",
      "Time taken: 77.3s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.1302\n",
      "Average policy_loss: 0.9559\n",
      "Average value_loss: 0.1743\n",
      "Replay buffer size: 5484\n",
      "Time taken: 23.6s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.1240\n",
      "Average policy_loss: 0.9530\n",
      "Average value_loss: 0.1710\n",
      "Replay buffer size: 5582\n",
      "Time taken: 23.3s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.1163\n",
      "Average policy_loss: 0.9487\n",
      "Average value_loss: 0.1676\n",
      "Replay buffer size: 5675\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.0959\n",
      "Average policy_loss: 0.9290\n",
      "Average value_loss: 0.1670\n",
      "Replay buffer size: 5767\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.1031\n",
      "Average policy_loss: 0.9336\n",
      "Average value_loss: 0.1695\n",
      "Replay buffer size: 5852\n",
      "Time taken: 75.1s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.0977\n",
      "Average policy_loss: 0.9277\n",
      "Average value_loss: 0.1699\n",
      "Replay buffer size: 5943\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.0864\n",
      "Average policy_loss: 0.9216\n",
      "Average value_loss: 0.1648\n",
      "Replay buffer size: 6041\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.0824\n",
      "Average policy_loss: 0.9155\n",
      "Average value_loss: 0.1669\n",
      "Replay buffer size: 6135\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.0827\n",
      "Average policy_loss: 0.9134\n",
      "Average value_loss: 0.1694\n",
      "Replay buffer size: 6218\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.0678\n",
      "Average policy_loss: 0.9013\n",
      "Average value_loss: 0.1665\n",
      "Replay buffer size: 6309\n",
      "Time taken: 75.0s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.0641\n",
      "Average policy_loss: 0.8988\n",
      "Average value_loss: 0.1653\n",
      "Replay buffer size: 6407\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.0635\n",
      "Average policy_loss: 0.8991\n",
      "Average value_loss: 0.1644\n",
      "Replay buffer size: 6498\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.0564\n",
      "Average policy_loss: 0.8909\n",
      "Average value_loss: 0.1655\n",
      "Replay buffer size: 6590\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.0532\n",
      "Average policy_loss: 0.8889\n",
      "Average value_loss: 0.1643\n",
      "Replay buffer size: 6690\n",
      "Time taken: 20.8s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.0466\n",
      "Average policy_loss: 0.8831\n",
      "Average value_loss: 0.1635\n",
      "Replay buffer size: 6780\n",
      "Time taken: 75.8s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.0482\n",
      "Average policy_loss: 0.8866\n",
      "Average value_loss: 0.1616\n",
      "Replay buffer size: 6873\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.0380\n",
      "Average policy_loss: 0.8738\n",
      "Average value_loss: 0.1642\n",
      "Replay buffer size: 6959\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.0336\n",
      "Average policy_loss: 0.8706\n",
      "Average value_loss: 0.1630\n",
      "Replay buffer size: 7053\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.0319\n",
      "Average policy_loss: 0.8713\n",
      "Average value_loss: 0.1606\n",
      "Replay buffer size: 7150\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.0179\n",
      "Average policy_loss: 0.8633\n",
      "Average value_loss: 0.1545\n",
      "Replay buffer size: 7246\n",
      "Time taken: 74.9s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.0233\n",
      "Average policy_loss: 0.8644\n",
      "Average value_loss: 0.1589\n",
      "Replay buffer size: 7331\n",
      "Time taken: 23.2s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.0201\n",
      "Average policy_loss: 0.8641\n",
      "Average value_loss: 0.1560\n",
      "Replay buffer size: 7430\n",
      "Time taken: 23.3s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.0144\n",
      "Average policy_loss: 0.8591\n",
      "Average value_loss: 0.1553\n",
      "Replay buffer size: 7521\n",
      "Time taken: 23.3s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.0130\n",
      "Average policy_loss: 0.8579\n",
      "Average value_loss: 0.1551\n",
      "Replay buffer size: 7613\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.0048\n",
      "Average policy_loss: 0.8489\n",
      "Average value_loss: 0.1559\n",
      "Replay buffer size: 7707\n",
      "Time taken: 74.4s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.0051\n",
      "Average policy_loss: 0.8478\n",
      "Average value_loss: 0.1573\n",
      "Replay buffer size: 7799\n",
      "Time taken: 23.7s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.0004\n",
      "Average policy_loss: 0.8473\n",
      "Average value_loss: 0.1531\n",
      "Replay buffer size: 7893\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.9985\n",
      "Average policy_loss: 0.8468\n",
      "Average value_loss: 0.1518\n",
      "Replay buffer size: 7983\n",
      "Time taken: 23.3s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.9967\n",
      "Average policy_loss: 0.8448\n",
      "Average value_loss: 0.1519\n",
      "Replay buffer size: 8079\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.0006\n",
      "Average policy_loss: 0.8472\n",
      "Average value_loss: 0.1534\n",
      "Replay buffer size: 8168\n",
      "Time taken: 73.3s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.9945\n",
      "Average policy_loss: 0.8435\n",
      "Average value_loss: 0.1510\n",
      "Replay buffer size: 8255\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.0010\n",
      "Average policy_loss: 0.8465\n",
      "Average value_loss: 0.1545\n",
      "Replay buffer size: 8343\n",
      "Time taken: 23.9s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.9949\n",
      "Average policy_loss: 0.8431\n",
      "Average value_loss: 0.1518\n",
      "Replay buffer size: 8427\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.9894\n",
      "Average policy_loss: 0.8374\n",
      "Average value_loss: 0.1520\n",
      "Replay buffer size: 8523\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.9924\n",
      "Average policy_loss: 0.8373\n",
      "Average value_loss: 0.1550\n",
      "Replay buffer size: 8614\n",
      "Time taken: 73.1s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.9899\n",
      "Average policy_loss: 0.8371\n",
      "Average value_loss: 0.1528\n",
      "Replay buffer size: 8708\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.9852\n",
      "Average policy_loss: 0.8329\n",
      "Average value_loss: 0.1524\n",
      "Replay buffer size: 8796\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.9875\n",
      "Average policy_loss: 0.8339\n",
      "Average value_loss: 0.1535\n",
      "Replay buffer size: 8895\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.9809\n",
      "Average policy_loss: 0.8297\n",
      "Average value_loss: 0.1512\n",
      "Replay buffer size: 8980\n",
      "Time taken: 23.6s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.9827\n",
      "Average policy_loss: 0.8331\n",
      "Average value_loss: 0.1496\n",
      "Replay buffer size: 9074\n",
      "Time taken: 72.5s\n",
      "\n",
      "Training complete! Total time: 0.9h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>iteration_time</td><td>▁▇▂▂▂▂█▂▂▂█▂▂▂▂▂▂█▂▂█▂▂▇▂▂█▂▂▂▂▂▂▂▂▂█▂▂▂</td></tr><tr><td>loss</td><td>█▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▂▃▄▁▁▅▁▄▂▅▄▅▄▃▃▃▆▄▇▅▆▇▅▆▄█▇▃▂█▅▆▃▇▇█▃▂▆▂</td></tr><tr><td>policy_loss</td><td>█▆▆▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▆▅▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.25</td></tr><tr><td>buffer_size</td><td>9074</td></tr><tr><td>iteration_time</td><td>72.54292</td></tr><tr><td>loss</td><td>0.98272</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>94</td></tr><tr><td>policy_loss</td><td>0.83311</td></tr><tr><td>total_time_hours</td><td>0.88975</td></tr><tr><td>value_loss</td><td>0.14961</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust-sweep-35</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/gndt3i61' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/gndt3i61</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_173207-gndt3i61/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: igd0zblk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.008490693503024e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: tiny\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.6688208057630084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5.213378425619524e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_182539-igd0zblk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/igd0zblk' target=\"_blank\">solar-sweep-36</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/igd0zblk' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/igd0zblk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 4.6733\n",
      "Average policy_loss: 4.1587\n",
      "Average value_loss: 0.5146\n",
      "Replay buffer size: 99\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 4.4883\n",
      "Average policy_loss: 4.0028\n",
      "Average value_loss: 0.4854\n",
      "Replay buffer size: 187\n",
      "Time taken: 9.3s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 4.6555\n",
      "Average policy_loss: 4.0677\n",
      "Average value_loss: 0.5878\n",
      "Replay buffer size: 277\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 4.6074\n",
      "Average policy_loss: 3.9904\n",
      "Average value_loss: 0.6170\n",
      "Replay buffer size: 371\n",
      "Time taken: 9.4s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 4.4932\n",
      "Average policy_loss: 3.8974\n",
      "Average value_loss: 0.5957\n",
      "Replay buffer size: 453\n",
      "Time taken: 35.2s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 4.3887\n",
      "Average policy_loss: 3.7934\n",
      "Average value_loss: 0.5953\n",
      "Replay buffer size: 546\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 4.2787\n",
      "Average policy_loss: 3.6813\n",
      "Average value_loss: 0.5974\n",
      "Replay buffer size: 636\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 4.2066\n",
      "Average policy_loss: 3.6313\n",
      "Average value_loss: 0.5754\n",
      "Replay buffer size: 729\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 4.1404\n",
      "Average policy_loss: 3.5736\n",
      "Average value_loss: 0.5669\n",
      "Replay buffer size: 803\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 4.0400\n",
      "Average policy_loss: 3.5001\n",
      "Average value_loss: 0.5399\n",
      "Replay buffer size: 900\n",
      "Time taken: 40.3s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 3.9696\n",
      "Average policy_loss: 3.4240\n",
      "Average value_loss: 0.5457\n",
      "Replay buffer size: 985\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 3.8712\n",
      "Average policy_loss: 3.3441\n",
      "Average value_loss: 0.5271\n",
      "Replay buffer size: 1081\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 3.7613\n",
      "Average policy_loss: 3.2420\n",
      "Average value_loss: 0.5193\n",
      "Replay buffer size: 1167\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 3.7010\n",
      "Average policy_loss: 3.2047\n",
      "Average value_loss: 0.4963\n",
      "Replay buffer size: 1261\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 3.6530\n",
      "Average policy_loss: 3.1472\n",
      "Average value_loss: 0.5058\n",
      "Replay buffer size: 1351\n",
      "Time taken: 42.8s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 3.6151\n",
      "Average policy_loss: 3.1206\n",
      "Average value_loss: 0.4945\n",
      "Replay buffer size: 1445\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 3.5683\n",
      "Average policy_loss: 3.0661\n",
      "Average value_loss: 0.5022\n",
      "Replay buffer size: 1536\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 3.5533\n",
      "Average policy_loss: 3.0370\n",
      "Average value_loss: 0.5163\n",
      "Replay buffer size: 1618\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 3.4830\n",
      "Average policy_loss: 2.9817\n",
      "Average value_loss: 0.5013\n",
      "Replay buffer size: 1709\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 3.4812\n",
      "Average policy_loss: 2.9731\n",
      "Average value_loss: 0.5081\n",
      "Replay buffer size: 1792\n",
      "Time taken: 42.9s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 3.4278\n",
      "Average policy_loss: 2.9193\n",
      "Average value_loss: 0.5085\n",
      "Replay buffer size: 1872\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 3.3362\n",
      "Average policy_loss: 2.8471\n",
      "Average value_loss: 0.4891\n",
      "Replay buffer size: 1965\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 3.3107\n",
      "Average policy_loss: 2.8369\n",
      "Average value_loss: 0.4738\n",
      "Replay buffer size: 2057\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 3.2818\n",
      "Average policy_loss: 2.8117\n",
      "Average value_loss: 0.4700\n",
      "Replay buffer size: 2148\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 3.2042\n",
      "Average policy_loss: 2.7541\n",
      "Average value_loss: 0.4502\n",
      "Replay buffer size: 2243\n",
      "Time taken: 46.4s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 3.1797\n",
      "Average policy_loss: 2.7348\n",
      "Average value_loss: 0.4449\n",
      "Replay buffer size: 2335\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 3.1139\n",
      "Average policy_loss: 2.6704\n",
      "Average value_loss: 0.4434\n",
      "Replay buffer size: 2420\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 3.0630\n",
      "Average policy_loss: 2.6299\n",
      "Average value_loss: 0.4330\n",
      "Replay buffer size: 2514\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 3.0374\n",
      "Average policy_loss: 2.6114\n",
      "Average value_loss: 0.4260\n",
      "Replay buffer size: 2604\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 3.0168\n",
      "Average policy_loss: 2.5891\n",
      "Average value_loss: 0.4277\n",
      "Replay buffer size: 2699\n",
      "Time taken: 45.3s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 2.9988\n",
      "Average policy_loss: 2.5716\n",
      "Average value_loss: 0.4271\n",
      "Replay buffer size: 2783\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 2.9846\n",
      "Average policy_loss: 2.5667\n",
      "Average value_loss: 0.4179\n",
      "Replay buffer size: 2883\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 2.9237\n",
      "Average policy_loss: 2.5202\n",
      "Average value_loss: 0.4036\n",
      "Replay buffer size: 2979\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 2.9328\n",
      "Average policy_loss: 2.5318\n",
      "Average value_loss: 0.4010\n",
      "Replay buffer size: 3070\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 2.8945\n",
      "Average policy_loss: 2.4995\n",
      "Average value_loss: 0.3950\n",
      "Replay buffer size: 3161\n",
      "Time taken: 46.9s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 2.8775\n",
      "Average policy_loss: 2.4804\n",
      "Average value_loss: 0.3970\n",
      "Replay buffer size: 3255\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 2.8874\n",
      "Average policy_loss: 2.4923\n",
      "Average value_loss: 0.3951\n",
      "Replay buffer size: 3348\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 2.8370\n",
      "Average policy_loss: 2.4494\n",
      "Average value_loss: 0.3876\n",
      "Replay buffer size: 3435\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 2.8033\n",
      "Average policy_loss: 2.4139\n",
      "Average value_loss: 0.3893\n",
      "Replay buffer size: 3528\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 2.7896\n",
      "Average policy_loss: 2.4084\n",
      "Average value_loss: 0.3811\n",
      "Replay buffer size: 3619\n",
      "Time taken: 49.3s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 2.7643\n",
      "Average policy_loss: 2.3857\n",
      "Average value_loss: 0.3786\n",
      "Replay buffer size: 3699\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 2.7403\n",
      "Average policy_loss: 2.3631\n",
      "Average value_loss: 0.3772\n",
      "Replay buffer size: 3787\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 2.7171\n",
      "Average policy_loss: 2.3457\n",
      "Average value_loss: 0.3714\n",
      "Replay buffer size: 3879\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 2.6950\n",
      "Average policy_loss: 2.3263\n",
      "Average value_loss: 0.3687\n",
      "Replay buffer size: 3961\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 2.6567\n",
      "Average policy_loss: 2.2945\n",
      "Average value_loss: 0.3622\n",
      "Replay buffer size: 4041\n",
      "Time taken: 46.7s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 2.6609\n",
      "Average policy_loss: 2.3026\n",
      "Average value_loss: 0.3583\n",
      "Replay buffer size: 4126\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 2.6449\n",
      "Average policy_loss: 2.2810\n",
      "Average value_loss: 0.3639\n",
      "Replay buffer size: 4215\n",
      "Time taken: 13.6s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 2.6202\n",
      "Average policy_loss: 2.2599\n",
      "Average value_loss: 0.3604\n",
      "Replay buffer size: 4306\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 2.6127\n",
      "Average policy_loss: 2.2578\n",
      "Average value_loss: 0.3549\n",
      "Replay buffer size: 4394\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 2.5966\n",
      "Average policy_loss: 2.2435\n",
      "Average value_loss: 0.3531\n",
      "Replay buffer size: 4487\n",
      "Time taken: 47.7s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 2.5723\n",
      "Average policy_loss: 2.2220\n",
      "Average value_loss: 0.3503\n",
      "Replay buffer size: 4572\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 2.5626\n",
      "Average policy_loss: 2.2076\n",
      "Average value_loss: 0.3550\n",
      "Replay buffer size: 4657\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 2.5438\n",
      "Average policy_loss: 2.1956\n",
      "Average value_loss: 0.3482\n",
      "Replay buffer size: 4742\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 2.5282\n",
      "Average policy_loss: 2.1819\n",
      "Average value_loss: 0.3462\n",
      "Replay buffer size: 4831\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 2.5227\n",
      "Average policy_loss: 2.1759\n",
      "Average value_loss: 0.3467\n",
      "Replay buffer size: 4920\n",
      "Time taken: 49.8s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 2.5016\n",
      "Average policy_loss: 2.1570\n",
      "Average value_loss: 0.3446\n",
      "Replay buffer size: 4997\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 2.4934\n",
      "Average policy_loss: 2.1502\n",
      "Average value_loss: 0.3432\n",
      "Replay buffer size: 5084\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 2.4837\n",
      "Average policy_loss: 2.1395\n",
      "Average value_loss: 0.3442\n",
      "Replay buffer size: 5167\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 2.4678\n",
      "Average policy_loss: 2.1263\n",
      "Average value_loss: 0.3415\n",
      "Replay buffer size: 5250\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 2.4766\n",
      "Average policy_loss: 2.1324\n",
      "Average value_loss: 0.3442\n",
      "Replay buffer size: 5326\n",
      "Time taken: 49.7s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 2.4438\n",
      "Average policy_loss: 2.0993\n",
      "Average value_loss: 0.3444\n",
      "Replay buffer size: 5399\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 2.4214\n",
      "Average policy_loss: 2.0846\n",
      "Average value_loss: 0.3368\n",
      "Replay buffer size: 5482\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 2.4277\n",
      "Average policy_loss: 2.0875\n",
      "Average value_loss: 0.3402\n",
      "Replay buffer size: 5567\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 2.4056\n",
      "Average policy_loss: 2.0723\n",
      "Average value_loss: 0.3333\n",
      "Replay buffer size: 5652\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 2.4227\n",
      "Average policy_loss: 2.0838\n",
      "Average value_loss: 0.3390\n",
      "Replay buffer size: 5739\n",
      "Time taken: 48.7s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 2.4093\n",
      "Average policy_loss: 2.0715\n",
      "Average value_loss: 0.3378\n",
      "Replay buffer size: 5828\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 2.3796\n",
      "Average policy_loss: 2.0498\n",
      "Average value_loss: 0.3298\n",
      "Replay buffer size: 5914\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 2.3745\n",
      "Average policy_loss: 2.0417\n",
      "Average value_loss: 0.3328\n",
      "Replay buffer size: 6004\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 2.3618\n",
      "Average policy_loss: 2.0314\n",
      "Average value_loss: 0.3303\n",
      "Replay buffer size: 6089\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 2.3561\n",
      "Average policy_loss: 2.0262\n",
      "Average value_loss: 0.3299\n",
      "Replay buffer size: 6178\n",
      "Time taken: 51.2s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 2.3469\n",
      "Average policy_loss: 2.0184\n",
      "Average value_loss: 0.3285\n",
      "Replay buffer size: 6266\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 2.3374\n",
      "Average policy_loss: 2.0093\n",
      "Average value_loss: 0.3281\n",
      "Replay buffer size: 6348\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 2.3312\n",
      "Average policy_loss: 2.0046\n",
      "Average value_loss: 0.3266\n",
      "Replay buffer size: 6435\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 2.3192\n",
      "Average policy_loss: 1.9944\n",
      "Average value_loss: 0.3248\n",
      "Replay buffer size: 6528\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 2.3084\n",
      "Average policy_loss: 1.9812\n",
      "Average value_loss: 0.3273\n",
      "Replay buffer size: 6616\n",
      "Time taken: 50.5s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 2.2982\n",
      "Average policy_loss: 1.9776\n",
      "Average value_loss: 0.3206\n",
      "Replay buffer size: 6694\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 2.2945\n",
      "Average policy_loss: 1.9711\n",
      "Average value_loss: 0.3234\n",
      "Replay buffer size: 6788\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 2.2889\n",
      "Average policy_loss: 1.9696\n",
      "Average value_loss: 0.3193\n",
      "Replay buffer size: 6874\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 2.2844\n",
      "Average policy_loss: 1.9624\n",
      "Average value_loss: 0.3220\n",
      "Replay buffer size: 6960\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 2.2682\n",
      "Average policy_loss: 1.9514\n",
      "Average value_loss: 0.3167\n",
      "Replay buffer size: 7042\n",
      "Time taken: 51.0s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 2.2578\n",
      "Average policy_loss: 1.9440\n",
      "Average value_loss: 0.3138\n",
      "Replay buffer size: 7124\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 2.2501\n",
      "Average policy_loss: 1.9358\n",
      "Average value_loss: 0.3143\n",
      "Replay buffer size: 7200\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 2.2515\n",
      "Average policy_loss: 1.9356\n",
      "Average value_loss: 0.3159\n",
      "Replay buffer size: 7283\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 2.2449\n",
      "Average policy_loss: 1.9279\n",
      "Average value_loss: 0.3170\n",
      "Replay buffer size: 7363\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 2.2319\n",
      "Average policy_loss: 1.9158\n",
      "Average value_loss: 0.3161\n",
      "Replay buffer size: 7454\n",
      "Time taken: 51.1s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 2.2289\n",
      "Average policy_loss: 1.9166\n",
      "Average value_loss: 0.3123\n",
      "Replay buffer size: 7547\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 2.2247\n",
      "Average policy_loss: 1.9073\n",
      "Average value_loss: 0.3174\n",
      "Replay buffer size: 7629\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 2.2243\n",
      "Average policy_loss: 1.9055\n",
      "Average value_loss: 0.3188\n",
      "Replay buffer size: 7706\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 2.2144\n",
      "Average policy_loss: 1.8996\n",
      "Average value_loss: 0.3148\n",
      "Replay buffer size: 7789\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 2.2104\n",
      "Average policy_loss: 1.8983\n",
      "Average value_loss: 0.3121\n",
      "Replay buffer size: 7870\n",
      "Time taken: 51.6s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 2.2020\n",
      "Average policy_loss: 1.8962\n",
      "Average value_loss: 0.3058\n",
      "Replay buffer size: 7952\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 2.1925\n",
      "Average policy_loss: 1.8864\n",
      "Average value_loss: 0.3061\n",
      "Replay buffer size: 8034\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 2.1920\n",
      "Average policy_loss: 1.8823\n",
      "Average value_loss: 0.3097\n",
      "Replay buffer size: 8116\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 2.1915\n",
      "Average policy_loss: 1.8803\n",
      "Average value_loss: 0.3111\n",
      "Replay buffer size: 8196\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 2.1888\n",
      "Average policy_loss: 1.8805\n",
      "Average value_loss: 0.3084\n",
      "Replay buffer size: 8276\n",
      "Time taken: 52.2s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 2.1750\n",
      "Average policy_loss: 1.8689\n",
      "Average value_loss: 0.3060\n",
      "Replay buffer size: 8352\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 2.1814\n",
      "Average policy_loss: 1.8767\n",
      "Average value_loss: 0.3046\n",
      "Replay buffer size: 8442\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 2.1789\n",
      "Average policy_loss: 1.8774\n",
      "Average value_loss: 0.3016\n",
      "Replay buffer size: 8521\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 2.1659\n",
      "Average policy_loss: 1.8611\n",
      "Average value_loss: 0.3048\n",
      "Replay buffer size: 8604\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 2.1683\n",
      "Average policy_loss: 1.8654\n",
      "Average value_loss: 0.3029\n",
      "Replay buffer size: 8687\n",
      "Time taken: 52.0s\n",
      "\n",
      "Training complete! Total time: 0.6h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iteration_time</td><td>▁▁▅▁▁▂▁▂▇▂▂▂▂▂▂▂▇▂▂█▂▂▂▂▂▂▂▂▂█▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>loss</td><td>███▇▇▅▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▆▇▄▇▁▅█▅▄▃█▇▅▇█▇▅▃▆▆▅▄▄▂▄▅▆▅▂▅▄▂▄▂▄▄▃▂▃▄</td></tr><tr><td>policy_loss</td><td>██▇▇▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>▆▅██▇▆▆▅▆▆▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.05</td></tr><tr><td>buffer_size</td><td>8687</td></tr><tr><td>iteration_time</td><td>52.04467</td></tr><tr><td>loss</td><td>2.16834</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>83</td></tr><tr><td>policy_loss</td><td>1.86544</td></tr><tr><td>total_time_hours</td><td>0.5836</td></tr><tr><td>value_loss</td><td>0.30289</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-36</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/igd0zblk' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/igd0zblk</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_182539-igd0zblk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pa53kjlz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.013969647630191706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.5996844467971668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001260649060622499\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_190048-pa53kjlz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/pa53kjlz' target=\"_blank\">silver-sweep-37</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/pa53kjlz' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/pa53kjlz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 2.5448\n",
      "Average policy_loss: 2.0556\n",
      "Average value_loss: 0.4891\n",
      "Replay buffer size: 95\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 0.9567\n",
      "Average policy_loss: 0.7160\n",
      "Average value_loss: 0.2407\n",
      "Replay buffer size: 181\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 0.8428\n",
      "Average policy_loss: 0.6795\n",
      "Average value_loss: 0.1633\n",
      "Replay buffer size: 266\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.7957\n",
      "Average policy_loss: 0.6627\n",
      "Average value_loss: 0.1330\n",
      "Replay buffer size: 350\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.7878\n",
      "Average policy_loss: 0.6691\n",
      "Average value_loss: 0.1187\n",
      "Replay buffer size: 432\n",
      "Time taken: 40.2s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.7790\n",
      "Average policy_loss: 0.6652\n",
      "Average value_loss: 0.1138\n",
      "Replay buffer size: 524\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.7401\n",
      "Average policy_loss: 0.6285\n",
      "Average value_loss: 0.1116\n",
      "Replay buffer size: 620\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.7737\n",
      "Average policy_loss: 0.6461\n",
      "Average value_loss: 0.1276\n",
      "Replay buffer size: 714\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.7535\n",
      "Average policy_loss: 0.6348\n",
      "Average value_loss: 0.1187\n",
      "Replay buffer size: 808\n",
      "Time taken: 14.2s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.7582\n",
      "Average policy_loss: 0.6321\n",
      "Average value_loss: 0.1261\n",
      "Replay buffer size: 900\n",
      "Time taken: 47.4s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.7720\n",
      "Average policy_loss: 0.6509\n",
      "Average value_loss: 0.1211\n",
      "Replay buffer size: 996\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.7752\n",
      "Average policy_loss: 0.6560\n",
      "Average value_loss: 0.1192\n",
      "Replay buffer size: 1088\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.7703\n",
      "Average policy_loss: 0.6542\n",
      "Average value_loss: 0.1161\n",
      "Replay buffer size: 1179\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.7610\n",
      "Average policy_loss: 0.6515\n",
      "Average value_loss: 0.1095\n",
      "Replay buffer size: 1269\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.7725\n",
      "Average policy_loss: 0.6567\n",
      "Average value_loss: 0.1158\n",
      "Replay buffer size: 1362\n",
      "Time taken: 51.5s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.7749\n",
      "Average policy_loss: 0.6581\n",
      "Average value_loss: 0.1168\n",
      "Replay buffer size: 1454\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.7640\n",
      "Average policy_loss: 0.6523\n",
      "Average value_loss: 0.1118\n",
      "Replay buffer size: 1546\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.7505\n",
      "Average policy_loss: 0.6414\n",
      "Average value_loss: 0.1091\n",
      "Replay buffer size: 1638\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.7493\n",
      "Average policy_loss: 0.6411\n",
      "Average value_loss: 0.1082\n",
      "Replay buffer size: 1736\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.7392\n",
      "Average policy_loss: 0.6335\n",
      "Average value_loss: 0.1058\n",
      "Replay buffer size: 1830\n",
      "Time taken: 54.2s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.7383\n",
      "Average policy_loss: 0.6318\n",
      "Average value_loss: 0.1065\n",
      "Replay buffer size: 1926\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.7300\n",
      "Average policy_loss: 0.6255\n",
      "Average value_loss: 0.1044\n",
      "Replay buffer size: 2026\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.7247\n",
      "Average policy_loss: 0.6217\n",
      "Average value_loss: 0.1030\n",
      "Replay buffer size: 2124\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.7124\n",
      "Average policy_loss: 0.6159\n",
      "Average value_loss: 0.0966\n",
      "Replay buffer size: 2224\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.7159\n",
      "Average policy_loss: 0.6190\n",
      "Average value_loss: 0.0969\n",
      "Replay buffer size: 2315\n",
      "Time taken: 56.2s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.7128\n",
      "Average policy_loss: 0.6180\n",
      "Average value_loss: 0.0948\n",
      "Replay buffer size: 2413\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.7078\n",
      "Average policy_loss: 0.6146\n",
      "Average value_loss: 0.0932\n",
      "Replay buffer size: 2509\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.7151\n",
      "Average policy_loss: 0.6173\n",
      "Average value_loss: 0.0978\n",
      "Replay buffer size: 2604\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.7128\n",
      "Average policy_loss: 0.6185\n",
      "Average value_loss: 0.0943\n",
      "Replay buffer size: 2694\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.7072\n",
      "Average policy_loss: 0.6136\n",
      "Average value_loss: 0.0936\n",
      "Replay buffer size: 2788\n",
      "Time taken: 53.0s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.7053\n",
      "Average policy_loss: 0.6136\n",
      "Average value_loss: 0.0917\n",
      "Replay buffer size: 2885\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.7170\n",
      "Average policy_loss: 0.6228\n",
      "Average value_loss: 0.0942\n",
      "Replay buffer size: 2976\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.7103\n",
      "Average policy_loss: 0.6180\n",
      "Average value_loss: 0.0923\n",
      "Replay buffer size: 3076\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.7045\n",
      "Average policy_loss: 0.6144\n",
      "Average value_loss: 0.0901\n",
      "Replay buffer size: 3169\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.6972\n",
      "Average policy_loss: 0.6061\n",
      "Average value_loss: 0.0910\n",
      "Replay buffer size: 3268\n",
      "Time taken: 51.5s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.6987\n",
      "Average policy_loss: 0.6081\n",
      "Average value_loss: 0.0906\n",
      "Replay buffer size: 3360\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.6922\n",
      "Average policy_loss: 0.6046\n",
      "Average value_loss: 0.0877\n",
      "Replay buffer size: 3456\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.6914\n",
      "Average policy_loss: 0.6044\n",
      "Average value_loss: 0.0870\n",
      "Replay buffer size: 3547\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.6912\n",
      "Average policy_loss: 0.6043\n",
      "Average value_loss: 0.0869\n",
      "Replay buffer size: 3640\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.6930\n",
      "Average policy_loss: 0.6065\n",
      "Average value_loss: 0.0865\n",
      "Replay buffer size: 3738\n",
      "Time taken: 53.9s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.6944\n",
      "Average policy_loss: 0.6069\n",
      "Average value_loss: 0.0875\n",
      "Replay buffer size: 3830\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.6957\n",
      "Average policy_loss: 0.6085\n",
      "Average value_loss: 0.0873\n",
      "Replay buffer size: 3927\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.6920\n",
      "Average policy_loss: 0.6046\n",
      "Average value_loss: 0.0875\n",
      "Replay buffer size: 4022\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.6884\n",
      "Average policy_loss: 0.6026\n",
      "Average value_loss: 0.0858\n",
      "Replay buffer size: 4117\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.6857\n",
      "Average policy_loss: 0.5999\n",
      "Average value_loss: 0.0858\n",
      "Replay buffer size: 4214\n",
      "Time taken: 51.0s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.6812\n",
      "Average policy_loss: 0.5973\n",
      "Average value_loss: 0.0840\n",
      "Replay buffer size: 4314\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.6790\n",
      "Average policy_loss: 0.5951\n",
      "Average value_loss: 0.0839\n",
      "Replay buffer size: 4406\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.6759\n",
      "Average policy_loss: 0.5930\n",
      "Average value_loss: 0.0829\n",
      "Replay buffer size: 4501\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.6742\n",
      "Average policy_loss: 0.5936\n",
      "Average value_loss: 0.0806\n",
      "Replay buffer size: 4599\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.6756\n",
      "Average policy_loss: 0.5936\n",
      "Average value_loss: 0.0820\n",
      "Replay buffer size: 4691\n",
      "Time taken: 56.6s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.6752\n",
      "Average policy_loss: 0.5938\n",
      "Average value_loss: 0.0814\n",
      "Replay buffer size: 4787\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.6770\n",
      "Average policy_loss: 0.5972\n",
      "Average value_loss: 0.0798\n",
      "Replay buffer size: 4882\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.6673\n",
      "Average policy_loss: 0.5893\n",
      "Average value_loss: 0.0780\n",
      "Replay buffer size: 4968\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.6703\n",
      "Average policy_loss: 0.5918\n",
      "Average value_loss: 0.0785\n",
      "Replay buffer size: 5061\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.6725\n",
      "Average policy_loss: 0.5940\n",
      "Average value_loss: 0.0786\n",
      "Replay buffer size: 5155\n",
      "Time taken: 53.2s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.6722\n",
      "Average policy_loss: 0.5929\n",
      "Average value_loss: 0.0793\n",
      "Replay buffer size: 5244\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.6722\n",
      "Average policy_loss: 0.5919\n",
      "Average value_loss: 0.0803\n",
      "Replay buffer size: 5340\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.6680\n",
      "Average policy_loss: 0.5894\n",
      "Average value_loss: 0.0786\n",
      "Replay buffer size: 5440\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.6668\n",
      "Average policy_loss: 0.5895\n",
      "Average value_loss: 0.0773\n",
      "Replay buffer size: 5540\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.6621\n",
      "Average policy_loss: 0.5863\n",
      "Average value_loss: 0.0758\n",
      "Replay buffer size: 5640\n",
      "Time taken: 53.9s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.6565\n",
      "Average policy_loss: 0.5824\n",
      "Average value_loss: 0.0741\n",
      "Replay buffer size: 5736\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.6616\n",
      "Average policy_loss: 0.5870\n",
      "Average value_loss: 0.0746\n",
      "Replay buffer size: 5829\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.6603\n",
      "Average policy_loss: 0.5855\n",
      "Average value_loss: 0.0748\n",
      "Replay buffer size: 5924\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.6640\n",
      "Average policy_loss: 0.5880\n",
      "Average value_loss: 0.0760\n",
      "Replay buffer size: 6014\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.6626\n",
      "Average policy_loss: 0.5886\n",
      "Average value_loss: 0.0740\n",
      "Replay buffer size: 6111\n",
      "Time taken: 54.6s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.6605\n",
      "Average policy_loss: 0.5868\n",
      "Average value_loss: 0.0738\n",
      "Replay buffer size: 6208\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.6541\n",
      "Average policy_loss: 0.5800\n",
      "Average value_loss: 0.0741\n",
      "Replay buffer size: 6306\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.6556\n",
      "Average policy_loss: 0.5829\n",
      "Average value_loss: 0.0726\n",
      "Replay buffer size: 6402\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.6566\n",
      "Average policy_loss: 0.5837\n",
      "Average value_loss: 0.0728\n",
      "Replay buffer size: 6494\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.6581\n",
      "Average policy_loss: 0.5859\n",
      "Average value_loss: 0.0722\n",
      "Replay buffer size: 6590\n",
      "Time taken: 53.9s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.6533\n",
      "Average policy_loss: 0.5814\n",
      "Average value_loss: 0.0718\n",
      "Replay buffer size: 6682\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.6543\n",
      "Average policy_loss: 0.5822\n",
      "Average value_loss: 0.0721\n",
      "Replay buffer size: 6773\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.6548\n",
      "Average policy_loss: 0.5816\n",
      "Average value_loss: 0.0733\n",
      "Replay buffer size: 6870\n",
      "Time taken: 15.3s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.6520\n",
      "Average policy_loss: 0.5808\n",
      "Average value_loss: 0.0712\n",
      "Replay buffer size: 6970\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.6515\n",
      "Average policy_loss: 0.5809\n",
      "Average value_loss: 0.0706\n",
      "Replay buffer size: 7070\n",
      "Time taken: 52.8s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.6493\n",
      "Average policy_loss: 0.5789\n",
      "Average value_loss: 0.0704\n",
      "Replay buffer size: 7167\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.6507\n",
      "Average policy_loss: 0.5817\n",
      "Average value_loss: 0.0690\n",
      "Replay buffer size: 7261\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.6475\n",
      "Average policy_loss: 0.5778\n",
      "Average value_loss: 0.0698\n",
      "Replay buffer size: 7356\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.6470\n",
      "Average policy_loss: 0.5779\n",
      "Average value_loss: 0.0691\n",
      "Replay buffer size: 7446\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.6503\n",
      "Average policy_loss: 0.5806\n",
      "Average value_loss: 0.0697\n",
      "Replay buffer size: 7545\n",
      "Time taken: 55.5s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.6530\n",
      "Average policy_loss: 0.5811\n",
      "Average value_loss: 0.0719\n",
      "Replay buffer size: 7630\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.6528\n",
      "Average policy_loss: 0.5796\n",
      "Average value_loss: 0.0731\n",
      "Replay buffer size: 7719\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.6487\n",
      "Average policy_loss: 0.5788\n",
      "Average value_loss: 0.0699\n",
      "Replay buffer size: 7813\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.6495\n",
      "Average policy_loss: 0.5786\n",
      "Average value_loss: 0.0710\n",
      "Replay buffer size: 7911\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.6454\n",
      "Average policy_loss: 0.5774\n",
      "Average value_loss: 0.0680\n",
      "Replay buffer size: 8011\n",
      "Time taken: 52.4s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.6463\n",
      "Average policy_loss: 0.5772\n",
      "Average value_loss: 0.0690\n",
      "Replay buffer size: 8109\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.6499\n",
      "Average policy_loss: 0.5808\n",
      "Average value_loss: 0.0690\n",
      "Replay buffer size: 8203\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.6530\n",
      "Average policy_loss: 0.5833\n",
      "Average value_loss: 0.0697\n",
      "Replay buffer size: 8288\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.6443\n",
      "Average policy_loss: 0.5753\n",
      "Average value_loss: 0.0690\n",
      "Replay buffer size: 8380\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.6520\n",
      "Average policy_loss: 0.5809\n",
      "Average value_loss: 0.0712\n",
      "Replay buffer size: 8474\n",
      "Time taken: 54.4s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.6498\n",
      "Average policy_loss: 0.5809\n",
      "Average value_loss: 0.0689\n",
      "Replay buffer size: 8562\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.6517\n",
      "Average policy_loss: 0.5816\n",
      "Average value_loss: 0.0701\n",
      "Replay buffer size: 8646\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.6521\n",
      "Average policy_loss: 0.5819\n",
      "Average value_loss: 0.0702\n",
      "Replay buffer size: 8746\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.6524\n",
      "Average policy_loss: 0.5819\n",
      "Average value_loss: 0.0705\n",
      "Replay buffer size: 8836\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.6474\n",
      "Average policy_loss: 0.5787\n",
      "Average value_loss: 0.0686\n",
      "Replay buffer size: 8936\n",
      "Time taken: 54.0s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.6507\n",
      "Average policy_loss: 0.5800\n",
      "Average value_loss: 0.0707\n",
      "Replay buffer size: 9029\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.6499\n",
      "Average policy_loss: 0.5801\n",
      "Average value_loss: 0.0699\n",
      "Replay buffer size: 9118\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.6475\n",
      "Average policy_loss: 0.5792\n",
      "Average value_loss: 0.0683\n",
      "Replay buffer size: 9207\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.6498\n",
      "Average policy_loss: 0.5799\n",
      "Average value_loss: 0.0699\n",
      "Replay buffer size: 9301\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.6471\n",
      "Average policy_loss: 0.5778\n",
      "Average value_loss: 0.0693\n",
      "Replay buffer size: 9401\n",
      "Time taken: 54.6s\n",
      "\n",
      "Training complete! Total time: 0.6h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iteration_time</td><td>▁▁▅▁▁▇▁▁▂▁▁▂▂▂▂█▂▂▇▂▂▂█▁▂▂█▁▁▂▂▂▂▂▂▁█▂▂█</td></tr><tr><td>loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▃▂▁▆▆▅▅▇▆█▅▆▄▆▇▅█▅▆▅▅▆▇█▇▄█▆▇▇█▄▂▆▇▂▃█▄█</td></tr><tr><td>policy_loss</td><td>█▆▅▄▄▄▄▄▃▃▃▂▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>0.95</td></tr><tr><td>buffer_size</td><td>9401</td></tr><tr><td>iteration_time</td><td>54.6204</td></tr><tr><td>loss</td><td>0.64714</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>100</td></tr><tr><td>policy_loss</td><td>0.57785</td></tr><tr><td>total_time_hours</td><td>0.64032</td></tr><tr><td>value_loss</td><td>0.06929</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silver-sweep-37</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/pa53kjlz' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/pa53kjlz</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 22 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_190048-pa53kjlz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xrs2pwv6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005894732331429047\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.8159122015632893\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.007810698451177676\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_193921-xrs2pwv6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/xrs2pwv6' target=\"_blank\">revived-sweep-38</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/xrs2pwv6' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/xrs2pwv6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.8942\n",
      "Average policy_loss: 1.2127\n",
      "Average value_loss: 0.6815\n",
      "Replay buffer size: 88\n",
      "Time taken: 7.4s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.0352\n",
      "Average policy_loss: 0.6070\n",
      "Average value_loss: 0.4282\n",
      "Replay buffer size: 180\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 0.9223\n",
      "Average policy_loss: 0.5281\n",
      "Average value_loss: 0.3942\n",
      "Replay buffer size: 279\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.8782\n",
      "Average policy_loss: 0.5577\n",
      "Average value_loss: 0.3205\n",
      "Replay buffer size: 368\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.8706\n",
      "Average policy_loss: 0.6299\n",
      "Average value_loss: 0.2407\n",
      "Replay buffer size: 459\n",
      "Time taken: 39.9s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.8647\n",
      "Average policy_loss: 0.6448\n",
      "Average value_loss: 0.2199\n",
      "Replay buffer size: 550\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.8520\n",
      "Average policy_loss: 0.6831\n",
      "Average value_loss: 0.1688\n",
      "Replay buffer size: 634\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.8820\n",
      "Average policy_loss: 0.7165\n",
      "Average value_loss: 0.1655\n",
      "Replay buffer size: 716\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.8788\n",
      "Average policy_loss: 0.7271\n",
      "Average value_loss: 0.1518\n",
      "Replay buffer size: 807\n",
      "Time taken: 19.1s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 100.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.8753\n",
      "Average policy_loss: 0.7310\n",
      "Average value_loss: 0.1443\n",
      "Replay buffer size: 895\n",
      "Time taken: 59.9s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.8770\n",
      "Average policy_loss: 0.7257\n",
      "Average value_loss: 0.1512\n",
      "Replay buffer size: 994\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.8666\n",
      "Average policy_loss: 0.7331\n",
      "Average value_loss: 0.1335\n",
      "Replay buffer size: 1090\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.8675\n",
      "Average policy_loss: 0.7361\n",
      "Average value_loss: 0.1314\n",
      "Replay buffer size: 1181\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.8793\n",
      "Average policy_loss: 0.7419\n",
      "Average value_loss: 0.1374\n",
      "Replay buffer size: 1269\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.8691\n",
      "Average policy_loss: 0.7413\n",
      "Average value_loss: 0.1278\n",
      "Replay buffer size: 1359\n",
      "Time taken: 61.5s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.8676\n",
      "Average policy_loss: 0.7457\n",
      "Average value_loss: 0.1219\n",
      "Replay buffer size: 1449\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.8821\n",
      "Average policy_loss: 0.7544\n",
      "Average value_loss: 0.1277\n",
      "Replay buffer size: 1541\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.8815\n",
      "Average policy_loss: 0.7530\n",
      "Average value_loss: 0.1285\n",
      "Replay buffer size: 1630\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.8764\n",
      "Average policy_loss: 0.7573\n",
      "Average value_loss: 0.1191\n",
      "Replay buffer size: 1726\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.8748\n",
      "Average policy_loss: 0.7559\n",
      "Average value_loss: 0.1189\n",
      "Replay buffer size: 1815\n",
      "Time taken: 69.4s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.8723\n",
      "Average policy_loss: 0.7566\n",
      "Average value_loss: 0.1157\n",
      "Replay buffer size: 1905\n",
      "Time taken: 22.4s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.8793\n",
      "Average policy_loss: 0.7588\n",
      "Average value_loss: 0.1205\n",
      "Replay buffer size: 1992\n",
      "Time taken: 23.2s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.8740\n",
      "Average policy_loss: 0.7611\n",
      "Average value_loss: 0.1129\n",
      "Replay buffer size: 2088\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.8677\n",
      "Average policy_loss: 0.7587\n",
      "Average value_loss: 0.1090\n",
      "Replay buffer size: 2174\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.8749\n",
      "Average policy_loss: 0.7666\n",
      "Average value_loss: 0.1083\n",
      "Replay buffer size: 2260\n",
      "Time taken: 61.6s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.8715\n",
      "Average policy_loss: 0.7652\n",
      "Average value_loss: 0.1063\n",
      "Replay buffer size: 2351\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.8666\n",
      "Average policy_loss: 0.7628\n",
      "Average value_loss: 0.1038\n",
      "Replay buffer size: 2449\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.8761\n",
      "Average policy_loss: 0.7686\n",
      "Average value_loss: 0.1075\n",
      "Replay buffer size: 2532\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.8781\n",
      "Average policy_loss: 0.7726\n",
      "Average value_loss: 0.1055\n",
      "Replay buffer size: 2623\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.8800\n",
      "Average policy_loss: 0.7732\n",
      "Average value_loss: 0.1068\n",
      "Replay buffer size: 2708\n",
      "Time taken: 64.6s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.8796\n",
      "Average policy_loss: 0.7728\n",
      "Average value_loss: 0.1067\n",
      "Replay buffer size: 2799\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.8729\n",
      "Average policy_loss: 0.7694\n",
      "Average value_loss: 0.1035\n",
      "Replay buffer size: 2895\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.8771\n",
      "Average policy_loss: 0.7729\n",
      "Average value_loss: 0.1042\n",
      "Replay buffer size: 2984\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.8833\n",
      "Average policy_loss: 0.7773\n",
      "Average value_loss: 0.1060\n",
      "Replay buffer size: 3066\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.8845\n",
      "Average policy_loss: 0.7763\n",
      "Average value_loss: 0.1082\n",
      "Replay buffer size: 3157\n",
      "Time taken: 61.9s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.8814\n",
      "Average policy_loss: 0.7728\n",
      "Average value_loss: 0.1086\n",
      "Replay buffer size: 3251\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.8840\n",
      "Average policy_loss: 0.7770\n",
      "Average value_loss: 0.1070\n",
      "Replay buffer size: 3336\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.8805\n",
      "Average policy_loss: 0.7744\n",
      "Average value_loss: 0.1061\n",
      "Replay buffer size: 3424\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.8782\n",
      "Average policy_loss: 0.7759\n",
      "Average value_loss: 0.1023\n",
      "Replay buffer size: 3511\n",
      "Time taken: 20.8s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.8768\n",
      "Average policy_loss: 0.7744\n",
      "Average value_loss: 0.1025\n",
      "Replay buffer size: 3611\n",
      "Time taken: 63.9s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.8823\n",
      "Average policy_loss: 0.7774\n",
      "Average value_loss: 0.1049\n",
      "Replay buffer size: 3694\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.8814\n",
      "Average policy_loss: 0.7788\n",
      "Average value_loss: 0.1026\n",
      "Replay buffer size: 3787\n",
      "Time taken: 19.1s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.8777\n",
      "Average policy_loss: 0.7756\n",
      "Average value_loss: 0.1021\n",
      "Replay buffer size: 3875\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.8794\n",
      "Average policy_loss: 0.7759\n",
      "Average value_loss: 0.1034\n",
      "Replay buffer size: 3965\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.8868\n",
      "Average policy_loss: 0.7818\n",
      "Average value_loss: 0.1050\n",
      "Replay buffer size: 4052\n",
      "Time taken: 61.4s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.8800\n",
      "Average policy_loss: 0.7774\n",
      "Average value_loss: 0.1026\n",
      "Replay buffer size: 4141\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.8835\n",
      "Average policy_loss: 0.7789\n",
      "Average value_loss: 0.1046\n",
      "Replay buffer size: 4224\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.8822\n",
      "Average policy_loss: 0.7776\n",
      "Average value_loss: 0.1046\n",
      "Replay buffer size: 4315\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.8856\n",
      "Average policy_loss: 0.7802\n",
      "Average value_loss: 0.1054\n",
      "Replay buffer size: 4406\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.8869\n",
      "Average policy_loss: 0.7787\n",
      "Average value_loss: 0.1082\n",
      "Replay buffer size: 4492\n",
      "Time taken: 63.6s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.8865\n",
      "Average policy_loss: 0.7814\n",
      "Average value_loss: 0.1051\n",
      "Replay buffer size: 4574\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.8840\n",
      "Average policy_loss: 0.7781\n",
      "Average value_loss: 0.1060\n",
      "Replay buffer size: 4666\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.8817\n",
      "Average policy_loss: 0.7773\n",
      "Average value_loss: 0.1043\n",
      "Replay buffer size: 4760\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.8875\n",
      "Average policy_loss: 0.7840\n",
      "Average value_loss: 0.1036\n",
      "Replay buffer size: 4842\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 100.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.8899\n",
      "Average policy_loss: 0.7857\n",
      "Average value_loss: 0.1042\n",
      "Replay buffer size: 4927\n",
      "Time taken: 63.9s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.8963\n",
      "Average policy_loss: 0.7913\n",
      "Average value_loss: 0.1050\n",
      "Replay buffer size: 5011\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.8888\n",
      "Average policy_loss: 0.7852\n",
      "Average value_loss: 0.1036\n",
      "Replay buffer size: 5105\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.8911\n",
      "Average policy_loss: 0.7877\n",
      "Average value_loss: 0.1034\n",
      "Replay buffer size: 5192\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.8860\n",
      "Average policy_loss: 0.7822\n",
      "Average value_loss: 0.1038\n",
      "Replay buffer size: 5282\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.8905\n",
      "Average policy_loss: 0.7884\n",
      "Average value_loss: 0.1021\n",
      "Replay buffer size: 5378\n",
      "Time taken: 61.0s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.8941\n",
      "Average policy_loss: 0.7929\n",
      "Average value_loss: 0.1012\n",
      "Replay buffer size: 5465\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.8901\n",
      "Average policy_loss: 0.7897\n",
      "Average value_loss: 0.1005\n",
      "Replay buffer size: 5553\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.8944\n",
      "Average policy_loss: 0.7936\n",
      "Average value_loss: 0.1008\n",
      "Replay buffer size: 5647\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.8937\n",
      "Average policy_loss: 0.7918\n",
      "Average value_loss: 0.1019\n",
      "Replay buffer size: 5737\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.8933\n",
      "Average policy_loss: 0.7922\n",
      "Average value_loss: 0.1010\n",
      "Replay buffer size: 5832\n",
      "Time taken: 61.5s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.8899\n",
      "Average policy_loss: 0.7911\n",
      "Average value_loss: 0.0988\n",
      "Replay buffer size: 5925\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.8904\n",
      "Average policy_loss: 0.7903\n",
      "Average value_loss: 0.1001\n",
      "Replay buffer size: 6025\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.8883\n",
      "Average policy_loss: 0.7895\n",
      "Average value_loss: 0.0988\n",
      "Replay buffer size: 6103\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.8873\n",
      "Average policy_loss: 0.7886\n",
      "Average value_loss: 0.0987\n",
      "Replay buffer size: 6192\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.8858\n",
      "Average policy_loss: 0.7874\n",
      "Average value_loss: 0.0984\n",
      "Replay buffer size: 6285\n",
      "Time taken: 65.0s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.8904\n",
      "Average policy_loss: 0.7928\n",
      "Average value_loss: 0.0976\n",
      "Replay buffer size: 6380\n",
      "Time taken: 23.6s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.8846\n",
      "Average policy_loss: 0.7851\n",
      "Average value_loss: 0.0995\n",
      "Replay buffer size: 6462\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.8854\n",
      "Average policy_loss: 0.7872\n",
      "Average value_loss: 0.0982\n",
      "Replay buffer size: 6552\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.8823\n",
      "Average policy_loss: 0.7863\n",
      "Average value_loss: 0.0960\n",
      "Replay buffer size: 6649\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.8872\n",
      "Average policy_loss: 0.7907\n",
      "Average value_loss: 0.0965\n",
      "Replay buffer size: 6729\n",
      "Time taken: 62.8s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.8871\n",
      "Average policy_loss: 0.7906\n",
      "Average value_loss: 0.0965\n",
      "Replay buffer size: 6811\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.8857\n",
      "Average policy_loss: 0.7895\n",
      "Average value_loss: 0.0962\n",
      "Replay buffer size: 6897\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.8883\n",
      "Average policy_loss: 0.7913\n",
      "Average value_loss: 0.0970\n",
      "Replay buffer size: 6988\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.8832\n",
      "Average policy_loss: 0.7881\n",
      "Average value_loss: 0.0952\n",
      "Replay buffer size: 7084\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.8890\n",
      "Average policy_loss: 0.7923\n",
      "Average value_loss: 0.0967\n",
      "Replay buffer size: 7170\n",
      "Time taken: 62.2s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.8848\n",
      "Average policy_loss: 0.7887\n",
      "Average value_loss: 0.0961\n",
      "Replay buffer size: 7260\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.8880\n",
      "Average policy_loss: 0.7926\n",
      "Average value_loss: 0.0954\n",
      "Replay buffer size: 7347\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.8840\n",
      "Average policy_loss: 0.7889\n",
      "Average value_loss: 0.0951\n",
      "Replay buffer size: 7440\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.8816\n",
      "Average policy_loss: 0.7855\n",
      "Average value_loss: 0.0962\n",
      "Replay buffer size: 7534\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.8835\n",
      "Average policy_loss: 0.7874\n",
      "Average value_loss: 0.0961\n",
      "Replay buffer size: 7629\n",
      "Time taken: 61.1s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.8838\n",
      "Average policy_loss: 0.7874\n",
      "Average value_loss: 0.0965\n",
      "Replay buffer size: 7716\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.8816\n",
      "Average policy_loss: 0.7870\n",
      "Average value_loss: 0.0947\n",
      "Replay buffer size: 7806\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.8820\n",
      "Average policy_loss: 0.7864\n",
      "Average value_loss: 0.0956\n",
      "Replay buffer size: 7895\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.8786\n",
      "Average policy_loss: 0.7851\n",
      "Average value_loss: 0.0936\n",
      "Replay buffer size: 7992\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.8811\n",
      "Average policy_loss: 0.7875\n",
      "Average value_loss: 0.0936\n",
      "Replay buffer size: 8076\n",
      "Time taken: 61.3s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.8789\n",
      "Average policy_loss: 0.7833\n",
      "Average value_loss: 0.0955\n",
      "Replay buffer size: 8161\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.8859\n",
      "Average policy_loss: 0.7885\n",
      "Average value_loss: 0.0974\n",
      "Replay buffer size: 8252\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.8818\n",
      "Average policy_loss: 0.7862\n",
      "Average value_loss: 0.0956\n",
      "Replay buffer size: 8348\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.8835\n",
      "Average policy_loss: 0.7882\n",
      "Average value_loss: 0.0954\n",
      "Replay buffer size: 8445\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.8838\n",
      "Average policy_loss: 0.7895\n",
      "Average value_loss: 0.0942\n",
      "Replay buffer size: 8534\n",
      "Time taken: 62.4s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.8817\n",
      "Average policy_loss: 0.7872\n",
      "Average value_loss: 0.0945\n",
      "Replay buffer size: 8626\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.8839\n",
      "Average policy_loss: 0.7886\n",
      "Average value_loss: 0.0953\n",
      "Replay buffer size: 8715\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.8804\n",
      "Average policy_loss: 0.7867\n",
      "Average value_loss: 0.0937\n",
      "Replay buffer size: 8810\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.8775\n",
      "Average policy_loss: 0.7849\n",
      "Average value_loss: 0.0926\n",
      "Replay buffer size: 8904\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.8800\n",
      "Average policy_loss: 0.7888\n",
      "Average value_loss: 0.0912\n",
      "Replay buffer size: 8996\n",
      "Time taken: 63.6s\n",
      "\n",
      "Training complete! Total time: 0.8h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iteration_time</td><td>▁▁▂▂▇▂▇▂▂█▂▇▂▂▂▇▂▂▂▂▂▂▂▇▂▇▂▂▂▂▂▂▂▂▇▂▇▂▂▇</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▅▅▃█▇▄▅▇▇▄█▃▅▇▂▆▃▄▃▅▃▅▄▃▄▆▁▅▆▇▂▇▆▇▄▃▃▇▅▆</td></tr><tr><td>policy_loss</td><td>▁▄▆▆▇▇▇▇▇▇▇▇█▇██████████████████████████</td></tr><tr><td>value_loss</td><td>█▇▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.05</td></tr><tr><td>buffer_size</td><td>8996</td></tr><tr><td>iteration_time</td><td>63.63387</td></tr><tr><td>loss</td><td>0.88</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>92</td></tr><tr><td>policy_loss</td><td>0.78876</td></tr><tr><td>total_time_hours</td><td>0.79082</td></tr><tr><td>value_loss</td><td>0.09125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">revived-sweep-38</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/xrs2pwv6' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/xrs2pwv6</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 22 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_193921-xrs2pwv6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tr6ss13k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03862567744897157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.6781602793764515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.006082793782026864\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_202658-tr6ss13k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/tr6ss13k' target=\"_blank\">young-sweep-39</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/tr6ss13k' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/tr6ss13k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 3.6506\n",
      "Average policy_loss: 2.2301\n",
      "Average value_loss: 1.4206\n",
      "Replay buffer size: 85\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 2.1396\n",
      "Average policy_loss: 0.5553\n",
      "Average value_loss: 1.5843\n",
      "Replay buffer size: 167\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.2129\n",
      "Average policy_loss: 0.5163\n",
      "Average value_loss: 0.6966\n",
      "Replay buffer size: 262\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.6859\n",
      "Average policy_loss: 0.5199\n",
      "Average value_loss: 0.1661\n",
      "Replay buffer size: 358\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.7500\n",
      "Average policy_loss: 0.5849\n",
      "Average value_loss: 0.1652\n",
      "Replay buffer size: 451\n",
      "Time taken: 43.3s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.6717\n",
      "Average policy_loss: 0.5356\n",
      "Average value_loss: 0.1361\n",
      "Replay buffer size: 543\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.6835\n",
      "Average policy_loss: 0.5437\n",
      "Average value_loss: 0.1397\n",
      "Replay buffer size: 633\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.7032\n",
      "Average policy_loss: 0.5675\n",
      "Average value_loss: 0.1357\n",
      "Replay buffer size: 729\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.6665\n",
      "Average policy_loss: 0.5435\n",
      "Average value_loss: 0.1230\n",
      "Replay buffer size: 829\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.6718\n",
      "Average policy_loss: 0.5549\n",
      "Average value_loss: 0.1170\n",
      "Replay buffer size: 923\n",
      "Time taken: 47.4s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.6543\n",
      "Average policy_loss: 0.5462\n",
      "Average value_loss: 0.1081\n",
      "Replay buffer size: 1019\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.6601\n",
      "Average policy_loss: 0.5581\n",
      "Average value_loss: 0.1020\n",
      "Replay buffer size: 1119\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.6433\n",
      "Average policy_loss: 0.5523\n",
      "Average value_loss: 0.0910\n",
      "Replay buffer size: 1217\n",
      "Time taken: 14.1s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.6540\n",
      "Average policy_loss: 0.5633\n",
      "Average value_loss: 0.0906\n",
      "Replay buffer size: 1314\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.6660\n",
      "Average policy_loss: 0.5735\n",
      "Average value_loss: 0.0926\n",
      "Replay buffer size: 1407\n",
      "Time taken: 51.0s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.6764\n",
      "Average policy_loss: 0.5809\n",
      "Average value_loss: 0.0956\n",
      "Replay buffer size: 1500\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.6684\n",
      "Average policy_loss: 0.5803\n",
      "Average value_loss: 0.0881\n",
      "Replay buffer size: 1600\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.6734\n",
      "Average policy_loss: 0.5853\n",
      "Average value_loss: 0.0881\n",
      "Replay buffer size: 1695\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.6917\n",
      "Average policy_loss: 0.5958\n",
      "Average value_loss: 0.0959\n",
      "Replay buffer size: 1791\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.6740\n",
      "Average policy_loss: 0.5889\n",
      "Average value_loss: 0.0852\n",
      "Replay buffer size: 1884\n",
      "Time taken: 55.3s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.6731\n",
      "Average policy_loss: 0.5860\n",
      "Average value_loss: 0.0871\n",
      "Replay buffer size: 1975\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.6967\n",
      "Average policy_loss: 0.5990\n",
      "Average value_loss: 0.0977\n",
      "Replay buffer size: 2074\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.6819\n",
      "Average policy_loss: 0.5955\n",
      "Average value_loss: 0.0864\n",
      "Replay buffer size: 2171\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.6800\n",
      "Average policy_loss: 0.5973\n",
      "Average value_loss: 0.0827\n",
      "Replay buffer size: 2270\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.6814\n",
      "Average policy_loss: 0.5967\n",
      "Average value_loss: 0.0848\n",
      "Replay buffer size: 2362\n",
      "Time taken: 54.6s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.6768\n",
      "Average policy_loss: 0.5952\n",
      "Average value_loss: 0.0816\n",
      "Replay buffer size: 2452\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.6803\n",
      "Average policy_loss: 0.5978\n",
      "Average value_loss: 0.0825\n",
      "Replay buffer size: 2550\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.6769\n",
      "Average policy_loss: 0.5966\n",
      "Average value_loss: 0.0803\n",
      "Replay buffer size: 2650\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.6757\n",
      "Average policy_loss: 0.5960\n",
      "Average value_loss: 0.0796\n",
      "Replay buffer size: 2740\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 50.00%, Draw rate = 50.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.6675\n",
      "Average policy_loss: 0.5897\n",
      "Average value_loss: 0.0778\n",
      "Replay buffer size: 2839\n",
      "Time taken: 55.4s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.6675\n",
      "Average policy_loss: 0.5925\n",
      "Average value_loss: 0.0750\n",
      "Replay buffer size: 2933\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.6714\n",
      "Average policy_loss: 0.5956\n",
      "Average value_loss: 0.0758\n",
      "Replay buffer size: 3029\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.6690\n",
      "Average policy_loss: 0.5938\n",
      "Average value_loss: 0.0753\n",
      "Replay buffer size: 3122\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.6685\n",
      "Average policy_loss: 0.5899\n",
      "Average value_loss: 0.0786\n",
      "Replay buffer size: 3210\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.6846\n",
      "Average policy_loss: 0.6045\n",
      "Average value_loss: 0.0801\n",
      "Replay buffer size: 3301\n",
      "Time taken: 53.9s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.6806\n",
      "Average policy_loss: 0.5991\n",
      "Average value_loss: 0.0815\n",
      "Replay buffer size: 3396\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.6763\n",
      "Average policy_loss: 0.6015\n",
      "Average value_loss: 0.0748\n",
      "Replay buffer size: 3488\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.6812\n",
      "Average policy_loss: 0.6031\n",
      "Average value_loss: 0.0781\n",
      "Replay buffer size: 3584\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.6794\n",
      "Average policy_loss: 0.6023\n",
      "Average value_loss: 0.0770\n",
      "Replay buffer size: 3674\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.6867\n",
      "Average policy_loss: 0.6068\n",
      "Average value_loss: 0.0799\n",
      "Replay buffer size: 3772\n",
      "Time taken: 67.4s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.7070\n",
      "Average policy_loss: 0.6279\n",
      "Average value_loss: 0.0792\n",
      "Replay buffer size: 3869\n",
      "Time taken: 25.2s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.7125\n",
      "Average policy_loss: 0.6272\n",
      "Average value_loss: 0.0853\n",
      "Replay buffer size: 3963\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.6893\n",
      "Average policy_loss: 0.6174\n",
      "Average value_loss: 0.0719\n",
      "Replay buffer size: 4059\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.6948\n",
      "Average policy_loss: 0.6190\n",
      "Average value_loss: 0.0758\n",
      "Replay buffer size: 4145\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.6915\n",
      "Average policy_loss: 0.6189\n",
      "Average value_loss: 0.0726\n",
      "Replay buffer size: 4245\n",
      "Time taken: 53.6s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.6990\n",
      "Average policy_loss: 0.6247\n",
      "Average value_loss: 0.0743\n",
      "Replay buffer size: 4336\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.6981\n",
      "Average policy_loss: 0.6263\n",
      "Average value_loss: 0.0718\n",
      "Replay buffer size: 4434\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.6903\n",
      "Average policy_loss: 0.6189\n",
      "Average value_loss: 0.0714\n",
      "Replay buffer size: 4530\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.7076\n",
      "Average policy_loss: 0.6322\n",
      "Average value_loss: 0.0754\n",
      "Replay buffer size: 4618\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.7140\n",
      "Average policy_loss: 0.6338\n",
      "Average value_loss: 0.0803\n",
      "Replay buffer size: 4711\n",
      "Time taken: 60.5s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.7334\n",
      "Average policy_loss: 0.6462\n",
      "Average value_loss: 0.0872\n",
      "Replay buffer size: 4807\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.7176\n",
      "Average policy_loss: 0.6425\n",
      "Average value_loss: 0.0751\n",
      "Replay buffer size: 4901\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.7114\n",
      "Average policy_loss: 0.6373\n",
      "Average value_loss: 0.0741\n",
      "Replay buffer size: 4999\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.7464\n",
      "Average policy_loss: 0.6534\n",
      "Average value_loss: 0.0930\n",
      "Replay buffer size: 5088\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.7116\n",
      "Average policy_loss: 0.6366\n",
      "Average value_loss: 0.0750\n",
      "Replay buffer size: 5175\n",
      "Time taken: 61.5s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.7343\n",
      "Average policy_loss: 0.6474\n",
      "Average value_loss: 0.0869\n",
      "Replay buffer size: 5272\n",
      "Time taken: 19.1s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.7163\n",
      "Average policy_loss: 0.6433\n",
      "Average value_loss: 0.0730\n",
      "Replay buffer size: 5362\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.7311\n",
      "Average policy_loss: 0.6505\n",
      "Average value_loss: 0.0805\n",
      "Replay buffer size: 5451\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.7484\n",
      "Average policy_loss: 0.6600\n",
      "Average value_loss: 0.0884\n",
      "Replay buffer size: 5549\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.7905\n",
      "Average policy_loss: 0.6988\n",
      "Average value_loss: 0.0917\n",
      "Replay buffer size: 5645\n",
      "Time taken: 60.1s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.7390\n",
      "Average policy_loss: 0.6642\n",
      "Average value_loss: 0.0748\n",
      "Replay buffer size: 5737\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.7311\n",
      "Average policy_loss: 0.6590\n",
      "Average value_loss: 0.0720\n",
      "Replay buffer size: 5837\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.7296\n",
      "Average policy_loss: 0.6552\n",
      "Average value_loss: 0.0744\n",
      "Replay buffer size: 5928\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.7294\n",
      "Average policy_loss: 0.6552\n",
      "Average value_loss: 0.0742\n",
      "Replay buffer size: 6026\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.7319\n",
      "Average policy_loss: 0.6604\n",
      "Average value_loss: 0.0715\n",
      "Replay buffer size: 6126\n",
      "Time taken: 63.0s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.7492\n",
      "Average policy_loss: 0.6690\n",
      "Average value_loss: 0.0802\n",
      "Replay buffer size: 6216\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.7368\n",
      "Average policy_loss: 0.6648\n",
      "Average value_loss: 0.0720\n",
      "Replay buffer size: 6311\n",
      "Time taken: 19.2s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.7347\n",
      "Average policy_loss: 0.6620\n",
      "Average value_loss: 0.0727\n",
      "Replay buffer size: 6407\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.7440\n",
      "Average policy_loss: 0.6695\n",
      "Average value_loss: 0.0745\n",
      "Replay buffer size: 6500\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 50.00%, Draw rate = 45.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.7413\n",
      "Average policy_loss: 0.6676\n",
      "Average value_loss: 0.0737\n",
      "Replay buffer size: 6588\n",
      "Time taken: 63.2s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.7451\n",
      "Average policy_loss: 0.6712\n",
      "Average value_loss: 0.0739\n",
      "Replay buffer size: 6684\n",
      "Time taken: 19.4s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.7465\n",
      "Average policy_loss: 0.6672\n",
      "Average value_loss: 0.0793\n",
      "Replay buffer size: 6776\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.7431\n",
      "Average policy_loss: 0.6691\n",
      "Average value_loss: 0.0741\n",
      "Replay buffer size: 6867\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.8149\n",
      "Average policy_loss: 0.7135\n",
      "Average value_loss: 0.1014\n",
      "Replay buffer size: 6959\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.7455\n",
      "Average policy_loss: 0.6759\n",
      "Average value_loss: 0.0696\n",
      "Replay buffer size: 7048\n",
      "Time taken: 65.8s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.7444\n",
      "Average policy_loss: 0.6708\n",
      "Average value_loss: 0.0736\n",
      "Replay buffer size: 7130\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.7835\n",
      "Average policy_loss: 0.6940\n",
      "Average value_loss: 0.0896\n",
      "Replay buffer size: 7220\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.7531\n",
      "Average policy_loss: 0.6783\n",
      "Average value_loss: 0.0748\n",
      "Replay buffer size: 7304\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.7891\n",
      "Average policy_loss: 0.7006\n",
      "Average value_loss: 0.0885\n",
      "Replay buffer size: 7398\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.7593\n",
      "Average policy_loss: 0.6822\n",
      "Average value_loss: 0.0771\n",
      "Replay buffer size: 7489\n",
      "Time taken: 64.0s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.7563\n",
      "Average policy_loss: 0.6786\n",
      "Average value_loss: 0.0777\n",
      "Replay buffer size: 7581\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.9698\n",
      "Average policy_loss: 0.8682\n",
      "Average value_loss: 0.1016\n",
      "Replay buffer size: 7681\n",
      "Time taken: 18.5s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.1208\n",
      "Average policy_loss: 1.0270\n",
      "Average value_loss: 0.0937\n",
      "Replay buffer size: 7755\n",
      "Time taken: 27.3s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.0146\n",
      "Average policy_loss: 0.9169\n",
      "Average value_loss: 0.0977\n",
      "Replay buffer size: 7854\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.9411\n",
      "Average policy_loss: 0.8495\n",
      "Average value_loss: 0.0916\n",
      "Replay buffer size: 7952\n",
      "Time taken: 68.6s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.8871\n",
      "Average policy_loss: 0.7918\n",
      "Average value_loss: 0.0953\n",
      "Replay buffer size: 8049\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.8455\n",
      "Average policy_loss: 0.7544\n",
      "Average value_loss: 0.0911\n",
      "Replay buffer size: 8145\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.8263\n",
      "Average policy_loss: 0.7429\n",
      "Average value_loss: 0.0834\n",
      "Replay buffer size: 8236\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.8120\n",
      "Average policy_loss: 0.7310\n",
      "Average value_loss: 0.0810\n",
      "Replay buffer size: 8327\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.8110\n",
      "Average policy_loss: 0.7289\n",
      "Average value_loss: 0.0820\n",
      "Replay buffer size: 8420\n",
      "Time taken: 74.5s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.8604\n",
      "Average policy_loss: 0.7487\n",
      "Average value_loss: 0.1117\n",
      "Replay buffer size: 8498\n",
      "Time taken: 25.5s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.8213\n",
      "Average policy_loss: 0.7360\n",
      "Average value_loss: 0.0853\n",
      "Replay buffer size: 8587\n",
      "Time taken: 22.1s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.8308\n",
      "Average policy_loss: 0.7485\n",
      "Average value_loss: 0.0823\n",
      "Replay buffer size: 8677\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.8477\n",
      "Average policy_loss: 0.7543\n",
      "Average value_loss: 0.0934\n",
      "Replay buffer size: 8759\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.8227\n",
      "Average policy_loss: 0.7368\n",
      "Average value_loss: 0.0859\n",
      "Replay buffer size: 8851\n",
      "Time taken: 72.2s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.8322\n",
      "Average policy_loss: 0.7464\n",
      "Average value_loss: 0.0858\n",
      "Replay buffer size: 8946\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.8505\n",
      "Average policy_loss: 0.7563\n",
      "Average value_loss: 0.0942\n",
      "Replay buffer size: 9035\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.9653\n",
      "Average policy_loss: 0.8527\n",
      "Average value_loss: 0.1126\n",
      "Replay buffer size: 9125\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.1346\n",
      "Average policy_loss: 1.0390\n",
      "Average value_loss: 0.0956\n",
      "Replay buffer size: 9199\n",
      "Time taken: 25.0s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.9281\n",
      "Average policy_loss: 0.8301\n",
      "Average value_loss: 0.0980\n",
      "Replay buffer size: 9292\n",
      "Time taken: 72.1s\n",
      "\n",
      "Training complete! Total time: 0.7h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>iteration_time</td><td>▁▁▁▁▂▂▂▂▂▆▂▂▂▂▆▂▂█▂▇▂▂▂▇▂▂▂▇▂▂▇▂▂█▂▃▃▃▃▂</td></tr><tr><td>loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▄▃▇▇▆▇▆█▇▇▇▆▇█▆▇▇█▇▆▅▅▅▇▆▇▇▆▇▆▆▅▅█▁▇▆▆▃▁</td></tr><tr><td>policy_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▂▂▂▂▃</td></tr><tr><td>value_loss</td><td>▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.05</td></tr><tr><td>buffer_size</td><td>9292</td></tr><tr><td>iteration_time</td><td>72.05141</td></tr><tr><td>loss</td><td>0.92811</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>93</td></tr><tr><td>policy_loss</td><td>0.83012</td></tr><tr><td>total_time_hours</td><td>0.7313</td></tr><tr><td>value_loss</td><td>0.098</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">young-sweep-39</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/tr6ss13k' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/tr6ss13k</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 16 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_202658-tr6ss13k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qjqzvbk9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.015946964266376425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.7340837764314487\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.036254775684257376\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_211059-qjqzvbk9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/qjqzvbk9' target=\"_blank\">worthy-sweep-40</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/qjqzvbk9' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/qjqzvbk9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 2.2184\n",
      "Average policy_loss: 1.6723\n",
      "Average value_loss: 0.5461\n",
      "Replay buffer size: 75\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.1974\n",
      "Average policy_loss: 1.0291\n",
      "Average value_loss: 0.1683\n",
      "Replay buffer size: 165\n",
      "Time taken: 13.5s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.0501\n",
      "Average policy_loss: 0.8833\n",
      "Average value_loss: 0.1668\n",
      "Replay buffer size: 256\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.9373\n",
      "Average policy_loss: 0.8149\n",
      "Average value_loss: 0.1224\n",
      "Replay buffer size: 356\n",
      "Time taken: 14.3s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.9395\n",
      "Average policy_loss: 0.8209\n",
      "Average value_loss: 0.1186\n",
      "Replay buffer size: 449\n",
      "Time taken: 47.7s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.9502\n",
      "Average policy_loss: 0.8246\n",
      "Average value_loss: 0.1256\n",
      "Replay buffer size: 538\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.9918\n",
      "Average policy_loss: 0.8645\n",
      "Average value_loss: 0.1273\n",
      "Replay buffer size: 616\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.0041\n",
      "Average policy_loss: 0.8739\n",
      "Average value_loss: 0.1302\n",
      "Replay buffer size: 706\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.0143\n",
      "Average policy_loss: 0.8805\n",
      "Average value_loss: 0.1338\n",
      "Replay buffer size: 789\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.9980\n",
      "Average policy_loss: 0.8767\n",
      "Average value_loss: 0.1213\n",
      "Replay buffer size: 881\n",
      "Time taken: 49.6s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.0179\n",
      "Average policy_loss: 0.8880\n",
      "Average value_loss: 0.1298\n",
      "Replay buffer size: 965\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.0156\n",
      "Average policy_loss: 0.8864\n",
      "Average value_loss: 0.1291\n",
      "Replay buffer size: 1053\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.0169\n",
      "Average policy_loss: 0.8896\n",
      "Average value_loss: 0.1272\n",
      "Replay buffer size: 1145\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.0066\n",
      "Average policy_loss: 0.8874\n",
      "Average value_loss: 0.1192\n",
      "Replay buffer size: 1238\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.0008\n",
      "Average policy_loss: 0.8805\n",
      "Average value_loss: 0.1203\n",
      "Replay buffer size: 1333\n",
      "Time taken: 52.3s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.0049\n",
      "Average policy_loss: 0.8892\n",
      "Average value_loss: 0.1157\n",
      "Replay buffer size: 1428\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.0135\n",
      "Average policy_loss: 0.8894\n",
      "Average value_loss: 0.1241\n",
      "Replay buffer size: 1515\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.0159\n",
      "Average policy_loss: 0.9008\n",
      "Average value_loss: 0.1150\n",
      "Replay buffer size: 1604\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.9968\n",
      "Average policy_loss: 0.8816\n",
      "Average value_loss: 0.1152\n",
      "Replay buffer size: 1699\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.0039\n",
      "Average policy_loss: 0.8889\n",
      "Average value_loss: 0.1150\n",
      "Replay buffer size: 1783\n",
      "Time taken: 58.2s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.9916\n",
      "Average policy_loss: 0.8831\n",
      "Average value_loss: 0.1085\n",
      "Replay buffer size: 1877\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.9841\n",
      "Average policy_loss: 0.8780\n",
      "Average value_loss: 0.1061\n",
      "Replay buffer size: 1972\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.9838\n",
      "Average policy_loss: 0.8762\n",
      "Average value_loss: 0.1076\n",
      "Replay buffer size: 2065\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.9932\n",
      "Average policy_loss: 0.8835\n",
      "Average value_loss: 0.1097\n",
      "Replay buffer size: 2155\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.9762\n",
      "Average policy_loss: 0.8722\n",
      "Average value_loss: 0.1040\n",
      "Replay buffer size: 2250\n",
      "Time taken: 52.9s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.9862\n",
      "Average policy_loss: 0.8782\n",
      "Average value_loss: 0.1080\n",
      "Replay buffer size: 2339\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.9842\n",
      "Average policy_loss: 0.8754\n",
      "Average value_loss: 0.1088\n",
      "Replay buffer size: 2435\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.9909\n",
      "Average policy_loss: 0.8850\n",
      "Average value_loss: 0.1059\n",
      "Replay buffer size: 2531\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.9693\n",
      "Average policy_loss: 0.8678\n",
      "Average value_loss: 0.1015\n",
      "Replay buffer size: 2631\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.9699\n",
      "Average policy_loss: 0.8703\n",
      "Average value_loss: 0.0996\n",
      "Replay buffer size: 2723\n",
      "Time taken: 53.7s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.9822\n",
      "Average policy_loss: 0.8834\n",
      "Average value_loss: 0.0988\n",
      "Replay buffer size: 2814\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.9713\n",
      "Average policy_loss: 0.8783\n",
      "Average value_loss: 0.0930\n",
      "Replay buffer size: 2912\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.9700\n",
      "Average policy_loss: 0.8733\n",
      "Average value_loss: 0.0967\n",
      "Replay buffer size: 3005\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.9749\n",
      "Average policy_loss: 0.8759\n",
      "Average value_loss: 0.0990\n",
      "Replay buffer size: 3096\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.9709\n",
      "Average policy_loss: 0.8719\n",
      "Average value_loss: 0.0990\n",
      "Replay buffer size: 3187\n",
      "Time taken: 56.7s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.9673\n",
      "Average policy_loss: 0.8698\n",
      "Average value_loss: 0.0975\n",
      "Replay buffer size: 3286\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.9688\n",
      "Average policy_loss: 0.8734\n",
      "Average value_loss: 0.0953\n",
      "Replay buffer size: 3383\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.9759\n",
      "Average policy_loss: 0.8789\n",
      "Average value_loss: 0.0970\n",
      "Replay buffer size: 3475\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.9677\n",
      "Average policy_loss: 0.8727\n",
      "Average value_loss: 0.0949\n",
      "Replay buffer size: 3567\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.9757\n",
      "Average policy_loss: 0.8767\n",
      "Average value_loss: 0.0989\n",
      "Replay buffer size: 3652\n",
      "Time taken: 54.7s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.9700\n",
      "Average policy_loss: 0.8765\n",
      "Average value_loss: 0.0934\n",
      "Replay buffer size: 3746\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.9756\n",
      "Average policy_loss: 0.8816\n",
      "Average value_loss: 0.0940\n",
      "Replay buffer size: 3838\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.9686\n",
      "Average policy_loss: 0.8712\n",
      "Average value_loss: 0.0974\n",
      "Replay buffer size: 3930\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.9690\n",
      "Average policy_loss: 0.8727\n",
      "Average value_loss: 0.0963\n",
      "Replay buffer size: 4016\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.9633\n",
      "Average policy_loss: 0.8693\n",
      "Average value_loss: 0.0940\n",
      "Replay buffer size: 4103\n",
      "Time taken: 55.8s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.9692\n",
      "Average policy_loss: 0.8726\n",
      "Average value_loss: 0.0966\n",
      "Replay buffer size: 4191\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.9695\n",
      "Average policy_loss: 0.8735\n",
      "Average value_loss: 0.0960\n",
      "Replay buffer size: 4289\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.9579\n",
      "Average policy_loss: 0.8668\n",
      "Average value_loss: 0.0910\n",
      "Replay buffer size: 4387\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.9652\n",
      "Average policy_loss: 0.8685\n",
      "Average value_loss: 0.0967\n",
      "Replay buffer size: 4484\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.9680\n",
      "Average policy_loss: 0.8752\n",
      "Average value_loss: 0.0928\n",
      "Replay buffer size: 4566\n",
      "Time taken: 56.3s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.9672\n",
      "Average policy_loss: 0.8706\n",
      "Average value_loss: 0.0966\n",
      "Replay buffer size: 4660\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.9662\n",
      "Average policy_loss: 0.8709\n",
      "Average value_loss: 0.0953\n",
      "Replay buffer size: 4737\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.9693\n",
      "Average policy_loss: 0.8716\n",
      "Average value_loss: 0.0977\n",
      "Replay buffer size: 4827\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.9676\n",
      "Average policy_loss: 0.8707\n",
      "Average value_loss: 0.0968\n",
      "Replay buffer size: 4918\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.9709\n",
      "Average policy_loss: 0.8742\n",
      "Average value_loss: 0.0968\n",
      "Replay buffer size: 5012\n",
      "Time taken: 54.6s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.9802\n",
      "Average policy_loss: 0.8832\n",
      "Average value_loss: 0.0970\n",
      "Replay buffer size: 5107\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.9725\n",
      "Average policy_loss: 0.8750\n",
      "Average value_loss: 0.0975\n",
      "Replay buffer size: 5206\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.9647\n",
      "Average policy_loss: 0.8689\n",
      "Average value_loss: 0.0958\n",
      "Replay buffer size: 5300\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.9715\n",
      "Average policy_loss: 0.8749\n",
      "Average value_loss: 0.0966\n",
      "Replay buffer size: 5396\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.9649\n",
      "Average policy_loss: 0.8699\n",
      "Average value_loss: 0.0950\n",
      "Replay buffer size: 5496\n",
      "Time taken: 56.3s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.9697\n",
      "Average policy_loss: 0.8738\n",
      "Average value_loss: 0.0959\n",
      "Replay buffer size: 5582\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.9758\n",
      "Average policy_loss: 0.8801\n",
      "Average value_loss: 0.0957\n",
      "Replay buffer size: 5677\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.9709\n",
      "Average policy_loss: 0.8752\n",
      "Average value_loss: 0.0957\n",
      "Replay buffer size: 5766\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.9782\n",
      "Average policy_loss: 0.8779\n",
      "Average value_loss: 0.1003\n",
      "Replay buffer size: 5853\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.9851\n",
      "Average policy_loss: 0.8849\n",
      "Average value_loss: 0.1002\n",
      "Replay buffer size: 5935\n",
      "Time taken: 58.2s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.9824\n",
      "Average policy_loss: 0.8837\n",
      "Average value_loss: 0.0987\n",
      "Replay buffer size: 6019\n",
      "Time taken: 19.4s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.9886\n",
      "Average policy_loss: 0.8873\n",
      "Average value_loss: 0.1013\n",
      "Replay buffer size: 6108\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.9755\n",
      "Average policy_loss: 0.8772\n",
      "Average value_loss: 0.0983\n",
      "Replay buffer size: 6193\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.9808\n",
      "Average policy_loss: 0.8799\n",
      "Average value_loss: 0.1008\n",
      "Replay buffer size: 6282\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.9840\n",
      "Average policy_loss: 0.8846\n",
      "Average value_loss: 0.0994\n",
      "Replay buffer size: 6367\n",
      "Time taken: 54.9s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.9812\n",
      "Average policy_loss: 0.8817\n",
      "Average value_loss: 0.0994\n",
      "Replay buffer size: 6456\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.9823\n",
      "Average policy_loss: 0.8846\n",
      "Average value_loss: 0.0976\n",
      "Replay buffer size: 6548\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.9733\n",
      "Average policy_loss: 0.8753\n",
      "Average value_loss: 0.0980\n",
      "Replay buffer size: 6643\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.9755\n",
      "Average policy_loss: 0.8803\n",
      "Average value_loss: 0.0952\n",
      "Replay buffer size: 6735\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.9756\n",
      "Average policy_loss: 0.8779\n",
      "Average value_loss: 0.0976\n",
      "Replay buffer size: 6825\n",
      "Time taken: 56.8s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.9805\n",
      "Average policy_loss: 0.8826\n",
      "Average value_loss: 0.0979\n",
      "Replay buffer size: 6911\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.9761\n",
      "Average policy_loss: 0.8773\n",
      "Average value_loss: 0.0988\n",
      "Replay buffer size: 6997\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.9799\n",
      "Average policy_loss: 0.8810\n",
      "Average value_loss: 0.0989\n",
      "Replay buffer size: 7092\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.9802\n",
      "Average policy_loss: 0.8805\n",
      "Average value_loss: 0.0997\n",
      "Replay buffer size: 7187\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.9804\n",
      "Average policy_loss: 0.8810\n",
      "Average value_loss: 0.0995\n",
      "Replay buffer size: 7277\n",
      "Time taken: 55.6s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.9725\n",
      "Average policy_loss: 0.8723\n",
      "Average value_loss: 0.1002\n",
      "Replay buffer size: 7366\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.9890\n",
      "Average policy_loss: 0.8897\n",
      "Average value_loss: 0.0993\n",
      "Replay buffer size: 7452\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.9812\n",
      "Average policy_loss: 0.8820\n",
      "Average value_loss: 0.0993\n",
      "Replay buffer size: 7542\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.9794\n",
      "Average policy_loss: 0.8833\n",
      "Average value_loss: 0.0961\n",
      "Replay buffer size: 7637\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.9884\n",
      "Average policy_loss: 0.8899\n",
      "Average value_loss: 0.0985\n",
      "Replay buffer size: 7726\n",
      "Time taken: 55.6s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.9841\n",
      "Average policy_loss: 0.8814\n",
      "Average value_loss: 0.1027\n",
      "Replay buffer size: 7821\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.9701\n",
      "Average policy_loss: 0.8715\n",
      "Average value_loss: 0.0987\n",
      "Replay buffer size: 7915\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.9783\n",
      "Average policy_loss: 0.8768\n",
      "Average value_loss: 0.1015\n",
      "Replay buffer size: 8004\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.9795\n",
      "Average policy_loss: 0.8750\n",
      "Average value_loss: 0.1045\n",
      "Replay buffer size: 8091\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.9789\n",
      "Average policy_loss: 0.8787\n",
      "Average value_loss: 0.1003\n",
      "Replay buffer size: 8191\n",
      "Time taken: 56.2s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.9793\n",
      "Average policy_loss: 0.8756\n",
      "Average value_loss: 0.1037\n",
      "Replay buffer size: 8279\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.9678\n",
      "Average policy_loss: 0.8705\n",
      "Average value_loss: 0.0973\n",
      "Replay buffer size: 8375\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.9904\n",
      "Average policy_loss: 0.8885\n",
      "Average value_loss: 0.1020\n",
      "Replay buffer size: 8465\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.9778\n",
      "Average policy_loss: 0.8751\n",
      "Average value_loss: 0.1028\n",
      "Replay buffer size: 8552\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.9808\n",
      "Average policy_loss: 0.8812\n",
      "Average value_loss: 0.0996\n",
      "Replay buffer size: 8651\n",
      "Time taken: 54.0s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.9713\n",
      "Average policy_loss: 0.8742\n",
      "Average value_loss: 0.0970\n",
      "Replay buffer size: 8744\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.9691\n",
      "Average policy_loss: 0.8724\n",
      "Average value_loss: 0.0967\n",
      "Replay buffer size: 8840\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.9750\n",
      "Average policy_loss: 0.8736\n",
      "Average value_loss: 0.1015\n",
      "Replay buffer size: 8931\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.9766\n",
      "Average policy_loss: 0.8765\n",
      "Average value_loss: 0.1001\n",
      "Replay buffer size: 9023\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.9674\n",
      "Average policy_loss: 0.8645\n",
      "Average value_loss: 0.1029\n",
      "Replay buffer size: 9112\n",
      "Time taken: 55.8s\n",
      "\n",
      "Training complete! Total time: 0.7h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>iteration_time</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂█▂▂█▂▃▃▂▂▂▂▂▂▂▂▂█▂▂▃█</td></tr><tr><td>loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>█▁▅▃▅▆▄▅▃▅▇█▅▅▆▅▇▅▆▄▅▆█▂▃▅▃▅▅▅▆▆▅▄▆▅▄█▄▅</td></tr><tr><td>policy_loss</td><td>▇▁▆▆▇▇█▆▇▇▇▆▇▅▆▆▅▆▆▆▆▅▅▆▆▆▆▇▆▆▆▆▆▇▇▆▆▆▆▅</td></tr><tr><td>value_loss</td><td>█▂▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.2</td></tr><tr><td>buffer_size</td><td>9112</td></tr><tr><td>iteration_time</td><td>55.79177</td></tr><tr><td>loss</td><td>0.96737</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>89</td></tr><tr><td>policy_loss</td><td>0.86445</td></tr><tr><td>total_time_hours</td><td>0.67035</td></tr><tr><td>value_loss</td><td>0.10291</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worthy-sweep-40</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/qjqzvbk9' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/qjqzvbk9</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 22 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_211059-qjqzvbk9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b29skn5d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03951229107871487\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: small\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.4830237912634562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0002582797354448806\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_215118-b29skn5d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/b29skn5d' target=\"_blank\">astral-sweep-41</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/b29skn5d' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/b29skn5d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.5095\n",
      "Average policy_loss: 0.7264\n",
      "Average value_loss: 0.7831\n",
      "Replay buffer size: 76\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 0.9776\n",
      "Average policy_loss: 0.6944\n",
      "Average value_loss: 0.2831\n",
      "Replay buffer size: 163\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 0.8532\n",
      "Average policy_loss: 0.6554\n",
      "Average value_loss: 0.1978\n",
      "Replay buffer size: 252\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.8493\n",
      "Average policy_loss: 0.6835\n",
      "Average value_loss: 0.1657\n",
      "Replay buffer size: 344\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.8667\n",
      "Average policy_loss: 0.7026\n",
      "Average value_loss: 0.1641\n",
      "Replay buffer size: 435\n",
      "Time taken: 54.6s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.8760\n",
      "Average policy_loss: 0.7108\n",
      "Average value_loss: 0.1652\n",
      "Replay buffer size: 520\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.8606\n",
      "Average policy_loss: 0.7107\n",
      "Average value_loss: 0.1498\n",
      "Replay buffer size: 618\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.8477\n",
      "Average policy_loss: 0.7081\n",
      "Average value_loss: 0.1396\n",
      "Replay buffer size: 712\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.8547\n",
      "Average policy_loss: 0.7137\n",
      "Average value_loss: 0.1411\n",
      "Replay buffer size: 802\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.8434\n",
      "Average policy_loss: 0.7106\n",
      "Average value_loss: 0.1328\n",
      "Replay buffer size: 896\n",
      "Time taken: 58.0s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.8510\n",
      "Average policy_loss: 0.7089\n",
      "Average value_loss: 0.1421\n",
      "Replay buffer size: 985\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.8579\n",
      "Average policy_loss: 0.7139\n",
      "Average value_loss: 0.1440\n",
      "Replay buffer size: 1078\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.8625\n",
      "Average policy_loss: 0.7121\n",
      "Average value_loss: 0.1503\n",
      "Replay buffer size: 1164\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.8655\n",
      "Average policy_loss: 0.7142\n",
      "Average value_loss: 0.1512\n",
      "Replay buffer size: 1245\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.8522\n",
      "Average policy_loss: 0.7052\n",
      "Average value_loss: 0.1470\n",
      "Replay buffer size: 1338\n",
      "Time taken: 60.1s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.8436\n",
      "Average policy_loss: 0.7016\n",
      "Average value_loss: 0.1420\n",
      "Replay buffer size: 1433\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.8374\n",
      "Average policy_loss: 0.6951\n",
      "Average value_loss: 0.1423\n",
      "Replay buffer size: 1527\n",
      "Time taken: 18.5s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.8320\n",
      "Average policy_loss: 0.6912\n",
      "Average value_loss: 0.1408\n",
      "Replay buffer size: 1624\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.8185\n",
      "Average policy_loss: 0.6815\n",
      "Average value_loss: 0.1371\n",
      "Replay buffer size: 1717\n",
      "Time taken: 19.1s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.8211\n",
      "Average policy_loss: 0.6836\n",
      "Average value_loss: 0.1375\n",
      "Replay buffer size: 1804\n",
      "Time taken: 59.2s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.8185\n",
      "Average policy_loss: 0.6822\n",
      "Average value_loss: 0.1363\n",
      "Replay buffer size: 1896\n",
      "Time taken: 18.3s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.8162\n",
      "Average policy_loss: 0.6830\n",
      "Average value_loss: 0.1332\n",
      "Replay buffer size: 1989\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.7975\n",
      "Average policy_loss: 0.6712\n",
      "Average value_loss: 0.1263\n",
      "Replay buffer size: 2089\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.8055\n",
      "Average policy_loss: 0.6782\n",
      "Average value_loss: 0.1273\n",
      "Replay buffer size: 2185\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.8028\n",
      "Average policy_loss: 0.6775\n",
      "Average value_loss: 0.1253\n",
      "Replay buffer size: 2280\n",
      "Time taken: 62.6s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.8034\n",
      "Average policy_loss: 0.6763\n",
      "Average value_loss: 0.1270\n",
      "Replay buffer size: 2372\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.8080\n",
      "Average policy_loss: 0.6813\n",
      "Average value_loss: 0.1267\n",
      "Replay buffer size: 2460\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.8063\n",
      "Average policy_loss: 0.6838\n",
      "Average value_loss: 0.1225\n",
      "Replay buffer size: 2555\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.8053\n",
      "Average policy_loss: 0.6843\n",
      "Average value_loss: 0.1210\n",
      "Replay buffer size: 2643\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.8110\n",
      "Average policy_loss: 0.6863\n",
      "Average value_loss: 0.1247\n",
      "Replay buffer size: 2726\n",
      "Time taken: 61.3s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.8033\n",
      "Average policy_loss: 0.6827\n",
      "Average value_loss: 0.1206\n",
      "Replay buffer size: 2822\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.8042\n",
      "Average policy_loss: 0.6806\n",
      "Average value_loss: 0.1236\n",
      "Replay buffer size: 2914\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.8016\n",
      "Average policy_loss: 0.6832\n",
      "Average value_loss: 0.1184\n",
      "Replay buffer size: 3014\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.7980\n",
      "Average policy_loss: 0.6797\n",
      "Average value_loss: 0.1183\n",
      "Replay buffer size: 3103\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.7937\n",
      "Average policy_loss: 0.6781\n",
      "Average value_loss: 0.1156\n",
      "Replay buffer size: 3194\n",
      "Time taken: 62.2s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.7969\n",
      "Average policy_loss: 0.6801\n",
      "Average value_loss: 0.1168\n",
      "Replay buffer size: 3288\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.7963\n",
      "Average policy_loss: 0.6798\n",
      "Average value_loss: 0.1164\n",
      "Replay buffer size: 3382\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.7995\n",
      "Average policy_loss: 0.6808\n",
      "Average value_loss: 0.1186\n",
      "Replay buffer size: 3474\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.7933\n",
      "Average policy_loss: 0.6773\n",
      "Average value_loss: 0.1160\n",
      "Replay buffer size: 3564\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.7985\n",
      "Average policy_loss: 0.6796\n",
      "Average value_loss: 0.1189\n",
      "Replay buffer size: 3651\n",
      "Time taken: 61.5s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.7968\n",
      "Average policy_loss: 0.6795\n",
      "Average value_loss: 0.1173\n",
      "Replay buffer size: 3747\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.7981\n",
      "Average policy_loss: 0.6810\n",
      "Average value_loss: 0.1171\n",
      "Replay buffer size: 3842\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.7956\n",
      "Average policy_loss: 0.6810\n",
      "Average value_loss: 0.1146\n",
      "Replay buffer size: 3940\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.8009\n",
      "Average policy_loss: 0.6841\n",
      "Average value_loss: 0.1168\n",
      "Replay buffer size: 4031\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.7978\n",
      "Average policy_loss: 0.6814\n",
      "Average value_loss: 0.1164\n",
      "Replay buffer size: 4116\n",
      "Time taken: 64.1s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.8077\n",
      "Average policy_loss: 0.6904\n",
      "Average value_loss: 0.1172\n",
      "Replay buffer size: 4211\n",
      "Time taken: 19.3s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.8001\n",
      "Average policy_loss: 0.6835\n",
      "Average value_loss: 0.1167\n",
      "Replay buffer size: 4304\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.8044\n",
      "Average policy_loss: 0.6885\n",
      "Average value_loss: 0.1159\n",
      "Replay buffer size: 4404\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.7912\n",
      "Average policy_loss: 0.6784\n",
      "Average value_loss: 0.1128\n",
      "Replay buffer size: 4502\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.8016\n",
      "Average policy_loss: 0.6871\n",
      "Average value_loss: 0.1145\n",
      "Replay buffer size: 4593\n",
      "Time taken: 67.8s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.7930\n",
      "Average policy_loss: 0.6804\n",
      "Average value_loss: 0.1126\n",
      "Replay buffer size: 4689\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.7967\n",
      "Average policy_loss: 0.6844\n",
      "Average value_loss: 0.1123\n",
      "Replay buffer size: 4779\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.7950\n",
      "Average policy_loss: 0.6830\n",
      "Average value_loss: 0.1121\n",
      "Replay buffer size: 4869\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.8000\n",
      "Average policy_loss: 0.6865\n",
      "Average value_loss: 0.1135\n",
      "Replay buffer size: 4958\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.7998\n",
      "Average policy_loss: 0.6867\n",
      "Average value_loss: 0.1131\n",
      "Replay buffer size: 5047\n",
      "Time taken: 66.3s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.7994\n",
      "Average policy_loss: 0.6865\n",
      "Average value_loss: 0.1130\n",
      "Replay buffer size: 5141\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.8038\n",
      "Average policy_loss: 0.6903\n",
      "Average value_loss: 0.1135\n",
      "Replay buffer size: 5228\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.8086\n",
      "Average policy_loss: 0.6925\n",
      "Average value_loss: 0.1161\n",
      "Replay buffer size: 5320\n",
      "Time taken: 19.2s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.8001\n",
      "Average policy_loss: 0.6867\n",
      "Average value_loss: 0.1133\n",
      "Replay buffer size: 5419\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.7988\n",
      "Average policy_loss: 0.6837\n",
      "Average value_loss: 0.1151\n",
      "Replay buffer size: 5514\n",
      "Time taken: 66.1s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.8033\n",
      "Average policy_loss: 0.6885\n",
      "Average value_loss: 0.1148\n",
      "Replay buffer size: 5608\n",
      "Time taken: 19.3s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.8028\n",
      "Average policy_loss: 0.6883\n",
      "Average value_loss: 0.1145\n",
      "Replay buffer size: 5706\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.8064\n",
      "Average policy_loss: 0.6920\n",
      "Average value_loss: 0.1143\n",
      "Replay buffer size: 5794\n",
      "Time taken: 23.8s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.8099\n",
      "Average policy_loss: 0.6940\n",
      "Average value_loss: 0.1159\n",
      "Replay buffer size: 5880\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 40.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.8123\n",
      "Average policy_loss: 0.6975\n",
      "Average value_loss: 0.1148\n",
      "Replay buffer size: 5972\n",
      "Time taken: 64.2s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.8101\n",
      "Average policy_loss: 0.6938\n",
      "Average value_loss: 0.1163\n",
      "Replay buffer size: 6062\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.8173\n",
      "Average policy_loss: 0.7011\n",
      "Average value_loss: 0.1162\n",
      "Replay buffer size: 6160\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.8060\n",
      "Average policy_loss: 0.6921\n",
      "Average value_loss: 0.1139\n",
      "Replay buffer size: 6258\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.8095\n",
      "Average policy_loss: 0.6942\n",
      "Average value_loss: 0.1153\n",
      "Replay buffer size: 6349\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.8127\n",
      "Average policy_loss: 0.6983\n",
      "Average value_loss: 0.1144\n",
      "Replay buffer size: 6449\n",
      "Time taken: 67.1s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.8138\n",
      "Average policy_loss: 0.6985\n",
      "Average value_loss: 0.1153\n",
      "Replay buffer size: 6541\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.8069\n",
      "Average policy_loss: 0.6929\n",
      "Average value_loss: 0.1139\n",
      "Replay buffer size: 6630\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.8065\n",
      "Average policy_loss: 0.6930\n",
      "Average value_loss: 0.1135\n",
      "Replay buffer size: 6722\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.8146\n",
      "Average policy_loss: 0.6994\n",
      "Average value_loss: 0.1152\n",
      "Replay buffer size: 6818\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.8167\n",
      "Average policy_loss: 0.7024\n",
      "Average value_loss: 0.1142\n",
      "Replay buffer size: 6907\n",
      "Time taken: 66.8s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.8123\n",
      "Average policy_loss: 0.6971\n",
      "Average value_loss: 0.1152\n",
      "Replay buffer size: 7000\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.8127\n",
      "Average policy_loss: 0.6989\n",
      "Average value_loss: 0.1139\n",
      "Replay buffer size: 7096\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.8109\n",
      "Average policy_loss: 0.6977\n",
      "Average value_loss: 0.1132\n",
      "Replay buffer size: 7182\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.8128\n",
      "Average policy_loss: 0.6962\n",
      "Average value_loss: 0.1166\n",
      "Replay buffer size: 7272\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.8136\n",
      "Average policy_loss: 0.6965\n",
      "Average value_loss: 0.1170\n",
      "Replay buffer size: 7363\n",
      "Time taken: 68.5s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.8180\n",
      "Average policy_loss: 0.7027\n",
      "Average value_loss: 0.1152\n",
      "Replay buffer size: 7457\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.8159\n",
      "Average policy_loss: 0.7000\n",
      "Average value_loss: 0.1159\n",
      "Replay buffer size: 7542\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.8172\n",
      "Average policy_loss: 0.7019\n",
      "Average value_loss: 0.1153\n",
      "Replay buffer size: 7632\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.8180\n",
      "Average policy_loss: 0.7023\n",
      "Average value_loss: 0.1157\n",
      "Replay buffer size: 7725\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.8147\n",
      "Average policy_loss: 0.6995\n",
      "Average value_loss: 0.1152\n",
      "Replay buffer size: 7819\n",
      "Time taken: 69.6s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.8182\n",
      "Average policy_loss: 0.7052\n",
      "Average value_loss: 0.1130\n",
      "Replay buffer size: 7907\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.8245\n",
      "Average policy_loss: 0.7081\n",
      "Average value_loss: 0.1163\n",
      "Replay buffer size: 7997\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.8148\n",
      "Average policy_loss: 0.6998\n",
      "Average value_loss: 0.1151\n",
      "Replay buffer size: 8088\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.8176\n",
      "Average policy_loss: 0.7036\n",
      "Average value_loss: 0.1141\n",
      "Replay buffer size: 8186\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.8228\n",
      "Average policy_loss: 0.7074\n",
      "Average value_loss: 0.1154\n",
      "Replay buffer size: 8275\n",
      "Time taken: 68.4s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.8229\n",
      "Average policy_loss: 0.7082\n",
      "Average value_loss: 0.1147\n",
      "Replay buffer size: 8359\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.8176\n",
      "Average policy_loss: 0.7038\n",
      "Average value_loss: 0.1137\n",
      "Replay buffer size: 8457\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.8302\n",
      "Average policy_loss: 0.7155\n",
      "Average value_loss: 0.1146\n",
      "Replay buffer size: 8546\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.8279\n",
      "Average policy_loss: 0.7120\n",
      "Average value_loss: 0.1159\n",
      "Replay buffer size: 8642\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.8263\n",
      "Average policy_loss: 0.7119\n",
      "Average value_loss: 0.1143\n",
      "Replay buffer size: 8732\n",
      "Time taken: 70.2s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.8268\n",
      "Average policy_loss: 0.7129\n",
      "Average value_loss: 0.1139\n",
      "Replay buffer size: 8818\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.8285\n",
      "Average policy_loss: 0.7145\n",
      "Average value_loss: 0.1140\n",
      "Replay buffer size: 8914\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.8255\n",
      "Average policy_loss: 0.7116\n",
      "Average value_loss: 0.1139\n",
      "Replay buffer size: 9006\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.8328\n",
      "Average policy_loss: 0.7176\n",
      "Average value_loss: 0.1153\n",
      "Replay buffer size: 9094\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.8312\n",
      "Average policy_loss: 0.7155\n",
      "Average value_loss: 0.1157\n",
      "Replay buffer size: 9175\n",
      "Time taken: 68.5s\n",
      "\n",
      "Training complete! Total time: 0.8h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>iteration_time</td><td>▁▁▂▂▂▂▇▂▂▂▂▂▂▂▂▇▂▇▂▂▂█▂▂▃▇▂▂█▂▂█▂▂█▂▂▂▂█</td></tr><tr><td>loss</td><td>█▃▄▄▃▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▃▅▂▆▄▁▅▅▅▅▆▅▇█▄▅▄▆▅█▄▄▆▆▄▇▅█▅▄▅▆▅▆▄▄▇▄▇▄</td></tr><tr><td>policy_loss</td><td>▁▄▆▇█▆▅▄▄▄▃▄▄▃▄▄▄▄▄▅▅▄▄▅▅▆▆▅▆▆▆▆▇▆▆▇▇███</td></tr><tr><td>value_loss</td><td>█▄▃▂▂▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.1</td></tr><tr><td>buffer_size</td><td>9175</td></tr><tr><td>iteration_time</td><td>68.52223</td></tr><tr><td>loss</td><td>0.83115</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>81</td></tr><tr><td>policy_loss</td><td>0.71548</td></tr><tr><td>total_time_hours</td><td>0.7959</td></tr><tr><td>value_loss</td><td>0.11567</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">astral-sweep-41</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/b29skn5d' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/b29skn5d</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 24 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_215118-b29skn5d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1qexohwq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.004272176241629109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.6510314825776856\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001031966998491176\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_223911-1qexohwq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1qexohwq' target=\"_blank\">leafy-sweep-42</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1qexohwq' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1qexohwq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.9031\n",
      "Average policy_loss: 1.5660\n",
      "Average value_loss: 0.3372\n",
      "Replay buffer size: 86\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.1175\n",
      "Average policy_loss: 0.5808\n",
      "Average value_loss: 0.5367\n",
      "Replay buffer size: 184\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.0386\n",
      "Average policy_loss: 0.5364\n",
      "Average value_loss: 0.5023\n",
      "Replay buffer size: 276\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.9011\n",
      "Average policy_loss: 0.5363\n",
      "Average value_loss: 0.3648\n",
      "Replay buffer size: 367\n",
      "Time taken: 10.7s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.7148\n",
      "Average policy_loss: 0.4860\n",
      "Average value_loss: 0.2288\n",
      "Replay buffer size: 465\n",
      "Time taken: 39.1s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.7092\n",
      "Average policy_loss: 0.5316\n",
      "Average value_loss: 0.1776\n",
      "Replay buffer size: 562\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.7457\n",
      "Average policy_loss: 0.5994\n",
      "Average value_loss: 0.1463\n",
      "Replay buffer size: 650\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.7633\n",
      "Average policy_loss: 0.6325\n",
      "Average value_loss: 0.1308\n",
      "Replay buffer size: 736\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.7823\n",
      "Average policy_loss: 0.6546\n",
      "Average value_loss: 0.1276\n",
      "Replay buffer size: 808\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.8029\n",
      "Average policy_loss: 0.6814\n",
      "Average value_loss: 0.1215\n",
      "Replay buffer size: 886\n",
      "Time taken: 39.1s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.7957\n",
      "Average policy_loss: 0.6816\n",
      "Average value_loss: 0.1141\n",
      "Replay buffer size: 968\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.8024\n",
      "Average policy_loss: 0.6904\n",
      "Average value_loss: 0.1120\n",
      "Replay buffer size: 1044\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.8010\n",
      "Average policy_loss: 0.6977\n",
      "Average value_loss: 0.1033\n",
      "Replay buffer size: 1112\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.7957\n",
      "Average policy_loss: 0.6952\n",
      "Average value_loss: 0.1005\n",
      "Replay buffer size: 1186\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.7957\n",
      "Average policy_loss: 0.6953\n",
      "Average value_loss: 0.1005\n",
      "Replay buffer size: 1256\n",
      "Time taken: 34.4s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.7981\n",
      "Average policy_loss: 0.6968\n",
      "Average value_loss: 0.1013\n",
      "Replay buffer size: 1330\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.7984\n",
      "Average policy_loss: 0.6998\n",
      "Average value_loss: 0.0985\n",
      "Replay buffer size: 1402\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.8011\n",
      "Average policy_loss: 0.7027\n",
      "Average value_loss: 0.0984\n",
      "Replay buffer size: 1478\n",
      "Time taken: 10.7s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.8020\n",
      "Average policy_loss: 0.7025\n",
      "Average value_loss: 0.0995\n",
      "Replay buffer size: 1554\n",
      "Time taken: 10.7s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.7944\n",
      "Average policy_loss: 0.7031\n",
      "Average value_loss: 0.0913\n",
      "Replay buffer size: 1626\n",
      "Time taken: 33.6s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.7935\n",
      "Average policy_loss: 0.6936\n",
      "Average value_loss: 0.0999\n",
      "Replay buffer size: 1705\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.7844\n",
      "Average policy_loss: 0.6958\n",
      "Average value_loss: 0.0885\n",
      "Replay buffer size: 1779\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.7869\n",
      "Average policy_loss: 0.6968\n",
      "Average value_loss: 0.0901\n",
      "Replay buffer size: 1855\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.7815\n",
      "Average policy_loss: 0.6936\n",
      "Average value_loss: 0.0879\n",
      "Replay buffer size: 1933\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.7838\n",
      "Average policy_loss: 0.6962\n",
      "Average value_loss: 0.0876\n",
      "Replay buffer size: 2005\n",
      "Time taken: 35.8s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.7824\n",
      "Average policy_loss: 0.6978\n",
      "Average value_loss: 0.0846\n",
      "Replay buffer size: 2079\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.7813\n",
      "Average policy_loss: 0.6975\n",
      "Average value_loss: 0.0838\n",
      "Replay buffer size: 2145\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.7713\n",
      "Average policy_loss: 0.6932\n",
      "Average value_loss: 0.0781\n",
      "Replay buffer size: 2215\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.7749\n",
      "Average policy_loss: 0.6934\n",
      "Average value_loss: 0.0815\n",
      "Replay buffer size: 2286\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.7757\n",
      "Average policy_loss: 0.6951\n",
      "Average value_loss: 0.0806\n",
      "Replay buffer size: 2358\n",
      "Time taken: 34.2s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.7738\n",
      "Average policy_loss: 0.6942\n",
      "Average value_loss: 0.0797\n",
      "Replay buffer size: 2430\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.7737\n",
      "Average policy_loss: 0.6950\n",
      "Average value_loss: 0.0786\n",
      "Replay buffer size: 2506\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.7710\n",
      "Average policy_loss: 0.6932\n",
      "Average value_loss: 0.0778\n",
      "Replay buffer size: 2582\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.7680\n",
      "Average policy_loss: 0.6894\n",
      "Average value_loss: 0.0786\n",
      "Replay buffer size: 2657\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.7592\n",
      "Average policy_loss: 0.6840\n",
      "Average value_loss: 0.0752\n",
      "Replay buffer size: 2731\n",
      "Time taken: 34.3s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.7609\n",
      "Average policy_loss: 0.6860\n",
      "Average value_loss: 0.0749\n",
      "Replay buffer size: 2807\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.7578\n",
      "Average policy_loss: 0.6847\n",
      "Average value_loss: 0.0731\n",
      "Replay buffer size: 2879\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.7497\n",
      "Average policy_loss: 0.6783\n",
      "Average value_loss: 0.0714\n",
      "Replay buffer size: 2957\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.7531\n",
      "Average policy_loss: 0.6800\n",
      "Average value_loss: 0.0731\n",
      "Replay buffer size: 3028\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.7524\n",
      "Average policy_loss: 0.6806\n",
      "Average value_loss: 0.0718\n",
      "Replay buffer size: 3102\n",
      "Time taken: 32.5s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.7509\n",
      "Average policy_loss: 0.6795\n",
      "Average value_loss: 0.0714\n",
      "Replay buffer size: 3168\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.7520\n",
      "Average policy_loss: 0.6811\n",
      "Average value_loss: 0.0708\n",
      "Replay buffer size: 3243\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.7539\n",
      "Average policy_loss: 0.6835\n",
      "Average value_loss: 0.0704\n",
      "Replay buffer size: 3323\n",
      "Time taken: 9.7s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.7583\n",
      "Average policy_loss: 0.6868\n",
      "Average value_loss: 0.0716\n",
      "Replay buffer size: 3399\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.7493\n",
      "Average policy_loss: 0.6787\n",
      "Average value_loss: 0.0706\n",
      "Replay buffer size: 3470\n",
      "Time taken: 32.7s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.7509\n",
      "Average policy_loss: 0.6821\n",
      "Average value_loss: 0.0688\n",
      "Replay buffer size: 3544\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.7479\n",
      "Average policy_loss: 0.6799\n",
      "Average value_loss: 0.0681\n",
      "Replay buffer size: 3616\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.7511\n",
      "Average policy_loss: 0.6813\n",
      "Average value_loss: 0.0698\n",
      "Replay buffer size: 3684\n",
      "Time taken: 9.7s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.7423\n",
      "Average policy_loss: 0.6770\n",
      "Average value_loss: 0.0653\n",
      "Replay buffer size: 3752\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.7401\n",
      "Average policy_loss: 0.6757\n",
      "Average value_loss: 0.0644\n",
      "Replay buffer size: 3824\n",
      "Time taken: 33.6s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.7447\n",
      "Average policy_loss: 0.6788\n",
      "Average value_loss: 0.0658\n",
      "Replay buffer size: 3898\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.7439\n",
      "Average policy_loss: 0.6810\n",
      "Average value_loss: 0.0629\n",
      "Replay buffer size: 3970\n",
      "Time taken: 9.7s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.7398\n",
      "Average policy_loss: 0.6772\n",
      "Average value_loss: 0.0626\n",
      "Replay buffer size: 4040\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.7375\n",
      "Average policy_loss: 0.6735\n",
      "Average value_loss: 0.0640\n",
      "Replay buffer size: 4113\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.7397\n",
      "Average policy_loss: 0.6767\n",
      "Average value_loss: 0.0631\n",
      "Replay buffer size: 4191\n",
      "Time taken: 33.6s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.7371\n",
      "Average policy_loss: 0.6737\n",
      "Average value_loss: 0.0634\n",
      "Replay buffer size: 4263\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.7368\n",
      "Average policy_loss: 0.6747\n",
      "Average value_loss: 0.0621\n",
      "Replay buffer size: 4333\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.7318\n",
      "Average policy_loss: 0.6724\n",
      "Average value_loss: 0.0594\n",
      "Replay buffer size: 4407\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.7346\n",
      "Average policy_loss: 0.6743\n",
      "Average value_loss: 0.0603\n",
      "Replay buffer size: 4484\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.7320\n",
      "Average policy_loss: 0.6712\n",
      "Average value_loss: 0.0608\n",
      "Replay buffer size: 4556\n",
      "Time taken: 32.6s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.7290\n",
      "Average policy_loss: 0.6692\n",
      "Average value_loss: 0.0598\n",
      "Replay buffer size: 4632\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.7347\n",
      "Average policy_loss: 0.6702\n",
      "Average value_loss: 0.0645\n",
      "Replay buffer size: 4702\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.7312\n",
      "Average policy_loss: 0.6681\n",
      "Average value_loss: 0.0631\n",
      "Replay buffer size: 4782\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.7302\n",
      "Average policy_loss: 0.6686\n",
      "Average value_loss: 0.0616\n",
      "Replay buffer size: 4850\n",
      "Time taken: 9.8s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.7327\n",
      "Average policy_loss: 0.6714\n",
      "Average value_loss: 0.0613\n",
      "Replay buffer size: 4928\n",
      "Time taken: 33.0s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.7225\n",
      "Average policy_loss: 0.6634\n",
      "Average value_loss: 0.0591\n",
      "Replay buffer size: 5000\n",
      "Time taken: 10.7s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.7297\n",
      "Average policy_loss: 0.6696\n",
      "Average value_loss: 0.0601\n",
      "Replay buffer size: 5073\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.7269\n",
      "Average policy_loss: 0.6657\n",
      "Average value_loss: 0.0612\n",
      "Replay buffer size: 5147\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.7279\n",
      "Average policy_loss: 0.6653\n",
      "Average value_loss: 0.0625\n",
      "Replay buffer size: 5219\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.7257\n",
      "Average policy_loss: 0.6669\n",
      "Average value_loss: 0.0588\n",
      "Replay buffer size: 5291\n",
      "Time taken: 32.6s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.7271\n",
      "Average policy_loss: 0.6690\n",
      "Average value_loss: 0.0581\n",
      "Replay buffer size: 5365\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.7214\n",
      "Average policy_loss: 0.6645\n",
      "Average value_loss: 0.0569\n",
      "Replay buffer size: 5433\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.7238\n",
      "Average policy_loss: 0.6678\n",
      "Average value_loss: 0.0559\n",
      "Replay buffer size: 5505\n",
      "Time taken: 9.7s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.7231\n",
      "Average policy_loss: 0.6649\n",
      "Average value_loss: 0.0581\n",
      "Replay buffer size: 5577\n",
      "Time taken: 9.7s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.7232\n",
      "Average policy_loss: 0.6666\n",
      "Average value_loss: 0.0567\n",
      "Replay buffer size: 5647\n",
      "Time taken: 33.6s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.7201\n",
      "Average policy_loss: 0.6650\n",
      "Average value_loss: 0.0551\n",
      "Replay buffer size: 5719\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.7199\n",
      "Average policy_loss: 0.6655\n",
      "Average value_loss: 0.0543\n",
      "Replay buffer size: 5787\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 65 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.7187\n",
      "Average policy_loss: 0.6649\n",
      "Average value_loss: 0.0538\n",
      "Replay buffer size: 5852\n",
      "Time taken: 9.8s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.7177\n",
      "Average policy_loss: 0.6636\n",
      "Average value_loss: 0.0540\n",
      "Replay buffer size: 5926\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.7194\n",
      "Average policy_loss: 0.6653\n",
      "Average value_loss: 0.0542\n",
      "Replay buffer size: 6008\n",
      "Time taken: 32.0s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.7210\n",
      "Average policy_loss: 0.6665\n",
      "Average value_loss: 0.0545\n",
      "Replay buffer size: 6080\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.7152\n",
      "Average policy_loss: 0.6624\n",
      "Average value_loss: 0.0528\n",
      "Replay buffer size: 6154\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.7192\n",
      "Average policy_loss: 0.6680\n",
      "Average value_loss: 0.0512\n",
      "Replay buffer size: 6226\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.7143\n",
      "Average policy_loss: 0.6618\n",
      "Average value_loss: 0.0525\n",
      "Replay buffer size: 6302\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.7193\n",
      "Average policy_loss: 0.6669\n",
      "Average value_loss: 0.0524\n",
      "Replay buffer size: 6374\n",
      "Time taken: 32.3s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.7106\n",
      "Average policy_loss: 0.6600\n",
      "Average value_loss: 0.0506\n",
      "Replay buffer size: 6442\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.7151\n",
      "Average policy_loss: 0.6629\n",
      "Average value_loss: 0.0523\n",
      "Replay buffer size: 6518\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.7149\n",
      "Average policy_loss: 0.6644\n",
      "Average value_loss: 0.0505\n",
      "Replay buffer size: 6592\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.7090\n",
      "Average policy_loss: 0.6573\n",
      "Average value_loss: 0.0517\n",
      "Replay buffer size: 6664\n",
      "Time taken: 9.7s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.7110\n",
      "Average policy_loss: 0.6617\n",
      "Average value_loss: 0.0493\n",
      "Replay buffer size: 6730\n",
      "Time taken: 33.4s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.7089\n",
      "Average policy_loss: 0.6603\n",
      "Average value_loss: 0.0486\n",
      "Replay buffer size: 6798\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.7065\n",
      "Average policy_loss: 0.6566\n",
      "Average value_loss: 0.0499\n",
      "Replay buffer size: 6868\n",
      "Time taken: 9.8s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.7085\n",
      "Average policy_loss: 0.6586\n",
      "Average value_loss: 0.0499\n",
      "Replay buffer size: 6942\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.7055\n",
      "Average policy_loss: 0.6568\n",
      "Average value_loss: 0.0487\n",
      "Replay buffer size: 7016\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.7012\n",
      "Average policy_loss: 0.6547\n",
      "Average value_loss: 0.0466\n",
      "Replay buffer size: 7092\n",
      "Time taken: 32.9s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.7070\n",
      "Average policy_loss: 0.6590\n",
      "Average value_loss: 0.0480\n",
      "Replay buffer size: 7170\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.7008\n",
      "Average policy_loss: 0.6540\n",
      "Average value_loss: 0.0468\n",
      "Replay buffer size: 7242\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.7002\n",
      "Average policy_loss: 0.6534\n",
      "Average value_loss: 0.0468\n",
      "Replay buffer size: 7312\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.7057\n",
      "Average policy_loss: 0.6586\n",
      "Average value_loss: 0.0471\n",
      "Replay buffer size: 7389\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.7058\n",
      "Average policy_loss: 0.6588\n",
      "Average value_loss: 0.0470\n",
      "Replay buffer size: 7463\n",
      "Time taken: 32.7s\n",
      "\n",
      "Training complete! Total time: 0.4h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>iteration_time</td><td>▁▁█▂▂█▁▁▁▁▁▁▁▇▁▁▇▁▁▁▁▁▁▁▆▁▁▁▇▁▁▁▁▁▁▁▁▁▇▁</td></tr><tr><td>loss</td><td>█▇▄▁▂▂▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▇█▆▃▂▃▃▄▃▄▂▃▃▃▃▄▄▂▃▃▂▃▃▄▃▃▃▄▂▄▃▃▃▃▂▁▃▃▂▃</td></tr><tr><td>policy_loss</td><td>█▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>value_loss</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.15</td></tr><tr><td>buffer_size</td><td>7463</td></tr><tr><td>iteration_time</td><td>32.70994</td></tr><tr><td>loss</td><td>0.70581</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>74</td></tr><tr><td>policy_loss</td><td>0.65882</td></tr><tr><td>total_time_hours</td><td>0.4209</td></tr><tr><td>value_loss</td><td>0.04699</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">leafy-sweep-42</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1qexohwq' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/1qexohwq</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 26 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_223911-1qexohwq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ym5evfg9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01715578684502239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: medium\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.5180851764381642\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.00026745893171497984\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_230433-ym5evfg9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ym5evfg9' target=\"_blank\">fresh-sweep-43</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ym5evfg9' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ym5evfg9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 2.0491\n",
      "Average policy_loss: 1.1416\n",
      "Average value_loss: 0.9075\n",
      "Replay buffer size: 90\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.1437\n",
      "Average policy_loss: 0.9110\n",
      "Average value_loss: 0.2327\n",
      "Replay buffer size: 175\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.0400\n",
      "Average policy_loss: 0.8409\n",
      "Average value_loss: 0.1992\n",
      "Replay buffer size: 262\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.0119\n",
      "Average policy_loss: 0.8343\n",
      "Average value_loss: 0.1776\n",
      "Replay buffer size: 357\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.9803\n",
      "Average policy_loss: 0.8227\n",
      "Average value_loss: 0.1576\n",
      "Replay buffer size: 443\n",
      "Time taken: 51.5s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.9275\n",
      "Average policy_loss: 0.7881\n",
      "Average value_loss: 0.1393\n",
      "Replay buffer size: 535\n",
      "Time taken: 13.9s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.9046\n",
      "Average policy_loss: 0.7713\n",
      "Average value_loss: 0.1333\n",
      "Replay buffer size: 625\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.8805\n",
      "Average policy_loss: 0.7567\n",
      "Average value_loss: 0.1237\n",
      "Replay buffer size: 723\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.8637\n",
      "Average policy_loss: 0.7500\n",
      "Average value_loss: 0.1136\n",
      "Replay buffer size: 819\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.8769\n",
      "Average policy_loss: 0.7547\n",
      "Average value_loss: 0.1222\n",
      "Replay buffer size: 909\n",
      "Time taken: 52.8s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.8864\n",
      "Average policy_loss: 0.7585\n",
      "Average value_loss: 0.1280\n",
      "Replay buffer size: 1000\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.8806\n",
      "Average policy_loss: 0.7569\n",
      "Average value_loss: 0.1237\n",
      "Replay buffer size: 1092\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.8949\n",
      "Average policy_loss: 0.7662\n",
      "Average value_loss: 0.1287\n",
      "Replay buffer size: 1175\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.9078\n",
      "Average policy_loss: 0.7733\n",
      "Average value_loss: 0.1346\n",
      "Replay buffer size: 1260\n",
      "Time taken: 15.1s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.9180\n",
      "Average policy_loss: 0.7802\n",
      "Average value_loss: 0.1378\n",
      "Replay buffer size: 1344\n",
      "Time taken: 55.4s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.9363\n",
      "Average policy_loss: 0.7929\n",
      "Average value_loss: 0.1433\n",
      "Replay buffer size: 1425\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.9479\n",
      "Average policy_loss: 0.8031\n",
      "Average value_loss: 0.1448\n",
      "Replay buffer size: 1513\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.9549\n",
      "Average policy_loss: 0.8069\n",
      "Average value_loss: 0.1480\n",
      "Replay buffer size: 1598\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.9729\n",
      "Average policy_loss: 0.8179\n",
      "Average value_loss: 0.1550\n",
      "Replay buffer size: 1688\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.9885\n",
      "Average policy_loss: 0.8323\n",
      "Average value_loss: 0.1562\n",
      "Replay buffer size: 1773\n",
      "Time taken: 69.5s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.9902\n",
      "Average policy_loss: 0.8329\n",
      "Average value_loss: 0.1574\n",
      "Replay buffer size: 1862\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.9946\n",
      "Average policy_loss: 0.8386\n",
      "Average value_loss: 0.1560\n",
      "Replay buffer size: 1950\n",
      "Time taken: 22.4s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.9944\n",
      "Average policy_loss: 0.8402\n",
      "Average value_loss: 0.1542\n",
      "Replay buffer size: 2040\n",
      "Time taken: 23.3s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.9950\n",
      "Average policy_loss: 0.8454\n",
      "Average value_loss: 0.1495\n",
      "Replay buffer size: 2134\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.0008\n",
      "Average policy_loss: 0.8516\n",
      "Average value_loss: 0.1492\n",
      "Replay buffer size: 2222\n",
      "Time taken: 70.7s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.0022\n",
      "Average policy_loss: 0.8514\n",
      "Average value_loss: 0.1507\n",
      "Replay buffer size: 2318\n",
      "Time taken: 24.6s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.0098\n",
      "Average policy_loss: 0.8592\n",
      "Average value_loss: 0.1507\n",
      "Replay buffer size: 2400\n",
      "Time taken: 23.6s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.0220\n",
      "Average policy_loss: 0.8661\n",
      "Average value_loss: 0.1558\n",
      "Replay buffer size: 2480\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.0192\n",
      "Average policy_loss: 0.8655\n",
      "Average value_loss: 0.1537\n",
      "Replay buffer size: 2572\n",
      "Time taken: 23.2s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.0249\n",
      "Average policy_loss: 0.8698\n",
      "Average value_loss: 0.1551\n",
      "Replay buffer size: 2662\n",
      "Time taken: 69.4s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.0164\n",
      "Average policy_loss: 0.8628\n",
      "Average value_loss: 0.1536\n",
      "Replay buffer size: 2753\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.0225\n",
      "Average policy_loss: 0.8718\n",
      "Average value_loss: 0.1506\n",
      "Replay buffer size: 2839\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.0289\n",
      "Average policy_loss: 0.8718\n",
      "Average value_loss: 0.1571\n",
      "Replay buffer size: 2928\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.0301\n",
      "Average policy_loss: 0.8728\n",
      "Average value_loss: 0.1573\n",
      "Replay buffer size: 3016\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.0296\n",
      "Average policy_loss: 0.8731\n",
      "Average value_loss: 0.1565\n",
      "Replay buffer size: 3105\n",
      "Time taken: 72.8s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.0272\n",
      "Average policy_loss: 0.8712\n",
      "Average value_loss: 0.1560\n",
      "Replay buffer size: 3198\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.0183\n",
      "Average policy_loss: 0.8668\n",
      "Average value_loss: 0.1514\n",
      "Replay buffer size: 3296\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.0253\n",
      "Average policy_loss: 0.8706\n",
      "Average value_loss: 0.1546\n",
      "Replay buffer size: 3389\n",
      "Time taken: 24.2s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.0193\n",
      "Average policy_loss: 0.8685\n",
      "Average value_loss: 0.1508\n",
      "Replay buffer size: 3483\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.0157\n",
      "Average policy_loss: 0.8661\n",
      "Average value_loss: 0.1495\n",
      "Replay buffer size: 3579\n",
      "Time taken: 67.7s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.0110\n",
      "Average policy_loss: 0.8663\n",
      "Average value_loss: 0.1447\n",
      "Replay buffer size: 3676\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.0143\n",
      "Average policy_loss: 0.8690\n",
      "Average value_loss: 0.1453\n",
      "Replay buffer size: 3765\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.0172\n",
      "Average policy_loss: 0.8716\n",
      "Average value_loss: 0.1455\n",
      "Replay buffer size: 3859\n",
      "Time taken: 24.2s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.0140\n",
      "Average policy_loss: 0.8706\n",
      "Average value_loss: 0.1434\n",
      "Replay buffer size: 3953\n",
      "Time taken: 24.0s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.0238\n",
      "Average policy_loss: 0.8753\n",
      "Average value_loss: 0.1486\n",
      "Replay buffer size: 4031\n",
      "Time taken: 71.3s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.0217\n",
      "Average policy_loss: 0.8761\n",
      "Average value_loss: 0.1456\n",
      "Replay buffer size: 4125\n",
      "Time taken: 22.4s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.0219\n",
      "Average policy_loss: 0.8742\n",
      "Average value_loss: 0.1478\n",
      "Replay buffer size: 4208\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.0182\n",
      "Average policy_loss: 0.8739\n",
      "Average value_loss: 0.1443\n",
      "Replay buffer size: 4302\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.0225\n",
      "Average policy_loss: 0.8764\n",
      "Average value_loss: 0.1461\n",
      "Replay buffer size: 4392\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.0233\n",
      "Average policy_loss: 0.8752\n",
      "Average value_loss: 0.1481\n",
      "Replay buffer size: 4470\n",
      "Time taken: 72.4s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.0287\n",
      "Average policy_loss: 0.8796\n",
      "Average value_loss: 0.1491\n",
      "Replay buffer size: 4563\n",
      "Time taken: 24.5s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.0214\n",
      "Average policy_loss: 0.8764\n",
      "Average value_loss: 0.1450\n",
      "Replay buffer size: 4658\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.0198\n",
      "Average policy_loss: 0.8764\n",
      "Average value_loss: 0.1434\n",
      "Replay buffer size: 4751\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.0204\n",
      "Average policy_loss: 0.8770\n",
      "Average value_loss: 0.1434\n",
      "Replay buffer size: 4838\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.0251\n",
      "Average policy_loss: 0.8796\n",
      "Average value_loss: 0.1455\n",
      "Replay buffer size: 4917\n",
      "Time taken: 72.0s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.0204\n",
      "Average policy_loss: 0.8767\n",
      "Average value_loss: 0.1437\n",
      "Replay buffer size: 5012\n",
      "Time taken: 23.6s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.0143\n",
      "Average policy_loss: 0.8731\n",
      "Average value_loss: 0.1412\n",
      "Replay buffer size: 5108\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.0188\n",
      "Average policy_loss: 0.8756\n",
      "Average value_loss: 0.1432\n",
      "Replay buffer size: 5190\n",
      "Time taken: 24.6s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.0155\n",
      "Average policy_loss: 0.8737\n",
      "Average value_loss: 0.1417\n",
      "Replay buffer size: 5284\n",
      "Time taken: 23.9s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.0125\n",
      "Average policy_loss: 0.8731\n",
      "Average value_loss: 0.1394\n",
      "Replay buffer size: 5378\n",
      "Time taken: 71.3s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.0133\n",
      "Average policy_loss: 0.8745\n",
      "Average value_loss: 0.1388\n",
      "Replay buffer size: 5470\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.0083\n",
      "Average policy_loss: 0.8718\n",
      "Average value_loss: 0.1366\n",
      "Replay buffer size: 5570\n",
      "Time taken: 24.1s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.0094\n",
      "Average policy_loss: 0.8725\n",
      "Average value_loss: 0.1368\n",
      "Replay buffer size: 5662\n",
      "Time taken: 23.8s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.0093\n",
      "Average policy_loss: 0.8729\n",
      "Average value_loss: 0.1364\n",
      "Replay buffer size: 5744\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.0078\n",
      "Average policy_loss: 0.8705\n",
      "Average value_loss: 0.1373\n",
      "Replay buffer size: 5828\n",
      "Time taken: 72.2s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.0040\n",
      "Average policy_loss: 0.8678\n",
      "Average value_loss: 0.1362\n",
      "Replay buffer size: 5921\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.0068\n",
      "Average policy_loss: 0.8689\n",
      "Average value_loss: 0.1379\n",
      "Replay buffer size: 6010\n",
      "Time taken: 23.6s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.0096\n",
      "Average policy_loss: 0.8701\n",
      "Average value_loss: 0.1395\n",
      "Replay buffer size: 6101\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.0102\n",
      "Average policy_loss: 0.8698\n",
      "Average value_loss: 0.1404\n",
      "Replay buffer size: 6191\n",
      "Time taken: 23.6s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.0039\n",
      "Average policy_loss: 0.8639\n",
      "Average value_loss: 0.1400\n",
      "Replay buffer size: 6285\n",
      "Time taken: 69.9s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.0094\n",
      "Average policy_loss: 0.8708\n",
      "Average value_loss: 0.1386\n",
      "Replay buffer size: 6376\n",
      "Time taken: 23.8s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.0100\n",
      "Average policy_loss: 0.8717\n",
      "Average value_loss: 0.1383\n",
      "Replay buffer size: 6468\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.0080\n",
      "Average policy_loss: 0.8711\n",
      "Average value_loss: 0.1369\n",
      "Replay buffer size: 6565\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.0067\n",
      "Average policy_loss: 0.8704\n",
      "Average value_loss: 0.1363\n",
      "Replay buffer size: 6654\n",
      "Time taken: 23.3s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.9998\n",
      "Average policy_loss: 0.8631\n",
      "Average value_loss: 0.1367\n",
      "Replay buffer size: 6749\n",
      "Time taken: 74.2s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.0015\n",
      "Average policy_loss: 0.8669\n",
      "Average value_loss: 0.1346\n",
      "Replay buffer size: 6846\n",
      "Time taken: 23.2s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.0016\n",
      "Average policy_loss: 0.8650\n",
      "Average value_loss: 0.1366\n",
      "Replay buffer size: 6932\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.9965\n",
      "Average policy_loss: 0.8621\n",
      "Average value_loss: 0.1345\n",
      "Replay buffer size: 7021\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.0015\n",
      "Average policy_loss: 0.8688\n",
      "Average value_loss: 0.1327\n",
      "Replay buffer size: 7118\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.9956\n",
      "Average policy_loss: 0.8621\n",
      "Average value_loss: 0.1336\n",
      "Replay buffer size: 7216\n",
      "Time taken: 70.9s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.9973\n",
      "Average policy_loss: 0.8639\n",
      "Average value_loss: 0.1334\n",
      "Replay buffer size: 7310\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.9924\n",
      "Average policy_loss: 0.8627\n",
      "Average value_loss: 0.1297\n",
      "Replay buffer size: 7406\n",
      "Time taken: 24.2s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.9998\n",
      "Average policy_loss: 0.8682\n",
      "Average value_loss: 0.1317\n",
      "Replay buffer size: 7497\n",
      "Time taken: 24.7s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.9945\n",
      "Average policy_loss: 0.8639\n",
      "Average value_loss: 0.1306\n",
      "Replay buffer size: 7590\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.9933\n",
      "Average policy_loss: 0.8618\n",
      "Average value_loss: 0.1315\n",
      "Replay buffer size: 7678\n",
      "Time taken: 72.4s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.9883\n",
      "Average policy_loss: 0.8600\n",
      "Average value_loss: 0.1283\n",
      "Replay buffer size: 7770\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.9951\n",
      "Average policy_loss: 0.8618\n",
      "Average value_loss: 0.1334\n",
      "Replay buffer size: 7853\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.9865\n",
      "Average policy_loss: 0.8570\n",
      "Average value_loss: 0.1295\n",
      "Replay buffer size: 7943\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.9939\n",
      "Average policy_loss: 0.8636\n",
      "Average value_loss: 0.1303\n",
      "Replay buffer size: 8041\n",
      "Time taken: 24.4s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.9932\n",
      "Average policy_loss: 0.8638\n",
      "Average value_loss: 0.1294\n",
      "Replay buffer size: 8131\n",
      "Time taken: 75.3s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.9886\n",
      "Average policy_loss: 0.8597\n",
      "Average value_loss: 0.1289\n",
      "Replay buffer size: 8225\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.9821\n",
      "Average policy_loss: 0.8560\n",
      "Average value_loss: 0.1261\n",
      "Replay buffer size: 8317\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.9861\n",
      "Average policy_loss: 0.8584\n",
      "Average value_loss: 0.1277\n",
      "Replay buffer size: 8411\n",
      "Time taken: 23.7s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.9845\n",
      "Average policy_loss: 0.8585\n",
      "Average value_loss: 0.1260\n",
      "Replay buffer size: 8499\n",
      "Time taken: 23.9s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.9876\n",
      "Average policy_loss: 0.8603\n",
      "Average value_loss: 0.1273\n",
      "Replay buffer size: 8586\n",
      "Time taken: 71.3s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.9811\n",
      "Average policy_loss: 0.8535\n",
      "Average value_loss: 0.1276\n",
      "Replay buffer size: 8669\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.9870\n",
      "Average policy_loss: 0.8567\n",
      "Average value_loss: 0.1303\n",
      "Replay buffer size: 8757\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.9852\n",
      "Average policy_loss: 0.8558\n",
      "Average value_loss: 0.1294\n",
      "Replay buffer size: 8848\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.9740\n",
      "Average policy_loss: 0.8475\n",
      "Average value_loss: 0.1265\n",
      "Replay buffer size: 8946\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.9794\n",
      "Average policy_loss: 0.8529\n",
      "Average value_loss: 0.1265\n",
      "Replay buffer size: 9041\n",
      "Time taken: 70.5s\n",
      "\n",
      "Training complete! Total time: 0.9h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iteration_time</td><td>▁▂▆▁▁▆▁▂▂▂█▂▂█▂▂▂█▂▂▂▂▂▂▂█▂█▂▂▂▂▂█▂▂▂▂▂▂</td></tr><tr><td>loss</td><td>█▄▂▁▁▂▂▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▇▆▅▅▆▃▄▅▄▇▁▅▅▆█▇█▂▇▅▁▇▇▂▇▆▂▃▅▇▆█▇█▇▇▆▇▂▇</td></tr><tr><td>policy_loss</td><td>█▄▂▂▂▁▁▁▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>value_loss</td><td>█▆▄▂▁▁▁▃▄▃▄▄▄▄▃▄▄▄▄▄▃▃▃▃▃▂▂▂▂▃▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.1</td></tr><tr><td>buffer_size</td><td>9041</td></tr><tr><td>iteration_time</td><td>70.46886</td></tr><tr><td>loss</td><td>0.97942</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>95</td></tr><tr><td>policy_loss</td><td>0.85291</td></tr><tr><td>total_time_hours</td><td>0.86627</td></tr><tr><td>value_loss</td><td>0.12651</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-sweep-43</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ym5evfg9' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/ym5evfg9</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_230433-ym5evfg9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r8dzlq0u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.002869612612950579\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.7666264946368808\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.194626106470751e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250301_235641-r8dzlq0u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/r8dzlq0u' target=\"_blank\">stellar-sweep-44</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/r8dzlq0u' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/r8dzlq0u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.8040\n",
      "Average policy_loss: 1.2633\n",
      "Average value_loss: 0.5407\n",
      "Replay buffer size: 91\n",
      "Time taken: 12.9s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.0612\n",
      "Average policy_loss: 0.7909\n",
      "Average value_loss: 0.2702\n",
      "Replay buffer size: 170\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 0.9182\n",
      "Average policy_loss: 0.7209\n",
      "Average value_loss: 0.1973\n",
      "Replay buffer size: 254\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 0.8609\n",
      "Average policy_loss: 0.6980\n",
      "Average value_loss: 0.1629\n",
      "Replay buffer size: 350\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.8807\n",
      "Average policy_loss: 0.7300\n",
      "Average value_loss: 0.1507\n",
      "Replay buffer size: 431\n",
      "Time taken: 46.5s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.8300\n",
      "Average policy_loss: 0.6994\n",
      "Average value_loss: 0.1306\n",
      "Replay buffer size: 529\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.8265\n",
      "Average policy_loss: 0.6958\n",
      "Average value_loss: 0.1307\n",
      "Replay buffer size: 616\n",
      "Time taken: 14.4s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.8107\n",
      "Average policy_loss: 0.6878\n",
      "Average value_loss: 0.1230\n",
      "Replay buffer size: 711\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.7784\n",
      "Average policy_loss: 0.6682\n",
      "Average value_loss: 0.1102\n",
      "Replay buffer size: 809\n",
      "Time taken: 12.8s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.7954\n",
      "Average policy_loss: 0.6807\n",
      "Average value_loss: 0.1147\n",
      "Replay buffer size: 896\n",
      "Time taken: 47.9s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.7732\n",
      "Average policy_loss: 0.6653\n",
      "Average value_loss: 0.1079\n",
      "Replay buffer size: 992\n",
      "Time taken: 13.0s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.7586\n",
      "Average policy_loss: 0.6585\n",
      "Average value_loss: 0.1001\n",
      "Replay buffer size: 1086\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.7723\n",
      "Average policy_loss: 0.6638\n",
      "Average value_loss: 0.1085\n",
      "Replay buffer size: 1178\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.7556\n",
      "Average policy_loss: 0.6537\n",
      "Average value_loss: 0.1018\n",
      "Replay buffer size: 1274\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.7462\n",
      "Average policy_loss: 0.6472\n",
      "Average value_loss: 0.0990\n",
      "Replay buffer size: 1371\n",
      "Time taken: 50.3s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.7443\n",
      "Average policy_loss: 0.6494\n",
      "Average value_loss: 0.0949\n",
      "Replay buffer size: 1468\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.7542\n",
      "Average policy_loss: 0.6553\n",
      "Average value_loss: 0.0988\n",
      "Replay buffer size: 1556\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.7437\n",
      "Average policy_loss: 0.6471\n",
      "Average value_loss: 0.0966\n",
      "Replay buffer size: 1655\n",
      "Time taken: 14.7s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.7491\n",
      "Average policy_loss: 0.6501\n",
      "Average value_loss: 0.0990\n",
      "Replay buffer size: 1749\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.7426\n",
      "Average policy_loss: 0.6455\n",
      "Average value_loss: 0.0971\n",
      "Replay buffer size: 1841\n",
      "Time taken: 53.8s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.7363\n",
      "Average policy_loss: 0.6429\n",
      "Average value_loss: 0.0934\n",
      "Replay buffer size: 1938\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.7385\n",
      "Average policy_loss: 0.6420\n",
      "Average value_loss: 0.0966\n",
      "Replay buffer size: 2034\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.7298\n",
      "Average policy_loss: 0.6362\n",
      "Average value_loss: 0.0936\n",
      "Replay buffer size: 2126\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.7208\n",
      "Average policy_loss: 0.6283\n",
      "Average value_loss: 0.0925\n",
      "Replay buffer size: 2221\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.7178\n",
      "Average policy_loss: 0.6293\n",
      "Average value_loss: 0.0885\n",
      "Replay buffer size: 2313\n",
      "Time taken: 54.7s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.7140\n",
      "Average policy_loss: 0.6277\n",
      "Average value_loss: 0.0863\n",
      "Replay buffer size: 2402\n",
      "Time taken: 15.7s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.7118\n",
      "Average policy_loss: 0.6256\n",
      "Average value_loss: 0.0861\n",
      "Replay buffer size: 2499\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.7111\n",
      "Average policy_loss: 0.6227\n",
      "Average value_loss: 0.0885\n",
      "Replay buffer size: 2588\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.7008\n",
      "Average policy_loss: 0.6141\n",
      "Average value_loss: 0.0867\n",
      "Replay buffer size: 2686\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.7058\n",
      "Average policy_loss: 0.6198\n",
      "Average value_loss: 0.0860\n",
      "Replay buffer size: 2776\n",
      "Time taken: 55.1s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.7018\n",
      "Average policy_loss: 0.6168\n",
      "Average value_loss: 0.0850\n",
      "Replay buffer size: 2869\n",
      "Time taken: 15.9s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.7015\n",
      "Average policy_loss: 0.6152\n",
      "Average value_loss: 0.0864\n",
      "Replay buffer size: 2967\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.7005\n",
      "Average policy_loss: 0.6144\n",
      "Average value_loss: 0.0861\n",
      "Replay buffer size: 3066\n",
      "Time taken: 14.9s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.7061\n",
      "Average policy_loss: 0.6168\n",
      "Average value_loss: 0.0893\n",
      "Replay buffer size: 3163\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.6974\n",
      "Average policy_loss: 0.6122\n",
      "Average value_loss: 0.0851\n",
      "Replay buffer size: 3257\n",
      "Time taken: 55.2s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.7041\n",
      "Average policy_loss: 0.6152\n",
      "Average value_loss: 0.0889\n",
      "Replay buffer size: 3348\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.7002\n",
      "Average policy_loss: 0.6120\n",
      "Average value_loss: 0.0881\n",
      "Replay buffer size: 3442\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.7035\n",
      "Average policy_loss: 0.6165\n",
      "Average value_loss: 0.0870\n",
      "Replay buffer size: 3535\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.6922\n",
      "Average policy_loss: 0.6076\n",
      "Average value_loss: 0.0846\n",
      "Replay buffer size: 3634\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.6944\n",
      "Average policy_loss: 0.6097\n",
      "Average value_loss: 0.0848\n",
      "Replay buffer size: 3724\n",
      "Time taken: 57.8s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.6923\n",
      "Average policy_loss: 0.6072\n",
      "Average value_loss: 0.0851\n",
      "Replay buffer size: 3822\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.6872\n",
      "Average policy_loss: 0.6036\n",
      "Average value_loss: 0.0836\n",
      "Replay buffer size: 3914\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.6880\n",
      "Average policy_loss: 0.6045\n",
      "Average value_loss: 0.0835\n",
      "Replay buffer size: 4010\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.6820\n",
      "Average policy_loss: 0.6003\n",
      "Average value_loss: 0.0817\n",
      "Replay buffer size: 4100\n",
      "Time taken: 15.8s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.6928\n",
      "Average policy_loss: 0.6087\n",
      "Average value_loss: 0.0841\n",
      "Replay buffer size: 4191\n",
      "Time taken: 57.6s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.6856\n",
      "Average policy_loss: 0.6027\n",
      "Average value_loss: 0.0829\n",
      "Replay buffer size: 4291\n",
      "Time taken: 16.3s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.6888\n",
      "Average policy_loss: 0.6066\n",
      "Average value_loss: 0.0822\n",
      "Replay buffer size: 4387\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.6888\n",
      "Average policy_loss: 0.6049\n",
      "Average value_loss: 0.0839\n",
      "Replay buffer size: 4476\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.6887\n",
      "Average policy_loss: 0.6085\n",
      "Average value_loss: 0.0802\n",
      "Replay buffer size: 4573\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.6865\n",
      "Average policy_loss: 0.6055\n",
      "Average value_loss: 0.0810\n",
      "Replay buffer size: 4671\n",
      "Time taken: 56.3s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.6808\n",
      "Average policy_loss: 0.6018\n",
      "Average value_loss: 0.0790\n",
      "Replay buffer size: 4767\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.6786\n",
      "Average policy_loss: 0.6009\n",
      "Average value_loss: 0.0777\n",
      "Replay buffer size: 4861\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.6786\n",
      "Average policy_loss: 0.6007\n",
      "Average value_loss: 0.0779\n",
      "Replay buffer size: 4951\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.6856\n",
      "Average policy_loss: 0.6066\n",
      "Average value_loss: 0.0790\n",
      "Replay buffer size: 5041\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.6863\n",
      "Average policy_loss: 0.6058\n",
      "Average value_loss: 0.0805\n",
      "Replay buffer size: 5132\n",
      "Time taken: 61.6s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.6917\n",
      "Average policy_loss: 0.6079\n",
      "Average value_loss: 0.0838\n",
      "Replay buffer size: 5229\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.6883\n",
      "Average policy_loss: 0.6063\n",
      "Average value_loss: 0.0820\n",
      "Replay buffer size: 5324\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.6881\n",
      "Average policy_loss: 0.6068\n",
      "Average value_loss: 0.0812\n",
      "Replay buffer size: 5412\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.6864\n",
      "Average policy_loss: 0.6038\n",
      "Average value_loss: 0.0826\n",
      "Replay buffer size: 5502\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.6918\n",
      "Average policy_loss: 0.6100\n",
      "Average value_loss: 0.0818\n",
      "Replay buffer size: 5596\n",
      "Time taken: 59.3s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.6846\n",
      "Average policy_loss: 0.6028\n",
      "Average value_loss: 0.0819\n",
      "Replay buffer size: 5689\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.6862\n",
      "Average policy_loss: 0.6035\n",
      "Average value_loss: 0.0827\n",
      "Replay buffer size: 5782\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.6877\n",
      "Average policy_loss: 0.6067\n",
      "Average value_loss: 0.0810\n",
      "Replay buffer size: 5876\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.6846\n",
      "Average policy_loss: 0.6038\n",
      "Average value_loss: 0.0809\n",
      "Replay buffer size: 5966\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.6906\n",
      "Average policy_loss: 0.6096\n",
      "Average value_loss: 0.0810\n",
      "Replay buffer size: 6058\n",
      "Time taken: 58.7s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.6884\n",
      "Average policy_loss: 0.6068\n",
      "Average value_loss: 0.0816\n",
      "Replay buffer size: 6153\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.6873\n",
      "Average policy_loss: 0.6070\n",
      "Average value_loss: 0.0803\n",
      "Replay buffer size: 6247\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.6833\n",
      "Average policy_loss: 0.6043\n",
      "Average value_loss: 0.0790\n",
      "Replay buffer size: 6335\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.6839\n",
      "Average policy_loss: 0.6047\n",
      "Average value_loss: 0.0792\n",
      "Replay buffer size: 6431\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.6860\n",
      "Average policy_loss: 0.6071\n",
      "Average value_loss: 0.0789\n",
      "Replay buffer size: 6529\n",
      "Time taken: 58.1s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.6828\n",
      "Average policy_loss: 0.6062\n",
      "Average value_loss: 0.0766\n",
      "Replay buffer size: 6625\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.6816\n",
      "Average policy_loss: 0.6051\n",
      "Average value_loss: 0.0764\n",
      "Replay buffer size: 6716\n",
      "Time taken: 17.0s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.6849\n",
      "Average policy_loss: 0.6062\n",
      "Average value_loss: 0.0787\n",
      "Replay buffer size: 6806\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.6791\n",
      "Average policy_loss: 0.6023\n",
      "Average value_loss: 0.0769\n",
      "Replay buffer size: 6902\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.6768\n",
      "Average policy_loss: 0.6026\n",
      "Average value_loss: 0.0742\n",
      "Replay buffer size: 6998\n",
      "Time taken: 61.0s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.6803\n",
      "Average policy_loss: 0.6042\n",
      "Average value_loss: 0.0761\n",
      "Replay buffer size: 7089\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.6891\n",
      "Average policy_loss: 0.6112\n",
      "Average value_loss: 0.0779\n",
      "Replay buffer size: 7181\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.6812\n",
      "Average policy_loss: 0.6051\n",
      "Average value_loss: 0.0761\n",
      "Replay buffer size: 7267\n",
      "Time taken: 17.1s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.6882\n",
      "Average policy_loss: 0.6111\n",
      "Average value_loss: 0.0771\n",
      "Replay buffer size: 7359\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.6914\n",
      "Average policy_loss: 0.6147\n",
      "Average value_loss: 0.0767\n",
      "Replay buffer size: 7453\n",
      "Time taken: 62.5s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.6917\n",
      "Average policy_loss: 0.6156\n",
      "Average value_loss: 0.0761\n",
      "Replay buffer size: 7541\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.6881\n",
      "Average policy_loss: 0.6116\n",
      "Average value_loss: 0.0765\n",
      "Replay buffer size: 7638\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.6948\n",
      "Average policy_loss: 0.6157\n",
      "Average value_loss: 0.0791\n",
      "Replay buffer size: 7724\n",
      "Time taken: 17.8s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.6895\n",
      "Average policy_loss: 0.6135\n",
      "Average value_loss: 0.0760\n",
      "Replay buffer size: 7820\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.6917\n",
      "Average policy_loss: 0.6161\n",
      "Average value_loss: 0.0756\n",
      "Replay buffer size: 7914\n",
      "Time taken: 61.8s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.6907\n",
      "Average policy_loss: 0.6139\n",
      "Average value_loss: 0.0768\n",
      "Replay buffer size: 8000\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.6899\n",
      "Average policy_loss: 0.6152\n",
      "Average value_loss: 0.0747\n",
      "Replay buffer size: 8086\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.7012\n",
      "Average policy_loss: 0.6221\n",
      "Average value_loss: 0.0790\n",
      "Replay buffer size: 8178\n",
      "Time taken: 19.3s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.7000\n",
      "Average policy_loss: 0.6228\n",
      "Average value_loss: 0.0773\n",
      "Replay buffer size: 8271\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.6955\n",
      "Average policy_loss: 0.6203\n",
      "Average value_loss: 0.0752\n",
      "Replay buffer size: 8371\n",
      "Time taken: 60.1s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.6968\n",
      "Average policy_loss: 0.6209\n",
      "Average value_loss: 0.0759\n",
      "Replay buffer size: 8464\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.6961\n",
      "Average policy_loss: 0.6208\n",
      "Average value_loss: 0.0752\n",
      "Replay buffer size: 8552\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.6975\n",
      "Average policy_loss: 0.6211\n",
      "Average value_loss: 0.0764\n",
      "Replay buffer size: 8644\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.6951\n",
      "Average policy_loss: 0.6204\n",
      "Average value_loss: 0.0747\n",
      "Replay buffer size: 8737\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.6947\n",
      "Average policy_loss: 0.6204\n",
      "Average value_loss: 0.0743\n",
      "Replay buffer size: 8835\n",
      "Time taken: 60.0s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.6921\n",
      "Average policy_loss: 0.6157\n",
      "Average value_loss: 0.0764\n",
      "Replay buffer size: 8929\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.6955\n",
      "Average policy_loss: 0.6210\n",
      "Average value_loss: 0.0745\n",
      "Replay buffer size: 9022\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.7019\n",
      "Average policy_loss: 0.6259\n",
      "Average value_loss: 0.0761\n",
      "Replay buffer size: 9113\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.6969\n",
      "Average policy_loss: 0.6216\n",
      "Average value_loss: 0.0753\n",
      "Replay buffer size: 9210\n",
      "Time taken: 18.1s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.7015\n",
      "Average policy_loss: 0.6250\n",
      "Average value_loss: 0.0765\n",
      "Replay buffer size: 9299\n",
      "Time taken: 60.3s\n",
      "\n",
      "Training complete! Total time: 0.7h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>iteration_time</td><td>▆▁▁▆▁▆▁▇▁▇▁▂▇▁▂▇▁▁▇▁▂▂▇▂▂█▂▂▇▂▂▂█▂▂▂▂▂▂█</td></tr><tr><td>loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▄▁▇▆▂█▅▇▇▅█▅▇▆▄▅▄▇▄▄▆▃▄▆▅▅▆▃█▄▅▅▆▇▂▅▃▅█▄</td></tr><tr><td>policy_loss</td><td>▆█▆▆▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂</td></tr><tr><td>value_loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.05</td></tr><tr><td>buffer_size</td><td>9299</td></tr><tr><td>iteration_time</td><td>60.2578</td></tr><tr><td>loss</td><td>0.70152</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>89</td></tr><tr><td>policy_loss</td><td>0.62503</td></tr><tr><td>total_time_hours</td><td>0.67711</td></tr><tr><td>value_loss</td><td>0.07649</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-sweep-44</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/r8dzlq0u' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/r8dzlq0u</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250301_235641-r8dzlq0u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 42xwipnd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009840250466546557\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.965336122464968\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.000397018136409093\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250302_003733-42xwipnd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/42xwipnd' target=\"_blank\">bright-sweep-45</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/42xwipnd' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/42xwipnd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 2.9848\n",
      "Average policy_loss: 1.4515\n",
      "Average value_loss: 1.5333\n",
      "Replay buffer size: 73\n",
      "Time taken: 4.6s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.9776\n",
      "Average policy_loss: 0.9427\n",
      "Average value_loss: 1.0348\n",
      "Replay buffer size: 161\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.2787\n",
      "Average policy_loss: 0.8796\n",
      "Average value_loss: 0.3991\n",
      "Replay buffer size: 252\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.0962\n",
      "Average policy_loss: 0.8737\n",
      "Average value_loss: 0.2225\n",
      "Replay buffer size: 339\n",
      "Time taken: 9.8s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 0.9942\n",
      "Average policy_loss: 0.8284\n",
      "Average value_loss: 0.1659\n",
      "Replay buffer size: 439\n",
      "Time taken: 31.6s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 0.9585\n",
      "Average policy_loss: 0.8139\n",
      "Average value_loss: 0.1446\n",
      "Replay buffer size: 539\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.9428\n",
      "Average policy_loss: 0.8051\n",
      "Average value_loss: 0.1377\n",
      "Replay buffer size: 627\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.9612\n",
      "Average policy_loss: 0.8324\n",
      "Average value_loss: 0.1288\n",
      "Replay buffer size: 705\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.9725\n",
      "Average policy_loss: 0.8433\n",
      "Average value_loss: 0.1292\n",
      "Replay buffer size: 785\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.9894\n",
      "Average policy_loss: 0.8598\n",
      "Average value_loss: 0.1296\n",
      "Replay buffer size: 869\n",
      "Time taken: 35.8s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.9964\n",
      "Average policy_loss: 0.8650\n",
      "Average value_loss: 0.1314\n",
      "Replay buffer size: 961\n",
      "Time taken: 11.2s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.0219\n",
      "Average policy_loss: 0.8728\n",
      "Average value_loss: 0.1491\n",
      "Replay buffer size: 1041\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.0167\n",
      "Average policy_loss: 0.8780\n",
      "Average value_loss: 0.1386\n",
      "Replay buffer size: 1123\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.0214\n",
      "Average policy_loss: 0.8799\n",
      "Average value_loss: 0.1415\n",
      "Replay buffer size: 1207\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.0205\n",
      "Average policy_loss: 0.8803\n",
      "Average value_loss: 0.1402\n",
      "Replay buffer size: 1289\n",
      "Time taken: 31.8s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.0257\n",
      "Average policy_loss: 0.8833\n",
      "Average value_loss: 0.1424\n",
      "Replay buffer size: 1368\n",
      "Time taken: 9.5s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.0239\n",
      "Average policy_loss: 0.8863\n",
      "Average value_loss: 0.1376\n",
      "Replay buffer size: 1448\n",
      "Time taken: 8.5s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.0140\n",
      "Average policy_loss: 0.8774\n",
      "Average value_loss: 0.1365\n",
      "Replay buffer size: 1524\n",
      "Time taken: 8.9s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.0145\n",
      "Average policy_loss: 0.8763\n",
      "Average value_loss: 0.1382\n",
      "Replay buffer size: 1596\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.0195\n",
      "Average policy_loss: 0.8821\n",
      "Average value_loss: 0.1374\n",
      "Replay buffer size: 1669\n",
      "Time taken: 30.2s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 66 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.0243\n",
      "Average policy_loss: 0.8832\n",
      "Average value_loss: 0.1411\n",
      "Replay buffer size: 1735\n",
      "Time taken: 7.8s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.0282\n",
      "Average policy_loss: 0.8857\n",
      "Average value_loss: 0.1425\n",
      "Replay buffer size: 1814\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.0364\n",
      "Average policy_loss: 0.8849\n",
      "Average value_loss: 0.1515\n",
      "Replay buffer size: 1887\n",
      "Time taken: 7.0s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.0435\n",
      "Average policy_loss: 0.8906\n",
      "Average value_loss: 0.1529\n",
      "Replay buffer size: 1960\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.0521\n",
      "Average policy_loss: 0.8957\n",
      "Average value_loss: 0.1565\n",
      "Replay buffer size: 2036\n",
      "Time taken: 29.8s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.0424\n",
      "Average policy_loss: 0.8908\n",
      "Average value_loss: 0.1517\n",
      "Replay buffer size: 2104\n",
      "Time taken: 8.3s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.0385\n",
      "Average policy_loss: 0.8859\n",
      "Average value_loss: 0.1525\n",
      "Replay buffer size: 2172\n",
      "Time taken: 7.4s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.0341\n",
      "Average policy_loss: 0.8823\n",
      "Average value_loss: 0.1518\n",
      "Replay buffer size: 2250\n",
      "Time taken: 7.7s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.0449\n",
      "Average policy_loss: 0.8888\n",
      "Average value_loss: 0.1561\n",
      "Replay buffer size: 2319\n",
      "Time taken: 8.1s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.0470\n",
      "Average policy_loss: 0.8969\n",
      "Average value_loss: 0.1501\n",
      "Replay buffer size: 2390\n",
      "Time taken: 25.6s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.0410\n",
      "Average policy_loss: 0.8917\n",
      "Average value_loss: 0.1492\n",
      "Replay buffer size: 2460\n",
      "Time taken: 6.2s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.0545\n",
      "Average policy_loss: 0.9025\n",
      "Average value_loss: 0.1520\n",
      "Replay buffer size: 2531\n",
      "Time taken: 7.7s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.0455\n",
      "Average policy_loss: 0.8975\n",
      "Average value_loss: 0.1481\n",
      "Replay buffer size: 2608\n",
      "Time taken: 7.2s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.0488\n",
      "Average policy_loss: 0.8954\n",
      "Average value_loss: 0.1534\n",
      "Replay buffer size: 2682\n",
      "Time taken: 7.7s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.0519\n",
      "Average policy_loss: 0.8992\n",
      "Average value_loss: 0.1528\n",
      "Replay buffer size: 2752\n",
      "Time taken: 28.7s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.0506\n",
      "Average policy_loss: 0.8966\n",
      "Average value_loss: 0.1540\n",
      "Replay buffer size: 2829\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.0549\n",
      "Average policy_loss: 0.8991\n",
      "Average value_loss: 0.1558\n",
      "Replay buffer size: 2906\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 73 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.0569\n",
      "Average policy_loss: 0.8986\n",
      "Average value_loss: 0.1583\n",
      "Replay buffer size: 2979\n",
      "Time taken: 8.3s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.0584\n",
      "Average policy_loss: 0.8984\n",
      "Average value_loss: 0.1599\n",
      "Replay buffer size: 3063\n",
      "Time taken: 8.6s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.0624\n",
      "Average policy_loss: 0.8968\n",
      "Average value_loss: 0.1657\n",
      "Replay buffer size: 3146\n",
      "Time taken: 29.8s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.0774\n",
      "Average policy_loss: 0.9071\n",
      "Average value_loss: 0.1703\n",
      "Replay buffer size: 3234\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.0658\n",
      "Average policy_loss: 0.8976\n",
      "Average value_loss: 0.1683\n",
      "Replay buffer size: 3318\n",
      "Time taken: 8.3s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.0662\n",
      "Average policy_loss: 0.9000\n",
      "Average value_loss: 0.1662\n",
      "Replay buffer size: 3407\n",
      "Time taken: 8.8s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.0785\n",
      "Average policy_loss: 0.9064\n",
      "Average value_loss: 0.1722\n",
      "Replay buffer size: 3492\n",
      "Time taken: 8.6s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.0680\n",
      "Average policy_loss: 0.9007\n",
      "Average value_loss: 0.1674\n",
      "Replay buffer size: 3581\n",
      "Time taken: 32.5s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.0573\n",
      "Average policy_loss: 0.8961\n",
      "Average value_loss: 0.1611\n",
      "Replay buffer size: 3674\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.0724\n",
      "Average policy_loss: 0.9036\n",
      "Average value_loss: 0.1687\n",
      "Replay buffer size: 3767\n",
      "Time taken: 11.2s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.0730\n",
      "Average policy_loss: 0.9059\n",
      "Average value_loss: 0.1671\n",
      "Replay buffer size: 3851\n",
      "Time taken: 12.0s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.0709\n",
      "Average policy_loss: 0.9048\n",
      "Average value_loss: 0.1661\n",
      "Replay buffer size: 3937\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.0735\n",
      "Average policy_loss: 0.9097\n",
      "Average value_loss: 0.1638\n",
      "Replay buffer size: 4032\n",
      "Time taken: 37.9s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.0773\n",
      "Average policy_loss: 0.9148\n",
      "Average value_loss: 0.1625\n",
      "Replay buffer size: 4114\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.0786\n",
      "Average policy_loss: 0.9099\n",
      "Average value_loss: 0.1687\n",
      "Replay buffer size: 4196\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.0854\n",
      "Average policy_loss: 0.9142\n",
      "Average value_loss: 0.1712\n",
      "Replay buffer size: 4273\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.0764\n",
      "Average policy_loss: 0.9122\n",
      "Average value_loss: 0.1641\n",
      "Replay buffer size: 4360\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.0897\n",
      "Average policy_loss: 0.9205\n",
      "Average value_loss: 0.1692\n",
      "Replay buffer size: 4450\n",
      "Time taken: 35.6s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.0860\n",
      "Average policy_loss: 0.9202\n",
      "Average value_loss: 0.1657\n",
      "Replay buffer size: 4542\n",
      "Time taken: 11.6s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.0823\n",
      "Average policy_loss: 0.9127\n",
      "Average value_loss: 0.1696\n",
      "Replay buffer size: 4629\n",
      "Time taken: 12.2s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.0870\n",
      "Average policy_loss: 0.9135\n",
      "Average value_loss: 0.1735\n",
      "Replay buffer size: 4717\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.0909\n",
      "Average policy_loss: 0.9200\n",
      "Average value_loss: 0.1709\n",
      "Replay buffer size: 4800\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.0829\n",
      "Average policy_loss: 0.9135\n",
      "Average value_loss: 0.1693\n",
      "Replay buffer size: 4896\n",
      "Time taken: 36.5s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.0766\n",
      "Average policy_loss: 0.9116\n",
      "Average value_loss: 0.1650\n",
      "Replay buffer size: 4983\n",
      "Time taken: 12.4s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.0819\n",
      "Average policy_loss: 0.9190\n",
      "Average value_loss: 0.1629\n",
      "Replay buffer size: 5074\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.0917\n",
      "Average policy_loss: 0.9258\n",
      "Average value_loss: 0.1659\n",
      "Replay buffer size: 5160\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.0919\n",
      "Average policy_loss: 0.9256\n",
      "Average value_loss: 0.1662\n",
      "Replay buffer size: 5244\n",
      "Time taken: 12.7s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.0945\n",
      "Average policy_loss: 0.9230\n",
      "Average value_loss: 0.1715\n",
      "Replay buffer size: 5328\n",
      "Time taken: 35.7s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.1005\n",
      "Average policy_loss: 0.9272\n",
      "Average value_loss: 0.1733\n",
      "Replay buffer size: 5408\n",
      "Time taken: 12.5s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.0982\n",
      "Average policy_loss: 0.9277\n",
      "Average value_loss: 0.1704\n",
      "Replay buffer size: 5494\n",
      "Time taken: 12.1s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.1015\n",
      "Average policy_loss: 0.9305\n",
      "Average value_loss: 0.1710\n",
      "Replay buffer size: 5576\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.1077\n",
      "Average policy_loss: 0.9375\n",
      "Average value_loss: 0.1702\n",
      "Replay buffer size: 5656\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.1048\n",
      "Average policy_loss: 0.9345\n",
      "Average value_loss: 0.1702\n",
      "Replay buffer size: 5732\n",
      "Time taken: 38.0s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.1092\n",
      "Average policy_loss: 0.9398\n",
      "Average value_loss: 0.1694\n",
      "Replay buffer size: 5812\n",
      "Time taken: 12.3s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.1150\n",
      "Average policy_loss: 0.9475\n",
      "Average value_loss: 0.1675\n",
      "Replay buffer size: 5888\n",
      "Time taken: 11.4s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.1181\n",
      "Average policy_loss: 0.9485\n",
      "Average value_loss: 0.1696\n",
      "Replay buffer size: 5978\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.1158\n",
      "Average policy_loss: 0.9473\n",
      "Average value_loss: 0.1684\n",
      "Replay buffer size: 6054\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.1198\n",
      "Average policy_loss: 0.9521\n",
      "Average value_loss: 0.1677\n",
      "Replay buffer size: 6132\n",
      "Time taken: 33.0s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.1130\n",
      "Average policy_loss: 0.9476\n",
      "Average value_loss: 0.1654\n",
      "Replay buffer size: 6206\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.1251\n",
      "Average policy_loss: 0.9573\n",
      "Average value_loss: 0.1678\n",
      "Replay buffer size: 6281\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.1165\n",
      "Average policy_loss: 0.9484\n",
      "Average value_loss: 0.1680\n",
      "Replay buffer size: 6360\n",
      "Time taken: 9.3s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.1261\n",
      "Average policy_loss: 0.9594\n",
      "Average value_loss: 0.1667\n",
      "Replay buffer size: 6436\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.1182\n",
      "Average policy_loss: 0.9515\n",
      "Average value_loss: 0.1667\n",
      "Replay buffer size: 6508\n",
      "Time taken: 33.1s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.1277\n",
      "Average policy_loss: 0.9612\n",
      "Average value_loss: 0.1665\n",
      "Replay buffer size: 6582\n",
      "Time taken: 9.2s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.1243\n",
      "Average policy_loss: 0.9623\n",
      "Average value_loss: 0.1620\n",
      "Replay buffer size: 6663\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.1242\n",
      "Average policy_loss: 0.9607\n",
      "Average value_loss: 0.1636\n",
      "Replay buffer size: 6748\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.1324\n",
      "Average policy_loss: 0.9669\n",
      "Average value_loss: 0.1655\n",
      "Replay buffer size: 6829\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.1301\n",
      "Average policy_loss: 0.9639\n",
      "Average value_loss: 0.1662\n",
      "Replay buffer size: 6908\n",
      "Time taken: 34.1s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 75 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.1317\n",
      "Average policy_loss: 0.9666\n",
      "Average value_loss: 0.1651\n",
      "Replay buffer size: 6983\n",
      "Time taken: 9.4s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.1349\n",
      "Average policy_loss: 0.9708\n",
      "Average value_loss: 0.1641\n",
      "Replay buffer size: 7057\n",
      "Time taken: 10.7s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.1342\n",
      "Average policy_loss: 0.9704\n",
      "Average value_loss: 0.1639\n",
      "Replay buffer size: 7129\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.1258\n",
      "Average policy_loss: 0.9613\n",
      "Average value_loss: 0.1645\n",
      "Replay buffer size: 7211\n",
      "Time taken: 9.7s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.1348\n",
      "Average policy_loss: 0.9713\n",
      "Average value_loss: 0.1635\n",
      "Replay buffer size: 7281\n",
      "Time taken: 32.1s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.1402\n",
      "Average policy_loss: 0.9757\n",
      "Average value_loss: 0.1645\n",
      "Replay buffer size: 7351\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.1352\n",
      "Average policy_loss: 0.9727\n",
      "Average value_loss: 0.1625\n",
      "Replay buffer size: 7431\n",
      "Time taken: 9.6s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 71 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.1411\n",
      "Average policy_loss: 0.9794\n",
      "Average value_loss: 0.1617\n",
      "Replay buffer size: 7502\n",
      "Time taken: 9.0s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.1300\n",
      "Average policy_loss: 0.9668\n",
      "Average value_loss: 0.1632\n",
      "Replay buffer size: 7580\n",
      "Time taken: 9.5s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.1265\n",
      "Average policy_loss: 0.9656\n",
      "Average value_loss: 0.1609\n",
      "Replay buffer size: 7660\n",
      "Time taken: 32.5s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 70 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.1385\n",
      "Average policy_loss: 0.9764\n",
      "Average value_loss: 0.1621\n",
      "Replay buffer size: 7730\n",
      "Time taken: 10.9s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.1334\n",
      "Average policy_loss: 0.9715\n",
      "Average value_loss: 0.1619\n",
      "Replay buffer size: 7806\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.1264\n",
      "Average policy_loss: 0.9679\n",
      "Average value_loss: 0.1585\n",
      "Replay buffer size: 7886\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.1413\n",
      "Average policy_loss: 0.9786\n",
      "Average value_loss: 0.1627\n",
      "Replay buffer size: 7963\n",
      "Time taken: 10.4s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.1405\n",
      "Average policy_loss: 0.9771\n",
      "Average value_loss: 0.1634\n",
      "Replay buffer size: 8041\n",
      "Time taken: 33.6s\n",
      "\n",
      "Training complete! Total time: 0.4h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>iteration_time</td><td>▁▂▂▂▂▇▂▂▂▇▇▂▁▂▂▂▂▂▂▇▃▃▃▃█▃█▃▃▂▂▂▂▂▇▂▂▂▂▂</td></tr><tr><td>loss</td><td>█▃▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▆▆▅█▆▄▄▄▅▁▁▃▂▃▃▆▆▇▅▇▆▆▆▅▆▅▃▆▃▃▂▄▄▄▂▂▄▃▃▃</td></tr><tr><td>policy_loss</td><td>█▂▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃</td></tr><tr><td>value_loss</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.25</td></tr><tr><td>buffer_size</td><td>8041</td></tr><tr><td>iteration_time</td><td>33.57955</td></tr><tr><td>loss</td><td>1.14047</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>78</td></tr><tr><td>policy_loss</td><td>0.97709</td></tr><tr><td>total_time_hours</td><td>0.40341</td></tr><tr><td>value_loss</td><td>0.16338</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bright-sweep-45</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/42xwipnd' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/42xwipnd</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 26 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250302_003733-42xwipnd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e3omdks4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006317382532920036\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.5749564637708762\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.13971962739925e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250302_010200-e3omdks4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/e3omdks4' target=\"_blank\">unique-sweep-46</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/e3omdks4' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/e3omdks4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 4.2492\n",
      "Average policy_loss: 3.5491\n",
      "Average value_loss: 0.7001\n",
      "Replay buffer size: 79\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.5985\n",
      "Average policy_loss: 1.1368\n",
      "Average value_loss: 0.4617\n",
      "Replay buffer size: 158\n",
      "Time taken: 11.9s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.2648\n",
      "Average policy_loss: 0.9123\n",
      "Average value_loss: 0.3526\n",
      "Replay buffer size: 232\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.2313\n",
      "Average policy_loss: 0.8940\n",
      "Average value_loss: 0.3373\n",
      "Replay buffer size: 320\n",
      "Time taken: 11.5s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 5.00%\n",
      "RandomAgent: Win rate = 50.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.1010\n",
      "Average policy_loss: 0.8277\n",
      "Average value_loss: 0.2733\n",
      "Replay buffer size: 406\n",
      "Time taken: 36.6s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.0539\n",
      "Average policy_loss: 0.7834\n",
      "Average value_loss: 0.2705\n",
      "Replay buffer size: 496\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 0.9794\n",
      "Average policy_loss: 0.7367\n",
      "Average value_loss: 0.2427\n",
      "Replay buffer size: 586\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 0.9187\n",
      "Average policy_loss: 0.6919\n",
      "Average value_loss: 0.2268\n",
      "Replay buffer size: 686\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 0.8453\n",
      "Average policy_loss: 0.6422\n",
      "Average value_loss: 0.2031\n",
      "Replay buffer size: 782\n",
      "Time taken: 11.1s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 5.00%\n",
      "RandomAgent: Win rate = 45.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 0.8200\n",
      "Average policy_loss: 0.6152\n",
      "Average value_loss: 0.2048\n",
      "Replay buffer size: 874\n",
      "Time taken: 36.2s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 0.7512\n",
      "Average policy_loss: 0.5787\n",
      "Average value_loss: 0.1725\n",
      "Replay buffer size: 970\n",
      "Time taken: 10.8s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 0.7209\n",
      "Average policy_loss: 0.5557\n",
      "Average value_loss: 0.1651\n",
      "Replay buffer size: 1063\n",
      "Time taken: 11.7s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 0.6829\n",
      "Average policy_loss: 0.5326\n",
      "Average value_loss: 0.1503\n",
      "Replay buffer size: 1159\n",
      "Time taken: 10.6s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 0.6592\n",
      "Average policy_loss: 0.5148\n",
      "Average value_loss: 0.1444\n",
      "Replay buffer size: 1253\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 0.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 0.6453\n",
      "Average policy_loss: 0.5038\n",
      "Average value_loss: 0.1415\n",
      "Replay buffer size: 1349\n",
      "Time taken: 36.6s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 0.6140\n",
      "Average policy_loss: 0.4863\n",
      "Average value_loss: 0.1277\n",
      "Replay buffer size: 1449\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 0.5920\n",
      "Average policy_loss: 0.4644\n",
      "Average value_loss: 0.1275\n",
      "Replay buffer size: 1545\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 0.5731\n",
      "Average policy_loss: 0.4547\n",
      "Average value_loss: 0.1184\n",
      "Replay buffer size: 1641\n",
      "Time taken: 11.0s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 0.5551\n",
      "Average policy_loss: 0.4461\n",
      "Average value_loss: 0.1090\n",
      "Replay buffer size: 1737\n",
      "Time taken: 10.2s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 5.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 0.5470\n",
      "Average policy_loss: 0.4395\n",
      "Average value_loss: 0.1075\n",
      "Replay buffer size: 1837\n",
      "Time taken: 33.6s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 0.5400\n",
      "Average policy_loss: 0.4309\n",
      "Average value_loss: 0.1092\n",
      "Replay buffer size: 1925\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 0.5297\n",
      "Average policy_loss: 0.4240\n",
      "Average value_loss: 0.1058\n",
      "Replay buffer size: 2025\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 0.5277\n",
      "Average policy_loss: 0.4264\n",
      "Average value_loss: 0.1014\n",
      "Replay buffer size: 2117\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 0.5248\n",
      "Average policy_loss: 0.4201\n",
      "Average value_loss: 0.1047\n",
      "Replay buffer size: 2213\n",
      "Time taken: 10.3s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 0.5017\n",
      "Average policy_loss: 0.4050\n",
      "Average value_loss: 0.0967\n",
      "Replay buffer size: 2313\n",
      "Time taken: 32.2s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 0.4975\n",
      "Average policy_loss: 0.4021\n",
      "Average value_loss: 0.0955\n",
      "Replay buffer size: 2410\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 0.4906\n",
      "Average policy_loss: 0.3963\n",
      "Average value_loss: 0.0943\n",
      "Replay buffer size: 2510\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 0.4773\n",
      "Average policy_loss: 0.3882\n",
      "Average value_loss: 0.0891\n",
      "Replay buffer size: 2610\n",
      "Time taken: 8.7s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 0.4685\n",
      "Average policy_loss: 0.3803\n",
      "Average value_loss: 0.0883\n",
      "Replay buffer size: 2710\n",
      "Time taken: 8.8s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 5.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 0.4624\n",
      "Average policy_loss: 0.3761\n",
      "Average value_loss: 0.0863\n",
      "Replay buffer size: 2810\n",
      "Time taken: 30.0s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.4484\n",
      "Average policy_loss: 0.3676\n",
      "Average value_loss: 0.0808\n",
      "Replay buffer size: 2910\n",
      "Time taken: 8.7s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.4393\n",
      "Average policy_loss: 0.3613\n",
      "Average value_loss: 0.0780\n",
      "Replay buffer size: 3010\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.4369\n",
      "Average policy_loss: 0.3568\n",
      "Average value_loss: 0.0801\n",
      "Replay buffer size: 3110\n",
      "Time taken: 8.3s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.4253\n",
      "Average policy_loss: 0.3497\n",
      "Average value_loss: 0.0757\n",
      "Replay buffer size: 3210\n",
      "Time taken: 8.6s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.4168\n",
      "Average policy_loss: 0.3439\n",
      "Average value_loss: 0.0729\n",
      "Replay buffer size: 3310\n",
      "Time taken: 28.3s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.4132\n",
      "Average policy_loss: 0.3395\n",
      "Average value_loss: 0.0737\n",
      "Replay buffer size: 3410\n",
      "Time taken: 8.4s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.4097\n",
      "Average policy_loss: 0.3372\n",
      "Average value_loss: 0.0724\n",
      "Replay buffer size: 3507\n",
      "Time taken: 8.6s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.3989\n",
      "Average policy_loss: 0.3291\n",
      "Average value_loss: 0.0698\n",
      "Replay buffer size: 3607\n",
      "Time taken: 8.1s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.3965\n",
      "Average policy_loss: 0.3270\n",
      "Average value_loss: 0.0695\n",
      "Replay buffer size: 3703\n",
      "Time taken: 8.7s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.3861\n",
      "Average policy_loss: 0.3213\n",
      "Average value_loss: 0.0648\n",
      "Replay buffer size: 3803\n",
      "Time taken: 27.9s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.3875\n",
      "Average policy_loss: 0.3188\n",
      "Average value_loss: 0.0688\n",
      "Replay buffer size: 3903\n",
      "Time taken: 8.5s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.3816\n",
      "Average policy_loss: 0.3166\n",
      "Average value_loss: 0.0649\n",
      "Replay buffer size: 3999\n",
      "Time taken: 8.8s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.3753\n",
      "Average policy_loss: 0.3131\n",
      "Average value_loss: 0.0622\n",
      "Replay buffer size: 4095\n",
      "Time taken: 9.1s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.3687\n",
      "Average policy_loss: 0.3072\n",
      "Average value_loss: 0.0615\n",
      "Replay buffer size: 4195\n",
      "Time taken: 8.0s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 50.00%, Draw rate = 40.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.3690\n",
      "Average policy_loss: 0.3056\n",
      "Average value_loss: 0.0634\n",
      "Replay buffer size: 4295\n",
      "Time taken: 30.7s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.3664\n",
      "Average policy_loss: 0.3050\n",
      "Average value_loss: 0.0614\n",
      "Replay buffer size: 4395\n",
      "Time taken: 8.2s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.3673\n",
      "Average policy_loss: 0.3072\n",
      "Average value_loss: 0.0601\n",
      "Replay buffer size: 4491\n",
      "Time taken: 9.5s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.3636\n",
      "Average policy_loss: 0.3064\n",
      "Average value_loss: 0.0572\n",
      "Replay buffer size: 4587\n",
      "Time taken: 10.1s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.3635\n",
      "Average policy_loss: 0.3071\n",
      "Average value_loss: 0.0565\n",
      "Replay buffer size: 4686\n",
      "Time taken: 10.5s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.3675\n",
      "Average policy_loss: 0.3105\n",
      "Average value_loss: 0.0570\n",
      "Replay buffer size: 4786\n",
      "Time taken: 35.3s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.3717\n",
      "Average policy_loss: 0.3150\n",
      "Average value_loss: 0.0567\n",
      "Replay buffer size: 4886\n",
      "Time taken: 10.0s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.3713\n",
      "Average policy_loss: 0.3157\n",
      "Average value_loss: 0.0556\n",
      "Replay buffer size: 4986\n",
      "Time taken: 10.7s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.3773\n",
      "Average policy_loss: 0.3211\n",
      "Average value_loss: 0.0562\n",
      "Replay buffer size: 5078\n",
      "Time taken: 13.2s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.3812\n",
      "Average policy_loss: 0.3239\n",
      "Average value_loss: 0.0572\n",
      "Replay buffer size: 5178\n",
      "Time taken: 13.3s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 20.00%\n",
      "RandomAgent: Win rate = 55.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.3868\n",
      "Average policy_loss: 0.3304\n",
      "Average value_loss: 0.0564\n",
      "Replay buffer size: 5275\n",
      "Time taken: 38.9s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.3909\n",
      "Average policy_loss: 0.3354\n",
      "Average value_loss: 0.0554\n",
      "Replay buffer size: 5371\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.4006\n",
      "Average policy_loss: 0.3455\n",
      "Average value_loss: 0.0551\n",
      "Replay buffer size: 5469\n",
      "Time taken: 13.4s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.4013\n",
      "Average policy_loss: 0.3467\n",
      "Average value_loss: 0.0547\n",
      "Replay buffer size: 5567\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.4047\n",
      "Average policy_loss: 0.3507\n",
      "Average value_loss: 0.0540\n",
      "Replay buffer size: 5665\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.4129\n",
      "Average policy_loss: 0.3571\n",
      "Average value_loss: 0.0558\n",
      "Replay buffer size: 5763\n",
      "Time taken: 47.3s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.4130\n",
      "Average policy_loss: 0.3598\n",
      "Average value_loss: 0.0532\n",
      "Replay buffer size: 5863\n",
      "Time taken: 16.2s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.4147\n",
      "Average policy_loss: 0.3618\n",
      "Average value_loss: 0.0528\n",
      "Replay buffer size: 5963\n",
      "Time taken: 13.1s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.4196\n",
      "Average policy_loss: 0.3655\n",
      "Average value_loss: 0.0541\n",
      "Replay buffer size: 6063\n",
      "Time taken: 16.1s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.4355\n",
      "Average policy_loss: 0.3797\n",
      "Average value_loss: 0.0558\n",
      "Replay buffer size: 6147\n",
      "Time taken: 17.2s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.4395\n",
      "Average policy_loss: 0.3827\n",
      "Average value_loss: 0.0567\n",
      "Replay buffer size: 6247\n",
      "Time taken: 49.7s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.4502\n",
      "Average policy_loss: 0.3911\n",
      "Average value_loss: 0.0591\n",
      "Replay buffer size: 6341\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.4551\n",
      "Average policy_loss: 0.3987\n",
      "Average value_loss: 0.0564\n",
      "Replay buffer size: 6439\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.4605\n",
      "Average policy_loss: 0.4043\n",
      "Average value_loss: 0.0562\n",
      "Replay buffer size: 6533\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.4699\n",
      "Average policy_loss: 0.4119\n",
      "Average value_loss: 0.0581\n",
      "Replay buffer size: 6623\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.4748\n",
      "Average policy_loss: 0.4165\n",
      "Average value_loss: 0.0582\n",
      "Replay buffer size: 6720\n",
      "Time taken: 54.8s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.4787\n",
      "Average policy_loss: 0.4204\n",
      "Average value_loss: 0.0584\n",
      "Replay buffer size: 6815\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.4929\n",
      "Average policy_loss: 0.4312\n",
      "Average value_loss: 0.0617\n",
      "Replay buffer size: 6915\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.4889\n",
      "Average policy_loss: 0.4307\n",
      "Average value_loss: 0.0582\n",
      "Replay buffer size: 7015\n",
      "Time taken: 18.2s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.4920\n",
      "Average policy_loss: 0.4351\n",
      "Average value_loss: 0.0569\n",
      "Replay buffer size: 7115\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 55.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.4980\n",
      "Average policy_loss: 0.4416\n",
      "Average value_loss: 0.0564\n",
      "Replay buffer size: 7208\n",
      "Time taken: 56.5s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.5032\n",
      "Average policy_loss: 0.4455\n",
      "Average value_loss: 0.0577\n",
      "Replay buffer size: 7308\n",
      "Time taken: 19.4s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.5099\n",
      "Average policy_loss: 0.4485\n",
      "Average value_loss: 0.0614\n",
      "Replay buffer size: 7405\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.5114\n",
      "Average policy_loss: 0.4522\n",
      "Average value_loss: 0.0592\n",
      "Replay buffer size: 7503\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.5142\n",
      "Average policy_loss: 0.4565\n",
      "Average value_loss: 0.0577\n",
      "Replay buffer size: 7597\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.5229\n",
      "Average policy_loss: 0.4631\n",
      "Average value_loss: 0.0598\n",
      "Replay buffer size: 7692\n",
      "Time taken: 57.4s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.5267\n",
      "Average policy_loss: 0.4679\n",
      "Average value_loss: 0.0588\n",
      "Replay buffer size: 7788\n",
      "Time taken: 19.8s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.5315\n",
      "Average policy_loss: 0.4718\n",
      "Average value_loss: 0.0598\n",
      "Replay buffer size: 7879\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.5318\n",
      "Average policy_loss: 0.4711\n",
      "Average value_loss: 0.0607\n",
      "Replay buffer size: 7978\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.5409\n",
      "Average policy_loss: 0.4791\n",
      "Average value_loss: 0.0618\n",
      "Replay buffer size: 8073\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.5463\n",
      "Average policy_loss: 0.4828\n",
      "Average value_loss: 0.0635\n",
      "Replay buffer size: 8165\n",
      "Time taken: 58.5s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.5502\n",
      "Average policy_loss: 0.4878\n",
      "Average value_loss: 0.0624\n",
      "Replay buffer size: 8260\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.5519\n",
      "Average policy_loss: 0.4886\n",
      "Average value_loss: 0.0633\n",
      "Replay buffer size: 8356\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.5545\n",
      "Average policy_loss: 0.4916\n",
      "Average value_loss: 0.0629\n",
      "Replay buffer size: 8453\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.5570\n",
      "Average policy_loss: 0.4943\n",
      "Average value_loss: 0.0627\n",
      "Replay buffer size: 8549\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 50.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.5642\n",
      "Average policy_loss: 0.5004\n",
      "Average value_loss: 0.0638\n",
      "Replay buffer size: 8649\n",
      "Time taken: 60.5s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.5725\n",
      "Average policy_loss: 0.5085\n",
      "Average value_loss: 0.0640\n",
      "Replay buffer size: 8744\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.5719\n",
      "Average policy_loss: 0.5093\n",
      "Average value_loss: 0.0627\n",
      "Replay buffer size: 8841\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.5742\n",
      "Average policy_loss: 0.5101\n",
      "Average value_loss: 0.0641\n",
      "Replay buffer size: 8930\n",
      "Time taken: 20.8s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.5771\n",
      "Average policy_loss: 0.5117\n",
      "Average value_loss: 0.0654\n",
      "Replay buffer size: 9024\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.5816\n",
      "Average policy_loss: 0.5167\n",
      "Average value_loss: 0.0649\n",
      "Replay buffer size: 9116\n",
      "Time taken: 60.9s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.5844\n",
      "Average policy_loss: 0.5179\n",
      "Average value_loss: 0.0665\n",
      "Replay buffer size: 9210\n",
      "Time taken: 19.0s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.5898\n",
      "Average policy_loss: 0.5232\n",
      "Average value_loss: 0.0666\n",
      "Replay buffer size: 9301\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.5906\n",
      "Average policy_loss: 0.5245\n",
      "Average value_loss: 0.0661\n",
      "Replay buffer size: 9399\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.5993\n",
      "Average policy_loss: 0.5299\n",
      "Average value_loss: 0.0693\n",
      "Replay buffer size: 9493\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.5967\n",
      "Average policy_loss: 0.5292\n",
      "Average value_loss: 0.0676\n",
      "Replay buffer size: 9588\n",
      "Time taken: 63.3s\n",
      "\n",
      "Training complete! Total time: 0.6h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▇▇▇▇▇███</td></tr><tr><td>iteration_time</td><td>▂▂▅▁▁▁▁▁▁▅▁▄▁▁▁▁▁▄▁▁▁▁▁▅▁▂▂▂▂▂█▃▃▃▃▃▃▃▃▃</td></tr><tr><td>loss</td><td>█▅▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▂▁▅▅▅▇▆▇▇▇▅█▇█████▇██▇█▆▇▇█▄▅▇███▆██▇▇▇▆</td></tr><tr><td>policy_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▆▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>0.85</td></tr><tr><td>buffer_size</td><td>9588</td></tr><tr><td>iteration_time</td><td>63.28807</td></tr><tr><td>loss</td><td>0.59675</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>95</td></tr><tr><td>policy_loss</td><td>0.52918</td></tr><tr><td>total_time_hours</td><td>0.55514</td></tr><tr><td>value_loss</td><td>0.06757</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unique-sweep-46</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/e3omdks4' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/e3omdks4</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 24 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250302_010200-e3omdks4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mwgt93eq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02989979919223195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.18152099402570257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.5932900722595426e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250302_013525-mwgt93eq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/mwgt93eq' target=\"_blank\">woven-sweep-47</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/mwgt93eq' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/mwgt93eq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.9625\n",
      "Average policy_loss: 1.4489\n",
      "Average value_loss: 0.5135\n",
      "Replay buffer size: 87\n",
      "Time taken: 11.3s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.2880\n",
      "Average policy_loss: 0.9782\n",
      "Average value_loss: 0.3098\n",
      "Replay buffer size: 174\n",
      "Time taken: 27.0s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.4261\n",
      "Average policy_loss: 1.0575\n",
      "Average value_loss: 0.3686\n",
      "Replay buffer size: 260\n",
      "Time taken: 27.0s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.4307\n",
      "Average policy_loss: 1.0778\n",
      "Average value_loss: 0.3530\n",
      "Replay buffer size: 352\n",
      "Time taken: 28.1s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.4158\n",
      "Average policy_loss: 1.0774\n",
      "Average value_loss: 0.3384\n",
      "Replay buffer size: 441\n",
      "Time taken: 82.7s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.4129\n",
      "Average policy_loss: 1.0794\n",
      "Average value_loss: 0.3336\n",
      "Replay buffer size: 527\n",
      "Time taken: 26.2s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.4395\n",
      "Average policy_loss: 1.1051\n",
      "Average value_loss: 0.3343\n",
      "Replay buffer size: 609\n",
      "Time taken: 28.2s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.4650\n",
      "Average policy_loss: 1.1273\n",
      "Average value_loss: 0.3378\n",
      "Replay buffer size: 687\n",
      "Time taken: 28.4s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.4909\n",
      "Average policy_loss: 1.1505\n",
      "Average value_loss: 0.3403\n",
      "Replay buffer size: 772\n",
      "Time taken: 26.5s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.4960\n",
      "Average policy_loss: 1.1518\n",
      "Average value_loss: 0.3441\n",
      "Replay buffer size: 851\n",
      "Time taken: 83.6s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.5170\n",
      "Average policy_loss: 1.1609\n",
      "Average value_loss: 0.3561\n",
      "Replay buffer size: 937\n",
      "Time taken: 26.1s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.5192\n",
      "Average policy_loss: 1.1687\n",
      "Average value_loss: 0.3505\n",
      "Replay buffer size: 1020\n",
      "Time taken: 27.5s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.5218\n",
      "Average policy_loss: 1.1723\n",
      "Average value_loss: 0.3494\n",
      "Replay buffer size: 1103\n",
      "Time taken: 28.1s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.5005\n",
      "Average policy_loss: 1.1606\n",
      "Average value_loss: 0.3399\n",
      "Replay buffer size: 1185\n",
      "Time taken: 27.4s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.4914\n",
      "Average policy_loss: 1.1593\n",
      "Average value_loss: 0.3321\n",
      "Replay buffer size: 1265\n",
      "Time taken: 80.3s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.4811\n",
      "Average policy_loss: 1.1562\n",
      "Average value_loss: 0.3249\n",
      "Replay buffer size: 1351\n",
      "Time taken: 26.3s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.4553\n",
      "Average policy_loss: 1.1401\n",
      "Average value_loss: 0.3152\n",
      "Replay buffer size: 1441\n",
      "Time taken: 26.7s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.4359\n",
      "Average policy_loss: 1.1319\n",
      "Average value_loss: 0.3040\n",
      "Replay buffer size: 1533\n",
      "Time taken: 25.1s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.4343\n",
      "Average policy_loss: 1.1286\n",
      "Average value_loss: 0.3057\n",
      "Replay buffer size: 1617\n",
      "Time taken: 26.2s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 100.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.4186\n",
      "Average policy_loss: 1.1147\n",
      "Average value_loss: 0.3039\n",
      "Replay buffer size: 1705\n",
      "Time taken: 79.8s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.4274\n",
      "Average policy_loss: 1.1151\n",
      "Average value_loss: 0.3123\n",
      "Replay buffer size: 1795\n",
      "Time taken: 27.1s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.4017\n",
      "Average policy_loss: 1.1027\n",
      "Average value_loss: 0.2990\n",
      "Replay buffer size: 1887\n",
      "Time taken: 26.7s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.4031\n",
      "Average policy_loss: 1.0995\n",
      "Average value_loss: 0.3037\n",
      "Replay buffer size: 1975\n",
      "Time taken: 27.2s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.3859\n",
      "Average policy_loss: 1.0925\n",
      "Average value_loss: 0.2934\n",
      "Replay buffer size: 2061\n",
      "Time taken: 26.5s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.3835\n",
      "Average policy_loss: 1.0906\n",
      "Average value_loss: 0.2930\n",
      "Replay buffer size: 2147\n",
      "Time taken: 79.4s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.3688\n",
      "Average policy_loss: 1.0819\n",
      "Average value_loss: 0.2869\n",
      "Replay buffer size: 2232\n",
      "Time taken: 25.4s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.3746\n",
      "Average policy_loss: 1.0806\n",
      "Average value_loss: 0.2941\n",
      "Replay buffer size: 2325\n",
      "Time taken: 24.8s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.3669\n",
      "Average policy_loss: 1.0772\n",
      "Average value_loss: 0.2897\n",
      "Replay buffer size: 2410\n",
      "Time taken: 25.4s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.3635\n",
      "Average policy_loss: 1.0646\n",
      "Average value_loss: 0.2989\n",
      "Replay buffer size: 2495\n",
      "Time taken: 27.1s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.3563\n",
      "Average policy_loss: 1.0621\n",
      "Average value_loss: 0.2942\n",
      "Replay buffer size: 2587\n",
      "Time taken: 81.8s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.3662\n",
      "Average policy_loss: 1.0682\n",
      "Average value_loss: 0.2980\n",
      "Replay buffer size: 2677\n",
      "Time taken: 26.6s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.3528\n",
      "Average policy_loss: 1.0599\n",
      "Average value_loss: 0.2929\n",
      "Replay buffer size: 2766\n",
      "Time taken: 26.0s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.3516\n",
      "Average policy_loss: 1.0549\n",
      "Average value_loss: 0.2967\n",
      "Replay buffer size: 2847\n",
      "Time taken: 25.1s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.3380\n",
      "Average policy_loss: 1.0456\n",
      "Average value_loss: 0.2924\n",
      "Replay buffer size: 2933\n",
      "Time taken: 24.9s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.3497\n",
      "Average policy_loss: 1.0537\n",
      "Average value_loss: 0.2960\n",
      "Replay buffer size: 3021\n",
      "Time taken: 79.1s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.3405\n",
      "Average policy_loss: 1.0450\n",
      "Average value_loss: 0.2955\n",
      "Replay buffer size: 3110\n",
      "Time taken: 26.3s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.3412\n",
      "Average policy_loss: 1.0474\n",
      "Average value_loss: 0.2938\n",
      "Replay buffer size: 3199\n",
      "Time taken: 25.6s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.3401\n",
      "Average policy_loss: 1.0412\n",
      "Average value_loss: 0.2989\n",
      "Replay buffer size: 3285\n",
      "Time taken: 26.7s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.3319\n",
      "Average policy_loss: 1.0350\n",
      "Average value_loss: 0.2969\n",
      "Replay buffer size: 3375\n",
      "Time taken: 24.4s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.3338\n",
      "Average policy_loss: 1.0380\n",
      "Average value_loss: 0.2958\n",
      "Replay buffer size: 3458\n",
      "Time taken: 79.5s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.3208\n",
      "Average policy_loss: 1.0288\n",
      "Average value_loss: 0.2920\n",
      "Replay buffer size: 3554\n",
      "Time taken: 26.3s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.3183\n",
      "Average policy_loss: 1.0277\n",
      "Average value_loss: 0.2906\n",
      "Replay buffer size: 3650\n",
      "Time taken: 24.9s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.3162\n",
      "Average policy_loss: 1.0253\n",
      "Average value_loss: 0.2909\n",
      "Replay buffer size: 3738\n",
      "Time taken: 26.2s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.3058\n",
      "Average policy_loss: 1.0216\n",
      "Average value_loss: 0.2842\n",
      "Replay buffer size: 3832\n",
      "Time taken: 26.9s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.3058\n",
      "Average policy_loss: 1.0254\n",
      "Average value_loss: 0.2804\n",
      "Replay buffer size: 3924\n",
      "Time taken: 80.3s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.2982\n",
      "Average policy_loss: 1.0136\n",
      "Average value_loss: 0.2846\n",
      "Replay buffer size: 4013\n",
      "Time taken: 26.4s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.3126\n",
      "Average policy_loss: 1.0232\n",
      "Average value_loss: 0.2894\n",
      "Replay buffer size: 4094\n",
      "Time taken: 26.3s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.3000\n",
      "Average policy_loss: 1.0135\n",
      "Average value_loss: 0.2865\n",
      "Replay buffer size: 4187\n",
      "Time taken: 25.7s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.2965\n",
      "Average policy_loss: 1.0098\n",
      "Average value_loss: 0.2867\n",
      "Replay buffer size: 4273\n",
      "Time taken: 26.7s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.3024\n",
      "Average policy_loss: 1.0171\n",
      "Average value_loss: 0.2853\n",
      "Replay buffer size: 4363\n",
      "Time taken: 80.2s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.3306\n",
      "Average policy_loss: 1.0253\n",
      "Average value_loss: 0.3054\n",
      "Replay buffer size: 4446\n",
      "Time taken: 25.4s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.2826\n",
      "Average policy_loss: 1.0012\n",
      "Average value_loss: 0.2814\n",
      "Replay buffer size: 4534\n",
      "Time taken: 25.4s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.2892\n",
      "Average policy_loss: 1.0120\n",
      "Average value_loss: 0.2772\n",
      "Replay buffer size: 4628\n",
      "Time taken: 26.2s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.2874\n",
      "Average policy_loss: 1.0093\n",
      "Average value_loss: 0.2781\n",
      "Replay buffer size: 4719\n",
      "Time taken: 25.2s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.2762\n",
      "Average policy_loss: 0.9996\n",
      "Average value_loss: 0.2766\n",
      "Replay buffer size: 4807\n",
      "Time taken: 77.4s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.2862\n",
      "Average policy_loss: 1.0109\n",
      "Average value_loss: 0.2753\n",
      "Replay buffer size: 4895\n",
      "Time taken: 26.3s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.2666\n",
      "Average policy_loss: 0.9977\n",
      "Average value_loss: 0.2689\n",
      "Replay buffer size: 4995\n",
      "Time taken: 24.5s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.2746\n",
      "Average policy_loss: 1.0024\n",
      "Average value_loss: 0.2722\n",
      "Replay buffer size: 5080\n",
      "Time taken: 28.3s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.2674\n",
      "Average policy_loss: 0.9978\n",
      "Average value_loss: 0.2695\n",
      "Replay buffer size: 5171\n",
      "Time taken: 26.0s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.2680\n",
      "Average policy_loss: 0.9959\n",
      "Average value_loss: 0.2721\n",
      "Replay buffer size: 5250\n",
      "Time taken: 81.4s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.2538\n",
      "Average policy_loss: 0.9867\n",
      "Average value_loss: 0.2671\n",
      "Replay buffer size: 5346\n",
      "Time taken: 25.8s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.2649\n",
      "Average policy_loss: 0.9906\n",
      "Average value_loss: 0.2743\n",
      "Replay buffer size: 5437\n",
      "Time taken: 24.9s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.2661\n",
      "Average policy_loss: 0.9937\n",
      "Average value_loss: 0.2724\n",
      "Replay buffer size: 5528\n",
      "Time taken: 25.1s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.2716\n",
      "Average policy_loss: 1.0009\n",
      "Average value_loss: 0.2707\n",
      "Replay buffer size: 5618\n",
      "Time taken: 24.0s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.2640\n",
      "Average policy_loss: 0.9944\n",
      "Average value_loss: 0.2695\n",
      "Replay buffer size: 5708\n",
      "Time taken: 80.2s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.2624\n",
      "Average policy_loss: 0.9949\n",
      "Average value_loss: 0.2675\n",
      "Replay buffer size: 5798\n",
      "Time taken: 24.7s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.2593\n",
      "Average policy_loss: 0.9891\n",
      "Average value_loss: 0.2702\n",
      "Replay buffer size: 5891\n",
      "Time taken: 26.3s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.2550\n",
      "Average policy_loss: 0.9874\n",
      "Average value_loss: 0.2676\n",
      "Replay buffer size: 5976\n",
      "Time taken: 24.9s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.2518\n",
      "Average policy_loss: 0.9843\n",
      "Average value_loss: 0.2675\n",
      "Replay buffer size: 6065\n",
      "Time taken: 24.1s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.2555\n",
      "Average policy_loss: 0.9880\n",
      "Average value_loss: 0.2675\n",
      "Replay buffer size: 6156\n",
      "Time taken: 80.8s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.2483\n",
      "Average policy_loss: 0.9817\n",
      "Average value_loss: 0.2665\n",
      "Replay buffer size: 6238\n",
      "Time taken: 26.4s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.2439\n",
      "Average policy_loss: 0.9796\n",
      "Average value_loss: 0.2643\n",
      "Replay buffer size: 6333\n",
      "Time taken: 25.0s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.2488\n",
      "Average policy_loss: 0.9840\n",
      "Average value_loss: 0.2648\n",
      "Replay buffer size: 6428\n",
      "Time taken: 25.0s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.2388\n",
      "Average policy_loss: 0.9748\n",
      "Average value_loss: 0.2640\n",
      "Replay buffer size: 6522\n",
      "Time taken: 26.2s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.2366\n",
      "Average policy_loss: 0.9768\n",
      "Average value_loss: 0.2598\n",
      "Replay buffer size: 6609\n",
      "Time taken: 79.7s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.2428\n",
      "Average policy_loss: 0.9801\n",
      "Average value_loss: 0.2627\n",
      "Replay buffer size: 6697\n",
      "Time taken: 25.4s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.2348\n",
      "Average policy_loss: 0.9754\n",
      "Average value_loss: 0.2593\n",
      "Replay buffer size: 6783\n",
      "Time taken: 24.8s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.2405\n",
      "Average policy_loss: 0.9744\n",
      "Average value_loss: 0.2661\n",
      "Replay buffer size: 6873\n",
      "Time taken: 24.1s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.2421\n",
      "Average policy_loss: 0.9781\n",
      "Average value_loss: 0.2641\n",
      "Replay buffer size: 6963\n",
      "Time taken: 25.7s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.2385\n",
      "Average policy_loss: 0.9727\n",
      "Average value_loss: 0.2659\n",
      "Replay buffer size: 7045\n",
      "Time taken: 78.6s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.2382\n",
      "Average policy_loss: 0.9766\n",
      "Average value_loss: 0.2615\n",
      "Replay buffer size: 7138\n",
      "Time taken: 26.6s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.2298\n",
      "Average policy_loss: 0.9659\n",
      "Average value_loss: 0.2639\n",
      "Replay buffer size: 7229\n",
      "Time taken: 25.8s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.2321\n",
      "Average policy_loss: 0.9693\n",
      "Average value_loss: 0.2628\n",
      "Replay buffer size: 7319\n",
      "Time taken: 26.1s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.2374\n",
      "Average policy_loss: 0.9727\n",
      "Average value_loss: 0.2647\n",
      "Replay buffer size: 7413\n",
      "Time taken: 26.2s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.2313\n",
      "Average policy_loss: 0.9700\n",
      "Average value_loss: 0.2613\n",
      "Replay buffer size: 7509\n",
      "Time taken: 77.8s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.2333\n",
      "Average policy_loss: 0.9701\n",
      "Average value_loss: 0.2632\n",
      "Replay buffer size: 7601\n",
      "Time taken: 24.3s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.2301\n",
      "Average policy_loss: 0.9704\n",
      "Average value_loss: 0.2598\n",
      "Replay buffer size: 7685\n",
      "Time taken: 24.6s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.2239\n",
      "Average policy_loss: 0.9707\n",
      "Average value_loss: 0.2532\n",
      "Replay buffer size: 7776\n",
      "Time taken: 26.1s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.2250\n",
      "Average policy_loss: 0.9660\n",
      "Average value_loss: 0.2589\n",
      "Replay buffer size: 7860\n",
      "Time taken: 25.0s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.2200\n",
      "Average policy_loss: 0.9648\n",
      "Average value_loss: 0.2553\n",
      "Replay buffer size: 7956\n",
      "Time taken: 79.7s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.2202\n",
      "Average policy_loss: 0.9665\n",
      "Average value_loss: 0.2537\n",
      "Replay buffer size: 8051\n",
      "Time taken: 23.0s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.2229\n",
      "Average policy_loss: 0.9665\n",
      "Average value_loss: 0.2564\n",
      "Replay buffer size: 8136\n",
      "Time taken: 25.9s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.2195\n",
      "Average policy_loss: 0.9659\n",
      "Average value_loss: 0.2536\n",
      "Replay buffer size: 8222\n",
      "Time taken: 24.2s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.2131\n",
      "Average policy_loss: 0.9605\n",
      "Average value_loss: 0.2526\n",
      "Replay buffer size: 8321\n",
      "Time taken: 26.2s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.2217\n",
      "Average policy_loss: 0.9675\n",
      "Average value_loss: 0.2542\n",
      "Replay buffer size: 8414\n",
      "Time taken: 81.6s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.2144\n",
      "Average policy_loss: 0.9601\n",
      "Average value_loss: 0.2543\n",
      "Replay buffer size: 8502\n",
      "Time taken: 26.4s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.2135\n",
      "Average policy_loss: 0.9596\n",
      "Average value_loss: 0.2539\n",
      "Replay buffer size: 8589\n",
      "Time taken: 25.4s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.2215\n",
      "Average policy_loss: 0.9675\n",
      "Average value_loss: 0.2540\n",
      "Replay buffer size: 8680\n",
      "Time taken: 25.0s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.2140\n",
      "Average policy_loss: 0.9601\n",
      "Average value_loss: 0.2539\n",
      "Replay buffer size: 8771\n",
      "Time taken: 25.1s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.2153\n",
      "Average policy_loss: 0.9628\n",
      "Average value_loss: 0.2525\n",
      "Replay buffer size: 8867\n",
      "Time taken: 80.5s\n",
      "\n",
      "Training complete! Total time: 1.0h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇███</td></tr><tr><td>iteration_time</td><td>▁▁█▁▁▁█▁▁▁▁█▁▁█▁▁▁▁▁▁▁▁▁▇▁█▁▁▁▁▁█▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▃▆▇██▇▆▅▅▄▄▄▄▄▄▄▃▃▃▃▃▄▃▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▄▄▅▄▃▃▂▁▄▆▃▅▆▅▄▇▅▅▅▆▇▄▆▃▇▅▃▁█▃▆▇▆▆▇▆▆█▄▆</td></tr><tr><td>policy_loss</td><td>█▁▃▃▃▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▃▃▃▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.2</td></tr><tr><td>buffer_size</td><td>8867</td></tr><tr><td>iteration_time</td><td>80.50791</td></tr><tr><td>loss</td><td>1.21535</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>96</td></tr><tr><td>policy_loss</td><td>0.9628</td></tr><tr><td>total_time_hours</td><td>1.01701</td></tr><tr><td>value_loss</td><td>0.25254</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">woven-sweep-47</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/mwgt93eq' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/mwgt93eq</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250302_013525-mwgt93eq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9y8nbmkn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00010840278403668248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: xlarge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.873471271655084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.002175201218305422\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250302_023636-9y8nbmkn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/9y8nbmkn' target=\"_blank\">vital-sweep-48</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/9y8nbmkn' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/9y8nbmkn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 3.6069\n",
      "Average policy_loss: 2.5141\n",
      "Average value_loss: 1.0928\n",
      "Replay buffer size: 93\n",
      "Time taken: 9.8s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 2.1548\n",
      "Average policy_loss: 1.1104\n",
      "Average value_loss: 1.0444\n",
      "Replay buffer size: 193\n",
      "Time taken: 9.3s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 2.1444\n",
      "Average policy_loss: 1.0955\n",
      "Average value_loss: 1.0489\n",
      "Replay buffer size: 284\n",
      "Time taken: 9.9s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 2.1003\n",
      "Average policy_loss: 1.0505\n",
      "Average value_loss: 1.0498\n",
      "Replay buffer size: 378\n",
      "Time taken: 11.8s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 2.1521\n",
      "Average policy_loss: 1.1016\n",
      "Average value_loss: 1.0505\n",
      "Replay buffer size: 473\n",
      "Time taken: 39.5s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 2.1444\n",
      "Average policy_loss: 1.0799\n",
      "Average value_loss: 1.0645\n",
      "Replay buffer size: 562\n",
      "Time taken: 14.8s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 2.1003\n",
      "Average policy_loss: 1.0381\n",
      "Average value_loss: 1.0622\n",
      "Replay buffer size: 654\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 2.0986\n",
      "Average policy_loss: 1.0349\n",
      "Average value_loss: 1.0637\n",
      "Replay buffer size: 745\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 2.0848\n",
      "Average policy_loss: 1.0255\n",
      "Average value_loss: 1.0593\n",
      "Replay buffer size: 841\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 55.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 2.0845\n",
      "Average policy_loss: 1.0202\n",
      "Average value_loss: 1.0643\n",
      "Replay buffer size: 934\n",
      "Time taken: 50.3s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 2.0750\n",
      "Average policy_loss: 1.0124\n",
      "Average value_loss: 1.0625\n",
      "Replay buffer size: 1029\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 2.0545\n",
      "Average policy_loss: 0.9977\n",
      "Average value_loss: 1.0568\n",
      "Replay buffer size: 1121\n",
      "Time taken: 16.4s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 2.0568\n",
      "Average policy_loss: 0.9904\n",
      "Average value_loss: 1.0664\n",
      "Replay buffer size: 1216\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 2.0603\n",
      "Average policy_loss: 0.9990\n",
      "Average value_loss: 1.0613\n",
      "Replay buffer size: 1312\n",
      "Time taken: 16.6s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 15.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 2.0500\n",
      "Average policy_loss: 0.9832\n",
      "Average value_loss: 1.0668\n",
      "Replay buffer size: 1409\n",
      "Time taken: 56.0s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 2.0396\n",
      "Average policy_loss: 0.9760\n",
      "Average value_loss: 1.0636\n",
      "Replay buffer size: 1498\n",
      "Time taken: 17.6s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 2.0641\n",
      "Average policy_loss: 0.9974\n",
      "Average value_loss: 1.0667\n",
      "Replay buffer size: 1591\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 2.0552\n",
      "Average policy_loss: 0.9874\n",
      "Average value_loss: 1.0677\n",
      "Replay buffer size: 1687\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 2.0580\n",
      "Average policy_loss: 0.9913\n",
      "Average value_loss: 1.0667\n",
      "Replay buffer size: 1782\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 2.0476\n",
      "Average policy_loss: 0.9843\n",
      "Average value_loss: 1.0633\n",
      "Replay buffer size: 1869\n",
      "Time taken: 59.5s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 2.0494\n",
      "Average policy_loss: 0.9855\n",
      "Average value_loss: 1.0639\n",
      "Replay buffer size: 1961\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 2.0477\n",
      "Average policy_loss: 0.9823\n",
      "Average value_loss: 1.0654\n",
      "Replay buffer size: 2052\n",
      "Time taken: 19.4s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 2.0563\n",
      "Average policy_loss: 0.9846\n",
      "Average value_loss: 1.0717\n",
      "Replay buffer size: 2144\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 2.0632\n",
      "Average policy_loss: 0.9894\n",
      "Average value_loss: 1.0738\n",
      "Replay buffer size: 2230\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 15.00%\n",
      "RandomAgent: Win rate = 40.00%, Draw rate = 40.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 2.0578\n",
      "Average policy_loss: 0.9862\n",
      "Average value_loss: 1.0716\n",
      "Replay buffer size: 2322\n",
      "Time taken: 61.4s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 2.0580\n",
      "Average policy_loss: 0.9819\n",
      "Average value_loss: 1.0761\n",
      "Replay buffer size: 2415\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 2.0633\n",
      "Average policy_loss: 0.9836\n",
      "Average value_loss: 1.0797\n",
      "Replay buffer size: 2507\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 2.0672\n",
      "Average policy_loss: 0.9851\n",
      "Average value_loss: 1.0821\n",
      "Replay buffer size: 2599\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 2.0514\n",
      "Average policy_loss: 0.9760\n",
      "Average value_loss: 1.0754\n",
      "Replay buffer size: 2694\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 15.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 2.0658\n",
      "Average policy_loss: 0.9857\n",
      "Average value_loss: 1.0801\n",
      "Replay buffer size: 2786\n",
      "Time taken: 62.1s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 2.0626\n",
      "Average policy_loss: 0.9826\n",
      "Average value_loss: 1.0800\n",
      "Replay buffer size: 2881\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 2.0572\n",
      "Average policy_loss: 0.9752\n",
      "Average value_loss: 1.0820\n",
      "Replay buffer size: 2978\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 2.0499\n",
      "Average policy_loss: 0.9722\n",
      "Average value_loss: 1.0777\n",
      "Replay buffer size: 3072\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 2.0740\n",
      "Average policy_loss: 0.9808\n",
      "Average value_loss: 1.0932\n",
      "Replay buffer size: 3166\n",
      "Time taken: 20.5s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 60.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 2.0609\n",
      "Average policy_loss: 0.9764\n",
      "Average value_loss: 1.0845\n",
      "Replay buffer size: 3255\n",
      "Time taken: 64.5s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 2.0808\n",
      "Average policy_loss: 0.9903\n",
      "Average value_loss: 1.0904\n",
      "Replay buffer size: 3339\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 2.0803\n",
      "Average policy_loss: 0.9991\n",
      "Average value_loss: 1.0812\n",
      "Replay buffer size: 3421\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 2.0815\n",
      "Average policy_loss: 0.9964\n",
      "Average value_loss: 1.0851\n",
      "Replay buffer size: 3516\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 2.0792\n",
      "Average policy_loss: 0.9895\n",
      "Average value_loss: 1.0898\n",
      "Replay buffer size: 3609\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 2.0857\n",
      "Average policy_loss: 0.9916\n",
      "Average value_loss: 1.0941\n",
      "Replay buffer size: 3695\n",
      "Time taken: 66.3s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 2.0914\n",
      "Average policy_loss: 0.9995\n",
      "Average value_loss: 1.0919\n",
      "Replay buffer size: 3782\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 2.0813\n",
      "Average policy_loss: 0.9940\n",
      "Average value_loss: 1.0872\n",
      "Replay buffer size: 3875\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 2.0921\n",
      "Average policy_loss: 0.9960\n",
      "Average value_loss: 1.0962\n",
      "Replay buffer size: 3972\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 2.0872\n",
      "Average policy_loss: 0.9950\n",
      "Average value_loss: 1.0922\n",
      "Replay buffer size: 4068\n",
      "Time taken: 20.8s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 10.00%\n",
      "RandomAgent: Win rate = 50.00%, Draw rate = 50.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 2.0910\n",
      "Average policy_loss: 0.9976\n",
      "Average value_loss: 1.0934\n",
      "Replay buffer size: 4163\n",
      "Time taken: 65.7s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 2.0900\n",
      "Average policy_loss: 1.0003\n",
      "Average value_loss: 1.0897\n",
      "Replay buffer size: 4243\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 2.1006\n",
      "Average policy_loss: 1.0078\n",
      "Average value_loss: 1.0928\n",
      "Replay buffer size: 4333\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 2.1028\n",
      "Average policy_loss: 1.0097\n",
      "Average value_loss: 1.0931\n",
      "Replay buffer size: 4415\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 2.1060\n",
      "Average policy_loss: 1.0094\n",
      "Average value_loss: 1.0966\n",
      "Replay buffer size: 4505\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 2.1019\n",
      "Average policy_loss: 1.0070\n",
      "Average value_loss: 1.0949\n",
      "Replay buffer size: 4597\n",
      "Time taken: 66.8s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 2.1027\n",
      "Average policy_loss: 1.0136\n",
      "Average value_loss: 1.0892\n",
      "Replay buffer size: 4688\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 2.1123\n",
      "Average policy_loss: 1.0111\n",
      "Average value_loss: 1.1012\n",
      "Replay buffer size: 4771\n",
      "Time taken: 23.1s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 2.1115\n",
      "Average policy_loss: 1.0144\n",
      "Average value_loss: 1.0971\n",
      "Replay buffer size: 4863\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 2.1021\n",
      "Average policy_loss: 1.0082\n",
      "Average value_loss: 1.0939\n",
      "Replay buffer size: 4956\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 55.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 2.1137\n",
      "Average policy_loss: 1.0164\n",
      "Average value_loss: 1.0972\n",
      "Replay buffer size: 5040\n",
      "Time taken: 68.2s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 2.1259\n",
      "Average policy_loss: 1.0260\n",
      "Average value_loss: 1.0999\n",
      "Replay buffer size: 5133\n",
      "Time taken: 23.6s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 2.1229\n",
      "Average policy_loss: 1.0260\n",
      "Average value_loss: 1.0969\n",
      "Replay buffer size: 5218\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 2.1234\n",
      "Average policy_loss: 1.0247\n",
      "Average value_loss: 1.0987\n",
      "Replay buffer size: 5306\n",
      "Time taken: 22.4s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 2.1196\n",
      "Average policy_loss: 1.0221\n",
      "Average value_loss: 1.0975\n",
      "Replay buffer size: 5399\n",
      "Time taken: 23.8s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 2.1218\n",
      "Average policy_loss: 1.0251\n",
      "Average value_loss: 1.0967\n",
      "Replay buffer size: 5478\n",
      "Time taken: 67.7s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 2.1200\n",
      "Average policy_loss: 1.0251\n",
      "Average value_loss: 1.0949\n",
      "Replay buffer size: 5559\n",
      "Time taken: 24.0s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 2.1269\n",
      "Average policy_loss: 1.0318\n",
      "Average value_loss: 1.0951\n",
      "Replay buffer size: 5643\n",
      "Time taken: 23.1s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 2.1282\n",
      "Average policy_loss: 1.0244\n",
      "Average value_loss: 1.1037\n",
      "Replay buffer size: 5734\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 2.1317\n",
      "Average policy_loss: 1.0301\n",
      "Average value_loss: 1.1016\n",
      "Replay buffer size: 5829\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 35.00%\n",
      "RandomAgent: Win rate = 55.00%, Draw rate = 40.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 2.1331\n",
      "Average policy_loss: 1.0321\n",
      "Average value_loss: 1.1010\n",
      "Replay buffer size: 5916\n",
      "Time taken: 69.7s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 2.1284\n",
      "Average policy_loss: 1.0294\n",
      "Average value_loss: 1.0990\n",
      "Replay buffer size: 5996\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 2.1387\n",
      "Average policy_loss: 1.0362\n",
      "Average value_loss: 1.1024\n",
      "Replay buffer size: 6089\n",
      "Time taken: 22.4s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 2.1425\n",
      "Average policy_loss: 1.0381\n",
      "Average value_loss: 1.1045\n",
      "Replay buffer size: 6175\n",
      "Time taken: 22.1s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 2.1345\n",
      "Average policy_loss: 1.0346\n",
      "Average value_loss: 1.0999\n",
      "Replay buffer size: 6259\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 2.1397\n",
      "Average policy_loss: 1.0354\n",
      "Average value_loss: 1.1042\n",
      "Replay buffer size: 6350\n",
      "Time taken: 68.2s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 2.1491\n",
      "Average policy_loss: 1.0441\n",
      "Average value_loss: 1.1050\n",
      "Replay buffer size: 6428\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 2.1539\n",
      "Average policy_loss: 1.0459\n",
      "Average value_loss: 1.1080\n",
      "Replay buffer size: 6513\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 2.1555\n",
      "Average policy_loss: 1.0426\n",
      "Average value_loss: 1.1129\n",
      "Replay buffer size: 6595\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 2.1529\n",
      "Average policy_loss: 1.0513\n",
      "Average value_loss: 1.1016\n",
      "Replay buffer size: 6682\n",
      "Time taken: 24.1s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 25.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 2.1520\n",
      "Average policy_loss: 1.0430\n",
      "Average value_loss: 1.1090\n",
      "Replay buffer size: 6766\n",
      "Time taken: 70.0s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 2.1600\n",
      "Average policy_loss: 1.0526\n",
      "Average value_loss: 1.1074\n",
      "Replay buffer size: 6854\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 2.1473\n",
      "Average policy_loss: 1.0452\n",
      "Average value_loss: 1.1020\n",
      "Replay buffer size: 6945\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 2.1588\n",
      "Average policy_loss: 1.0487\n",
      "Average value_loss: 1.1101\n",
      "Replay buffer size: 7030\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 2.1487\n",
      "Average policy_loss: 1.0436\n",
      "Average value_loss: 1.1051\n",
      "Replay buffer size: 7118\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 15.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 2.1496\n",
      "Average policy_loss: 1.0456\n",
      "Average value_loss: 1.1040\n",
      "Replay buffer size: 7199\n",
      "Time taken: 70.2s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 2.1563\n",
      "Average policy_loss: 1.0522\n",
      "Average value_loss: 1.1041\n",
      "Replay buffer size: 7293\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 2.1723\n",
      "Average policy_loss: 1.0589\n",
      "Average value_loss: 1.1134\n",
      "Replay buffer size: 7361\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 2.1721\n",
      "Average policy_loss: 1.0626\n",
      "Average value_loss: 1.1095\n",
      "Replay buffer size: 7451\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 2.1746\n",
      "Average policy_loss: 1.0618\n",
      "Average value_loss: 1.1128\n",
      "Replay buffer size: 7539\n",
      "Time taken: 23.2s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 2.1713\n",
      "Average policy_loss: 1.0532\n",
      "Average value_loss: 1.1182\n",
      "Replay buffer size: 7626\n",
      "Time taken: 69.9s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.6949\n",
      "Average policy_loss: 1.0707\n",
      "Average value_loss: 0.6241\n",
      "Replay buffer size: 7719\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.2562\n",
      "Average policy_loss: 1.0671\n",
      "Average value_loss: 0.1891\n",
      "Replay buffer size: 7805\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.2401\n",
      "Average policy_loss: 1.0673\n",
      "Average value_loss: 0.1728\n",
      "Replay buffer size: 7894\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.2423\n",
      "Average policy_loss: 1.0757\n",
      "Average value_loss: 0.1666\n",
      "Replay buffer size: 7978\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.2385\n",
      "Average policy_loss: 1.0766\n",
      "Average value_loss: 0.1619\n",
      "Replay buffer size: 8066\n",
      "Time taken: 68.4s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.2342\n",
      "Average policy_loss: 1.0734\n",
      "Average value_loss: 0.1608\n",
      "Replay buffer size: 8154\n",
      "Time taken: 23.3s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.2345\n",
      "Average policy_loss: 1.0769\n",
      "Average value_loss: 0.1576\n",
      "Replay buffer size: 8245\n",
      "Time taken: 23.7s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.2289\n",
      "Average policy_loss: 1.0739\n",
      "Average value_loss: 0.1550\n",
      "Replay buffer size: 8329\n",
      "Time taken: 23.9s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.2304\n",
      "Average policy_loss: 1.0791\n",
      "Average value_loss: 0.1513\n",
      "Replay buffer size: 8416\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.2329\n",
      "Average policy_loss: 1.0822\n",
      "Average value_loss: 0.1507\n",
      "Replay buffer size: 8510\n",
      "Time taken: 69.1s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.2344\n",
      "Average policy_loss: 1.0870\n",
      "Average value_loss: 0.1474\n",
      "Replay buffer size: 8588\n",
      "Time taken: 23.5s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.2327\n",
      "Average policy_loss: 1.0832\n",
      "Average value_loss: 0.1496\n",
      "Replay buffer size: 8682\n",
      "Time taken: 22.6s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.2291\n",
      "Average policy_loss: 1.0820\n",
      "Average value_loss: 0.1471\n",
      "Replay buffer size: 8767\n",
      "Time taken: 22.8s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.2298\n",
      "Average policy_loss: 1.0827\n",
      "Average value_loss: 0.1471\n",
      "Replay buffer size: 8854\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.2367\n",
      "Average policy_loss: 1.0902\n",
      "Average value_loss: 0.1465\n",
      "Replay buffer size: 8942\n",
      "Time taken: 69.9s\n",
      "\n",
      "Training complete! Total time: 0.8h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▃▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>iteration_time</td><td>▁▁▂▂▆▂▇▇▂▂▂▂▂▂█▂▂▂▂▂█▃▂█▃▂█▃▂▂▂█▂█▂▂█▃▃▃</td></tr><tr><td>loss</td><td>██▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▆▆▇▇▅▇█▇▄▆█▇▅▃▂▄██▇▁▅▆▆▂▄▁▃▄▁▆▆▄▃▄▄▃▅▃▇▄</td></tr><tr><td>policy_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>value_loss</td><td>█▇███████████████████████████████▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>0.95</td></tr><tr><td>buffer_size</td><td>8942</td></tr><tr><td>iteration_time</td><td>69.91262</td></tr><tr><td>loss</td><td>1.23671</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>88</td></tr><tr><td>policy_loss</td><td>1.09025</td></tr><tr><td>total_time_hours</td><td>0.81609</td></tr><tr><td>value_loss</td><td>0.14646</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vital-sweep-48</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/9y8nbmkn' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/9y8nbmkn</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 22 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250302_023636-9y8nbmkn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6yd6ohjb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006240627863831675\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: medium\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.8537371052272262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0007780525146509451\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250302_032543-6yd6ohjb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/6yd6ohjb' target=\"_blank\">glad-sweep-49</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/6yd6ohjb' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/6yd6ohjb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.8282\n",
      "Average policy_loss: 1.3740\n",
      "Average value_loss: 0.4541\n",
      "Replay buffer size: 90\n",
      "Time taken: 9.4s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 0.9463\n",
      "Average policy_loss: 0.7601\n",
      "Average value_loss: 0.1862\n",
      "Replay buffer size: 182\n",
      "Time taken: 13.7s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 0.9888\n",
      "Average policy_loss: 0.8126\n",
      "Average value_loss: 0.1762\n",
      "Replay buffer size: 263\n",
      "Time taken: 17.5s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.0515\n",
      "Average policy_loss: 0.8967\n",
      "Average value_loss: 0.1548\n",
      "Replay buffer size: 351\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 0.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.0345\n",
      "Average policy_loss: 0.8932\n",
      "Average value_loss: 0.1413\n",
      "Replay buffer size: 443\n",
      "Time taken: 63.5s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 68 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.0576\n",
      "Average policy_loss: 0.9076\n",
      "Average value_loss: 0.1500\n",
      "Replay buffer size: 511\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.0635\n",
      "Average policy_loss: 0.9097\n",
      "Average value_loss: 0.1538\n",
      "Replay buffer size: 592\n",
      "Time taken: 16.8s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.0730\n",
      "Average policy_loss: 0.9234\n",
      "Average value_loss: 0.1496\n",
      "Replay buffer size: 668\n",
      "Time taken: 17.3s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.0891\n",
      "Average policy_loss: 0.9432\n",
      "Average value_loss: 0.1459\n",
      "Replay buffer size: 752\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 55.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.0792\n",
      "Average policy_loss: 0.9330\n",
      "Average value_loss: 0.1461\n",
      "Replay buffer size: 830\n",
      "Time taken: 50.6s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.0882\n",
      "Average policy_loss: 0.9375\n",
      "Average value_loss: 0.1506\n",
      "Replay buffer size: 911\n",
      "Time taken: 15.6s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.0895\n",
      "Average policy_loss: 0.9403\n",
      "Average value_loss: 0.1491\n",
      "Replay buffer size: 990\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 72 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.0891\n",
      "Average policy_loss: 0.9381\n",
      "Average value_loss: 0.1510\n",
      "Replay buffer size: 1062\n",
      "Time taken: 14.0s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.0835\n",
      "Average policy_loss: 0.9330\n",
      "Average value_loss: 0.1505\n",
      "Replay buffer size: 1136\n",
      "Time taken: 16.0s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.0775\n",
      "Average policy_loss: 0.9304\n",
      "Average value_loss: 0.1471\n",
      "Replay buffer size: 1210\n",
      "Time taken: 49.5s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.0813\n",
      "Average policy_loss: 0.9312\n",
      "Average value_loss: 0.1502\n",
      "Replay buffer size: 1284\n",
      "Time taken: 14.5s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 74 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.0827\n",
      "Average policy_loss: 0.9345\n",
      "Average value_loss: 0.1481\n",
      "Replay buffer size: 1358\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.0820\n",
      "Average policy_loss: 0.9345\n",
      "Average value_loss: 0.1475\n",
      "Replay buffer size: 1446\n",
      "Time taken: 15.5s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.0924\n",
      "Average policy_loss: 0.9350\n",
      "Average value_loss: 0.1574\n",
      "Replay buffer size: 1524\n",
      "Time taken: 15.2s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.0915\n",
      "Average policy_loss: 0.9346\n",
      "Average value_loss: 0.1569\n",
      "Replay buffer size: 1604\n",
      "Time taken: 49.7s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 69 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.0858\n",
      "Average policy_loss: 0.9302\n",
      "Average value_loss: 0.1556\n",
      "Replay buffer size: 1673\n",
      "Time taken: 13.8s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.0870\n",
      "Average policy_loss: 0.9235\n",
      "Average value_loss: 0.1635\n",
      "Replay buffer size: 1755\n",
      "Time taken: 15.4s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.0773\n",
      "Average policy_loss: 0.9163\n",
      "Average value_loss: 0.1609\n",
      "Replay buffer size: 1839\n",
      "Time taken: 16.7s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.0846\n",
      "Average policy_loss: 0.9232\n",
      "Average value_loss: 0.1614\n",
      "Replay buffer size: 1921\n",
      "Time taken: 16.5s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.0861\n",
      "Average policy_loss: 0.9223\n",
      "Average value_loss: 0.1638\n",
      "Replay buffer size: 1998\n",
      "Time taken: 52.9s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.0892\n",
      "Average policy_loss: 0.9260\n",
      "Average value_loss: 0.1633\n",
      "Replay buffer size: 2080\n",
      "Time taken: 17.9s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.0830\n",
      "Average policy_loss: 0.9220\n",
      "Average value_loss: 0.1610\n",
      "Replay buffer size: 2172\n",
      "Time taken: 17.4s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.0829\n",
      "Average policy_loss: 0.9211\n",
      "Average value_loss: 0.1618\n",
      "Replay buffer size: 2250\n",
      "Time taken: 16.9s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.0844\n",
      "Average policy_loss: 0.9194\n",
      "Average value_loss: 0.1650\n",
      "Replay buffer size: 2333\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.0792\n",
      "Average policy_loss: 0.9154\n",
      "Average value_loss: 0.1638\n",
      "Replay buffer size: 2422\n",
      "Time taken: 56.6s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 1.0808\n",
      "Average policy_loss: 0.9178\n",
      "Average value_loss: 0.1631\n",
      "Replay buffer size: 2508\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 1.0757\n",
      "Average policy_loss: 0.9094\n",
      "Average value_loss: 0.1663\n",
      "Replay buffer size: 2595\n",
      "Time taken: 19.4s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 1.0829\n",
      "Average policy_loss: 0.9139\n",
      "Average value_loss: 0.1690\n",
      "Replay buffer size: 2678\n",
      "Time taken: 18.6s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 1.0825\n",
      "Average policy_loss: 0.9120\n",
      "Average value_loss: 0.1705\n",
      "Replay buffer size: 2765\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 1.0810\n",
      "Average policy_loss: 0.9112\n",
      "Average value_loss: 0.1698\n",
      "Replay buffer size: 2849\n",
      "Time taken: 57.3s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 1.0840\n",
      "Average policy_loss: 0.9178\n",
      "Average value_loss: 0.1662\n",
      "Replay buffer size: 2934\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 1.0767\n",
      "Average policy_loss: 0.9092\n",
      "Average value_loss: 0.1675\n",
      "Replay buffer size: 3022\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 1.0778\n",
      "Average policy_loss: 0.9100\n",
      "Average value_loss: 0.1678\n",
      "Replay buffer size: 3118\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 1.0718\n",
      "Average policy_loss: 0.9078\n",
      "Average value_loss: 0.1639\n",
      "Replay buffer size: 3203\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 83 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 1.0740\n",
      "Average policy_loss: 0.9095\n",
      "Average value_loss: 0.1645\n",
      "Replay buffer size: 3286\n",
      "Time taken: 62.2s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 1.0702\n",
      "Average policy_loss: 0.9065\n",
      "Average value_loss: 0.1637\n",
      "Replay buffer size: 3368\n",
      "Time taken: 20.8s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 1.0657\n",
      "Average policy_loss: 0.9002\n",
      "Average value_loss: 0.1655\n",
      "Replay buffer size: 3463\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 1.0616\n",
      "Average policy_loss: 0.8994\n",
      "Average value_loss: 0.1622\n",
      "Replay buffer size: 3550\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 1.0640\n",
      "Average policy_loss: 0.9025\n",
      "Average value_loss: 0.1615\n",
      "Replay buffer size: 3646\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 35.00%, Draw rate = 30.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 1.0558\n",
      "Average policy_loss: 0.8964\n",
      "Average value_loss: 0.1594\n",
      "Replay buffer size: 3736\n",
      "Time taken: 61.6s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 1.0599\n",
      "Average policy_loss: 0.8995\n",
      "Average value_loss: 0.1603\n",
      "Replay buffer size: 3827\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 1.0543\n",
      "Average policy_loss: 0.8959\n",
      "Average value_loss: 0.1584\n",
      "Replay buffer size: 3923\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 1.0545\n",
      "Average policy_loss: 0.8960\n",
      "Average value_loss: 0.1585\n",
      "Replay buffer size: 4013\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 1.0519\n",
      "Average policy_loss: 0.8936\n",
      "Average value_loss: 0.1584\n",
      "Replay buffer size: 4097\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 1.0569\n",
      "Average policy_loss: 0.8977\n",
      "Average value_loss: 0.1592\n",
      "Replay buffer size: 4184\n",
      "Time taken: 60.4s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 1.0596\n",
      "Average policy_loss: 0.9002\n",
      "Average value_loss: 0.1594\n",
      "Replay buffer size: 4277\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 1.0531\n",
      "Average policy_loss: 0.8940\n",
      "Average value_loss: 0.1591\n",
      "Replay buffer size: 4362\n",
      "Time taken: 19.3s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 1.0531\n",
      "Average policy_loss: 0.8934\n",
      "Average value_loss: 0.1598\n",
      "Replay buffer size: 4448\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 1.0463\n",
      "Average policy_loss: 0.8878\n",
      "Average value_loss: 0.1584\n",
      "Replay buffer size: 4534\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 40.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 1.0487\n",
      "Average policy_loss: 0.8922\n",
      "Average value_loss: 0.1565\n",
      "Replay buffer size: 4627\n",
      "Time taken: 62.3s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 1.0446\n",
      "Average policy_loss: 0.8867\n",
      "Average value_loss: 0.1579\n",
      "Replay buffer size: 4717\n",
      "Time taken: 19.2s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 1.0437\n",
      "Average policy_loss: 0.8860\n",
      "Average value_loss: 0.1578\n",
      "Replay buffer size: 4814\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 1.0431\n",
      "Average policy_loss: 0.8865\n",
      "Average value_loss: 0.1565\n",
      "Replay buffer size: 4908\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 1.0417\n",
      "Average policy_loss: 0.8862\n",
      "Average value_loss: 0.1555\n",
      "Replay buffer size: 4997\n",
      "Time taken: 22.4s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 1.0461\n",
      "Average policy_loss: 0.8885\n",
      "Average value_loss: 0.1576\n",
      "Replay buffer size: 5083\n",
      "Time taken: 63.9s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 1.0483\n",
      "Average policy_loss: 0.8891\n",
      "Average value_loss: 0.1592\n",
      "Replay buffer size: 5171\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 1.0473\n",
      "Average policy_loss: 0.8915\n",
      "Average value_loss: 0.1558\n",
      "Replay buffer size: 5253\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 1.0459\n",
      "Average policy_loss: 0.8886\n",
      "Average value_loss: 0.1572\n",
      "Replay buffer size: 5346\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 77 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 1.0496\n",
      "Average policy_loss: 0.8933\n",
      "Average value_loss: 0.1562\n",
      "Replay buffer size: 5423\n",
      "Time taken: 20.8s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 1.0522\n",
      "Average policy_loss: 0.8923\n",
      "Average value_loss: 0.1600\n",
      "Replay buffer size: 5508\n",
      "Time taken: 66.8s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 1.0536\n",
      "Average policy_loss: 0.8943\n",
      "Average value_loss: 0.1594\n",
      "Replay buffer size: 5593\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 1.0482\n",
      "Average policy_loss: 0.8919\n",
      "Average value_loss: 0.1563\n",
      "Replay buffer size: 5689\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 1.0548\n",
      "Average policy_loss: 0.9018\n",
      "Average value_loss: 0.1530\n",
      "Replay buffer size: 5776\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 1.0513\n",
      "Average policy_loss: 0.8942\n",
      "Average value_loss: 0.1570\n",
      "Replay buffer size: 5872\n",
      "Time taken: 22.4s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 20.00%, Draw rate = 50.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 1.0437\n",
      "Average policy_loss: 0.8891\n",
      "Average value_loss: 0.1547\n",
      "Replay buffer size: 5963\n",
      "Time taken: 62.4s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 1.0442\n",
      "Average policy_loss: 0.8913\n",
      "Average value_loss: 0.1529\n",
      "Replay buffer size: 6057\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 1.0478\n",
      "Average policy_loss: 0.8959\n",
      "Average value_loss: 0.1519\n",
      "Replay buffer size: 6151\n",
      "Time taken: 22.4s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 1.0473\n",
      "Average policy_loss: 0.8950\n",
      "Average value_loss: 0.1523\n",
      "Replay buffer size: 6236\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 1.0426\n",
      "Average policy_loss: 0.8901\n",
      "Average value_loss: 0.1526\n",
      "Replay buffer size: 6323\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 1.0436\n",
      "Average policy_loss: 0.8926\n",
      "Average value_loss: 0.1510\n",
      "Replay buffer size: 6417\n",
      "Time taken: 68.1s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 1.0494\n",
      "Average policy_loss: 0.8979\n",
      "Average value_loss: 0.1515\n",
      "Replay buffer size: 6495\n",
      "Time taken: 23.2s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 1.0530\n",
      "Average policy_loss: 0.9009\n",
      "Average value_loss: 0.1522\n",
      "Replay buffer size: 6574\n",
      "Time taken: 23.4s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 1.0530\n",
      "Average policy_loss: 0.9013\n",
      "Average value_loss: 0.1517\n",
      "Replay buffer size: 6666\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 1.0488\n",
      "Average policy_loss: 0.8986\n",
      "Average value_loss: 0.1501\n",
      "Replay buffer size: 6754\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 1.0432\n",
      "Average policy_loss: 0.8926\n",
      "Average value_loss: 0.1506\n",
      "Replay buffer size: 6848\n",
      "Time taken: 68.7s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 1.0449\n",
      "Average policy_loss: 0.8973\n",
      "Average value_loss: 0.1476\n",
      "Replay buffer size: 6939\n",
      "Time taken: 22.3s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 1.0448\n",
      "Average policy_loss: 0.8979\n",
      "Average value_loss: 0.1468\n",
      "Replay buffer size: 7026\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 1.0449\n",
      "Average policy_loss: 0.8947\n",
      "Average value_loss: 0.1502\n",
      "Replay buffer size: 7122\n",
      "Time taken: 22.5s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 1.0423\n",
      "Average policy_loss: 0.8945\n",
      "Average value_loss: 0.1479\n",
      "Replay buffer size: 7214\n",
      "Time taken: 22.4s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 1.0376\n",
      "Average policy_loss: 0.8914\n",
      "Average value_loss: 0.1462\n",
      "Replay buffer size: 7308\n",
      "Time taken: 68.8s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 1.0390\n",
      "Average policy_loss: 0.8925\n",
      "Average value_loss: 0.1464\n",
      "Replay buffer size: 7396\n",
      "Time taken: 22.9s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 1.0408\n",
      "Average policy_loss: 0.8926\n",
      "Average value_loss: 0.1482\n",
      "Replay buffer size: 7484\n",
      "Time taken: 23.2s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 1.0374\n",
      "Average policy_loss: 0.8891\n",
      "Average value_loss: 0.1483\n",
      "Replay buffer size: 7572\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 1.0330\n",
      "Average policy_loss: 0.8867\n",
      "Average value_loss: 0.1463\n",
      "Replay buffer size: 7658\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 1.0404\n",
      "Average policy_loss: 0.8927\n",
      "Average value_loss: 0.1477\n",
      "Replay buffer size: 7746\n",
      "Time taken: 65.2s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 1.0396\n",
      "Average policy_loss: 0.8916\n",
      "Average value_loss: 0.1480\n",
      "Replay buffer size: 7836\n",
      "Time taken: 23.8s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 1.0386\n",
      "Average policy_loss: 0.8899\n",
      "Average value_loss: 0.1486\n",
      "Replay buffer size: 7921\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 1.0395\n",
      "Average policy_loss: 0.8921\n",
      "Average value_loss: 0.1474\n",
      "Replay buffer size: 8010\n",
      "Time taken: 23.8s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 1.0405\n",
      "Average policy_loss: 0.8929\n",
      "Average value_loss: 0.1476\n",
      "Replay buffer size: 8101\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 60.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 1.0431\n",
      "Average policy_loss: 0.8934\n",
      "Average value_loss: 0.1496\n",
      "Replay buffer size: 8195\n",
      "Time taken: 67.0s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 1.0369\n",
      "Average policy_loss: 0.8904\n",
      "Average value_loss: 0.1465\n",
      "Replay buffer size: 8285\n",
      "Time taken: 23.7s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 1.0386\n",
      "Average policy_loss: 0.8919\n",
      "Average value_loss: 0.1467\n",
      "Replay buffer size: 8372\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 1.0422\n",
      "Average policy_loss: 0.8950\n",
      "Average value_loss: 0.1472\n",
      "Replay buffer size: 8468\n",
      "Time taken: 21.5s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 1.0390\n",
      "Average policy_loss: 0.8940\n",
      "Average value_loss: 0.1450\n",
      "Replay buffer size: 8567\n",
      "Time taken: 23.8s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 30.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 1.0421\n",
      "Average policy_loss: 0.8965\n",
      "Average value_loss: 0.1455\n",
      "Replay buffer size: 8658\n",
      "Time taken: 68.7s\n",
      "\n",
      "Training complete! Total time: 0.8h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>iteration_time</td><td>▁▂▇▂▂▆▂▂▂▂▂▇▂▂▂▂▂▂▂▂▇▂▂▂▂▇▂▂█▃▃▃▃▂█▃▂█▃▃</td></tr><tr><td>loss</td><td>█▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▆▇▃▅▇▂▄▂▃▁▂▃▄▄▄▅▅█▄▅▅▅▇▅▇██▇▇▂▇▅▇▅▇▅▅▆▅▆</td></tr><tr><td>policy_loss</td><td>▁▆▅▆██▇▇▇▇▆▆▆▆▆▅▆▆▅▅▅▅▅▅▅▅▅▅▅▆▅▆▅▅▅▅▅▅▅▅</td></tr><tr><td>value_loss</td><td>█▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.25</td></tr><tr><td>buffer_size</td><td>8658</td></tr><tr><td>iteration_time</td><td>68.67727</td></tr><tr><td>loss</td><td>1.04205</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>91</td></tr><tr><td>policy_loss</td><td>0.89651</td></tr><tr><td>total_time_hours</td><td>0.77658</td></tr><tr><td>value_loss</td><td>0.14554</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glad-sweep-49</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/6yd6ohjb' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/6yd6ohjb</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250302_032543-6yd6ohjb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7c3e98y3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcheckpoint_frequency: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgames_per_iteration: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0443884942945996\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_illegal_moves: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_value: -5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_iterations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_simulations: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treplay_buffer_max_size: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps_per_iteration: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_size: tiny\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalue_softness: 0.8855538374778479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.00011723740862830225\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'AlphaZero-TicTacToe' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes/wandb/run-20250302_041225-7c3e98y3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/7c3e98y3' target=\"_blank\">golden-sweep-50</a></strong> to <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/sweeps/z91b8lti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/7c3e98y3' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/7c3e98y3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: transformer\n",
      "Using device: mps\n",
      "\n",
      "Iteration 1/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 1 summary:\n",
      "Average loss: 1.2178\n",
      "Average policy_loss: 1.0263\n",
      "Average value_loss: 0.1915\n",
      "Replay buffer size: 80\n",
      "Time taken: 14.6s\n",
      "\n",
      "Iteration 2/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 2 summary:\n",
      "Average loss: 1.1077\n",
      "Average policy_loss: 0.9700\n",
      "Average value_loss: 0.1377\n",
      "Replay buffer size: 167\n",
      "Time taken: 15.0s\n",
      "\n",
      "Iteration 3/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 3 summary:\n",
      "Average loss: 1.0684\n",
      "Average policy_loss: 0.9676\n",
      "Average value_loss: 0.1008\n",
      "Replay buffer size: 258\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 4/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 4 summary:\n",
      "Average loss: 1.0728\n",
      "Average policy_loss: 0.9732\n",
      "Average value_loss: 0.0996\n",
      "Replay buffer size: 342\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 5/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 45.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 5 summary:\n",
      "Average loss: 1.1033\n",
      "Average policy_loss: 0.9981\n",
      "Average value_loss: 0.1052\n",
      "Replay buffer size: 426\n",
      "Time taken: 66.7s\n",
      "\n",
      "Iteration 6/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 81 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 6 summary:\n",
      "Average loss: 1.1253\n",
      "Average policy_loss: 1.0068\n",
      "Average value_loss: 0.1185\n",
      "Replay buffer size: 507\n",
      "Time taken: 19.1s\n",
      "\n",
      "Iteration 7/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 7 summary:\n",
      "Average loss: 1.1271\n",
      "Average policy_loss: 1.0092\n",
      "Average value_loss: 0.1178\n",
      "Replay buffer size: 587\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 8/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 8 summary:\n",
      "Average loss: 1.1302\n",
      "Average policy_loss: 1.0109\n",
      "Average value_loss: 0.1193\n",
      "Replay buffer size: 663\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 9/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 9 summary:\n",
      "Average loss: 1.1602\n",
      "Average policy_loss: 1.0274\n",
      "Average value_loss: 0.1328\n",
      "Replay buffer size: 750\n",
      "Time taken: 22.4s\n",
      "\n",
      "Iteration 10/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 65.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 10 summary:\n",
      "Average loss: 1.1491\n",
      "Average policy_loss: 1.0178\n",
      "Average value_loss: 0.1313\n",
      "Replay buffer size: 834\n",
      "Time taken: 69.4s\n",
      "\n",
      "Iteration 11/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 11 summary:\n",
      "Average loss: 1.1454\n",
      "Average policy_loss: 1.0208\n",
      "Average value_loss: 0.1246\n",
      "Replay buffer size: 920\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 12/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 12 summary:\n",
      "Average loss: 1.1266\n",
      "Average policy_loss: 1.0065\n",
      "Average value_loss: 0.1201\n",
      "Replay buffer size: 1010\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 13/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 13 summary:\n",
      "Average loss: 1.1306\n",
      "Average policy_loss: 1.0077\n",
      "Average value_loss: 0.1229\n",
      "Replay buffer size: 1096\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 14/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 82 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 14 summary:\n",
      "Average loss: 1.1208\n",
      "Average policy_loss: 1.0036\n",
      "Average value_loss: 0.1172\n",
      "Replay buffer size: 1178\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 15/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 25.00%, Draw rate = 70.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 15 summary:\n",
      "Average loss: 1.1135\n",
      "Average policy_loss: 0.9921\n",
      "Average value_loss: 0.1214\n",
      "Replay buffer size: 1269\n",
      "Time taken: 67.5s\n",
      "\n",
      "Iteration 16/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 16 summary:\n",
      "Average loss: 1.1011\n",
      "Average policy_loss: 0.9846\n",
      "Average value_loss: 0.1165\n",
      "Replay buffer size: 1358\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 17/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 17 summary:\n",
      "Average loss: 1.0895\n",
      "Average policy_loss: 0.9750\n",
      "Average value_loss: 0.1145\n",
      "Replay buffer size: 1447\n",
      "Time taken: 18.0s\n",
      "\n",
      "Iteration 18/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 18 summary:\n",
      "Average loss: 1.0918\n",
      "Average policy_loss: 0.9742\n",
      "Average value_loss: 0.1176\n",
      "Replay buffer size: 1537\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 19/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 19 summary:\n",
      "Average loss: 1.0708\n",
      "Average policy_loss: 0.9601\n",
      "Average value_loss: 0.1106\n",
      "Replay buffer size: 1635\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 20/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 75.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 20 summary:\n",
      "Average loss: 1.0581\n",
      "Average policy_loss: 0.9494\n",
      "Average value_loss: 0.1086\n",
      "Replay buffer size: 1727\n",
      "Time taken: 68.7s\n",
      "\n",
      "Iteration 21/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 21 summary:\n",
      "Average loss: 1.0504\n",
      "Average policy_loss: 0.9406\n",
      "Average value_loss: 0.1098\n",
      "Replay buffer size: 1820\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 22/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 22 summary:\n",
      "Average loss: 1.0460\n",
      "Average policy_loss: 0.9381\n",
      "Average value_loss: 0.1079\n",
      "Replay buffer size: 1911\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 23/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 23 summary:\n",
      "Average loss: 1.0281\n",
      "Average policy_loss: 0.9246\n",
      "Average value_loss: 0.1035\n",
      "Replay buffer size: 2005\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 24/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 24 summary:\n",
      "Average loss: 1.0284\n",
      "Average policy_loss: 0.9230\n",
      "Average value_loss: 0.1054\n",
      "Replay buffer size: 2094\n",
      "Time taken: 20.1s\n",
      "\n",
      "Iteration 25/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 79 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 25 summary:\n",
      "Average loss: 1.0295\n",
      "Average policy_loss: 0.9238\n",
      "Average value_loss: 0.1057\n",
      "Replay buffer size: 2173\n",
      "Time taken: 67.4s\n",
      "\n",
      "Iteration 26/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 26 summary:\n",
      "Average loss: 1.0185\n",
      "Average policy_loss: 0.9170\n",
      "Average value_loss: 0.1015\n",
      "Replay buffer size: 2269\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 27/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 27 summary:\n",
      "Average loss: 1.0239\n",
      "Average policy_loss: 0.9222\n",
      "Average value_loss: 0.1018\n",
      "Replay buffer size: 2359\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 28/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 28 summary:\n",
      "Average loss: 1.0179\n",
      "Average policy_loss: 0.9143\n",
      "Average value_loss: 0.1036\n",
      "Replay buffer size: 2451\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 29/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 29 summary:\n",
      "Average loss: 1.0058\n",
      "Average policy_loss: 0.9038\n",
      "Average value_loss: 0.1020\n",
      "Replay buffer size: 2547\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 30/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 80 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 15.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 30 summary:\n",
      "Average loss: 1.0086\n",
      "Average policy_loss: 0.9040\n",
      "Average value_loss: 0.1047\n",
      "Replay buffer size: 2627\n",
      "Time taken: 66.9s\n",
      "\n",
      "Iteration 31/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 31 summary:\n",
      "Average loss: 0.9959\n",
      "Average policy_loss: 0.8951\n",
      "Average value_loss: 0.1008\n",
      "Replay buffer size: 2717\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 32/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 32 summary:\n",
      "Average loss: 0.9962\n",
      "Average policy_loss: 0.8948\n",
      "Average value_loss: 0.1014\n",
      "Replay buffer size: 2808\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 33/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 33 summary:\n",
      "Average loss: 0.9929\n",
      "Average policy_loss: 0.8905\n",
      "Average value_loss: 0.1024\n",
      "Replay buffer size: 2898\n",
      "Time taken: 18.5s\n",
      "\n",
      "Iteration 34/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 34 summary:\n",
      "Average loss: 0.9843\n",
      "Average policy_loss: 0.8851\n",
      "Average value_loss: 0.0992\n",
      "Replay buffer size: 2994\n",
      "Time taken: 18.7s\n",
      "\n",
      "Iteration 35/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 35 summary:\n",
      "Average loss: 0.9798\n",
      "Average policy_loss: 0.8796\n",
      "Average value_loss: 0.1002\n",
      "Replay buffer size: 3088\n",
      "Time taken: 64.8s\n",
      "\n",
      "Iteration 36/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 36 summary:\n",
      "Average loss: 0.9780\n",
      "Average policy_loss: 0.8778\n",
      "Average value_loss: 0.1002\n",
      "Replay buffer size: 3184\n",
      "Time taken: 17.7s\n",
      "\n",
      "Iteration 37/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 37 summary:\n",
      "Average loss: 0.9715\n",
      "Average policy_loss: 0.8748\n",
      "Average value_loss: 0.0967\n",
      "Replay buffer size: 3281\n",
      "Time taken: 19.3s\n",
      "\n",
      "Iteration 38/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 100 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 38 summary:\n",
      "Average loss: 0.9621\n",
      "Average policy_loss: 0.8668\n",
      "Average value_loss: 0.0952\n",
      "Replay buffer size: 3381\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 39/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 39 summary:\n",
      "Average loss: 0.9638\n",
      "Average policy_loss: 0.8715\n",
      "Average value_loss: 0.0922\n",
      "Replay buffer size: 3471\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 40/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 40 summary:\n",
      "Average loss: 0.9554\n",
      "Average policy_loss: 0.8607\n",
      "Average value_loss: 0.0947\n",
      "Replay buffer size: 3570\n",
      "Time taken: 66.6s\n",
      "\n",
      "Iteration 41/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 41 summary:\n",
      "Average loss: 0.9630\n",
      "Average policy_loss: 0.8688\n",
      "Average value_loss: 0.0942\n",
      "Replay buffer size: 3661\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 42/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 42 summary:\n",
      "Average loss: 0.9619\n",
      "Average policy_loss: 0.8625\n",
      "Average value_loss: 0.0994\n",
      "Replay buffer size: 3755\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 43/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 43 summary:\n",
      "Average loss: 0.9487\n",
      "Average policy_loss: 0.8578\n",
      "Average value_loss: 0.0908\n",
      "Replay buffer size: 3844\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 44/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 44 summary:\n",
      "Average loss: 0.9480\n",
      "Average policy_loss: 0.8540\n",
      "Average value_loss: 0.0940\n",
      "Replay buffer size: 3932\n",
      "Time taken: 18.4s\n",
      "\n",
      "Iteration 45/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 65.00%, Draw rate = 35.00%\n",
      "\n",
      "Iteration 45 summary:\n",
      "Average loss: 0.9407\n",
      "Average policy_loss: 0.8496\n",
      "Average value_loss: 0.0910\n",
      "Replay buffer size: 4027\n",
      "Time taken: 66.3s\n",
      "\n",
      "Iteration 46/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 94 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 46 summary:\n",
      "Average loss: 0.9433\n",
      "Average policy_loss: 0.8538\n",
      "Average value_loss: 0.0895\n",
      "Replay buffer size: 4121\n",
      "Time taken: 18.5s\n",
      "\n",
      "Iteration 47/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 47 summary:\n",
      "Average loss: 0.9318\n",
      "Average policy_loss: 0.8418\n",
      "Average value_loss: 0.0900\n",
      "Replay buffer size: 4219\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 48/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 48 summary:\n",
      "Average loss: 0.9382\n",
      "Average policy_loss: 0.8475\n",
      "Average value_loss: 0.0907\n",
      "Replay buffer size: 4310\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 49/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 49 summary:\n",
      "Average loss: 0.9316\n",
      "Average policy_loss: 0.8442\n",
      "Average value_loss: 0.0874\n",
      "Replay buffer size: 4407\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 50/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 80.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 50 summary:\n",
      "Average loss: 0.9306\n",
      "Average policy_loss: 0.8393\n",
      "Average value_loss: 0.0912\n",
      "Replay buffer size: 4493\n",
      "Time taken: 69.9s\n",
      "\n",
      "Iteration 51/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 51 summary:\n",
      "Average loss: 0.9346\n",
      "Average policy_loss: 0.8464\n",
      "Average value_loss: 0.0881\n",
      "Replay buffer size: 4585\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 52/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 76 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 52 summary:\n",
      "Average loss: 0.9280\n",
      "Average policy_loss: 0.8363\n",
      "Average value_loss: 0.0917\n",
      "Replay buffer size: 4661\n",
      "Time taken: 18.9s\n",
      "\n",
      "Iteration 53/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 53 summary:\n",
      "Average loss: 0.9303\n",
      "Average policy_loss: 0.8393\n",
      "Average value_loss: 0.0911\n",
      "Replay buffer size: 4751\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 54/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 54 summary:\n",
      "Average loss: 0.9330\n",
      "Average policy_loss: 0.8410\n",
      "Average value_loss: 0.0920\n",
      "Replay buffer size: 4836\n",
      "Time taken: 19.6s\n",
      "\n",
      "Iteration 55/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 55 summary:\n",
      "Average loss: 0.9240\n",
      "Average policy_loss: 0.8345\n",
      "Average value_loss: 0.0895\n",
      "Replay buffer size: 4926\n",
      "Time taken: 70.8s\n",
      "\n",
      "Iteration 56/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 56 summary:\n",
      "Average loss: 0.9241\n",
      "Average policy_loss: 0.8351\n",
      "Average value_loss: 0.0890\n",
      "Replay buffer size: 5025\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 57/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 78 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 57 summary:\n",
      "Average loss: 0.9280\n",
      "Average policy_loss: 0.8357\n",
      "Average value_loss: 0.0923\n",
      "Replay buffer size: 5103\n",
      "Time taken: 21.4s\n",
      "\n",
      "Iteration 58/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 58 summary:\n",
      "Average loss: 0.9227\n",
      "Average policy_loss: 0.8336\n",
      "Average value_loss: 0.0891\n",
      "Replay buffer size: 5199\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 59/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 59 summary:\n",
      "Average loss: 0.9224\n",
      "Average policy_loss: 0.8299\n",
      "Average value_loss: 0.0925\n",
      "Replay buffer size: 5283\n",
      "Time taken: 21.6s\n",
      "\n",
      "Iteration 60/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 95.00%, Draw rate = 5.00%\n",
      "\n",
      "Iteration 60 summary:\n",
      "Average loss: 0.9216\n",
      "Average policy_loss: 0.8321\n",
      "Average value_loss: 0.0894\n",
      "Replay buffer size: 5373\n",
      "Time taken: 69.4s\n",
      "\n",
      "Iteration 61/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 86 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 61 summary:\n",
      "Average loss: 0.9240\n",
      "Average policy_loss: 0.8331\n",
      "Average value_loss: 0.0909\n",
      "Replay buffer size: 5459\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 62/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 62 summary:\n",
      "Average loss: 0.9244\n",
      "Average policy_loss: 0.8331\n",
      "Average value_loss: 0.0912\n",
      "Replay buffer size: 5555\n",
      "Time taken: 21.8s\n",
      "\n",
      "Iteration 63/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 63 summary:\n",
      "Average loss: 0.9260\n",
      "Average policy_loss: 0.8350\n",
      "Average value_loss: 0.0910\n",
      "Replay buffer size: 5645\n",
      "Time taken: 23.6s\n",
      "\n",
      "Iteration 64/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 64 summary:\n",
      "Average loss: 0.9212\n",
      "Average policy_loss: 0.8298\n",
      "Average value_loss: 0.0914\n",
      "Replay buffer size: 5738\n",
      "Time taken: 22.2s\n",
      "\n",
      "Iteration 65/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 65 summary:\n",
      "Average loss: 0.9190\n",
      "Average policy_loss: 0.8262\n",
      "Average value_loss: 0.0928\n",
      "Replay buffer size: 5830\n",
      "Time taken: 71.1s\n",
      "\n",
      "Iteration 66/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 66 summary:\n",
      "Average loss: 0.9216\n",
      "Average policy_loss: 0.8297\n",
      "Average value_loss: 0.0919\n",
      "Replay buffer size: 5927\n",
      "Time taken: 22.1s\n",
      "\n",
      "Iteration 67/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 67 summary:\n",
      "Average loss: 0.9206\n",
      "Average policy_loss: 0.8300\n",
      "Average value_loss: 0.0906\n",
      "Replay buffer size: 6011\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 68/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 84 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 68 summary:\n",
      "Average loss: 0.9197\n",
      "Average policy_loss: 0.8283\n",
      "Average value_loss: 0.0913\n",
      "Replay buffer size: 6095\n",
      "Time taken: 21.0s\n",
      "\n",
      "Iteration 69/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 91 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 69 summary:\n",
      "Average loss: 0.9155\n",
      "Average policy_loss: 0.8274\n",
      "Average value_loss: 0.0881\n",
      "Replay buffer size: 6186\n",
      "Time taken: 19.9s\n",
      "\n",
      "Iteration 70/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 70.00%, Draw rate = 30.00%\n",
      "\n",
      "Iteration 70 summary:\n",
      "Average loss: 0.9190\n",
      "Average policy_loss: 0.8286\n",
      "Average value_loss: 0.0904\n",
      "Replay buffer size: 6278\n",
      "Time taken: 72.0s\n",
      "\n",
      "Iteration 71/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 71 summary:\n",
      "Average loss: 0.9172\n",
      "Average policy_loss: 0.8252\n",
      "Average value_loss: 0.0920\n",
      "Replay buffer size: 6363\n",
      "Time taken: 21.2s\n",
      "\n",
      "Iteration 72/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 72 summary:\n",
      "Average loss: 0.9153\n",
      "Average policy_loss: 0.8225\n",
      "Average value_loss: 0.0929\n",
      "Replay buffer size: 6460\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 73/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 73 summary:\n",
      "Average loss: 0.9108\n",
      "Average policy_loss: 0.8193\n",
      "Average value_loss: 0.0914\n",
      "Replay buffer size: 6552\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 74/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 74 summary:\n",
      "Average loss: 0.9129\n",
      "Average policy_loss: 0.8213\n",
      "Average value_loss: 0.0915\n",
      "Replay buffer size: 6650\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 75/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 85.00%, Draw rate = 15.00%\n",
      "\n",
      "Iteration 75 summary:\n",
      "Average loss: 0.9052\n",
      "Average policy_loss: 0.8189\n",
      "Average value_loss: 0.0863\n",
      "Replay buffer size: 6749\n",
      "Time taken: 68.4s\n",
      "\n",
      "Iteration 76/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 76 summary:\n",
      "Average loss: 0.9018\n",
      "Average policy_loss: 0.8134\n",
      "Average value_loss: 0.0885\n",
      "Replay buffer size: 6839\n",
      "Time taken: 20.6s\n",
      "\n",
      "Iteration 77/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 77 summary:\n",
      "Average loss: 0.9038\n",
      "Average policy_loss: 0.8163\n",
      "Average value_loss: 0.0875\n",
      "Replay buffer size: 6931\n",
      "Time taken: 20.8s\n",
      "\n",
      "Iteration 78/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 93 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 78 summary:\n",
      "Average loss: 0.9021\n",
      "Average policy_loss: 0.8141\n",
      "Average value_loss: 0.0880\n",
      "Replay buffer size: 7024\n",
      "Time taken: 22.0s\n",
      "\n",
      "Iteration 79/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 79 summary:\n",
      "Average loss: 0.9115\n",
      "Average policy_loss: 0.8181\n",
      "Average value_loss: 0.0934\n",
      "Replay buffer size: 7113\n",
      "Time taken: 20.4s\n",
      "\n",
      "Iteration 80/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 5.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 80 summary:\n",
      "Average loss: 0.9178\n",
      "Average policy_loss: 0.8242\n",
      "Average value_loss: 0.0937\n",
      "Replay buffer size: 7202\n",
      "Time taken: 69.0s\n",
      "\n",
      "Iteration 81/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 81 summary:\n",
      "Average loss: 0.9141\n",
      "Average policy_loss: 0.8258\n",
      "Average value_loss: 0.0883\n",
      "Replay buffer size: 7294\n",
      "Time taken: 20.2s\n",
      "\n",
      "Iteration 82/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 82 summary:\n",
      "Average loss: 0.9033\n",
      "Average policy_loss: 0.8154\n",
      "Average value_loss: 0.0879\n",
      "Replay buffer size: 7383\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 83/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 83 summary:\n",
      "Average loss: 0.9035\n",
      "Average policy_loss: 0.8169\n",
      "Average value_loss: 0.0867\n",
      "Replay buffer size: 7479\n",
      "Time taken: 21.9s\n",
      "\n",
      "Iteration 84/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 84 summary:\n",
      "Average loss: 0.9042\n",
      "Average policy_loss: 0.8169\n",
      "Average value_loss: 0.0874\n",
      "Replay buffer size: 7577\n",
      "Time taken: 20.7s\n",
      "\n",
      "Iteration 85/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 100.00%\n",
      "RandomAgent: Win rate = 90.00%, Draw rate = 10.00%\n",
      "\n",
      "Iteration 85 summary:\n",
      "Average loss: 0.9011\n",
      "Average policy_loss: 0.8145\n",
      "Average value_loss: 0.0866\n",
      "Replay buffer size: 7667\n",
      "Time taken: 68.0s\n",
      "\n",
      "Iteration 86/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 99 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 86 summary:\n",
      "Average loss: 0.9029\n",
      "Average policy_loss: 0.8176\n",
      "Average value_loss: 0.0853\n",
      "Replay buffer size: 7766\n",
      "Time taken: 21.3s\n",
      "\n",
      "Iteration 87/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 87 summary:\n",
      "Average loss: 0.8988\n",
      "Average policy_loss: 0.8117\n",
      "Average value_loss: 0.0871\n",
      "Replay buffer size: 7853\n",
      "Time taken: 18.8s\n",
      "\n",
      "Iteration 88/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 88 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 88 summary:\n",
      "Average loss: 0.8964\n",
      "Average policy_loss: 0.8096\n",
      "Average value_loss: 0.0868\n",
      "Replay buffer size: 7941\n",
      "Time taken: 19.4s\n",
      "\n",
      "Iteration 89/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 95 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 89 summary:\n",
      "Average loss: 0.8945\n",
      "Average policy_loss: 0.8084\n",
      "Average value_loss: 0.0862\n",
      "Replay buffer size: 8036\n",
      "Time taken: 19.7s\n",
      "\n",
      "Iteration 90/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 98 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 10.00%, Draw rate = 85.00%\n",
      "RandomAgent: Win rate = 80.00%, Draw rate = 20.00%\n",
      "\n",
      "Iteration 90 summary:\n",
      "Average loss: 0.8958\n",
      "Average policy_loss: 0.8091\n",
      "Average value_loss: 0.0866\n",
      "Replay buffer size: 8134\n",
      "Time taken: 68.1s\n",
      "\n",
      "Iteration 91/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 91 summary:\n",
      "Average loss: 0.8956\n",
      "Average policy_loss: 0.8104\n",
      "Average value_loss: 0.0853\n",
      "Replay buffer size: 8230\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 92/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 89 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 92 summary:\n",
      "Average loss: 0.8990\n",
      "Average policy_loss: 0.8115\n",
      "Average value_loss: 0.0875\n",
      "Replay buffer size: 8319\n",
      "Time taken: 22.7s\n",
      "\n",
      "Iteration 93/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 93 summary:\n",
      "Average loss: 0.8994\n",
      "Average policy_loss: 0.8109\n",
      "Average value_loss: 0.0885\n",
      "Replay buffer size: 8415\n",
      "Time taken: 20.3s\n",
      "\n",
      "Iteration 94/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 97 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 94 summary:\n",
      "Average loss: 0.8992\n",
      "Average policy_loss: 0.8099\n",
      "Average value_loss: 0.0893\n",
      "Replay buffer size: 8512\n",
      "Time taken: 21.7s\n",
      "\n",
      "Iteration 95/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 87 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 90.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 95 summary:\n",
      "Average loss: 0.8920\n",
      "Average policy_loss: 0.8056\n",
      "Average value_loss: 0.0864\n",
      "Replay buffer size: 8599\n",
      "Time taken: 69.8s\n",
      "\n",
      "Iteration 96/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 96 summary:\n",
      "Average loss: 0.8921\n",
      "Average policy_loss: 0.8039\n",
      "Average value_loss: 0.0882\n",
      "Replay buffer size: 8689\n",
      "Time taken: 20.0s\n",
      "\n",
      "Iteration 97/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 85 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 97 summary:\n",
      "Average loss: 0.8876\n",
      "Average policy_loss: 0.8008\n",
      "Average value_loss: 0.0868\n",
      "Replay buffer size: 8774\n",
      "Time taken: 21.1s\n",
      "\n",
      "Iteration 98/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 92 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 98 summary:\n",
      "Average loss: 0.8926\n",
      "Average policy_loss: 0.8073\n",
      "Average value_loss: 0.0852\n",
      "Replay buffer size: 8866\n",
      "Time taken: 19.5s\n",
      "\n",
      "Iteration 99/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 90 new positions\n",
      "Training phase...\n",
      "\n",
      "Iteration 99 summary:\n",
      "Average loss: 0.8912\n",
      "Average policy_loss: 0.8027\n",
      "Average value_loss: 0.0885\n",
      "Replay buffer size: 8956\n",
      "Time taken: 20.9s\n",
      "\n",
      "Iteration 100/100\n",
      "Self-play phase...\n",
      "Playing game 10/10\n",
      "Generated 96 new positions\n",
      "Training phase...\n",
      "\n",
      "Evaluating against opponents...\n",
      "\n",
      "Evaluation results:\n",
      "MCTS: Win rate = 0.00%, Draw rate = 95.00%\n",
      "RandomAgent: Win rate = 75.00%, Draw rate = 25.00%\n",
      "\n",
      "Iteration 100 summary:\n",
      "Average loss: 0.8851\n",
      "Average policy_loss: 0.7992\n",
      "Average value_loss: 0.0859\n",
      "Replay buffer size: 9052\n",
      "Time taken: 72.1s\n",
      "\n",
      "Training complete! Total time: 0.8h\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer_size</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>iteration_time</td><td>▁▂▂▇▂▂▇▂▂▇▁▁▂▁▇▂▂▁▂▂▂▂▂▂█▂█▂▂█▂▂▂▂▂▂█▂▂█</td></tr><tr><td>loss</td><td>▇▆▆████▇▇▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▁▁▁▁▁</td></tr><tr><td>num_games</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_positions</td><td>▂▅▃▂▂▄▅▅▅▆▆▅▁▅▅▆▇██▅▃▅█▁▃▆▃▇▅▇▅▅▇▇█▄▇▇▇▃</td></tr><tr><td>policy_loss</td><td>████▇▇▇▆▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>value_loss</td><td>█▃▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▃▂▂▁▁▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_win_rate</td><td>1.15</td></tr><tr><td>buffer_size</td><td>9052</td></tr><tr><td>iteration_time</td><td>72.10831</td></tr><tr><td>loss</td><td>0.88509</td></tr><tr><td>num_games</td><td>10</td></tr><tr><td>num_positions</td><td>96</td></tr><tr><td>policy_loss</td><td>0.79922</td></tr><tr><td>total_time_hours</td><td>0.83259</td></tr><tr><td>value_loss</td><td>0.08587</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">golden-sweep-50</strong> at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/7c3e98y3' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe/runs/7c3e98y3</a><br> View project at: <a href='https://wandb.ai/eigenway/AlphaZero-TicTacToe' target=\"_blank\">https://wandb.ai/eigenway/AlphaZero-TicTacToe</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250302_041225-7c3e98y3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(\n",
    "    sweep=sweep_config,\n",
    "    project='AlphaZero-TicTacToe',\n",
    "    entity='eigenway',\n",
    ")\n",
    "\n",
    "\n",
    "wandb.agent(\n",
    "    sweep_id,\n",
    "    function=sweep_agent,\n",
    "    count=50\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dots-and-boxes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
