{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/eohjelle/Documents/2025-dots-and-boxes/dots-and-boxes\n"
     ]
    }
   ],
   "source": [
    "# Change directory to the root of the project\n",
    "import os \n",
    "os.chdir('..')\n",
    "os.chdir('..')\n",
    "os.chdir('..')\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will create an exhaustive training data set for tic tac toe using the Minimax agent, in the form of a replay buffer compatible with AlphaZeroTrainer. The idea is to use this dataset to run some sweeps, and to understand which deep learning models will perform best in theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from applications.tic_tac_toe.game_state import TicTacToeState\n",
    "from core.implementations.Minimax import Minimax\n",
    "\n",
    "# Creat minmax agent and expand the game tree\n",
    "state = TicTacToeState()\n",
    "agent = Minimax(state)\n",
    "agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 549946\n",
      "Number of states: 5478\n"
     ]
    }
   ],
   "source": [
    "# This is for testing the state_dict design\n",
    "\n",
    "def count_nodes(root):\n",
    "    if root.is_leaf():\n",
    "        return 1\n",
    "    else:\n",
    "        return 1 + sum(count_nodes(child) for child in root.children.values())\n",
    "\n",
    "print(f\"Number of nodes: {count_nodes(agent.root)}\")\n",
    "\n",
    "def count_states(agent):\n",
    "    return len(agent.state_dict)\n",
    "\n",
    "print(f\"Number of states: {count_states(agent)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of unique examples, translated into AlphaZero format for compatibility with models\n",
    "\n",
    "from core.implementations.AlphaZero import AlphaZeroTarget\n",
    "from core.data_structures import TrainingExample\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "def get_subexamples(root) -> Dict[TicTacToeState, TrainingExample[Tuple[int, int], AlphaZeroTarget]]:\n",
    "    policy = {action: 0.0 for action in root.children.keys()}\n",
    "    for action in root.value.best_actions:\n",
    "        policy[action] = 1/len(root.value.best_actions)\n",
    "    state_to_examples = {}\n",
    "    state_to_examples[root.state] = TrainingExample(\n",
    "        state=root.state,\n",
    "        target=(policy, root.value.value),\n",
    "        data={'legal_actions': list(root.children.keys())}\n",
    "    )\n",
    "    for child in root.children.values():\n",
    "        state_to_examples.update(get_subexamples(child))\n",
    "    return state_to_examples\n",
    "\n",
    "examples = list(get_subexamples(agent.root).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "State: \n",
      "X |  | O\n",
      "---------\n",
      " | O | X\n",
      "---------\n",
      "X | O | \n",
      "Target: ({(0, 1): 0.0, (1, 0): 1.0, (2, 2): 0.0}, 1.0)\n",
      "Data: {'legal_actions': [(0, 1), (1, 0), (2, 2)]}\n",
      "\n",
      "\n",
      "Example 2:\n",
      "State: \n",
      "X |  | O\n",
      "---------\n",
      " | O | X\n",
      "---------\n",
      "X | O | X\n",
      "Target: ({(0, 1): 1.0, (1, 0): 0.0}, 1.0)\n",
      "Data: {'legal_actions': [(0, 1), (1, 0)]}\n",
      "\n",
      "\n",
      "Example 3:\n",
      "State: \n",
      "X |  | O\n",
      "---------\n",
      " | O | X\n",
      "---------\n",
      "X |  | O\n",
      "Target: ({(0, 1): 0.0, (1, 0): 1.0, (2, 1): 0.0}, 1.0)\n",
      "Data: {'legal_actions': [(0, 1), (1, 0), (2, 1)]}\n",
      "\n",
      "\n",
      "Number of unique examples: 5478\n"
     ]
    }
   ],
   "source": [
    "k = 1053\n",
    "for i, example in enumerate(examples[k:k+3]):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"State: \\n{example.state}\")\n",
    "    print(f\"Target: {example.target}\")\n",
    "    print(f\"Data: {example.data}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(f\"Number of unique examples: {len(examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.data_structures import ReplayBuffer\n",
    "from applications.tic_tac_toe.tensor_mapping import MLPTensorMapping, TokenizedTensorMapping\n",
    "import torch\n",
    "\n",
    "device = torch.device('mps') # Change to 'cuda' or 'cpu' if needed\n",
    "\n",
    "for model_name, tensor_mapping in [\n",
    "    ('mlp', MLPTensorMapping),\n",
    "    ('transformer', TokenizedTensorMapping)\n",
    "]:\n",
    "    state_encoder = lambda state: tensor_mapping.encode_state(state, device)\n",
    "    example_encoder = lambda example: tensor_mapping.encode_example(example, device)\n",
    "    buffer = ReplayBuffer(max_size=len(examples))\n",
    "    buffer.extend(examples, state_encoder, example_encoder)\n",
    "    # buffer.save(f'applications/tic_tac_toe/training_data/{model_name}.pkl')\n",
    "    # buffer.save_to_wandb(\n",
    "    #     artifact_name=f'tic_tac_toe_{tensor_mapping.__name__}_training_data',\n",
    "    #     project='AlphaZero-TicTacToe',\n",
    "    #     description=f'Training data for tic tac toe using {model_name} model created by Minimax agent'\n",
    "    # )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dots-and-boxes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
